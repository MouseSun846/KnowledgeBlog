import comp from "D:/Code/knowledgeblob/project/src/.vuepress/.temp/pages/技术科普/论文/nnScaler.html.vue"
const data = JSON.parse("{\"path\":\"/%E6%8A%80%E6%9C%AF%E7%A7%91%E6%99%AE/%E8%AE%BA%E6%96%87/nnScaler.html\",\"title\":\"nnScaler：重塑深度学习并行策略，大幅提升训练效率\",\"lang\":\"zh-CN\",\"frontmatter\":{\"date\":\"2024-09-11T00:00:00.000Z\",\"title\":\"nnScaler：重塑深度学习并行策略，大幅提升训练效率\",\"category\":[\"nnScaler\"],\"tag\":[\"nnScaler\",\"GPU\"],\"description\":\"MPress: Democratizing Billion-Scale Model Training on Multi-GPU Servers via Memory-Saving Inter-Operator Parallelism 地址：https://www.usenix.org/system/files/osdi24-lin-zhiqi.pdf ...\",\"head\":[[\"meta\",{\"property\":\"og:url\",\"content\":\"https://mousesun846.github.io/KnowledgeBlog/KnowledgeBlog/%E6%8A%80%E6%9C%AF%E7%A7%91%E6%99%AE/%E8%AE%BA%E6%96%87/nnScaler.html\"}],[\"meta\",{\"property\":\"og:site_name\",\"content\":\"知识笔记\"}],[\"meta\",{\"property\":\"og:title\",\"content\":\"nnScaler：重塑深度学习并行策略，大幅提升训练效率\"}],[\"meta\",{\"property\":\"og:description\",\"content\":\"MPress: Democratizing Billion-Scale Model Training on Multi-GPU Servers via Memory-Saving Inter-Operator Parallelism 地址：https://www.usenix.org/system/files/osdi24-lin-zhiqi.pdf ...\"}],[\"meta\",{\"property\":\"og:type\",\"content\":\"article\"}],[\"meta\",{\"property\":\"og:locale\",\"content\":\"zh-CN\"}],[\"meta\",{\"property\":\"og:updated_time\",\"content\":\"2024-09-11T02:55:15.000Z\"}],[\"meta\",{\"property\":\"article:author\",\"content\":\"MouseSun\"}],[\"meta\",{\"property\":\"article:tag\",\"content\":\"nnScaler\"}],[\"meta\",{\"property\":\"article:tag\",\"content\":\"GPU\"}],[\"meta\",{\"property\":\"article:published_time\",\"content\":\"2024-09-11T00:00:00.000Z\"}],[\"meta\",{\"property\":\"article:modified_time\",\"content\":\"2024-09-11T02:55:15.000Z\"}],[\"script\",{\"type\":\"application/ld+json\"},\"{\\\"@context\\\":\\\"https://schema.org\\\",\\\"@type\\\":\\\"Article\\\",\\\"headline\\\":\\\"nnScaler：重塑深度学习并行策略，大幅提升训练效率\\\",\\\"image\\\":[\\\"\\\"],\\\"datePublished\\\":\\\"2024-09-11T00:00:00.000Z\\\",\\\"dateModified\\\":\\\"2024-09-11T02:55:15.000Z\\\",\\\"author\\\":[{\\\"@type\\\":\\\"Person\\\",\\\"name\\\":\\\"MouseSun\\\",\\\"url\\\":\\\"https://github.com/MouseSun846\\\",\\\"email\\\":\\\"\\\"}]}\"]]},\"headers\":[{\"level\":3,\"title\":\"摘要\",\"slug\":\"摘要\",\"link\":\"#摘要\",\"children\":[]},{\"level\":3,\"title\":\"1 引言\",\"slug\":\"_1-引言\",\"link\":\"#_1-引言\",\"children\":[]},{\"level\":3,\"title\":\"2、背景与动机\",\"slug\":\"_2、背景与动机\",\"link\":\"#_2、背景与动机\",\"children\":[]},{\"level\":3,\"title\":\"现有搜索空间的局限性\",\"slug\":\"现有搜索空间的局限性\",\"link\":\"#现有搜索空间的局限性\",\"children\":[]},{\"level\":3,\"title\":\"由于灵活性带来的新挑战\",\"slug\":\"由于灵活性带来的新挑战\",\"link\":\"#由于灵活性带来的新挑战\",\"children\":[]},{\"level\":3,\"title\":\"3. 并行化搜索空间构建\",\"slug\":\"_3-并行化搜索空间构建\",\"link\":\"#_3-并行化搜索空间构建\",\"children\":[]}],\"git\":{\"createdTime\":1726023315000,\"updatedTime\":1726023315000,\"contributors\":[{\"name\":\"mousesun\",\"email\":\"3026098675@qq.com\",\"commits\":1}]},\"readingTime\":{\"minutes\":11.45,\"words\":3436},\"filePathRelative\":\"技术科普/论文/nnScaler.md\",\"localizedDate\":\"2024年9月11日\",\"excerpt\":\"<div class=\\\"hint-container tip\\\">\\n<p class=\\\"hint-container-title\\\">MPress: Democratizing Billion-Scale Model Training on Multi-GPU Servers via Memory-Saving Inter-Operator Parallelism</p>\\n<p>地址：<a href=\\\"https://www.usenix.org/system/files/osdi24-lin-zhiqi.pdf\\\" target=\\\"_blank\\\" rel=\\\"noopener noreferrer\\\">https://www.usenix.org/system/files/osdi24-lin-zhiqi.pdf</a>\\n中文解读：<a href=\\\"https://mp.weixin.qq.com/s/GV_CF9fPpxsPBNbEsvhS5g\\\" target=\\\"_blank\\\" rel=\\\"noopener noreferrer\\\">https://mp.weixin.qq.com/s/GV_CF9fPpxsPBNbEsvhS5g</a></p>\\n</div>\",\"autoDesc\":true}")
export { comp, data }
