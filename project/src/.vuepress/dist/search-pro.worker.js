const V=Object.entries,et=Object.fromEntries,st="ENTRIES",L="KEYS",T="VALUES",_="";class D{set;_type;_path;constructor(t,s){const n=t._tree,o=Array.from(n.keys());this.set=t,this._type=s,this._path=o.length>0?[{node:n,keys:o}]:[]}next(){const t=this.dive();return this.backtrack(),t}dive(){if(this._path.length===0)return{done:!0,value:void 0};const{node:t,keys:s}=E(this._path);if(E(s)===_)return{done:!1,value:this.result()};const n=t.get(E(s));return this._path.push({node:n,keys:Array.from(n.keys())}),this.dive()}backtrack(){if(this._path.length===0)return;const t=E(this._path).keys;t.pop(),!(t.length>0)&&(this._path.pop(),this.backtrack())}key(){return this.set._prefix+this._path.map(({keys:t})=>E(t)).filter(t=>t!==_).join("")}value(){return E(this._path).node.get(_)}result(){switch(this._type){case T:return this.value();case L:return this.key();default:return[this.key(),this.value()]}}[Symbol.iterator](){return this}}const E=e=>e[e.length-1],nt=(e,t,s)=>{const n=new Map;if(t===void 0)return n;const o=t.length+1,u=o+s,i=new Uint8Array(u*o).fill(s+1);for(let r=0;r<o;++r)i[r]=r;for(let r=1;r<u;++r)i[r*o]=r;return R(e,t,s,n,i,1,o,""),n},R=(e,t,s,n,o,u,i,r)=>{const d=u*i;t:for(const c of e.keys())if(c===_){const a=o[d-1];a<=s&&n.set(r,[e.get(c),a])}else{let a=u;for(let h=0;h<c.length;++h,++a){const g=c[h],m=i*a,p=m-i;let l=o[m];const f=Math.max(0,a-s-1),y=Math.min(i-1,a+s);for(let F=f;F<y;++F){const v=g!==t[F],z=o[p+F]+ +v,A=o[p+F+1]+1,w=o[m+F]+1,j=o[m+F+1]=Math.min(z,A,w);j<l&&(l=j)}if(l>s)continue t}R(e.get(c),t,s,n,o,a,i,r+c)}};class C{_tree;_prefix;_size=void 0;constructor(t=new Map,s=""){this._tree=t,this._prefix=s}atPrefix(t){if(!t.startsWith(this._prefix))throw new Error("Mismatched prefix");const[s,n]=x(this._tree,t.slice(this._prefix.length));if(s===void 0){const[o,u]=O(n);for(const i of o.keys())if(i!==_&&i.startsWith(u)){const r=new Map;return r.set(i.slice(u.length),o.get(i)),new C(r,t)}}return new C(s,t)}clear(){this._size=void 0,this._tree.clear()}delete(t){return this._size=void 0,ot(this._tree,t)}entries(){return new D(this,st)}forEach(t){for(const[s,n]of this)t(s,n,this)}fuzzyGet(t,s){return nt(this._tree,t,s)}get(t){const s=k(this._tree,t);return s!==void 0?s.get(_):void 0}has(t){const s=k(this._tree,t);return s!==void 0&&s.has(_)}keys(){return new D(this,L)}set(t,s){if(typeof t!="string")throw new Error("key must be a string");return this._size=void 0,I(this._tree,t).set(_,s),this}get size(){if(this._size)return this._size;this._size=0;const t=this.entries();for(;!t.next().done;)this._size+=1;return this._size}update(t,s){if(typeof t!="string")throw new Error("key must be a string");this._size=void 0;const n=I(this._tree,t);return n.set(_,s(n.get(_))),this}fetch(t,s){if(typeof t!="string")throw new Error("key must be a string");this._size=void 0;const n=I(this._tree,t);let o=n.get(_);return o===void 0&&n.set(_,o=s()),o}values(){return new D(this,T)}[Symbol.iterator](){return this.entries()}static from(t){const s=new C;for(const[n,o]of t)s.set(n,o);return s}static fromObject(t){return C.from(Object.entries(t))}}const x=(e,t,s=[])=>{if(t.length===0||e==null)return[e,s];for(const n of e.keys())if(n!==_&&t.startsWith(n))return s.push([e,n]),x(e.get(n),t.slice(n.length),s);return s.push([e,t]),x(void 0,"",s)},k=(e,t)=>{if(t.length===0||e==null)return e;for(const s of e.keys())if(s!==_&&t.startsWith(s))return k(e.get(s),t.slice(s.length))},I=(e,t)=>{const s=t.length;t:for(let n=0;e&&n<s;){for(const u of e.keys())if(u!==_&&t[n]===u[0]){const i=Math.min(s-n,u.length);let r=1;for(;r<i&&t[n+r]===u[r];)++r;const d=e.get(u);if(r===u.length)e=d;else{const c=new Map;c.set(u.slice(r),d),e.set(t.slice(n,n+r),c),e.delete(u),e=c}n+=r;continue t}const o=new Map;return e.set(t.slice(n),o),o}return e},ot=(e,t)=>{const[s,n]=x(e,t);if(s!==void 0){if(s.delete(_),s.size===0)W(n);else if(s.size===1){const[o,u]=s.entries().next().value;q(n,o,u)}}},W=e=>{if(e.length===0)return;const[t,s]=O(e);if(t.delete(s),t.size===0)W(e.slice(0,-1));else if(t.size===1){const[n,o]=t.entries().next().value;n!==_&&q(e.slice(0,-1),n,o)}},q=(e,t,s)=>{if(e.length===0)return;const[n,o]=O(e);n.set(o+t,s),n.delete(o)},O=e=>e[e.length-1],ut=(e,t)=>{const s=e._idToShortId.get(t);if(s!=null)return e._storedFields.get(s)},it=/[\n\r -#%-*,-/:;?@[-\]_{}\u00A0\u00A1\u00A7\u00AB\u00B6\u00B7\u00BB\u00BF\u037E\u0387\u055A-\u055F\u0589\u058A\u05BE\u05C0\u05C3\u05C6\u05F3\u05F4\u0609\u060A\u060C\u060D\u061B\u061E\u061F\u066A-\u066D\u06D4\u0700-\u070D\u07F7-\u07F9\u0830-\u083E\u085E\u0964\u0965\u0970\u09FD\u0A76\u0AF0\u0C77\u0C84\u0DF4\u0E4F\u0E5A\u0E5B\u0F04-\u0F12\u0F14\u0F3A-\u0F3D\u0F85\u0FD0-\u0FD4\u0FD9\u0FDA\u104A-\u104F\u10FB\u1360-\u1368\u1400\u166E\u1680\u169B\u169C\u16EB-\u16ED\u1735\u1736\u17D4-\u17D6\u17D8-\u17DA\u1800-\u180A\u1944\u1945\u1A1E\u1A1F\u1AA0-\u1AA6\u1AA8-\u1AAD\u1B5A-\u1B60\u1BFC-\u1BFF\u1C3B-\u1C3F\u1C7E\u1C7F\u1CC0-\u1CC7\u1CD3\u2000-\u200A\u2010-\u2029\u202F-\u2043\u2045-\u2051\u2053-\u205F\u207D\u207E\u208D\u208E\u2308-\u230B\u2329\u232A\u2768-\u2775\u27C5\u27C6\u27E6-\u27EF\u2983-\u2998\u29D8-\u29DB\u29FC\u29FD\u2CF9-\u2CFC\u2CFE\u2CFF\u2D70\u2E00-\u2E2E\u2E30-\u2E4F\u3000-\u3003\u3008-\u3011\u3014-\u301F\u3030\u303D\u30A0\u30FB\uA4FE\uA4FF\uA60D-\uA60F\uA673\uA67E\uA6F2-\uA6F7\uA874-\uA877\uA8CE\uA8CF\uA8F8-\uA8FA\uA8FC\uA92E\uA92F\uA95F\uA9C1-\uA9CD\uA9DE\uA9DF\uAA5C-\uAA5F\uAADE\uAADF\uAAF0\uAAF1\uABEB\uFD3E\uFD3F\uFE10-\uFE19\uFE30-\uFE52\uFE54-\uFE61\uFE63\uFE68\uFE6A\uFE6B\uFF01-\uFF03\uFF05-\uFF0A\uFF0C-\uFF0F\uFF1A\uFF1B\uFF1F\uFF20\uFF3B-\uFF3D\uFF3F\uFF5B\uFF5D\uFF5F-\uFF65]+/u,M="or",$="and",rt="and_not",ct=(e,t)=>{e.includes(t)||e.push(t)},N=(e,t)=>{for(const s of t)e.includes(s)||e.push(s)},P=({score:e},{score:t})=>t-e,lt=()=>new Map,b=e=>{const t=new Map;for(const s of Object.keys(e))t.set(parseInt(s,10),e[s]);return t},G=(e,t)=>Object.prototype.hasOwnProperty.call(e,t)?e[t]:void 0,ht={[M]:(e,t)=>{for(const s of t.keys()){const n=e.get(s);if(n==null)e.set(s,t.get(s));else{const{score:o,terms:u,match:i}=t.get(s);n.score=n.score+o,n.match=Object.assign(n.match,i),N(n.terms,u)}}return e},[$]:(e,t)=>{const s=new Map;for(const n of t.keys()){const o=e.get(n);if(o==null)continue;const{score:u,terms:i,match:r}=t.get(n);N(o.terms,i),s.set(n,{score:o.score+u,terms:o.terms,match:Object.assign(o.match,r)})}return s},[rt]:(e,t)=>{for(const s of t.keys())e.delete(s);return e}},dt=(e,t,s,n,o,u)=>{const{k:i,b:r,d}=u;return Math.log(1+(s-t+.5)/(t+.5))*(d+e*(i+1)/(e+i*(1-r+r*n/o)))},at=e=>(t,s,n)=>{const o=typeof e.fuzzy=="function"?e.fuzzy(t,s,n):e.fuzzy||!1,u=typeof e.prefix=="function"?e.prefix(t,s,n):e.prefix===!0;return{term:t,fuzzy:o,prefix:u}},H=(e,t,s,n)=>{for(const o of Object.keys(e._fieldIds))if(e._fieldIds[o]===s){e._options.logger("warn",`SlimSearch: document with ID ${e._documentIds.get(t)} has changed before removal: term "${n}" was not present in field "${o}". Removing a document after it has changed can corrupt the index!`,"version_conflict");return}},ft=(e,t,s,n)=>{if(!e._index.has(n)){H(e,s,t,n);return}const o=e._index.fetch(n,lt),u=o.get(t);u==null||u.get(s)==null?H(e,s,t,n):u.get(s)<=1?u.size<=1?o.delete(t):u.delete(s):u.set(s,u.get(s)-1),e._index.get(n).size===0&&e._index.delete(n)},gt={k:1.2,b:.7,d:.5},mt={idField:"id",extractField:(e,t)=>e[t],tokenize:e=>e.split(it),processTerm:e=>e.toLowerCase(),fields:void 0,searchOptions:void 0,storeFields:[],logger:(e,t)=>{typeof console?.[e]=="function"&&console[e](t)},autoVacuum:!0},J={combineWith:M,prefix:!1,fuzzy:!1,maxFuzzy:6,boost:{},weights:{fuzzy:.45,prefix:.375},bm25:gt},pt={combineWith:$,prefix:(e,t,s)=>t===s.length-1},Ft={batchSize:1e3,batchWait:10},U={minDirtFactor:.1,minDirtCount:20},_t={...Ft,...U},K=Symbol("*"),yt=(e,t)=>{const s=new Map,n={...e._options.searchOptions,...t};for(const[o,u]of e._documentIds){const i=n.boostDocument?n.boostDocument(u,"",e._storedFields.get(o)):1;s.set(o,{score:i,terms:[],match:{}})}return s},X=(e,t=M)=>{if(e.length===0)return new Map;const s=t.toLowerCase(),n=ht[s];if(!n)throw new Error(`Invalid combination operator: ${t}`);return e.reduce(n)||new Map},S=(e,t,s,n,o,u,i,r,d=new Map)=>{if(o==null)return d;for(const c of Object.keys(u)){const a=u[c],h=e._fieldIds[c],g=o.get(h);if(g==null)continue;let m=g.size;const p=e._avgFieldLength[h];for(const l of g.keys()){if(!e._documentIds.has(l)){ft(e,h,l,s),m-=1;continue}const f=i?i(e._documentIds.get(l),s,e._storedFields.get(l)):1;if(!f)continue;const y=g.get(l),F=e._fieldLength.get(l)[h],v=dt(y,m,e._documentCount,F,p,r),z=n*a*f*v,A=d.get(l);if(A){A.score+=z,ct(A.terms,t);const w=G(A.match,s);w?w.push(c):A.match[s]=[c]}else d.set(l,{score:z,terms:[t],match:{[s]:[c]}})}}return d},At=(e,t,s)=>{const n={...e._options.searchOptions,...s},o=(n.fields||e._options.fields).reduce((l,f)=>({...l,[f]:G(n.boost,f)||1}),{}),{boostDocument:u,weights:i,maxFuzzy:r,bm25:d}=n,{fuzzy:c,prefix:a}={...J.weights,...i},h=e._index.get(t.term),g=S(e,t.term,t.term,1,h,o,u,d);let m,p;if(t.prefix&&(m=e._index.atPrefix(t.term)),t.fuzzy){const l=t.fuzzy===!0?.2:t.fuzzy,f=l<1?Math.min(r,Math.round(t.term.length*l)):l;f&&(p=e._index.fuzzyGet(t.term,f))}if(m)for(const[l,f]of m){const y=l.length-t.term.length;if(!y)continue;p?.delete(l);const F=a*l.length/(l.length+.3*y);S(e,t.term,l,F,f,o,u,d,g)}if(p)for(const l of p.keys()){const[f,y]=p.get(l);if(!y)continue;const F=c*l.length/(l.length+y);S(e,t.term,l,F,f,o,u,d,g)}return g},Y=(e,t,s={})=>{if(t===K)return yt(e,s);if(typeof t!="string"){const a={...s,...t,queries:void 0},h=t.queries.map(g=>Y(e,g,a));return X(h,a.combineWith)}const{tokenize:n,processTerm:o,searchOptions:u}=e._options,i={tokenize:n,processTerm:o,...u,...s},{tokenize:r,processTerm:d}=i,c=r(t).flatMap(a=>d(a)).filter(a=>!!a).map(at(i)).map(a=>At(e,a,i));return X(c,i.combineWith)},Q=(e,t,s={})=>{const n=Y(e,t,s),o=[];for(const[u,{score:i,terms:r,match:d}]of n){const c=r.length||1,a={id:e._documentIds.get(u),score:i*c,terms:Object.keys(d),queryTerms:r,match:d};Object.assign(a,e._storedFields.get(u)),(s.filter==null||s.filter(a))&&o.push(a)}return t===K&&s.boostDocument==null&&e._options.searchOptions.boostDocument==null||o.sort(P),o},Ct=(e,t,s={})=>{s={...e._options.autoSuggestOptions,...s};const n=new Map;for(const{score:u,terms:i}of Q(e,t,s)){const r=i.join(" "),d=n.get(r);d!=null?(d.score+=u,d.count+=1):n.set(r,{score:u,terms:i,count:1})}const o=[];for(const[u,{score:i,terms:r,count:d}]of n)o.push({suggestion:u,terms:r,score:i/d});return o.sort(P),o};class Et{_options;_index;_documentCount;_documentIds;_idToShortId;_fieldIds;_fieldLength;_avgFieldLength;_nextId;_storedFields;_dirtCount;_currentVacuum;_enqueuedVacuum;_enqueuedVacuumConditions;constructor(t){if(t?.fields==null)throw new Error('SlimSearch: option "fields" must be provided');const s=t.autoVacuum==null||t.autoVacuum===!0?_t:t.autoVacuum;this._options={...mt,...t,autoVacuum:s,searchOptions:{...J,...t.searchOptions||{}},autoSuggestOptions:{...pt,...t.autoSuggestOptions||{}}},this._index=new C,this._documentCount=0,this._documentIds=new Map,this._idToShortId=new Map,this._fieldIds={},this._fieldLength=new Map,this._avgFieldLength=[],this._nextId=0,this._storedFields=new Map,this._dirtCount=0,this._currentVacuum=null,this._enqueuedVacuum=null,this._enqueuedVacuumConditions=U,this.addFields(this._options.fields)}get isVacuuming(){return this._currentVacuum!=null}get dirtCount(){return this._dirtCount}get dirtFactor(){return this._dirtCount/(1+this._documentCount+this._dirtCount)}get documentCount(){return this._documentCount}get termCount(){return this._index.size}toJSON(){const t=[];for(const[s,n]of this._index){const o={};for(const[u,i]of n)o[u]=Object.fromEntries(i);t.push([s,o])}return{documentCount:this._documentCount,nextId:this._nextId,documentIds:Object.fromEntries(this._documentIds),fieldIds:this._fieldIds,fieldLength:Object.fromEntries(this._fieldLength),averageFieldLength:this._avgFieldLength,storedFields:Object.fromEntries(this._storedFields),dirtCount:this._dirtCount,index:t,serializationVersion:2}}addFields(t){for(let s=0;s<t.length;s++)this._fieldIds[t[s]]=s}}const zt=({index:e,documentCount:t,nextId:s,documentIds:n,fieldIds:o,fieldLength:u,averageFieldLength:i,storedFields:r,dirtCount:d,serializationVersion:c},a)=>{if(c!==1&&c!==2)throw new Error("SlimSearch: cannot deserialize an index created with an incompatible version");const h=new Et(a);h._documentCount=t,h._nextId=s,h._documentIds=b(n),h._idToShortId=new Map,h._fieldIds=o,h._fieldLength=b(u),h._avgFieldLength=i,h._storedFields=b(r),h._dirtCount=d||0,h._index=new C;for(const[g,m]of h._documentIds)h._idToShortId.set(m,g);for(const[g,m]of e){const p=new Map;for(const l of Object.keys(m)){let f=m[l];c===1&&(f=f.ds),p.set(parseInt(l,10),b(f))}h._index.set(g,p)}return h},B=(e,t)=>{const s=e.toLowerCase(),n=t.toLowerCase(),o=[];let u=0,i=0;const r=(c,a=!1)=>{let h="";i===0?h=c.length>20?`… ${c.slice(-20)}`:c:a?h=c.length+i>100?`${c.slice(0,100-i)}… `:c:h=c.length>20?`${c.slice(0,20)} … ${c.slice(-20)}`:c,h&&o.push(h),i+=h.length,a||(o.push(["mark",t]),i+=t.length,i>=100&&o.push(" …"))};let d=s.indexOf(n,u);if(d===-1)return null;for(;d>=0;){const c=d+n.length;if(r(e.slice(u,d)),u=c,i>100)break;d=s.indexOf(n,u)}return i<100&&r(e.slice(u),!0),o},wt=(e,t)=>t.contents.reduce((s,[,n])=>s+n,0)-e.contents.reduce((s,[,n])=>s+n,0),xt=(e,t)=>Math.max(...t.contents.map(([,s])=>s))-Math.max(...e.contents.map(([,s])=>s)),Z=(e,t,s={})=>{const n={};return Q(t,e,{boost:{h:2,t:1,c:4},prefix:!0,...s}).forEach(o=>{const{id:u,terms:i,score:r}=o,d=u.includes("@"),c=u.includes("#"),[a,h]=u.split(/[#@]/),g=Number(a),m=i.sort((l,f)=>l.length-f.length).filter((l,f)=>i.slice(f+1).every(y=>!y.includes(l))),{contents:p}=n[g]??={title:"",contents:[]};if(d)p.push([{type:"customField",id:g,index:h,display:m.map(l=>o.c.map(f=>B(f,l))).flat().filter(l=>l!==null)},r]);else{const l=m.map(f=>B(o.h,f)).filter(f=>f!==null);if(l.length&&p.push([{type:c?"heading":"title",id:g,...c&&{anchor:h},display:l},r]),"t"in o)for(const f of o.t){const y=m.map(F=>B(f,F)).filter(F=>F!==null);y.length&&p.push([{type:"text",id:g,...c&&{anchor:h},display:y},r])}}}),V(n).sort(([,o],[,u])=>"max"==="total"?wt(o,u):xt(o,u)).map(([o,{title:u,contents:i}])=>{if(!u){const r=ut(t,o);r&&(u=r.h)}return{title:u,contents:i.map(([r])=>r)}})},tt=(e,t,s={})=>{const n=Ct(t,e,{fuzzy:.2,maxFuzzy:3,...s}).map(({suggestion:o})=>o);return e.includes(" ")?n:n.filter(o=>!o.includes(" "))},bt=et(V(JSON.parse("{\"/\":{\"documentCount\":471,\"nextId\":471,\"documentIds\":{\"0\":\"1\",\"1\":\"1#docker-buildx-安装架构\",\"2\":\"1#构建镜像\",\"3\":\"1@0\",\"4\":\"1@1\",\"5\":\"2\",\"6\":\"2@0\",\"7\":\"2@1\",\"8\":\"3\",\"9\":\"3#访问模式-access-modes\",\"10\":\"3#回收策略-reclaim-policy\",\"11\":\"3#pv-status\",\"12\":\"3#_1-available\",\"13\":\"3#_2-bound\",\"14\":\"3#_3-released\",\"15\":\"3#_4-failed\",\"16\":\"3#状态转换\",\"17\":\"3#状态图示\",\"18\":\"3#resourcequotas\",\"19\":\"3#作用\",\"20\":\"3#配置示例\",\"21\":\"3#主要字段\",\"22\":\"3#使用场景\",\"23\":\"3#limitranges\",\"24\":\"3#作用-1\",\"25\":\"3#配置示例-1\",\"26\":\"3#主要字段-1\",\"27\":\"3#使用场景-1\",\"28\":\"3#比较与总结\",\"29\":\"3#k8s技能图谱\",\"30\":\"3#静态pod\",\"31\":\"3#static-pod-的特点\",\"32\":\"3#创建-static-pod\",\"33\":\"3#使用场景-2\",\"34\":\"3#监控和管理\",\"35\":\"3#taint\",\"36\":\"3#taint-机制\",\"37\":\"3#无头服务-headless-services\",\"38\":\"3#headless-service-的特点\",\"39\":\"3#使用场景-3\",\"40\":\"3#headless-service-的定义示例\",\"41\":\"3#statefulset-与-headless-service-的结合\",\"42\":\"3#定义-headless-service\",\"43\":\"3#定义-statefulset\",\"44\":\"3#总结\",\"45\":\"3#kubelet的hairpin-mode\",\"46\":\"3#hairpin-mode-的工作原理\",\"47\":\"3#配置-hairpin-mode\",\"48\":\"3#配置示例-2\",\"49\":\"3#使用场景-4\",\"50\":\"3#总结-1\",\"51\":\"3#资源短缺\",\"52\":\"3#如何能够让-kubernetes-的调度器尽可能地将-pod-分布在不同机器上-避免-堆叠-呢\",\"53\":\"3#_1-pod-反亲和性-pod-anti-affinity\",\"54\":\"3#示例\",\"55\":\"3#_2-节点亲和性-node-affinity\",\"56\":\"3#示例-1\",\"57\":\"3#_3-分布式调度策略-spread-constraints\",\"58\":\"3#示例-2\",\"59\":\"3#_4-自定义调度器策略-custom-scheduler-policies\",\"60\":\"3#示例-3\",\"61\":\"3#kubelet如何实现-exec、logs-等接口\",\"62\":\"3#集群安装\",\"63\":\"3@0\",\"64\":\"3@1\",\"65\":\"4\",\"66\":\"4#_1-nginx容器启动\",\"67\":\"4#_2-安装kong\",\"68\":\"4#_3-创建服务-hello-service\",\"69\":\"4#_4-查询服务-hello-service\",\"70\":\"4#_5-删除服务-hello-service\",\"71\":\"4#_6-创建路由-hello-route\",\"72\":\"4#_7-查询路由-hello-route\",\"73\":\"4#_8-删除路由-hello-route\",\"74\":\"4#_9-访问服务\",\"75\":\"4#总结\",\"76\":\"4@0\",\"77\":\"4@1\",\"78\":\"5\",\"79\":\"5#概念概述\",\"80\":\"5#pipeline\",\"81\":\"5#python-sdk\",\"82\":\"5#dsl-compiler\",\"83\":\"5#pipeline-service\",\"84\":\"5#kubernetes-resources\",\"85\":\"5#orchestration-controllers\",\"86\":\"5#artifact-storage\",\"87\":\"5#persistence-agent-and-ml-metadata\",\"88\":\"5#pipeline-web-server\",\"89\":\"5#pipeline-1\",\"90\":\"5#component\",\"91\":\"5#组件代码\",\"92\":\"5#组件定义\",\"93\":\"5#容器化组件\",\"94\":\"5#graph\",\"95\":\"5#experiment\",\"96\":\"5#主要的-argo-工作流执行器类型包括\",\"97\":\"5#如何选择适合的执行器\",\"98\":\"5#controller-manager\",\"99\":\"5#官网地址\",\"100\":\"5#kubernetes-应用程序\",\"101\":\"5#它提供了\",\"102\":\"5#这可以被以下用户使用\",\"103\":\"5#目标\",\"104\":\"5#非目标\",\"105\":\"5#什么是-katib\",\"106\":\"5#为什么选择-katib\",\"107\":\"5#pipeline服务注册流程\",\"108\":\"5#api-v1beta1-注册的服务\",\"109\":\"5#api-v2beta1-注册的服务\",\"110\":\"5#其他\",\"111\":\"5#总结\",\"112\":\"5#pipeline创建流程\",\"113\":\"5#创建runs\",\"114\":\"5@0\",\"115\":\"5@1\",\"116\":\"6\",\"117\":\"6#operator-的基本概念\",\"118\":\"6#operator-的工作原理\",\"119\":\"6#operator-的应用场景\",\"120\":\"6#operator-的优势\",\"121\":\"6#使用-operator-的示例\",\"122\":\"6#开发-operator-的工具\",\"123\":\"6#总结\",\"124\":\"6@0\",\"125\":\"6@1\",\"126\":\"7\",\"127\":\"7#编程语言\",\"128\":\"7#技术栈\",\"129\":\"7#mlops\",\"130\":\"7#前端开发\",\"131\":\"7#项目经验\",\"132\":\"7#联系方式\",\"133\":\"7@0\",\"134\":\"7@1\",\"135\":\"8\",\"136\":\"8@0\",\"137\":\"8@1\",\"138\":\"9\",\"139\":\"9#参考资料\",\"140\":\"9@0\",\"141\":\"9@1\",\"142\":\"10\",\"143\":\"10#nccl\",\"144\":\"10#下载源码\",\"145\":\"10#构建编译\",\"146\":\"10#nccl-test\",\"147\":\"10#下载\",\"148\":\"10#编译\",\"149\":\"10#运行\",\"150\":\"10#参数\",\"151\":\"10#具体工作原理\",\"152\":\"10#参数说明\",\"153\":\"10#返回\",\"154\":\"10#代码解释\",\"155\":\"10#应用场景\",\"156\":\"10#torch-cuda-nccl-py\",\"157\":\"10#核心功能\",\"158\":\"10#参数解析\",\"159\":\"10#核心逻辑\",\"160\":\"10#示例\",\"161\":\"10#torch-csrc-cuda-python-nccl-cpp\",\"162\":\"10#代码解析\",\"163\":\"10#总结\",\"164\":\"10#torch-csrc-cuda-module-cpp\",\"165\":\"10#代码结构和功能\",\"166\":\"10#总结-1\",\"167\":\"10#torch-dynamo-trace-rules-py\",\"168\":\"10#代码解析-1\",\"169\":\"10#示例用法\",\"170\":\"10#总结-2\",\"171\":\"10#代码解析-2\",\"172\":\"10#典型应用\",\"173\":\"10#示例解释\",\"174\":\"10#总结-3\",\"175\":\"10#nccl-topo\",\"176\":\"10#代码解析-3\",\"177\":\"10#拓扑结构的意义\",\"178\":\"10@0\",\"179\":\"10@1\",\"180\":\"11\",\"181\":\"11#主要功能\",\"182\":\"11#使用场景\",\"183\":\"11#示例代码\",\"184\":\"11#总结\",\"185\":\"11#spmd-模型的核心思想\",\"186\":\"11#spmd-与其他并行模型的比较\",\"187\":\"11#应用场景\",\"188\":\"11#示例\",\"189\":\"11#总结-1\",\"190\":\"11#mpmd-模型的核心思想\",\"191\":\"11#mpmd-与-spmd-的比较\",\"192\":\"11#应用场景-1\",\"193\":\"11#示例场景\",\"194\":\"11#实现-mpmd-的框架\",\"195\":\"11#总结-2\",\"196\":\"11#mpi-的核心概念\",\"197\":\"11#mpi-的主要功能\",\"198\":\"11#使用场景-1\",\"199\":\"11#示例代码-1\",\"200\":\"11#总结-3\",\"201\":\"11#源码解读\",\"202\":\"11#init-process-group\",\"203\":\"11#初始化默认的分布式进程组。\",\"204\":\"11#参数说明\",\"205\":\"11#backend\",\"206\":\"11#backend-类\",\"207\":\"11#注意\",\"208\":\"11@0\",\"209\":\"11@1\",\"210\":\"12\",\"211\":\"12#指标解释\",\"212\":\"12#hpa\",\"213\":\"12@0\",\"214\":\"12@1\",\"215\":\"13\",\"216\":\"13#awesome-compression\",\"217\":\"13#项目简介\",\"218\":\"13#unlock-huggingface\",\"219\":\"13#llm-deploy\",\"220\":\"13#self-llm\",\"221\":\"13#llm-universe\",\"222\":\"13#项目简介-1\",\"223\":\"13#大模型简介-何为大模型、大模型特点是什么、langchain-是什么-如何开发一个-llm-应用-针对小白开发者的简单介绍\",\"224\":\"13#tiny-universe\",\"225\":\"13#llm-cookbook\",\"226\":\"13#项目简介-2\",\"227\":\"13#handy-ollama\",\"228\":\"13#项目简介-3\",\"229\":\"13#machine-learning-toy-code\",\"230\":\"13#so-large-lm\",\"231\":\"13#项目简介-4\",\"232\":\"13#aifoundation\",\"233\":\"13#aisystem\",\"234\":\"13#llm-action\",\"235\":\"13@0\",\"236\":\"13@1\",\"237\":\"14\",\"238\":\"14#ubuntu\",\"239\":\"14#ping-安装\",\"240\":\"14#获取公网ip\",\"241\":\"14#ffmpeg\",\"242\":\"14#视频抽帧转图片\",\"243\":\"14@0\",\"244\":\"14@1\",\"245\":\"15\",\"246\":\"15#地址\",\"247\":\"15#论文\",\"248\":\"15#介绍\",\"249\":\"15#重要亮点\",\"250\":\"15@0\",\"251\":\"15@1\",\"252\":\"16\",\"253\":\"16#解释命令\",\"254\":\"16#使用场景\",\"255\":\"16#注意事项\",\"256\":\"16#扩容磁盘\",\"257\":\"16#_1-卸载并删除-nvme0n1p1-分区\",\"258\":\"16#_2-创建新的分区并标记为-lvm\",\"259\":\"16#_3-将新分区添加到-lvm-物理卷\",\"260\":\"16#_4-扩展逻辑卷-centos-root\",\"261\":\"16#_5-扩展-xfs-文件系统\",\"262\":\"16#_6-验证扩展结果\",\"263\":\"16#wsl-启用systemd\",\"264\":\"16#wsl2迁移至其他目录\",\"265\":\"16@0\",\"266\":\"16@1\",\"267\":\"17\",\"268\":\"17#_1-协议基础\",\"269\":\"17#_2-连接管理\",\"270\":\"17#_3-多路复用\",\"271\":\"17#_4-头部压缩\",\"272\":\"17#_5-服务器推送\",\"273\":\"17#_6-优先级和流控制\",\"274\":\"17#_7-加密和安全\",\"275\":\"17#_8-协议扩展性\",\"276\":\"17#_9-性能改进\",\"277\":\"17#总结\",\"278\":\"17#查看系统中已有的veth设备对或确认已创建的veth设备对-可以使用以下几种方法\",\"279\":\"17#使用-ip-命令\",\"280\":\"17#使用-ifconfig-命令\",\"281\":\"17#查看具体veth设备对的详细信息\",\"282\":\"17#示例\",\"283\":\"17#检查命名空间中的veth设备\",\"284\":\"17#vlan-与vxlan\",\"285\":\"17#vlan-virtual-local-area-network\",\"286\":\"17#vxlan-virtual-extensible-lan\",\"287\":\"17#对比\",\"288\":\"17#总结-1\",\"289\":\"17#vxlan与vtep\",\"290\":\"17#vxlan-virtual-extensible-lan-1\",\"291\":\"17#vtep-vxlan-tunnel-endpoint\",\"292\":\"17#vxlan-和-vtep-的工作流程\",\"293\":\"17#总结-2\",\"294\":\"17#ip-neigh-show\",\"295\":\"17#总结-3\",\"296\":\"17#bridge-fdb-show\",\"297\":\"17#示例输出\",\"298\":\"17#输出字段解释\",\"299\":\"17#常用选项\",\"300\":\"17#使用示例\",\"301\":\"17#总结-4\",\"302\":\"17#arp协议\",\"303\":\"17#arp-工作原理\",\"304\":\"17#arp-报文格式\",\"305\":\"17#arp-缓存\",\"306\":\"17#arp的安全问题\",\"307\":\"17#arp欺骗的防御措施\",\"308\":\"17#总结-5\",\"309\":\"17#bgp协议\",\"310\":\"17#bgp-的主要特性和工作原理\",\"311\":\"17#bgp-的工作过程\",\"312\":\"17#bgp-的优势和挑战\",\"313\":\"17#优势\",\"314\":\"17#挑战\",\"315\":\"17#总结-6\",\"316\":\"17#ifconfig、ip-a、ip-link、ip-route-和-iptables-是网络管理中常用的命令。它们各自有不同的功能-但一起使用时可以全面管理和配置网络接口、路由和防火墙规则。以下是这些命令的功能及其关系的详细介绍\",\"317\":\"17#ifconfig\",\"318\":\"17#功能\",\"319\":\"17#用法\",\"320\":\"17#ip-a-也称-ip-addr\",\"321\":\"17#功能-1\",\"322\":\"17#用法-1\",\"323\":\"17#ip-link\",\"324\":\"17#功能-2\",\"325\":\"17#用法-2\",\"326\":\"17#ip-route\",\"327\":\"17#功能-3\",\"328\":\"17#用法-3\",\"329\":\"17#iptables\",\"330\":\"17#功能-4\",\"331\":\"17#用法-4\",\"332\":\"17#关系\",\"333\":\"17#七层网络模型\",\"334\":\"17#_1-物理层-physical-layer\",\"335\":\"17#_2-数据链路层-data-link-layer\",\"336\":\"17#_3-网络层-network-layer\",\"337\":\"17#_4-传输层-transport-layer\",\"338\":\"17#_5-会话层-session-layer\",\"339\":\"17#_6-表示层-presentation-layer\",\"340\":\"17#_7-应用层-application-layer\",\"341\":\"17#各层之间的关系\",\"342\":\"17#应用示例\",\"343\":\"17#总结-7\",\"344\":\"17#spine交换机-leaf-交换机-以及组网架构\",\"345\":\"17#_1-spine交换机\",\"346\":\"17#_2-leaf交换机\",\"347\":\"17#_3-spine-leaf组网架构\",\"348\":\"17#_4-spine-leaf架构的应用场景\",\"349\":\"17#总结-8\",\"350\":\"17#rdma\",\"351\":\"17#rdma-介绍\",\"352\":\"17#nvlink-和-nvswitch-介绍\",\"353\":\"17#nvlink-nvswitch-与-rdma-的区别\",\"354\":\"17#依赖关系\",\"355\":\"17#适用场景\",\"356\":\"17#总结-9\",\"357\":\"17@0\",\"358\":\"17@1\",\"359\":\"18\",\"360\":\"18@0\",\"361\":\"18@1\",\"362\":\"19\",\"363\":\"19#地址\",\"364\":\"19#文档\",\"365\":\"19#配置\",\"366\":\"19#docker-compose\",\"367\":\"19#访问\",\"368\":\"19#fastgpt\",\"369\":\"19#oneapi\",\"370\":\"19#地址-1\",\"371\":\"19#文档-1\",\"372\":\"19#docker-compose-1\",\"373\":\"19#cosyvoice-部署\",\"374\":\"19#模型下载\",\"375\":\"19#镜像启动\",\"376\":\"19#服务启动\",\"377\":\"19@0\",\"378\":\"19@1\",\"379\":\"20\",\"380\":\"20#部署文档\",\"381\":\"20#docker-compose\",\"382\":\"20#env\",\"383\":\"20#minio-bucket-config-json\",\"384\":\"20@0\",\"385\":\"20@1\",\"386\":\"21\",\"387\":\"21#sringboot-keycloak\",\"388\":\"21#springboot-casdoor\",\"389\":\"21#springboot-logto\",\"390\":\"21#springboot-zitadel\",\"391\":\"21@0\",\"392\":\"21@1\",\"393\":\"22\",\"394\":\"22#问题背景\",\"395\":\"22#论文创新点\",\"396\":\"22#实验方法\",\"397\":\"22#结论\",\"398\":\"22#ii-背景与动机\",\"399\":\"22#操作间并行\",\"400\":\"22#gpu内存消耗的问题\",\"401\":\"22#内存优化及其局限性\",\"402\":\"22#硬件趋势与机遇\",\"403\":\"22#iii-mpress-内部原理\",\"404\":\"22#a-设计原则\",\"405\":\"22#b-mpress的总体概述及工作流程\",\"406\":\"22#c-d2d交换\",\"407\":\"22#d-内存压缩规划\",\"408\":\"22#e-实现细节\",\"409\":\"22#iv-评估\",\"410\":\"22#a-实验设置\",\"411\":\"22#b-mpress在pipedream上的性能\",\"412\":\"22#c-mpress在dapple上的性能\",\"413\":\"22#d-敏感性分析\",\"414\":\"22#d2d交换优化的影响\",\"415\":\"22#内存压缩方法的成本比较\",\"416\":\"22#mpress选择的策略\",\"417\":\"22#v-硬件见解\",\"418\":\"22#vi-相关工作\",\"419\":\"22#vii-结论\",\"420\":\"22@0\",\"421\":\"22@1\",\"422\":\"23\",\"423\":\"23#摘要\",\"424\":\"23#_1-引言\",\"425\":\"23#_2-背景与动机\",\"426\":\"23#_2-1-现有搜索空间的局限性\",\"427\":\"23#_2-2-由于灵活性带来的新挑战\",\"428\":\"23#_3-并行化搜索空间构建\",\"429\":\"23#op-trans\",\"430\":\"23#op-assign\",\"431\":\"23#op-order\",\"432\":\"23#_4-在搜索空间中应用约束\",\"433\":\"23#_4-1-现有搜索空间的约束\",\"434\":\"23#_4-2-新的约束\",\"435\":\"23#_4-2-1-swin-transformer-的约束\",\"436\":\"23#_4-2-2-t5-的约束\",\"437\":\"23#_4-2-3-alphafold2-的约束\",\"438\":\"23#_4-3-讨论\",\"439\":\"23#_5-计划搜索策略\",\"440\":\"23#_5-1-算子划分与放置搜索\",\"441\":\"23#_5-2-时间顺序搜索\",\"442\":\"23#_6-并行化计划的编译\",\"443\":\"23#张量抽象-vtensor-和-ptensor\",\"444\":\"23#数据依赖的物化\",\"445\":\"23#_7-实现与经验\",\"446\":\"23#_7-1-实践经验\",\"447\":\"23#_7-1-1-调试-nnscaler\",\"448\":\"23#_7-1-2-模型准确性\",\"449\":\"23#_7-1-3-就地操作符\",\"450\":\"23#_8-评估\",\"451\":\"23#_8-1-计划构建的表达能力\",\"452\":\"23#_8-2-计划搜索结果\",\"453\":\"23#_8-3-端到端性能\",\"454\":\"23#_8-3-1-实验设置\",\"455\":\"23#_8-3-2-swintransformer-的结果\",\"456\":\"23#_8-3-3-t5-的结果\",\"457\":\"23#_8-3-4-alphafold2-的结果\",\"458\":\"23#_8-3-5-性能较低硬件上的实验\",\"459\":\"23#_8-4-带有约束的搜索效率\",\"460\":\"23@0\",\"461\":\"23@1\",\"462\":\"25\",\"463\":\"26\",\"464\":\"27\",\"465\":\"28\",\"466\":\"29\",\"467\":\"30\",\"468\":\"31\",\"469\":\"32\",\"470\":\"33\"},\"fieldIds\":{\"h\":0,\"t\":1,\"c\":2},\"fieldLength\":{\"0\":[1,2],\"1\":[3,57],\"2\":[1,15],\"3\":[null,null,1],\"4\":[null,null,1],\"5\":[1,152],\"6\":[null,null,1],\"7\":[null,null,1],\"8\":[1,2],\"9\":[4,16],\"10\":[4,13],\"11\":[3,20],\"12\":[2,16],\"13\":[2,13],\"14\":[2,16],\"15\":[2,11],\"16\":[1,27],\"17\":[1,23],\"18\":[1,9],\"19\":[1,10],\"20\":[1,40],\"21\":[1,13],\"22\":[1,10],\"23\":[1,12],\"24\":[1,14],\"25\":[1,45],\"26\":[1,13],\"27\":[1,10],\"28\":[1,23],\"29\":[1],\"30\":[1,27],\"31\":[3,43],\"32\":[3,40],\"33\":[1,31],\"34\":[1,34],\"35\":[1,10],\"36\":[2,147],\"37\":[4,17],\"38\":[3,35],\"39\":[1,17],\"40\":[3,37],\"41\":[5,7],\"42\":[3,22],\"43\":[2,44],\"44\":[1,21],\"45\":[1,20],\"46\":[3,19],\"47\":[1,22],\"48\":[1,22],\"49\":[1,11],\"50\":[1,16],\"51\":[1,92],\"52\":[9,10],\"53\":[6,6],\"54\":[1,32],\"55\":[5,7],\"56\":[1,26],\"57\":[5,10],\"58\":[1,32],\"59\":[6,7],\"60\":[1,26],\"61\":[4,73],\"62\":[1,138],\"63\":[null,null,1],\"64\":[null,null,1],\"65\":[1,3],\"66\":[2,29],\"67\":[2,3],\"68\":[2,23],\"69\":[2,10],\"70\":[2,13],\"71\":[2,19],\"72\":[2,12],\"73\":[2,13],\"74\":[2,14],\"75\":[1,257],\"76\":[null,null,1],\"77\":[null,null,3],\"78\":[2,35],\"79\":[1,11],\"80\":[1,3],\"81\":[3,5],\"82\":[1,3],\"83\":[1,2],\"84\":[1,4],\"85\":[1,7],\"86\":[1,17],\"87\":[1,6],\"88\":[1,7],\"89\":[1,33],\"90\":[1,18],\"91\":[1,24],\"92\":[1,22],\"93\":[1,13],\"94\":[1,29],\"95\":[1,106],\"96\":[4,41],\"97\":[2,220],\"98\":[2,64],\"99\":[1,6],\"100\":[2,21],\"101\":[2,14],\"102\":[2,13],\"103\":[1,24],\"104\":[1,6],\"105\":[3,64],\"106\":[3,45],\"107\":[1,5],\"108\":[3,42],\"109\":[3,19],\"110\":[1,6],\"111\":[1,28],\"112\":[1,2],\"113\":[1,5],\"114\":[null,null,1],\"115\":[null,null,1],\"116\":[2,17],\"117\":[2,29],\"118\":[2,23],\"119\":[2,19],\"120\":[2,16],\"121\":[3,18],\"122\":[3,20],\"123\":[1,17],\"124\":[null,null,1],\"125\":[null,null,1],\"126\":[1,12],\"127\":[1,26],\"128\":[1,23],\"129\":[1,7],\"130\":[1,23],\"131\":[1,18],\"132\":[1,1],\"133\":[null,null,1],\"134\":[null,null,1],\"135\":[1],\"136\":[null,null,1],\"137\":[null,null,2],\"138\":[1,6],\"139\":[1,26],\"140\":[null,null,1],\"141\":[null,null,1],\"142\":[1,1],\"143\":[1,141],\"144\":[1,8],\"145\":[1,31],\"146\":[2],\"147\":[1,8],\"148\":[1,4],\"149\":[1,289],\"150\":[1,220],\"151\":[1,34],\"152\":[2,16],\"153\":[2,7],\"154\":[2,52],\"155\":[1,6],\"156\":[4,103],\"157\":[1,16],\"158\":[1,62],\"159\":[1,35],\"160\":[1,33],\"161\":[6,85],\"162\":[1,120],\"163\":[1,23],\"164\":[5,43],\"165\":[1,49],\"166\":[1,16],\"167\":[5,24],\"168\":[1,36],\"169\":[1,28],\"170\":[1,40],\"171\":[1,62],\"172\":[1,15],\"173\":[1,20],\"174\":[1,15],\"175\":[2,72],\"176\":[2,64],\"177\":[2,15],\"178\":[null,null,1],\"179\":[null,null,1],\"180\":[1,15],\"181\":[1,39],\"182\":[1,10],\"183\":[1,38],\"184\":[1,19],\"185\":[2,25],\"186\":[2,19],\"187\":[1,21],\"188\":[1,13],\"189\":[1,24],\"190\":[2,30],\"191\":[4,20],\"192\":[1,23],\"193\":[1,17],\"194\":[3,8],\"195\":[1,30],\"196\":[2,55],\"197\":[2,19],\"198\":[1,19],\"199\":[1,46],\"200\":[1,7],\"201\":[1],\"202\":[3,36],\"203\":[2,24],\"204\":[2,117],\"205\":[1,79],\"206\":[2,23],\"207\":[2,32],\"208\":[null,null,1],\"209\":[null,null,2],\"210\":[3,3],\"211\":[1,42],\"212\":[1,56],\"213\":[null,null,2],\"214\":[null,null,1],\"215\":[1,1],\"216\":[1],\"217\":[1,20],\"218\":[1,18],\"219\":[1,7],\"220\":[1,44],\"221\":[1],\"222\":[1,6],\"223\":[10,61],\"224\":[1,40],\"225\":[1,3],\"226\":[1,47],\"227\":[1],\"228\":[1,37],\"229\":[1,8],\"230\":[1],\"231\":[1,25],\"232\":[1,19],\"233\":[1,13],\"234\":[1],\"235\":[null,null,1],\"236\":[null,null,1],\"237\":[1],\"238\":[1],\"239\":[2,4],\"240\":[1,5],\"241\":[1],\"242\":[1,18],\"243\":[null,null,1],\"244\":[null,null,1],\"245\":[1,4],\"246\":[1,5],\"247\":[1,5],\"248\":[1,8],\"249\":[1,47],\"250\":[null,null,1],\"251\":[null,null,1],\"252\":[1,8],\"253\":[2,12],\"254\":[2,14],\"255\":[2,170],\"256\":[1,15],\"257\":[3,26],\"258\":[3,28],\"259\":[4,11],\"260\":[2,11],\"261\":[3,11],\"262\":[2,14],\"263\":[2,44],\"264\":[1,24],\"265\":[null,null,1],\"266\":[null,null,1],\"267\":[1,12],\"268\":[2,10],\"269\":[2,19],\"270\":[2,15],\"271\":[2,14],\"272\":[2,13],\"273\":[2,13],\"274\":[2,14],\"275\":[2,11],\"276\":[2,11],\"277\":[1,36],\"278\":[3],\"279\":[2,13],\"280\":[2,7],\"281\":[1,5],\"282\":[1,37],\"283\":[1,70],\"284\":[2,12],\"285\":[6,28],\"286\":[5,25],\"287\":[1,32],\"288\":[1,6],\"289\":[1],\"290\":[5,23],\"291\":[5,29],\"292\":[4,15],\"293\":[1,10],\"294\":[3,50],\"295\":[1,12],\"296\":[3,12],\"297\":[1,20],\"298\":[1,22],\"299\":[1,12],\"300\":[1,9],\"301\":[1,6],\"302\":[1,12],\"303\":[2,26],\"304\":[2,39],\"305\":[2,7],\"306\":[1,9],\"307\":[1,13],\"308\":[1,6],\"309\":[1,16],\"310\":[2,48],\"311\":[2,23],\"312\":[2],\"313\":[2,9],\"314\":[2,9],\"315\":[1,8],\"316\":[7],\"317\":[1],\"318\":[2,10],\"319\":[2,17],\"320\":[2],\"321\":[2,9],\"322\":[2,3],\"323\":[1],\"324\":[2,6],\"325\":[2,10],\"326\":[1],\"327\":[2,6],\"328\":[2,18],\"329\":[1],\"330\":[2,11],\"331\":[2,17],\"332\":[1,31],\"333\":[1,11],\"334\":[5,15],\"335\":[6,18],\"336\":[5,15],\"337\":[5,13],\"338\":[5,10],\"339\":[5,15],\"340\":[5,16],\"341\":[1,9],\"342\":[1,10],\"343\":[1,5],\"344\":[4,11],\"345\":[2,24],\"346\":[2,25],\"347\":[2,51],\"348\":[2,16],\"349\":[1,13],\"350\":[1,13],\"351\":[2,24],\"352\":[4,32],\"353\":[5,20],\"354\":[1,26],\"355\":[1,14],\"356\":[1,15],\"357\":[null,null,1],\"358\":[null,null,1],\"359\":[1,98],\"360\":[null,null,1],\"361\":[null,null,1],\"362\":[3,1],\"363\":[1,5],\"364\":[1,6],\"365\":[1,177],\"366\":[2,319],\"367\":[1],\"368\":[1,8],\"369\":[1,6],\"370\":[1,7],\"371\":[1,8],\"372\":[2,110],\"373\":[2,11],\"374\":[1,11],\"375\":[1,14],\"376\":[1,12],\"377\":[null,null,1],\"378\":[null,null,4],\"379\":[1,1],\"380\":[1,6],\"381\":[2,152],\"382\":[1,96],\"383\":[4,36],\"384\":[null,null,1],\"385\":[null,null,1],\"386\":[1,2],\"387\":[3,15],\"388\":[3,1],\"389\":[3,8],\"390\":[3,1],\"391\":[null,null,1],\"392\":[null,null,1],\"393\":[2,29],\"394\":[2,11],\"395\":[2,15],\"396\":[2,12],\"397\":[2,4],\"398\":[2,64],\"399\":[1,24],\"400\":[1,24],\"401\":[1,27],\"402\":[1,14],\"403\":[3],\"404\":[2,23],\"405\":[2,45],\"406\":[2,40],\"407\":[2,64],\"408\":[2,44],\"409\":[2,8],\"410\":[2,124],\"411\":[2,82],\"412\":[2,112],\"413\":[2,11],\"414\":[1,40],\"415\":[1,49],\"416\":[1,64],\"417\":[2,70],\"418\":[2,80],\"419\":[2,23],\"420\":[null,null,1],\"421\":[null,null,2],\"422\":[3,35],\"423\":[1,39],\"424\":[2,53],\"425\":[2,80],\"426\":[3,43],\"427\":[2,24],\"428\":[2,15],\"429\":[2,55],\"430\":[2,11],\"431\":[2,69],\"432\":[2,18],\"433\":[3,110],\"434\":[3,6],\"435\":[6,66],\"436\":[4,34],\"437\":[5,44],\"438\":[3,24],\"439\":[2,32],\"440\":[3,27],\"441\":[3,12],\"442\":[2,25],\"443\":[4,59],\"444\":[1,54],\"445\":[2,55],\"446\":[3,49],\"447\":[4,15],\"448\":[4,36],\"449\":[4,21],\"450\":[2,36],\"451\":[3,63],\"452\":[3,62],\"453\":[3,10],\"454\":[4,106],\"455\":[5,69],\"456\":[4,58],\"457\":[5,62],\"458\":[4,52],\"459\":[3,74],\"460\":[null,null,1],\"461\":[null,null,2],\"462\":[1,3],\"463\":[1],\"464\":[1],\"465\":[1],\"466\":[1],\"467\":[1],\"468\":[1],\"469\":[1],\"470\":[1]},\"averageFieldLength\":[1.9046529644309114,30.863369642902672,0.6923488111264021],\"storedFields\":{\"0\":{\"h\":\"docker知识点\",\"t\":[\"docker 笔记总结\"]},\"1\":{\"h\":\"docker buildx 安装架构\",\"t\":[\"参考：https://github.com/moby/buildkit/blob/master/docs/multi-platform.md\",\"docker run --privileged --rm tonistiigi/binfmt --install all\",\"执行结果如下\",\"(base) root@DESKTOP-P54EAF3:~# docker buildx ls NAME/NODE DRIVER/ENDPOINT STATUS BUILDKIT PLATFORMS default * docker default default running v0.11.7-0.20230525183624-798ad6b0ce9f linux/amd64, linux/amd64/v2, linux/amd64/v3, linux/386, linux/arm64, linux/riscv64, linux/ppc64le, linux/s390x, linux/mips64le, linux/mips64, linux/arm/v7, linux/arm/v6\"]},\"2\":{\"h\":\"构建镜像\",\"t\":[\"最好先拉取镜像对应 dockerfile 基础镜像， 默认builder只支持一种架构指定 docker buildx build --platform linux/arm64 -t vnet:arch_more .\"]},\"3\":{\"c\":[\"docker\"]},\"4\":{\"c\":[\"笔记\"]},\"5\":{\"h\":\"etcd\",\"t\":[\"etcd获取分布式锁\",\"cli, err := clientv3.New(clientv3.Config{Endpoints: endpoints}) if err != nil { log.Fatal(err) } defer cli.Close() // create two separate sessions for lock competition s1, err := concurrency.NewSession(cli, concurrency.WithTTL(10)) if err != nil { log.Fatal(err) } defer s1.Close() m1 := concurrency.NewMutex(s1, \\\"/my-lock/\\\") // acquire lock for s1 if err := m1.Lock(context.TODO()); err != nil { log.Fatal(err) } fmt.Println(\\\"acquired lock for s1\\\") if err := m1.Unlock(context.TODO()); err != nil { log.Fatal(err) } fmt.Println(\\\"released lock for s1\\\")\",\"1、首先通过 concurrency.NewSession 方法创建 Session，本质是创建了一个 TTL 为 10 的 Lease。\",\"2、其次得到 session 对象后，通过 concurrency.NewMutex 创建了一个 mutex 对象，包含 Lease、key prefix 等信息。\",\"3、然后通过 mutex 对象的 Lock 方法尝试获取锁。\",\"当 CreateRevision 为 0 时，它会创建一个 prefix 为 /my-lock 的 key（ /my-lock + LeaseID)，并获取到 /my-lock prefix 下面最早创建的一个 key（revision 最小），分布式锁最终是由写入此 key 的 client 获得，其他 client 则进入等待模式。\",\"4、最后使用结束，可通过 mutex 对象的 Unlock 方法释放锁。\",\"未获得锁的 client 是如何等待的呢?\",\"// wait for deletion revisions prior to myKey hdr, werr := waitDeletes(ctx, client, m.pfx, m.myRev-1) // release lock key if wait failed if werr != nil { m.Unlock(client.Ctx()) } else { m.hdr = hdr }\",\"通过 Watch 机制各自监听 prefix 相同，revision 比自己小的 key，因为只有 revision 比自己小的 key 释放锁，我才能有机会，获得锁，如下代码所示，其中 waitDelete 会使用我们上面的介绍的 Watch 去监听比自己小的 key\",\"为什么使用etcd分布式锁比redis分布式锁更好？\",\"相比 Redis 基于主备异步复制导致锁的安全性问题，etcd 是基于 Raft 共识算法实现的，一个写请求需要经过集群多数节点确认。因此一旦分布式锁申请返回给 client 成功后，它一定是持久化到了集群多数节点上，不会出现 Redis 主备异步复制可能导致丢数据的问题，具备更高的安全性。\",\"分布式锁的三个主要核心要素\",\"安全性、互斥性。在同一时间内，不允许多个 client 同时获得锁。\",\"活性。无论 client 出现 crash 还是遭遇网络分区，你都需要确保任意故障场景下，都不会出现死锁，常用的解决方案是超时和自动过期机制。\",\"高可用、高性能。加锁、释放锁的过程性能开销要尽量低，同时要保证高可用，避免单点故障。\"]},\"6\":{\"c\":[\"etcd\"]},\"7\":{\"c\":[\"分布式锁\"]},\"8\":{\"h\":\"k8s知识点\",\"t\":[\"k8s 笔记总结\"]},\"9\":{\"h\":\"访问模式（Access Modes）\",\"t\":[\"Kubernetes支持的访问模式如下。\",\"ReadWriteOnce（RWO）：读写权限，并且只能被单个Node挂 载。\",\"ReadOnlyMany（ROX）：只读权限，允许被多个Node挂载。\",\"ReadWriteMany（RWX）：读写权限，允许被多个Node挂载。\",\"某些PV可能支持多种访问模式，但PV在挂载时只能使用一种访问模式，多种访问模式不能同时生效。\"]},\"10\":{\"h\":\"回收策略（Reclaim Policy）\",\"t\":[\"Kubernetes支持的回收策略如下。\",\"Retain：保留数据，需要手工处理。\",\"Recycle：简单清除文件的操作。\",\"Delete：与PV相连的后端存储完成Volume的删除操作。\",\"目前只有NFS和HostPath两种类型的PV支持Recycle策略； AWSElasticBlockStore、GCEPersistentDisk、AzureDisk和Cinder类型的PV支持Delete策略。\"]},\"11\":{\"h\":\"PV (STATUS)\",\"t\":[\"在 Kubernetes 中，PersistentVolume (PV) 是一个集群级别的资源，用于表示集群中持久化存储的详细信息和状态。PV 的状态由其 STATUS 字段来表示，它反映了存储卷的当前状态。了解这些状态有助于掌握 PV 在生命周期中的位置，以及它是否能够被持久卷声明 (PersistentVolumeClaim, PVC) 使用。\",\"以下是 Kubernetes 中 PV 的几种可能的状态：\"]},\"12\":{\"h\":\"1.\",\"t\":[\"描述: 该状态表示 PV 可以被绑定到 PVC。PV 处于 Available 状态时，它未被任何 PVC 使用，可以供新的 PVC 绑定。\",\"特点: \",\"PV 还未与任何 PVC 绑定。\",\"准备好用于新的 PVC 绑定。\"]},\"13\":{\"h\":\"2.\",\"t\":[\"描述: 该状态表示 PV 已经被绑定到一个 PVC，且正被 PVC 使用。\",\"特点: \",\"PV 已经与一个 PVC 绑定。\",\"它不能再被其他 PVC 绑定，直到被释放。\"]},\"14\":{\"h\":\"3.\",\"t\":[\"描述: 该状态表示 PV 之前已经绑定的 PVC 已经被删除，但是 PV 本身还没有被集群中的任何新 PVC 再次使用。\",\"特点: \",\"PVC 已被删除。\",\"数据可能仍然存在于 PV 上，但它还未被新的 PVC 重新绑定。\"]},\"15\":{\"h\":\"4.\",\"t\":[\"描述: 该状态表示 PV 由于某种原因无法使用，通常是因为与 PV 相关的存储设备出现了错误或问题。\",\"特点: \",\"PV 在操作过程中遇到错误，无法正常使用。\",\"可能需要管理员干预以修复问题。\"]},\"16\":{\"h\":\"状态转换\",\"t\":[\"PV 的状态转换通常遵循以下过程：\",\"初始状态: PV 被创建后，处于 Available 状态。\",\"绑定: 一个 PVC 请求匹配 PV，PV 被绑定到 PVC 后，状态变为 Bound。\",\"释放: PVC 被删除后，PV 状态变为 Released。\",\"再利用或删除: \",\"如果允许再利用，管理员可以手动将 PV 状态重置为 Available，使其可以绑定到新的 PVC。\",\"如果 PV 被认为不再需要，可能会被删除。\"]},\"17\":{\"h\":\"状态图示\",\"t\":[\"以下是状态转换的示意图：\",\"Available | | PVC 绑定 V Bound | | PVC 删除 V Released | | 删除或再利用 V Failed (或) Available\",\"在 Kubernetes（K8s）集群中，ResourceQuotas 和 LimitRanges 是两种用于资源管理和控制的机制。它们帮助管理员确保资源的公平分配和高效利用。以下是对这两者的详细介绍：\"]},\"18\":{\"h\":\"ResourceQuotas\",\"t\":[\"ResourceQuotas 是一种在 Kubernetes 中用来限制命名空间（Namespace）内资源总量的机制。它们用于防止某个命名空间消耗过多的集群资源，从而影响其他命名空间的正常运行。\"]},\"19\":{\"h\":\"作用\",\"t\":[\"限制命名空间资源使用: ResourceQuotas 确保每个命名空间不会消耗超过指定的资源限额。\",\"控制资源分配: 它们帮助管理员公平分配集群资源，防止资源耗尽。\",\"提升资源管理能力: 通过设置资源限额，管理员可以更好地管理和监控资源使用情况。\"]},\"20\":{\"h\":\"配置示例\",\"t\":[\"以下是一个 ResourceQuota 的 YAML 配置示例，它限制了某个命名空间内的 CPU 和内存总量，以及对象数量（如 Pod 和 Service）：\",\"apiVersion: v1 kind: ResourceQuota metadata: name: example-quota namespace: example-namespace spec: hard: pods: \\\"10\\\" # 限制 Pod 的总数量 services: \\\"5\\\" # 限制 Service 的总数量 requests.cpu: \\\"4\\\" # 限制 CPU 请求总量 requests.memory: \\\"8Gi\\\" # 限制内存请求总量 limits.cpu: \\\"10\\\" # 限制 CPU 使用总量 limits.memory: \\\"16Gi\\\" # 限制内存使用总量\"]},\"21\":{\"h\":\"主要字段\",\"t\":[\"hard: 定义了资源的硬性限制，包括 CPU、内存、存储和对象数量等。\",\"scopes: 可选字段，指定了 ResourceQuota 适用的对象范围（如仅应用于某些特定的资源类型）。\"]},\"22\":{\"h\":\"使用场景\",\"t\":[\"开发环境: 限制资源以确保测试环境不会占用过多的生产资源。\",\"多租户环境: 在共享集群中，控制不同租户（命名空间）之间的资源使用。\",\"成本管理: 控制资源使用来管理和控制成本。\"]},\"23\":{\"h\":\"LimitRanges\",\"t\":[\"LimitRanges 是一种在 Kubernetes 中用于限制命名空间内单个 Pod 或容器资源使用的机制。与 ResourceQuotas 的整体限制不同，LimitRanges 主要控制单个 Pod 或容器的资源使用范围。\"]},\"24\":{\"h\":\"作用\",\"t\":[\"设置默认资源限制: 如果 Pod 或容器没有指定资源请求和限制，LimitRanges 可以提供默认值。\",\"防止资源过度消耗: 通过限制单个容器或 Pod 的资源使用，防止过多的资源消耗影响整个集群的性能。\",\"鼓励合理的资源分配: 鼓励开发人员在部署 Pod 时合理设置资源请求和限制。\"]},\"25\":{\"h\":\"配置示例\",\"t\":[\"以下是一个 LimitRange 的 YAML 配置示例，它为容器设置了 CPU 和内存的默认值和最大/最小值：\",\"apiVersion: v1 kind: LimitRange metadata: name: example-limits namespace: example-namespace spec: limits: - max: cpu: \\\"1\\\" # 容器的最大 CPU 使用量 memory: \\\"1Gi\\\" # 容器的最大内存使用量 min: cpu: \\\"100m\\\" # 容器的最小 CPU 使用量 memory: \\\"128Mi\\\" # 容器的最小内存使用量 default: cpu: \\\"500m\\\" # 容器的默认 CPU 请求量 memory: \\\"512Mi\\\" # 容器的默认内存请求量 defaultRequest: cpu: \\\"250m\\\" # 容器的默认 CPU 请求 memory: \\\"256Mi\\\" # 容器的默认内存请求 type: Container # 应用类型\"]},\"26\":{\"h\":\"主要字段\",\"t\":[\"max: 定义了单个容器可以请求的最大资源量。\",\"min: 定义了单个容器必须请求的最小资源量。\",\"default: 定义了容器没有指定资源请求和限制时的默认值。\",\"defaultRequest: 定义了容器没有指定资源请求时的默认请求值。\",\"type: 指定了限制适用于 Pod 还是容器。\"]},\"27\":{\"h\":\"使用场景\",\"t\":[\"应用程序标准化: 在命名空间内强制执行资源使用标准，确保所有容器符合预期的资源使用模式。\",\"资源优化: 防止资源过度配置或资源不足，从而优化集群性能和资源利用率。\",\"开发与测试环境: 在不同环境中设置不同的限制，确保资源的合理分配和使用。\"]},\"28\":{\"h\":\"比较与总结\",\"t\":[\"ResourceQuotas:\",\"范围: 适用于整个命名空间的资源总量。\",\"目的: 控制命名空间内的资源使用上限，确保集群资源的公平分配和高效利用。\",\"典型场景: 多租户环境、开发环境中的资源限制。\",\"LimitRanges:\",\"范围: 适用于单个 Pod 或容器的资源使用。\",\"目的: 设置资源使用的默认值和最大/最小限制，防止个体资源过度消耗。\",\"典型场景: 应用程序的资源标准化和资源优化。\",\"两者结合使用，可以在 Kubernetes 集群中提供强大的资源管理能力，确保资源的公平分配和高效使用。\"]},\"29\":{\"h\":\"k8s技能图谱\"},\"30\":{\"h\":\"静态pod\",\"t\":[\"Static Pod 是 Kubernetes 中的一种特殊类型的 Pod，它由 kubelet 直接管理，而不是通过 Kubernetes API Server 来创建和管理。Static Pod 通常用于集群管理工具（如 Kubernetes 本身）的部署和管理，尤其是在 Kubernetes 控制平面组件（如 etcd、kube-apiserver、kube-controller-manager 和 kube-scheduler）自身的管理中。\"]},\"31\":{\"h\":\"Static Pod 的特点\",\"t\":[\"由 kubelet 管理：\",\"Static Pod 由运行在节点上的 kubelet 直接管理，不需要 API Server 的参与。\",\"kubelet 会定期扫描特定的目录（通常是 /etc/kubernetes/manifests）中的 Pod 定义文件，并根据这些文件创建和管理 Pod。\",\"没有 ReplicaSet 或 Deployment：\",\"Static Pod 不是通过 Deployment、ReplicaSet 或其他控制器管理的，因此它们没有自动伸缩、滚动更新等高级特性。\",\"静态配置：\",\"Static Pod 的配置是静态文件，通常是 JSON 或 YAML 格式，存放在节点的文件系统中。\",\"这些配置文件不会因为 API Server 或 etcd 的故障而丢失，因此非常适合用于管理集群的核心组件。\",\"自动重启：\",\"如果 Static Pod 崩溃或被删除，kubelet 会根据配置文件自动重新创建它们，保证这些关键组件的高可用性。\"]},\"32\":{\"h\":\"创建 Static Pod\",\"t\":[\"要创建一个 Static Pod，你需要在节点的特定目录中（通常是 /etc/kubernetes/manifests）创建一个包含 Pod 定义的 YAML 文件。以下是一个示例：\",\"# 文件路径：/etc/kubernetes/manifests/static-pod-example.yaml apiVersion: v1 kind: Pod metadata: name: static-pod-example namespace: kube-system spec: containers: - name: nginx image: nginx:latest ports: - containerPort: 80\",\"将上述 YAML 文件保存到节点的 /etc/kubernetes/manifests 目录中后，kubelet 会自动检测到该文件并创建对应的 Pod。\"]},\"33\":{\"h\":\"使用场景\",\"t\":[\"Static Pod 通常用于以下场景：\",\"Kubernetes 控制平面组件：\",\"部署和管理 Kubernetes 控制平面组件（如 etcd、kube-apiserver、kube-controller-manager 和 kube-scheduler），这些组件必须在集群启动时运行，不能依赖于 Kubernetes 自身来管理。\",\"集群启动和恢复：\",\"在集群启动或恢复过程中，使用 Static Pod 确保关键组件能够独立于 Kubernetes API Server 和 etcd 正常启动。\",\"简化的节点管理：\",\"在一些简化的集群管理方案中，可能会使用 Static Pod 来运行节点级别的服务或代理，而不依赖于 Kubernetes 控制器。\"]},\"34\":{\"h\":\"监控和管理\",\"t\":[\"由于 Static Pod 由 kubelet 直接管理，因此它们的一些管理和监控操作与普通 Pod 略有不同：\",\"日志查看：你仍然可以使用 kubectl logs 命令查看 Static Pod 的日志。\",\"状态检查：可以使用 kubectl get pod -n kube-system 命令查看 Static Pod 的状态。\",\"更新 Pod：要更新 Static Pod，需要手动编辑对应的 YAML 文件，kubelet 会自动检测到文件的变化并重新创建 Pod。\",\"Static Pod 是 Kubernetes 提供的一种灵活机制，用于确保关键组件的高可用性和独立性，是集群稳定运行的关键保障之一。\"]},\"35\":{\"h\":\"Taint\",\"t\":[\"Taint 是 Kubernetes 中的一种机制，用于限制 Pod 在节点上运行的条件。Taint 可以应用于节点，并指定一个键值对，用于限制 Pod 在节点上运行的条件。\"]},\"36\":{\"h\":\"Taint 机制\",\"t\":[\"Taint 是应用在节点上的属性，表示这个节点对某些 Pod 来说是不合适的。每个 Taint 由三个部分组成：\",\"键（Key）：标识 Taint 的名称。\",\"值（Value）：标识 Taint 的具体值。\",\"效果（Effect）：标识 Taint 的作用方式。常见的效果有三种： \",\"NoSchedule：新的 Pod 不会被调度到这个节点上。\",\"PreferNoSchedule：尽量避免将新的 Pod 调度到这个节点上，但如果没有其他合适的节点，也可能会调度。\",\"NoExecute：已经运行在这个节点上的 Pod 会被驱逐，新 Pod 也不会被调度到这个节点上。\",\"节点设置taint\",\"kubectl taint no minikube level=high:NoSchedule\",\"移除 Taint\",\"kubectl taint no minikube level=high:NoSchedule-\",\"Pod设置toleration\",\"apiVersion: apps/v1 kind: Deployment metadata: name: nginx spec: replicas: 1 selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - name: nginx command: [\\\"python3\\\"] args: [\\\"-m\\\", \\\"http.server\\\", \\\"9999\\\"] image: \\\"registry.cnbita.com:5000/wangshi/python:3.10\\\" imagePullPolicy: IfNotPresent ports: - name: http containerPort: 80 protocol: TCP resources: requests: cpu: 100m memory: 128Mi limits: cpu: 500m memory: 256Mi tolerations: - key: \\\"level\\\" operator: \\\"Equal\\\" value: \\\"high\\\" effect: \\\"NoSchedule\\\"\",\"上述配置说明pod能够容忍节点设置taint的level=high:NoSchedule，如果pod不设置亲和性tolerations，则无法进行部署。如下所示：\",\"Tolerations: node.kubernetes.io/not-ready:NoExecute op=Exists for 300s node.kubernetes.io/unreachable:NoExecute op=Exists for 300s Events: Type Reason Age From Message ---- ------ ---- ---- ------- Warning FailedScheduling 3m57s default-scheduler 0/1 nodes are available: 1 node(s) had untolerated taint {level: high}. preemption: 0/1 nodes are available: 1 Preemption is not helpful for scheduling..\",\"在 Kubernetes 中，taint 是用于节点管理的机制，通过标记节点来影响 Pod 的调度。Taints 可以防止某些 Pod 调度到特定节点上，除非这些 Pod 具有相应的 toleration。这种机制有助于确保工作负载在集群中得到更好地分布和隔离。\"]},\"37\":{\"h\":\"无头服务（Headless Services）\",\"t\":[\"在 Kubernetes 中，Headless Service 是一种特殊类型的 Service，不会分配集群 IP（ClusterIP）。这种服务类型主要用于暴露 StatefulSet 的每个 Pod，并且允许直接访问每个 Pod。下面是对 Kubernetes Headless Service 的详细介绍：\"]},\"38\":{\"h\":\"Headless Service 的特点\",\"t\":[\"没有 Cluster IP：\",\"与普通的 Kubernetes Service 不同，Headless Service 不会为服务分配一个 Cluster IP。它通过将 ClusterIP 字段设置为 None 来实现这一点。\",\"直接访问 Pod：\",\"Headless Service 允许客户端直接访问服务后端的每个 Pod，而不是通过负载均衡器来访问。这对于需要直接与特定 Pod 进行通信的场景非常有用，例如 StatefulSet 中的数据库分片或有状态应用。\",\"DNS 解析：\",\"Headless Service 会为每个 Pod 创建一个 DNS 记录，这样客户端可以通过 DNS 名称直接访问特定的 Pod。对于 StatefulSet，每个 Pod 都有一个稳定的 DNS 名称。\"]},\"39\":{\"h\":\"使用场景\",\"t\":[\"Headless Service 主要用于以下几种场景：\",\"StatefulSet：\",\"StatefulSet 通常用于部署有状态应用，例如数据库集群或分布式文件系统。Headless Service 允许这些有状态应用中的各个 Pod 直接相互访问。\",\"自定义服务发现：\",\"在某些情况下，应用需要自定义的服务发现机制，而不是 Kubernetes 提供的负载均衡。Headless Service 允许应用自行管理和发现服务实例。\"]},\"40\":{\"h\":\"Headless Service 的定义示例\",\"t\":[\"以下是一个 Headless Service 的 YAML 定义示例：\",\"apiVersion: v1 kind: Service metadata: name: headless-service namespace: default spec: clusterIP: None selector: app: my-app ports: - name: http port: 80 targetPort: 8080\",\"这个示例定义了一个名为 headless-service 的服务，没有 ClusterIP。它选择了带有标签 app: my-app 的 Pod，并将流量从服务的 80 端口转发到 Pod 的 8080 端口。\"]},\"41\":{\"h\":\"StatefulSet 与 Headless Service 的结合\",\"t\":[\"以下是一个使用 Headless Service 的 StatefulSet 示例：\"]},\"42\":{\"h\":\"定义 Headless Service\",\"t\":[\"apiVersion: v1 kind: Service metadata: name: my-stateful-service namespace: default spec: clusterIP: None selector: app: my-stateful-app ports: - name: http port: 80 targetPort: 8080\"]},\"43\":{\"h\":\"定义 StatefulSet\",\"t\":[\"apiVersion: apps/v1 kind: StatefulSet metadata: name: my-stateful-app namespace: default spec: serviceName: \\\"my-stateful-service\\\" replicas: 3 selector: matchLabels: app: my-stateful-app template: metadata: labels: app: my-stateful-app spec: containers: - name: my-container image: my-image ports: - containerPort: 8080\",\"在这个例子中，my-stateful-service 是一个 Headless Service，它与 my-stateful-app StatefulSet 结合使用。每个 StatefulSet Pod 都有一个稳定的 DNS 名称，例如 my-stateful-app-0.my-stateful-service.default.svc.cluster.local。\"]},\"44\":{\"h\":\"总结\",\"t\":[\"Headless Service 是 Kubernetes 中的一种特殊服务类型，适用于需要直接访问每个 Pod 的场景。它通过不分配 Cluster IP 来实现这一点，并为每个 Pod 提供稳定的 DNS 记录。Headless Service 通常用于有状态应用和自定义服务发现场景，尤其是在 StatefulSet 中。\"]},\"45\":{\"h\":\"Kubelet的\",\"t\":[\"Kubelet 的 hairpin-mode 是一个配置选项，它决定了 Pod 内的容器是否能够通过 Pod 的 IP 访问自身以及同一 Pod 中的其他容器的服务。这种访问模式被称为“发夹模式（Hairpin Mode）”。具体来说，hairpin-mode 的作用是在容器网络接口上设置发夹规则，使得流量可以从容器发出后，又从同一个网络接口回到容器内部。\"]},\"46\":{\"h\":\"Hairpin Mode 的工作原理\",\"t\":[\"在发夹模式下，容器内的应用可以通过服务 IP 或者 Pod IP 访问同一 Pod 内的其他容器。这种模式主要用于以下情况：\",\"自访问：容器需要通过 Pod IP 访问自己，例如某些服务需要通过自身的外部 IP 进行健康检查。\",\"内部通信：同一个 Pod 内的多个容器之间的通信，通过 Pod 的网络接口实现内循环。\"]},\"47\":{\"h\":\"配置\",\"t\":[\"Kubelet 提供了几个选项来配置 hairpin-mode：\",\"hairpin-veth：启用发夹模式，这是默认模式。Kubelet 会在创建容器网络接口时启用发夹规则。\",\"promiscuous-bridge：使用混杂模式的网桥。这种模式在性能上可能有一些开销，但在某些网络插件或环境下可能是必要的。\",\"none：禁用发夹模式。这种模式下，容器无法通过 Pod IP 访问自身或同一 Pod 内的其他容器。\"]},\"48\":{\"h\":\"配置示例\",\"t\":[\"要配置 hairpin-mode，可以在 Kubelet 的启动参数中设置。例如，在 kubelet 配置文件中：\",\"apiVersion: kubelet.config.k8s.io/v1beta1 kind: KubeletConfiguration hairpinMode: hairpin-veth\",\"或者在启动 Kubelet 时通过命令行参数：\",\"kubelet --hairpin-mode=hairpin-veth\"]},\"49\":{\"h\":\"使用场景\",\"t\":[\"服务自身健康检查：某些服务需要通过 Pod IP 对自身进行健康检查。\",\"同一 Pod 内的容器通信：Pod 内部的不同容器通过 Pod IP 进行通信，简化网络配置。\"]},\"50\":{\"h\":\"总结\",\"t\":[\"hairpin-mode 是 Kubelet 的一个重要配置选项，用于控制容器是否能够通过 Pod IP 进行自访问和内部通信。根据具体的应用场景和需求，可以选择适当的发夹模式配置。常见的选择是默认的 hairpin-veth 模式，它能够在大多数场景下提供良好的性能和功能支持。\"]},\"51\":{\"h\":\"资源短缺\",\"t\":[\"QoS 划分的主要应用场景，是当宿主机资源紧张的时候，kubelet 对 Pod 进行 Eviction（即资源回收）时需要用到的。\",\"具体地说，当 Kubernetes 所管理的宿主机上不可压缩资源短缺时，就有可能触发 Eviction。比如，可用内存（memory.available）、可用的宿主机磁盘空间（nodefs.available），以及容器运行时镜像存储空间（imagefs.available）等等。\",\"目前，Kubernetes 为你设置的 Eviction 的默认阈值如下所示：\",\"memory.available<100Mi nodefs.available<10% nodefs.inodesFree<5% imagefs.available<15%\",\"上述各个触发条件在 kubelet 里都是可配置的\",\"kubelet --eviction-hard=imagefs.available<10%,memory.available<500Mi,nodefs.available<5%,nodefs.inodesFree<5% --eviction-soft=imagefs.available<30%,nodefs.available<10% --eviction-soft-grace-period=imagefs.available=2m,nodefs.available=2m --eviction-max-pod-grace-period=600\",\"Eviction 在 Kubernetes 里其实分为 Soft 和 Hard 两种模式。\",\"其中，Soft Eviction 允许你为 Eviction 过程设置一段“优雅时间”，比如上面例子里的 imagefs.available=2m，就意味着当 imagefs 不足的阈值达到 2 分钟之后，kubelet 才会开始 Eviction 的过程。\",\"而 Hard Eviction 模式下，Eviction 过程就会在阈值达到之后立刻开始。\",\"Kubernetes 计算 Eviction 阈值的数据来源，主要依赖于从 Cgroups 读取到的值，以及使用 cAdvisor 监控到的数据。\",\"Pod 的 QoS 类别： Guaranteed > Burstable > BestEffort\",\"Kubernetes 会保证只有当 Guaranteed 类别的 Pod 的资源使用量超过了其 limits 的限制，或者宿主机本身正处于 Memory Pressure 状态时，Guaranteed 的 Pod 才可能被选中进行 Eviction 操作。\"]},\"52\":{\"h\":\"如何能够让 Kubernetes 的调度器尽可能地将 Pod 分布在不同机器上，避免“堆叠”呢?\",\"t\":[\"在 Kubernetes 中，可以通过以下几种方式配置调度策略，以尽可能地将 Pod 分布在不同的节点上，避免“堆叠”：\"]},\"53\":{\"h\":\"1. Pod 反亲和性（Pod Anti-Affinity）\",\"t\":[\"Pod 反亲和性是一种调度约束，允许用户指定某些 Pod 不应该与其他特定 Pod 运行在同一个节点上。\"]},\"54\":{\"h\":\"示例\",\"t\":[\"apiVersion: v1 kind: Pod metadata: name: example-pod spec: affinity: podAntiAffinity: requiredDuringSchedulingIgnoredDuringExecution: - labelSelector: matchExpressions: - key: app operator: In values: - myapp topologyKey: \\\"kubernetes.io/hostname\\\"\",\"在这个示例中，podAntiAffinity 指定了具有相同标签 app=myapp 的 Pod 不应该被调度到相同的节点上。topologyKey 为 kubernetes.io/hostname，表示约束作用在节点级别。\"]},\"55\":{\"h\":\"2. 节点亲和性（Node Affinity）\",\"t\":[\"Node Affinity 允许调度器根据节点标签选择合适的节点。这可以用于避免将所有 Pod 调度到相同的节点。\"]},\"56\":{\"h\":\"示例\",\"t\":[\"apiVersion: v1 kind: Pod metadata: name: example-pod spec: affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: disktype operator: In values: - ssd\",\"这个示例展示了如何使用节点标签（disktype=ssd）进行调度，以确保 Pod 被调度到带有特定标签的节点上。\"]},\"57\":{\"h\":\"3. 分布式调度策略（Spread Constraints）\",\"t\":[\"Kubernetes 1.18 引入了 TopologySpreadConstraints，允许用户定义分布式调度策略，确保 Pod 均匀地分布在集群的不同节点上。\"]},\"58\":{\"h\":\"示例\",\"t\":[\"apiVersion: v1 kind: Pod metadata: name: example-pod spec: topologySpreadConstraints: - maxSkew: 1 topologyKey: kubernetes.io/hostname whenUnsatisfiable: DoNotSchedule labelSelector: matchLabels: app: myapp containers: - name: my-container image: my-image\",\"在这个示例中，topologySpreadConstraints 指定 Pod 应该均匀地分布在不同的节点上。maxSkew 表示同一节点上的 Pod 数量与其他节点上的最大偏差不超过1。\"]},\"59\":{\"h\":\"4. 自定义调度器策略（Custom Scheduler Policies）\",\"t\":[\"Kubernetes 允许使用自定义调度策略文件来自定义调度行为。例如，可以设置 EvenPodsSpreadPriority 来实现均匀调度。\"]},\"60\":{\"h\":\"示例\",\"t\":[\"自定义调度策略文件（scheduler-policy-config.json）：\",\"{ \\\"kind\\\": \\\"Policy\\\", \\\"apiVersion\\\": \\\"v1\\\", \\\"priorities\\\": [ { \\\"name\\\": \\\"EvenPodsSpreadPriority\\\", \\\"weight\\\": 1 } ] }\",\"启动调度器时使用该策略文件：\",\"kube-scheduler --policy-config-file=scheduler-policy-config.json\",\"通过配置这些策略，可以显著改善 Pod 在集群中的分布情况，避免“堆叠”问题，实现资源的更高效利用。\"]},\"61\":{\"h\":\"kubelet如何实现 exec、logs 等接口\",\"t\":[\"gRPC 接口调用期间，kubelet 需要跟容器项目维护一个长连接来传输数据。这种 API，我们就称之为 Streaming API。\",\"CRI shim 里对 Streaming API 的实现，依赖于一套独立的 Streaming Server 机制。\",\"可以看到，当我们对一个容器执行 kubectl exec 命令的时候，这个请求首先交给 API Server，然后 API Server 就会调用 kubelet 的 Exec API。\",\"这时，kubelet 就会调用 CRI 的 Exec 接口，而负责响应这个接口的，自然就是具体的 CRI shim。\",\"但在这一步，CRI shim 并不会直接去调用后端的容器项目（比如 Docker ）来进行处理，而只会返回一个 URL 给 kubelet。这个 URL，就是该 CRI shim 对应的 Streaming Server 的地址和端口。\",\"而 kubelet 在拿到这个 URL 之后，就会把它以 Redirect 的方式返回给 API Server。所以这时候，API Server 就会通过重定向来向 Streaming Server 发起真正的 /exec 请求，与它建立长连接\",\"当然，这个 Streaming Server 本身，是需要通过使用 SIG-Node 为你维护的 Streaming API 库来实现的。并且，Streaming Server 会在 CRI shim 启动时就一起启动。此外，Stream Server 这一部分具体怎么实现，完全可以由 CRI shim 的维护者自行决定。比如，对于 Docker 项目来说，dockershim 就是直接调用 Docker 的 Exec API 来作为实现的。\"]},\"62\":{\"h\":\"集群安装\",\"t\":[\"kubeadm init --cri-socket unix:///var/run/cri-dockerd.sock\",\"kubeadm reset --cri-socket unix:///var/run/cri-dockerd.sock\",\"解决\",\"l 29 15:07:31 DESKTOP-P54EAF3 kubelet[3437386]: I0729 15:07:31.604995 3437386 server.go:469] \\\"Golang settings\\\" GOGC=\\\"\\\" GOMAXPROCS=\\\"\\\" GOTRACEBACK=\\\"\\\" Jul 29 15:07:31 DESKTOP-P54EAF3 kubelet[3437386]: I0729 15:07:31.605172 3437386 server.go:895] \\\"Client rotation is on, will bootstrap in background\\\" Jul 29 15:07:31 DESKTOP-P54EAF3 kubelet[3437386]: I0729 15:07:31.607274 3437386 certificate_store.go:130] Loading cert/key pair from \\\"/var/lib/kubelet/pki/kubelet-client-current.pem\\\". Jul 29 15:07:31 DESKTOP-P54EAF3 kubelet[3437386]: I0729 15:07:31.608035 3437386 dynamic_cafile_content.go:157] \\\"Starting controller\\\" name=\\\"client-ca-bundle::/etc/kubernetes/pki/ca.crt\\\" Jul 29 15:07:31 DESKTOP-P54EAF3 kubelet[3437386]: W0729 15:07:31.611818 3437386 sysinfo.go:203] Nodes topology is not available, providing CPU topology Jul 29 15:07:31 DESKTOP-P54EAF3 kubelet[3437386]: I0729 15:07:31.619656 3437386 server.go:725] \\\"--cgroups-per-qos enabled, but --cgroup-root was not specified. defaulting to /\\\" Jul 29 15:07:31 DESKTOP-P54EAF3 kubelet[3437386]: E0729 15:07:31.619995 3437386 run.go:74] \\\"command failed\\\" err=\\\"failed to run Kubelet: running with swap on is not supported, please disable swap! or set --fail-swap-on flag to false. /proc/swaps contained: [Filename\\\\t\\\\t\\\\t\\\\tType\\\\t\\\\tSize\\\\t\\\\tUsed\\\\t\\\\tPriority /dev/sdb partition\\\\t4194304\\\\t\\\\t8580\\\\t\\\\t-2]\\\" Jul 29 15:07:31 DESKTOP-P54EAF3 systemd[1]: kubelet.service: Main process exited, code=exited, status=1/FAILURE Jul 29 15:07:31 DESKTOP-P54EAF3 systemd[1]: kubelet.service: Failed with result 'exit-code'.\"]},\"63\":{\"c\":[\"k8s\"]},\"64\":{\"c\":[\"笔记\"]},\"65\":{\"h\":\"Kong和Nginx部署服务\",\"t\":[\"Kong和Nginx创建服务和路由\",\"下面是你使用Kong和Nginx创建服务和路由的步骤总结：\"]},\"66\":{\"h\":\"1. Nginx容器启动\",\"t\":[\"你通过以下命令启动了一个Nginx容器，该容器暴露8088端口并挂载了配置文件和项目目录：\",\"docker run -itd --name nginx --privileged --restart=always --network=kong-net -m 2GB -p 8088:8088 -v /mnt/d/docker/nginx/project:/data/project -v /mnt/d/docker/nginx/conf/nginx.conf:/etc/nginx/nginx.conf nginx:latest\",\"容器名: nginx\",\"网络: kong-net\",\"端口映射: 8088:8088\",\"挂载: 项目目录和nginx配置文件\"]},\"67\":{\"h\":\"2. 安装Kong\",\"t\":[\"按照Kong官方文档安装指南安装了Kong，并确保Kong服务已正确启动。\"]},\"68\":{\"h\":\"3. 创建服务\",\"t\":[\"通过以下命令在Kong中创建了一个名为 hello_service 的服务，指向Nginx服务中的 index.html 文件：\",\"curl -i -s -X POST http://localhost:8001/services \\\\ --data name=hello_service \\\\ --data url='http://nginx:8088/index.html'\"]},\"69\":{\"h\":\"4. 查询服务\",\"t\":[\"通过以下命令查询了服务是否成功创建：\",\"curl -X GET http://localhost:8001/services/hello_service\"]},\"70\":{\"h\":\"5. 删除服务\",\"t\":[\"如果需要删除服务，可以使用以下命令：\",\"curl -i -s -X DELETE http://localhost:8001/services/hello_service\"]},\"71\":{\"h\":\"6. 创建路由\",\"t\":[\"为 hello_service 创建了一个路由 hello_route，设置路径为 /hello：\",\"curl -i -X POST http://localhost:8001/services/hello_service/routes \\\\ --data 'paths[]=/hello' \\\\ --data name=hello_route\"]},\"72\":{\"h\":\"7. 查询路由\",\"t\":[\"通过以下命令查询了路由是否成功创建：\",\"curl -X GET http://localhost:8001/services/hello_service/routes/hello_route\"]},\"73\":{\"h\":\"8. 删除路由\",\"t\":[\"如果需要删除路由，可以使用以下命令：\",\"curl -i -s -X DELETE http://localhost:8001/routes/hello_route\"]},\"74\":{\"h\":\"9. 访问服务\",\"t\":[\"最终，你可以通过以下命令访问Kong代理的服务：\",\"curl -X GET http://localhost:8000/hello\",\"这将通过Kong访问到Nginx提供的 index.html 页面。\"]},\"75\":{\"h\":\"总结\",\"t\":[\"Nginx容器: 用于提供静态文件，通过Kong路由访问。\",\"Kong服务: 用于管理和代理请求，将Kong中的服务映射到Nginx容器中的资源。\",\"Kong路由: 用于定义访问路径，将特定的路径请求路由到相应的服务。\",\"验证和管理: 通过 curl 命令查询、删除服务和路由，确保配置正确。\",\"这个配置实现了通过Kong网关将请求转发到Nginx容器中的具体路径。\",\"index.html\",\"<!DOCTYPE html> <html lang=\\\"en\\\"> <head> <meta charset=\\\"UTF-8\\\"> <meta name=\\\"viewport\\\" content=\\\"width=device-width, initial-scale=1.0\\\"> <title>Hello World</title> <style> body { display: flex; justify-content: center; align-items: center; height: 100vh; margin: 0; background: linear-gradient(to right, #ff7e5f, #feb47b); /* 渐变背景 */ color: white; font-family: Arial, sans-serif; font-size: 48px; } h1 { margin: 0; } footer { text-align: center; position: absolute; bottom: 10px; width: 100%; font-size: 14px; color: #ffffff; } </style> </head> <body> <h1>Hello, World!</h1> <footer> <p><a href=\\\"https://beian.miit.gov.cn/\\\" target=\\\"_blank\\\" style=\\\"color: white;\\\">8888888</a></p> </footer> </body> </html>\",\"nginx.conf\",\"worker_processes 1; events { worker_connections 1024; } http { include mime.types; default_type application/octet-stream; access_log off; error_log /dev/null crit; sendfile on; keepalive_timeout 65; server { listen 8088; server_name localhost; ssl_session_cache shared:SSL:1m; ssl_session_timeout 30m; ssl_prefer_server_ciphers on; # 安全链接可选的加密协议 ssl_protocols TLSv1.1 TLSv1.2 TLSv1.3; # 配置加密套件/加密算法，写法遵循 openssl 标准。 ssl_ciphers EECDH+CHACHA20:EECDH+CHACHA20-draft:EECDH+AES128:RSA+AES128:EECDH+AES256:RSA+AES256:EECDH+3DES:RSA+3DES:!MD5; location / { proxy_redirect off; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection \\\"upgrade\\\"; proxy_read_timeout 3600s; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; proxy_set_header X-Forwarded-Port $server_port; add_header backendIP $upstream_addr; add_header backendCode $upstream_status; # 允许跨域的请求，可以自定义变量$http_origin，*表示所有 add_header 'Access-Control-Allow-Origin' *; # 允许携带cookie请求 add_header 'Access-Control-Allow-Credentials' 'true'; # 允许跨域请求的方法：GET,POST,OPTIONS,PUT add_header 'Access-Control-Allow-Methods' 'GET,POST,OPTIONS,PUT'; # 允许请求时携带的头部信息，*表示所有 add_header 'Access-Control-Allow-Headers' *; # 允许发送按段获取资源的请求 add_header 'Access-Control-Expose-Headers' 'Content-Length,Content-Range'; add_header X-Frame-Options SAMEORIGIN always; # 禁用缓存 proxy_cache off; # 添加 Cache-Control 响应头 add_header Cache-Control \\\"no-cache, no-store\\\"; # 一定要有！！！否则Post请求无法进行跨域！ # 在发送Post跨域请求前，会以Options方式发送预检请求，服务器接受时才会正式请求 if ($request_method = 'OPTIONS') { add_header 'Access-Control-Max-Age' 1728000; add_header 'Content-Type' 'text/plain; charset=utf-8'; add_header 'Content-Length' 0; # 对于Options方式的请求返回204，表示接受跨域请求 return 204; } root /data/project; index index.html; # 默认文件名 } } }\"]},\"76\":{\"c\":[\"kong\"]},\"77\":{\"c\":[\"kong\",\"nginx\",\"html\"]},\"78\":{\"h\":\"Kubeflow 简介\",\"t\":[\"k8s 云原生之Kubeflow 简介\",\"https://www.kubeflow.org/docs/started/introduction/\",\"Kubeflow 简介 Kubeflow 项目致力于让机器学习 (ML) 工作流在 Kubernetes 上的部署变得简单、可移植且可扩展。我们的目标不是重新创建其他服务，而是提供一种简单的方法，将最佳的 ML 开源系统部署到各种基础设施中。只要您运行 Kubernetes，就可以运行 Kubeflow。 下图展示了主要的 Kubeflow 组件，涵盖 Kubernetes 之上 ML 生命周期的每个步骤。 \",\"Kubeflow 是一个面向想要构建和试验 ML 管道的数据科学家的平台。Kubeflow 还适用于想要将 ML 系统部署到各种环境以进行开发、测试和生产级服务的 ML 工程师和运营团队。\"]},\"79\":{\"h\":\"概念概述\",\"t\":[\"Kubeflow 是_Kubernetes 的 ML 工具包_。 下图展示了 Kubeflow 作为在 Kubernetes 之上安排 ML 系统组件的平台： \"]},\"80\":{\"h\":\"Pipeline\",\"t\":[\"在高层次上，管道的执行过程如下：\"]},\"81\":{\"h\":\"Python SDK：\",\"t\":[\"使用Kubeflow Pipelines特定领域语言（DSL）创建组件或指定管道。\"]},\"82\":{\"h\":\"：\",\"t\":[\"DSL编译器将您的管道的Python代码转换为静态配置（YAML）。\"]},\"83\":{\"h\":\"：\",\"t\":[\"调用管道服务以从静态配置创建管道运行。\"]},\"84\":{\"h\":\"：\",\"t\":[\"管道服务调用Kubernetes API服务器以创建运行管道所需的必要Kubernetes资源（CRD）。\"]},\"85\":{\"h\":\"：\",\"t\":[\"一组编排控制器执行完成管道所需的容器。这些容器在虚拟机上的Kubernetes Pod中执行。一个示例控制器是Argo Workflow控制器，它编排基于任务的工作流。\"]},\"86\":{\"h\":\"：\",\"t\":[\"Pod存储两种类型的数据：\",\"Metadata：实验、作业、管道运行和单个标量指标。度量数据被聚合用于排序和过滤。Kubeflow Pipelines将元数据存储在MySQL数据库中。\",\"Artifacts：管道包、视图和大规模指标（时间序列）。使用大规模指标来调试管道运行或调查单个运行的性能。Kubeflow Pipelines将工件存储在像Minio服务器或Cloud Storage之类的工件存储中。\",\"MySQL数据库和Minio服务器都由Kubernetes持久卷子系统支持。\"]},\"87\":{\"h\":\"：\",\"t\":[\"管道持久性代理监视管道服务创建的Kubernetes资源，并将这些资源的状态持久化到ML元数据服务中。管道持久性代理记录已执行的容器集合及其输入和输出。输入/输出包括容器参数或数据工件URI。\"]},\"88\":{\"h\":\"：\",\"t\":[\"管道Web服务器从各种服务中收集数据以显示相关视图：当前运行的管道列表、管道执行历史记录、数据工件列表、有关单个管道运行的调试信息、有关单个管道运行的执行状态。\"]},\"89\":{\"h\":\"Pipeline\",\"t\":[\"在 Kubeflow Pipelines 中，管道是对机器学习（ML）工作流的描述，包括工作流中的所有组件及其相互关系，以图的形式呈现。管道配置包括运行管道所需的输入（参数）的定义，以及每个组件的输入和输出。 当你运行一个管道时，系统会启动一个或多个 Kubernetes Pod，这些 Pod 对应于工作流（管道）中的各个步骤（组件）。这些 Pod 会启动 Docker 容器，而容器则会启动你的程序。 开发完成管道后，你可以使用 Kubeflow Pipelines UI 或 Kubeflow Pipelines SDK 上传你的管道。\"]},\"90\":{\"h\":\"Component\",\"t\":[\"在 Kubeflow Pipelines 中，组件是一个独立的代码集，它执行机器学习（ML）工作流（管道）中的某一步骤，例如数据预处理、数据转换、模型训练等。组件类似于函数，具有名称、参数、返回值和主体。\"]},\"91\":{\"h\":\"组件代码\",\"t\":[\"每个组件的代码包括以下部分：\",\"客户端代码：与端点通信以提交作业的代码。例如，与 Google Dataproc API 通信以提交 Spark 作业的代码。\",\"运行时代码：执行实际作业的代码，通常在集群中运行。例如，将原始数据转换为预处理数据的 Spark 代码。\",\"关于客户端代码和运行时代码的命名约定——对于名为“mytask”的任务：\",\"mytask.py 程序包含客户端代码。\",\"mytask 目录包含所有运行时代码。\"]},\"92\":{\"h\":\"组件定义\",\"t\":[\"用 YAML 格式的组件规范描述 Kubeflow Pipelines 系统中的组件。组件定义包括以下部分：\",\"元数据：名称、描述等。\",\"接口：输入/输出规范（名称、类型、描述、默认值等）。\",\"实现：描述在给定组件输入参数值的情况下如何运行组件的规范。实现部分还描述了组件完成运行后如何获取输出值。\",\"有关组件的完整定义，请参见组件规范。\"]},\"93\":{\"h\":\"容器化组件\",\"t\":[\"你必须将组件打包为 Docker 镜像。组件代表容器内的特定程序或入口点。 管道中的每个组件独立执行。组件不会在同一进程中运行，也不能直接共享内存数据。你必须将传递给组件之间的数据序列化（转换为字符串或文件），以便数据可以在分布式网络上传输。然后，必须反序列化这些数据以供下游组件使用。\"]},\"94\":{\"h\":\"Graph\",\"t\":[\"在 Kubeflow Pipelines 中，图（Graph）是管道运行时在 Kubeflow Pipelines UI 中的图形表示。图显示了管道运行已执行或正在执行的步骤，箭头指示了管道组件之间的父/子关系。运行一开始，就可以查看这个图。图中的每个节点对应管道中的一个步骤，并进行相应的标注。 每个节点的右上角有一个图标，指示其状态：运行中（running）、成功（succeeded）、失败（failed）或跳过（skipped）。当节点的父节点包含条件语句时，节点可能会被跳过。\"]},\"95\":{\"h\":\"Experiment\",\"t\":[\"实验是一个工作空间，你可以在其中尝试管道的不同配置。你可以使用实验将你的运行组织成逻辑组。实验可以包含任意的运行，包括定期运行。\",\"一次运行（run）是对管道的单次执行。运行包含你尝试的所有实验的不可变日志，设计为自包含的，以便于重现。你可以通过查看 Kubeflow Pipelines UI 上的运行详情页面来跟踪运行的进度，在那里你可以看到运行时的图表、输出工件和每个步骤的日志。 定期运行（recurring run）或在 Kubeflow Pipelines 后端 API 中称为作业（job），是管道的可重复运行。定期运行的配置包括指定所有参数值的管道副本和运行触发器。你可以在任何实验中启动定期运行，它会定期启动运行配置的新副本。你可以从 Kubeflow Pipelines UI 启用/禁用定期运行。你还可以指定最大并发运行数，以限制并行启动的运行数量。如果管道预计运行时间较长且触发频繁运行，这会很有帮助。\",\"运行触发器是一个标志，用于告知系统何时生成新的定期运行配置。可用的运行触发器类型包括：\",\"周期性（Periodic）：基于时间间隔调度运行（例如：每2小时或每45分钟）。\",\"Cron：使用 cron 语法调度运行。\",\"步骤（step）是管道中某个组件的执行。步骤与其组件之间的关系是一种实例化关系，类似于运行与其管道之间的关系。在复杂的管道中，组件可以在循环中多次执行，或在解析管道代码中的 if/else 类似子句后有条件地执行。\",\"输出工件（output artifact）是由管道组件发出的输出，Kubeflow Pipelines UI 能理解并呈现为丰富的可视化内容。包括工件在内的管道组件非常有用，因为它们可以用于性能评估、快速决策或不同运行间的比较。工件还使得理解管道各个组件的工作方式成为可能。工件可以是简单的文本数据视图，也可以是丰富的交互式可视化。\",\"注意：Kubeflow Pipelines 已从使用 kubeflow/metadata 转向使用 google/ml-metadata 作为元数据依赖。 Kubeflow Pipelines 后端将管道运行的运行时信息存储在元数据存储中。运行时信息包括任务的状态、工件的可用性、与执行或工件关联的自定义属性等。了解更多信息，请参阅 ML Metadata 入门指南。 如果一个工件被多个不同运行中的执行使用，你可以查看跨管道运行的工件和执行之间的连接。这种连接可视化称为谱系图（Lineage Graph）。\",\"Argo 工作流执行器是一个符合特定接口的进程，使 Argo 能够执行某些操作，如监控 Pod 日志、收集工件、管理容器生命周期等。 Kubeflow Pipelines 使用 Argo Workflows 作为工作流引擎，因此 Kubeflow Pipelines 用户需要选择一个工作流执行器。\"]},\"96\":{\"h\":\"主要的 Argo 工作流执行器类型包括：\",\"t\":[\"K8sAPIExecutor：通过 Kubernetes API 直接与集群交互，执行和监控容器。这是默认的执行器，适用于大多数场景。\",\"PNSExecutor：通过共享的进程命名空间（Process Namespace Sharing），使主容器可以访问子容器的文件系统和进程。这对于需要在容器之间共享数据的工作流特别有用。\",\"EmissaryExecutor：基于 Emissary-Ingress，专为高效的文件操作和网络操作设计，适用于需要高效处理大量小文件的工作流。 自 2022 年 2 月 Kubeflow Pipelines 1.8 正式发布以来，Emissary 执行器一直是 Kubeflow Pipelines 的默认执行器。\",\"DockerExecutor：直接与 Docker 守护进程交互来管理容器。这种方法依赖于 Docker，在某些 Kubernetes 配置中可能不适用。\"]},\"97\":{\"h\":\"如何选择适合的执行器：\",\"t\":[\"选择合适的工作流执行器取决于工作流的具体需求和集群环境：\",\"默认选择 K8sAPIExecutor：如果你的工作流不需要特别的资源共享或文件处理，默认的 K8sAPIExecutor 通常是最合适的选择。\",\"选择 PNSExecutor：如果你的工作流步骤之间需要共享文件或进程命名空间，那么 PNSExecutor 是一个好的选择。\",\"选择 EmissaryExecutor：如果你的工作流需要高效处理大量文件操作，尤其是小文件，可以选择 EmissaryExecutor。\",\"选择 DockerExecutor：如果你更熟悉 Docker 并且你的集群配置支持 Docker，可以考虑 DockerExecutor，但要注意其兼容性问题。\",\"注意，Argo Workflows 支持其他工作流执行器，但 Kubeflow Pipelines 团队仅推荐在 Emissary 执行器和 Docker 执行器之间进行选择。在配置 Kubeflow Pipelines 时，用户可以根据具体需求和工作流特点选择合适的 Argo 工作流执行器，以优化管道的执行效率和资源管理。\",\"[root@yigou-stg-101-61 ~]# kubectl get po -n kubeflow NAME READY STATUS RESTARTS AGE controller-manager-78d9bcc678-bgwtr 1/1 Running 0 17h katib-controller-7d7dffdb8f-7c6vk 1/1 Running 0 17h katib-db-manager-77d684cf4-tqtgh 1/1 Running 0 17h katib-ui-849479cf5f-rgmgf 1/1 Running 0 17h metadata-grpc-deployment-66457c4745-q9ddn 1/1 Running 0 17h metadata-writer-9956596d8-92g5h 1/1 Running 0 17h ml-pipeline-7cc7c5b47-k8r6z 1/1 Running 1 (17h ago) 17h ml-pipeline-persistenceagent-6c686b5b54-9bzwq 1/1 Running 0 17h ml-pipeline-scheduledworkflow-d894ffcd8-65j6h 1/1 Running 0 17h ml-pipeline-ui-57dbbdfd77-5bbh9 1/1 Running 0 17h ml-pipeline-viewer-crd-86868f775c-thcd8 1/1 Running 0 17h ml-pipeline-visualizationserver-5499555669-fsgks 1/1 Running 0 17h workflow-controller-799c5f4b48-nv8km 1/1 Running 0 17h\",\"下面是每个 Pod 的功能简介：\",\"controller-manager-78d9bcc678-bgwtr：\",\"控制器管理器 Pod，负责管理 Kubernetes 集群中的控制器，如 ReplicaSet、Deployment 等。\",\"katib-controller-7d7dffdb8f-7c6vk：\",\"Katib 控制器 Pod，是 Katib（超参数调优工具）的控制器组件，负责管理和调度超参数搜索任务。\",\"katib-db-manager-77d684cf4-tqtgh：\",\"Katib 数据库管理器 Pod，负责管理 Katib 的数据库，存储超参数调优任务的状态和结果。\",\"katib-ui-849479cf5f-rgmgf：\",\"Katib 用户界面 Pod，提供 Katib 的 Web 用户界面，用于查看和监控超参数调优任务的状态和结果。\",\"metadata-grpc-deployment-66457c4745-q9ddn：\",\"元数据 gRPC 服务 Pod，提供 Kubernetes 元数据服务，允许用户在 Kubeflow Pipelines 中创建和管理元数据。\",\"metadata-writer-9956596d8-92g5h：\",\"元数据写入器 Pod，负责将元数据写入到存储后端，与元数据 gRPC 服务一起用于 Kubeflow Pipelines。\",\"ml-pipeline-7cc7c5b47-k8r6z：\",\"ML Pipeline Pod，是 Kubeflow Pipelines 的核心组件之一，提供了机器学习工作流的定义、运行和监控功能。\",\"registry.cnbita.com:5000/kubeflow-pipelines/api-server\",\"backend/src/apiserver\",\"backend\\\\Dockerfile\",\"ml-pipeline-persistenceagent-6c686b5b54-9bzwq：\",\"ML Pipeline 持久化代理 Pod，负责管理 Kubeflow Pipelines 的持久化存储，存储工作流定义和执行状态。\",\"ml-pipeline-scheduledworkflow-d894ffcd8-65j6h：\",\"ML Pipeline 定时工作流 Pod，负责调度和执行 Kubeflow Pipelines 中的定时任务。\",\"ml-pipeline-ui-57dbbdfd77-5bbh9：\",\"ML Pipeline 用户界面 Pod，提供 Kubeflow Pipelines 的 Web 用户界面，用于创建、运行和监控机器学习工作流。\",\"ml-pipeline-viewer-crd-86868f775c-thcd8：\",\"ML Pipeline 视图 CRD Pod，用于自定义 Kubeflow Pipelines 中的自定义资源定义（CRD）的展示。\",\"ml-pipeline-visualizationserver-5499555669-fsgks：\",\"ML Pipeline 可视化服务器 Pod，提供 Kubeflow Pipelines 的可视化服务，用于展示机器学习工作流的执行状态和结果。\",\"workflow-controller-799c5f4b48-nv8km：\",\"工作流控制器 Pod，是 Kubeflow Pipelines 的控制器组件之一，负责管理和执行工作流任务。\",\"这些 Pod 组成了 Kubeflow 中的各个核心组件，提供了从超参数调优到机器学习工作流管理的完整功能。这些 Pod 之间有一定的关联关系，它们共同组成了 Kubeflow 平台，用于支持机器学习工作流的定义、运行、监控和优化。以下是它们之间的一些主要关联关系：\",\"控制器管理器 (controller-manager)：\",\"负责管理 Kubernetes 集群中的各种控制器，确保其他 Pod 和服务正常运行。\",\"Katib 组件：\",\"katib-controller：管理和调度超参数调优任务。\",\"katib-db-manager：管理存储 Katib 数据的数据库。\",\"katib-ui：提供 Katib 的 Web 用户界面。\",\"Katib 的各个组件通过数据库和控制器进行通信和协调，共同实现超参数调优功能。\",\"元数据服务 (metadata-grpc-deployment 和 metadata-writer)：\",\"metadata-grpc-deployment：提供 gRPC 接口，用于管理元数据。\",\"metadata-writer：负责将元数据写入到持久化存储中。\",\"这些组件通过元数据存储和 gRPC 接口进行通信，支持 Kubeflow Pipelines 中的元数据管理。\",\"Kubeflow Pipelines 组件：\",\"ml-pipeline：核心组件，负责机器学习工作流的定义、运行和监控。\",\"ml-pipeline-persistenceagent：管理工作流的持久化存储。\",\"ml-pipeline-scheduledworkflow：调度和执行定时任务。\",\"ml-pipeline-ui：提供 Web 用户界面，允许用户交互和监控工作流。\",\"ml-pipeline-viewer-crd：展示自定义资源定义（CRD）。\",\"ml-pipeline-visualizationserver：提供工作流执行状态和结果的可视化。\",\"这些组件通过存储系统、API 和用户界面进行紧密集成，形成完整的机器学习工作流管理平台。\",\"工作流控制器 (workflow-controller)：\",\"负责管理和执行工作流任务，确保工作流按照定义的步骤顺利执行。\",\"与 Kubeflow Pipelines 组件紧密合作，管理和协调工作流的各个部分。\",\"总体而言，这些 Pod 通过 Kubernetes 集群中的服务和控制器进行通信和协调，共同提供了一个功能强大的机器学习工作流管理平台。\"]},\"98\":{\"h\":\"controller-manager\",\"t\":[\"apiVersion: apps/v1 kind: Deployment metadata: name: controller-manager labels: control-plane: controller-manager controller-tools.k8s.io: \\\"1.0\\\" spec: selector: matchLabels: control-plane: controller-manager controller-tools.k8s.io: \\\"1.0\\\" template: metadata: labels: control-plane: controller-manager controller-tools.k8s.io: \\\"1.0\\\" spec: containers: - command: - /kube-app-manager # Built from https://github.com/kubernetes-sigs/application master branch on the date specified in the image tag. image: gcr.io/ml-pipeline/application-crd-controller:20231101 imagePullPolicy: IfNotPresent name: manager env: - name: NAMESPACE valueFrom: fieldRef: fieldPath: metadata.namespace resources: limits: cpu: 100m memory: 30Mi requests: cpu: 100m memory: 20Mi serviceAccountName: application\"]},\"99\":{\"h\":\"官网地址\",\"t\":[\"https://github.com/kubernetes-sigs/application\"]},\"100\":{\"h\":\"Kubernetes 应用程序\",\"t\":[\"Kubernetes 是一个开源系统，用于自动化部署、扩展和管理容器化应用程序。 上述描述来自 Kubernetes 主页，主要集中在容器化应用程序上。然而，Kubernetes 的元数据、对象和可视化（例如在 Dashboard 中）都集中在容器基础设施上，而不是应用程序本身。 本项目中的应用程序 CRD（自定义资源定义）和控制器旨在改变这种状况，使其能够在众多支持工具之间实现互操作。\"]},\"101\":{\"h\":\"它提供了：\",\"t\":[\"描述应用程序元数据的能力（例如，运行一个像 WordPress 这样的应用程序）\",\"一个连接基础设施（例如 Deployments）的根对象。这对于将各种资源联系在一起甚至清理（即垃圾回收）很有用\",\"为支持应用程序提供信息，帮助它们查询和理解支持应用程序的对象\",\"应用程序级别的健康检查\"]},\"102\":{\"h\":\"这可以被以下用户使用：\",\"t\":[\"希望以应用程序为中心进行操作的应用程序运营商\",\"像 Helm 这样的工具，它们将其软件包发布集中在应用程序安装上，并且希望与其他工具（例如 Dashboard）实现互操作\",\"希望可视化应用程序（不仅仅是基础设施视图）的 Dashboards\"]},\"103\":{\"h\":\"目标\",\"t\":[\"提供一个用于在 Kubernetes 中创建、查看和管理应用程序的标准 API。\",\"提供通过 kubectl 与应用程序 API 交互的 CLI 实现。\",\"提供应用程序的安装状态和垃圾回收。\",\"提供一种标准方式，使应用程序能够向 UI 展示基本的健康检查。\",\"提供一种明确的机制，使应用程序能够声明对另一个应用程序的依赖关系。\",\"通过创建工具可以实现的标准，促进生态系统工具和 UI 之间的互操作性。\",\"促进 Kubernetes 应用程序使用通用的标签和注释。\"]},\"104\":{\"h\":\"非目标\",\"t\":[\"创建一个所有工具必须实现的标准。\",\"提供一种方式，使 UI 能够显示应用程序的指标。\"]},\"105\":{\"h\":\"什么是 Katib？\",\"t\":[\"Katib 是一个原生于 Kubernetes 的自动化机器学习（AutoML）项目。Katib 支持超参数调优、提前停止和神经架构搜索（NAS）。了解更多 AutoML 信息，请访问 fast.ai、Google Cloud、Microsoft Azure 或 Amazon SageMaker。 Katib 是一个与机器学习（ML）框架无关的项目。它可以调优用任何用户选择的语言编写的应用程序的超参数，并且本身支持许多 ML 框架，例如 TensorFlow、MXNet、PyTorch、XGBoost 等。 Katib 支持多种 AutoML 算法，例如贝叶斯优化（Bayesian optimization）、帕尔森估计树（Tree of Parzen Estimators）、随机搜索（Random Search）、协方差矩阵自适应进化策略（Covariance Matrix Adaptation Evolution Strategy）、Hyperband、高效神经架构搜索（Efficient Neural Architecture Search）、可微分架构搜索（Differentiable Architecture Search）等等。更多算法支持即将推出。 Katib 项目是开源的。开发者指南是希望为该项目做出贡献的开发者的良好起点。 \"]},\"106\":{\"h\":\"为什么选择 Katib？\",\"t\":[\"Katib 解决了 AI/ML 生命周期中的自动化机器学习（AutoML）步骤中的超参数优化或神经架构搜索问题，如下图所示： \",\"多节点和多GPU分布式训练：Katib 可以协调多节点和多GPU的分布式训练工作负载。\",\"与 Kubeflow Training Operator 集成：Katib 与 Kubeflow 的训练操作（如 PyTorchJob）集成，允许优化任何规模的大模型的超参数。\",\"此外，Katib 可以协调更高级的优化工作流，如 Argo Workflows 和 Tekton Pipelines。\",\"可扩展性和可移植性：Katib 是可扩展和可移植的。Katib 运行 Kubernetes 容器来执行超参数调优任务，这使得 Katib 可以与任何 ML 训练框架一起使用。\",\"用户甚至可以使用 Katib 来优化非ML任务，只要能够收集优化指标。\",\"丰富的优化算法支持：Katib 与许多优化框架（如 Hyperopt 和 Optuna）集成，这些框架实现了大多数最先进的优化算法。\",\"用户可以利用 Katib 控制平面来实现和基准测试他们自己的优化算法。\"]},\"107\":{\"h\":\"pipeline服务注册流程\",\"t\":[\" 其他服务注册在 startRpcServer 函数中，注册了以下服务：\"]},\"108\":{\"h\":\"API v1beta1 注册的服务\",\"t\":[\"ExperimentService: 实验服务\",\"apiv1beta1.RegisterExperimentServiceServer(s, sharedExperimentServer)\",\"PipelineService: 流水线服务\",\"apiv1beta1.RegisterPipelineServiceServer(s, sharedPipelineServer)\",\"JobService: 作业服务\",\"apiv1beta1.RegisterJobServiceServer(s, sharedJobServer)\",\"RunService: 运行服务\",\"apiv1beta1.RegisterRunServiceServer(s, sharedRunServer)\",\"TaskService: 任务服务\",\"apiv1beta1.RegisterTaskServiceServer(s, server.NewTaskServer(resourceManager))\",\"ReportService: 报告服务\",\"apiv1beta1.RegisterReportServiceServer(s, server.NewReportServer(resourceManager))\",\"VisualizationService: 可视化服务\",\"apiv1beta1.RegisterVisualizationServiceServer( s, server.NewVisualizationServer( resourceManager, common.GetStringConfig(cm.VisualizationServiceHost), common.GetStringConfig(cm.VisualizationServicePort), ))\",\"AuthService: 认证服务\",\"apiv1beta1.RegisterAuthServiceServer(s, server.NewAuthServer(resourceManager))\"]},\"109\":{\"h\":\"API v2beta1 注册的服务\",\"t\":[\"ExperimentService: 实验服务\",\"apiv2beta1.RegisterExperimentServiceServer(s, sharedExperimentServer)\",\"PipelineService: 流水线服务\",\"apiv2beta1.RegisterPipelineServiceServer(s, sharedPipelineServer)\",\"RecurringRunService: 定期运行服务\",\"apiv2beta1.RegisterRecurringRunServiceServer(s, sharedJobServer)\",\"RunService: 运行服务\",\"apiv2beta1.RegisterRunServiceServer(s, sharedRunServer)\"]},\"110\":{\"h\":\"其他\",\"t\":[\"ReflectionService: 反射服务\",\"reflection.Register(s)\"]},\"111\":{\"h\":\"总结\",\"t\":[\"在这个 startRpcServer 函数中，注册了以下 13 个服务：\",\"ExperimentService（v1beta1 和 v2beta1）\",\"PipelineService（v1beta1 和 v2beta1）\",\"JobService（v1beta1）\",\"RunService（v1beta1 和 v2beta1）\",\"TaskService（v1beta1）\",\"ReportService（v1beta1）\",\"VisualizationService（v1beta1）\",\"AuthService（v1beta1）\",\"RecurringRunService（v2beta1）\",\"ReflectionService\",\"这些服务涵盖了实验管理、流水线管理、作业管理、运行管理、任务管理、报告生成、数据可视化和认证功能，并且支持不同版本的API。 \"]},\"112\":{\"h\":\"pipeline创建流程\",\"t\":[\" 创建流水线只是把相关参数信息写入数据库。\"]},\"113\":{\"h\":\"创建Runs\",\"t\":[\" Runs创建过程是 请求apiserver->请求workflow,然后保存相关数据\"]},\"114\":{\"c\":[\"云原生\"]},\"115\":{\"c\":[\"Kubeflow\"]},\"116\":{\"h\":\"k8s operator\",\"t\":[\"什么是 Kubernetes Operator？\",\"Kubernetes Operator 是一种软件扩展，使用 Kubernetes 原生的 API 和工具来自动管理复杂应用的生命周期。Operator 可以将人类操作员（例如系统管理员）的操作自动化，管理 Kubernetes 应用程序的配置、部署、升级、备份和故障处理等任务。\"]},\"117\":{\"h\":\"Operator 的基本概念\",\"t\":[\"Custom Resource (自定义资源，CR): Kubernetes 的内置资源（如 Pod、Service）可能无法满足所有应用的需求。CR 提供了定义自定义对象的能力，使得用户可以在 Kubernetes 中引入新的资源类型。\",\"Custom Resource Definition (自定义资源定义，CRD): CRD 是 Kubernetes 用于定义 CR 结构的机制。通过 CRD，用户可以创建和管理新的自定义资源。\",\"Controller (控制器): 控制器是 Kubernetes 中一个不断循环检查资源实际状态并使其符合预期状态的逻辑组件。Operator 就是一个高级的控制器，专门用于管理自定义资源。\"]},\"118\":{\"h\":\"Operator 的工作原理\",\"t\":[\"定义 CRD: 开发者首先需要定义 CRD，这描述了自定义资源的结构和规范。CRD 定义了资源的 API 和行为方式。\",\"实现控制器: 控制器监控自定义资源的状态，并根据用户定义的逻辑执行相应的操作。控制器的核心任务是不断将资源的实际状态调整为期望状态。\",\"部署 Operator: Operator 本质上是一个 Kubernetes 应用，它包括了 CRD 和控制器的实现。部署 Operator 后，用户可以使用 kubectl 等工具创建和管理自定义资源。\"]},\"119\":{\"h\":\"Operator 的应用场景\",\"t\":[\"应用部署和管理: Operator 可以自动化复杂应用的部署和管理过程。例如，数据库集群的创建、分片、复制等任务都可以通过 Operator 自动执行。\",\"自动化升级: Operator 可以监控应用的新版本，并自动执行无中断的滚动升级。\",\"备份和恢复: Operator 可以定期备份应用的数据，并在出现故障时自动进行恢复。\",\"自愈能力: Operator 可以监控应用的健康状态，自动修复出现的问题，例如重新启动故障的组件。\"]},\"120\":{\"h\":\"Operator 的优势\",\"t\":[\"简化运维操作: Operator 自动化了许多日常的运维任务，减少了人为操作的复杂性和风险。\",\"标准化管理流程: 通过 Operator，可以将最佳实践和操作流程编码成标准化的流程，使得复杂应用的管理变得更一致和可靠。\",\"增强 Kubernetes 的能力: Operator 将 Kubernetes 的管理能力扩展到了自定义应用领域，使得 Kubernetes 可以管理更复杂的工作负载。\"]},\"121\":{\"h\":\"使用 Operator 的示例\",\"t\":[\"Prometheus Operator: 用于简化 Prometheus 集群的部署和管理，自动处理 Prometheus 配置、目标发现和告警管理。\",\"ElasticSearch Operator: 管理 ElasticSearch 集群的部署、升级和扩展，确保高可用性和数据一致性。\",\"MySQL Operator: 自动化 MySQL 数据库的创建、备份和恢复，简化数据库集群的管理。\"]},\"122\":{\"h\":\"开发 Operator 的工具\",\"t\":[\"Operator SDK: 一个流行的工具包，提供了从生成基础代码到测试和部署的全流程支持，简化了 Operator 的开发过程。\",\"Kubebuilder: 提供了面向 Go 语言的开发框架和工具，用于生成和管理 Kubernetes API 扩展。\",\"KUDO (Kubernetes Universal Declarative Operator): 提供了一种声明性的方式来定义和管理 Operator，使得创建复杂的应用管理变得更简单。\"]},\"123\":{\"h\":\"总结\",\"t\":[\"Kubernetes Operator 是一种强大的工具，可以自动化和简化复杂应用的管理。通过定义自定义资源和控制器，Operator 能够将人类操作员的经验和最佳实践转化为自动化的操作流程，大大增强了 Kubernetes 的管理能力。无论是管理数据库、消息队列，还是大数据处理集群，Operator 都可以帮助实现高效的运维管理。\",\"如果你对开发 Kubernetes Operator 有兴趣，可以先从简单的示例开始，逐步深入理解其背后的原理和应用场景。\"]},\"124\":{\"c\":[\"云原生\"]},\"125\":{\"c\":[\"operator\"]},\"126\":{\"h\":\"个人介绍\",\"t\":[\"个人简介\",\"大家好，我是一名充满热情的全栈开发工程师，具备广泛的编程语言知识和丰富的实际项目经验。我始终追求技术创新，致力于通过高效、优质的代码解决复杂的业务问题。在开发过程中，我不仅关注性能优化和可扩展性，还注重代码的可维护性和团队协作，能够快速适应不同的项目需求。\"]},\"127\":{\"h\":\"编程语言\",\"t\":[\"Java: 我在Java领域有着深厚的积累，尤其擅长使用Spring Boot框架开发企业级应用，能够设计并实现高并发、高性能的后端服务，保障系统的稳定性与可扩展性。\",\"C++: 扎实的C++功底让我在系统级应用开发中游刃有余，能够编写高效、稳定的底层代码，解决复杂的系统问题。\",\"C: 精通C语言，擅长底层系统开发，具备处理硬件交互及操作系统底层模块的经验。\",\"Python: 熟练掌握Python，尤其在数据分析、机器学习领域有丰富经验，能够快速构建高效的分析和自动化工具。\",\"Go: 熟练使用Go语言开发高并发应用，善于利用其高效的内存管理机制和原生的协程支持，构建稳定的后端服务。\"]},\"128\":{\"h\":\"技术栈\",\"t\":[\"Kubernetes (k8s): 熟练掌握容器编排技术，能够高效部署和管理复杂的微服务架构，保障系统的弹性伸缩和高可用性。\",\"Spring Boot: 深入理解Spring Boot生态体系，擅长快速搭建和优化企业级应用，确保项目能够快速上线并稳定运行。\",\"MySQL: 精通MySQL数据库的设计与性能优化，具备大规模数据存储与查询优化的经验，能够提升系统的数据处理能力。\",\"Redis: 擅长利用Redis进行高效的缓存与存储操作，提升系统响应速度，优化用户体验。\",\"Nacos: 熟悉Nacos的服务发现与配置管理，能够确保微服务架构中各组件的稳定运行与快速扩展。\"]},\"129\":{\"h\":\"MLOps\",\"t\":[\"Kubeflow: 精通Kubeflow流水线的设计与实现，能够为机器学习模型的开发、训练、部署提供一体化解决方案，加速AI项目的落地与应用。\"]},\"130\":{\"h\":\"前端开发\",\"t\":[\"Vue: 熟练使用Vue.js进行动态、响应式的用户界面开发，能够设计出简洁美观且用户体验友好的前端页面。\",\"TypeScript (TS): 精通TypeScript，能够编写高质量、健壮的代码，确保前端应用的可维护性和稳定性。\",\"HTML: 掌握HTML的各种技术细节，具备良好的网页结构设计能力，能够实现高效、语义化的页面布局。\",\"Element-UI: 精通Element-UI库的使用，能够快速开发美观实用的前端组件，提升项目的开发效率与用户体验。\"]},\"131\":{\"h\":\"项目经验\",\"t\":[\"飞鸟云课堂\",\"日活流量：1GB+\",\"累计注册用户：5000+\",\"营销收入：80万元+\",\"《飞鸟云课堂》是一款专注于在线教育的产品，通过丰富的教学资源和优质的用户体验，吸引了大量用户并实现了显著的商业变现。\",\"我拥有将技术与商业需求相结合的能力，擅长从需求分析到产品落地的全流程开发。如果你正在寻找一位能够推动项目成功、具备创新能力的全栈开发工程师，欢迎联系我！期待与您合作，共同实现卓越的技术和商业目标。\"]},\"132\":{\"h\":\"联系方式\",\"t\":[\"微信\"]},\"133\":{\"c\":[\"个人介绍\"]},\"134\":{\"c\":[\"个人\"]},\"135\":{\"h\":\"clash节点转为V2ray\"},\"136\":{\"c\":[\"代理\"]},\"137\":{\"c\":[\"clash\",\"v2ray\"]},\"138\":{\"h\":\"异构计算\",\"t\":[\"异构计算交流\",\"注： 若二维码失效，加我V: KomorebiTimothy 备注：异构计算交流\"]},\"139\":{\"h\":\"参考资料\",\"t\":[\"异构万卡集群，GPU与国产计算卡芯片异构通信\",\"论文 异构GPU集群上大模型训练推理续\",\"论文 异构GPU集群上大模型训练推理续2\",\"论文 MLaaS：阿里大规模异构GPU集群中任务分析和调度\",\"ATC2024 异构GPU集群上大模型训练推理\",\"PATHWAYS：谷歌大规模异构计算编排调度系统（Jeff Dean 和 Sanjay Ghemawat联合出品）\",\"Pathways: Asynchronous Distributed Dataflow for ML\",\"VLDB23：Pytorch FSDP 分布式训练新篇章\"]},\"140\":{\"c\":[\"异构计算\"]},\"141\":{\"c\":[\"异构计算\"]},\"142\":{\"h\":\"nccl\",\"t\":[\"nccl\"]},\"143\":{\"h\":\"nccl\",\"t\":[\"NCCL是一款独立的库，提供标准的 GPU 通信例程，支持全规约（all-reduce）、全收集（all-gather）、规约（reduce）、广播（broadcast）、规约并散播（reduce-scatter）以及任意基于发送/接收的通信模式。该库经过优化，能够在使用 PCIe、NVLink、NVSwitch 以及基于 InfiniBand Verbs 或 TCP/IP 套接字的网络平台上实现高带宽。NCCL 支持任意数量的 GPU，无论是安装在单节点还是跨多个节点的系统中，并且可以在单进程或多进程（如 MPI）应用程序中使用。\",\"NCCL 概述 NVIDIA 集体通信库（NCCL，发音为“Nickel”）是一个库，提供拓扑感知的 GPU 间通信原语，能够方便地集成到应用程序中。\",\"NCCL 实现了集体通信和点对点发送/接收原语。它不是一个完整的并行编程框架，而是一个专注于加速 GPU 间通信的库。\",\"NCCL 提供以下集体通信原语：\",\"AllReduce（全规约）\",\"Broadcast（广播）\",\"Reduce（规约）\",\"AllGather（全收集）\",\"ReduceScatter（规约并散播）\",\"此外，它还支持点对点发送/接收通信，允许实现 scatter、gather 或 all-to-all 操作。\",\"在集体通信中，通信处理器之间的紧密同步是关键。传统上，基于 CUDA 的集体操作通常通过 CUDA 内存拷贝操作和 CUDA 核函数结合本地规约来实现。而 NCCL 则将每个集体操作实现为一个处理通信和计算操作的单一核函数。这样可以实现快速同步，并最大限度地减少达到峰值带宽所需的资源。\",\"NCCL 方便地免除了开发人员为特定机器优化应用程序的需求。NCCL 在多个 GPU 之间提供快速的集体通信，无论是在单个节点内还是跨节点。它支持多种互连技术，包括 PCIe、NVLINK、InfiniBand Verbs 和 IP 套接字。\",\"除了性能，简便的编程体验也是 NCCL 设计的主要考虑因素之一。NCCL 使用简单的 C API，可以轻松通过多种编程语言访问。NCCL 紧密遵循 MPI（消息传递接口）定义的流行集体操作 API，因此熟悉 MPI 的用户会发现 NCCL 的 API 非常容易使用。与 MPI 略有不同的是，NCCL 的集体操作带有一个“流”参数，使其能够直接与 CUDA 编程模型集成。最后，NCCL 几乎兼容任何多 GPU 并行化模型，例如：\",\"单线程控制所有 GPU\",\"多线程（例如，每个 GPU 一个线程）\",\"多进程（例如，MPI）\",\"NCCL 在深度学习框架中有着广泛的应用，AllReduce 集体操作在神经网络训练中被广泛使用。通过 NCCL 提供的多 GPU 和多节点通信，可以实现神经网络训练的高效扩展。\",\"NCCL 是一个通信库，提供用于高性能应用的 GPU 间优化通信。与 MPI 不同，NCCL 不提供并行环境，也不包含进程启动器和管理器。因此，NCCL 依赖于应用程序的进程管理系统和 CPU 端的通信系统来进行自启动。\",\"与 MPI 和其他为性能优化的库类似，NCCL 不提供 GPU 之间的安全网络通信。因此，用户有责任确保 NCCL 在安全的网络上运行，无论是在自启动阶段（由 NCCL_SOCKET_IFNAME 控制）还是在高速通信过程中。\"]},\"144\":{\"h\":\"下载源码\",\"t\":[\"git clone https://github.com/NVIDIA/nccl-tests.git\"]},\"145\":{\"h\":\"构建编译\",\"t\":[\"修改换行格式 LF\",\"src\\\\device\\\\generate.py src\\\\device\\\\Makefile\",\"编译并安装\",\" make -j src.build make install\",\"构建产物如下\",\"├── include │ ├── nccl.h │ └── nccl_net.h ├── lib ├── libnccl.so -> libnccl.so.2 ├── libnccl.so.2 -> libnccl.so.2.23.4 ├── libnccl.so.2.23.4 ├── libnccl_static.a └── pkgconfig └── nccl.pc\"]},\"146\":{\"h\":\"nccl-test\"},\"147\":{\"h\":\"下载\",\"t\":[\"git clone https://github.com/NVIDIA/nccl-tests.git\"]},\"148\":{\"h\":\"编译\",\"t\":[\"cd nccl-tests make\"]},\"149\":{\"h\":\"运行\",\"t\":[\"export NCCL_DEBUG=TRACE ./build/all_reduce_perf -b 8 -e 8M -f 2 -g 1 (base) root@DESKTOP-P54EAF3:/mnt/d/Code/nccl-tests# ./build/all_reduce_perf -b 8 -e 8M -f 2 -g 1 # nThread 1 nGpus 1 minBytes 8 maxBytes 8388608 step: 2(factor) warmup iters: 5 iters: 20 agg iters: 1 validation: 1 graph: 0 # # Using devices # Rank 0 Group 0 Pid 58239 on DESKTOP-P54EAF3 device 0 [0x01] NVIDIA GeForce GTX 1660 SUPER DESKTOP-P54EAF3:58239:58239 [0] NCCL INFO Bootstrap : Using eth0:172.26.190.235<0> DESKTOP-P54EAF3:58239:58239 [0] NCCL INFO cudaDriverVersion 12050 DESKTOP-P54EAF3:58239:58239 [0] NCCL INFO NCCL version 2.23.4+cuda12.1 DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal network plugin. DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO Failed to open libibverbs.so[.1] DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO NET/Socket : Using [0]eth0:172.26.190.235<0> [1]br-eaee979aadb0:172.19.0.1<0> [2]vethd14a450:fe80::c821:6bff:fea5:dcf9%vethd14a450<0> [3]vethc5ec3b7:fe80::74f5:23ff:fe0a:3d6d%vethc5ec3b7<0> DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO Using network Socket DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO ncclCommInitAll comm 0x559205409610 rank 0 nranks 1 cudaDev 0 nvmlDev 0 busId 1000 commId 0x89b784d33d72ebbb - Init START DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO Bootstrap timings total 0.000344 (create 0.000019, send 0.000105, recv 0.000096, ring 0.000000, delay 0.000000) DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO comm 0x559205409610 rank 0 nRanks 1 nNodes 1 localRanks 1 localRank 0 MNNVL 0 DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO Channel 00/32 : 0 DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO Channel 01/32 : 0 DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO Channel 02/32 : 0 DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO Channel 03/32 : 0 DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO Channel 04/32 : 0 DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO Channel 05/32 : 0 DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO Channel 06/32 : 0 DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO Channel 07/32 : 0 DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO Channel 08/32 : 0 DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO Channel 09/32 : 0 DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO Channel 10/32 : 0 DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO Channel 11/32 : 0 DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO Channel 12/32 : 0 DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO Channel 13/32 : 0 DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO Channel 14/32 : 0 DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO Channel 15/32 : 0 DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO Channel 16/32 : 0 DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO Channel 17/32 : 0 DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO Channel 18/32 : 0 DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO Channel 19/32 : 0 DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO Channel 20/32 : 0 DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO Channel 21/32 : 0 DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO Channel 22/32 : 0 DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO Channel 23/32 : 0 DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO Channel 24/32 : 0 DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO Channel 25/32 : 0 DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO Channel 26/32 : 0 DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO Channel 27/32 : 0 DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO Channel 28/32 : 0 DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO Channel 29/32 : 0 DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO Channel 30/32 : 0 DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO Channel 31/32 : 0 DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1 DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO P2P Chunksize set to 131072 DESKTOP-P54EAF3:58239:58246 [0] NCCL INFO [Proxy Service] Device 0 CPU core 8 DESKTOP-P54EAF3:58239:58247 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 11 DESKTOP-P54EAF3:58239:58248 [0] NCCL INFO [Proxy Progress] Device 0 CPU core 14 DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO 32 coll channels, 32 collnet channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO CC Off, Multi-GPU CC Off, workFifoBytes 1048576 DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so libnccl-net.so. Using internal tuner plugin. DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO ncclCommInitAll comm 0x559205409610 rank 0 nranks 1 cudaDev 0 nvmlDev 0 busId 1000 commId 0x89b784d33d72ebbb - Init COMPLETE DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO Init timings - ncclCommInitAll: rank 0 nranks 1 total 0.22 (kernels 0.15, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.00, graphs 0.00, connections 0.01, rest 0.00) # # out-of-place in-place # size count type redop root time algbw busbw #wrong time algbw busbw #wrong # (B) (elements) (us) (GB/s) (GB/s) (us) (GB/s) (GB/s) 8 2 float sum -1 9.32 0.00 0.00 0 0.14 0.06 0.00 0 16 4 float sum -1 14.29 0.00 0.00 0 0.15 0.11 0.00 0 32 8 float sum -1 12.24 0.00 0.00 0 0.15 0.22 0.00 0 64 16 float sum -1 14.00 0.00 0.00 0 0.15 0.44 0.00 0 128 32 float sum -1 11.98 0.01 0.00 0 1.06 0.12 0.00 0 256 64 float sum -1 11.72 0.02 0.00 0 0.15 1.71 0.00 0 512 128 float sum -1 13.87 0.04 0.00 0 0.15 3.53 0.00 0 1024 256 float sum -1 13.81 0.07 0.00 0 0.15 6.83 0.00 0 2048 512 float sum -1 17.77 0.12 0.00 0 0.15 13.65 0.00 0 4096 1024 float sum -1 14.04 0.29 0.00 0 0.15 28.25 0.00 0 8192 2048 float sum -1 13.54 0.61 0.00 0 0.15 54.61 0.00 0 16384 4096 float sum -1 11.61 1.41 0.00 0 0.15 109.23 0.00 0 32768 8192 float sum -1 13.64 2.40 0.00 0 0.15 218.45 0.00 0 65536 16384 float sum -1 15.48 4.23 0.00 0 0.13 504.12 0.00 0 131072 32768 float sum -1 23.09 5.68 0.00 0 0.13 1008.25 0.00 0 262144 65536 float sum -1 25.09 10.45 0.00 0 0.14 1872.46 0.00 0 524288 131072 float sum -1 26.29 19.94 0.00 0 0.15 3615.78 0.00 0 1048576 262144 float sum -1 20.98 49.98 0.00 0 0.16 6553.60 0.00 0 2097152 524288 float sum -1 26.15 80.20 0.00 0 0.16 13530.01 0.00 0 4194304 1048576 float sum -1 37.97 110.46 0.00 0 0.15 27962.03 0.00 0 8388608 2097152 float sum -1 66.97 125.27 0.00 0 0.14 59918.63 0.00 0 DESKTOP-P54EAF3:58239:58239 [0] NCCL INFO comm 0x559205409610 rank 0 nranks 1 cudaDev 0 busId 1000 - Destroy COMPLETE # Out of bounds values : 0 OK # Avg bus bandwidth : 0 #\"]},\"150\":{\"h\":\"参数\",\"t\":[\"所有测试支持相同的一组参数：\",\"GPU 数量 \",\"-t,--nthreads <线程数> 每个进程的线程数。默认值：1。\",\"-g,--ngpus <每个线程的 GPU 数量> 每个线程使用的 GPU 数量。默认值：1。\",\"扫描的大小范围 \",\"-b,--minbytes <最小字节数> 开始的最小大小。默认值：32M。\",\"-e,--maxbytes <最大字节数> 结束的最大大小。默认值：32M。\",\"递增方式可以是固定递增或乘法因子。仅应使用其中一种方式： \",\"-i,--stepbytes <递增字节数> 各大小之间的固定增量。默认值：1M。\",\"-f,--stepfactor <递增因子> 各大小之间的乘法因子。默认值：禁用。\",\"NCCL 操作参数 \",\"-o,--op <sum/prod/min/max/avg/all> 指定执行哪种规约操作。仅对 Allreduce、Reduce 或 ReduceScatter 等规约操作有效。默认值：Sum（求和）。\",\"-d,--datatype <nccltype/all> 指定使用哪种数据类型。默认值：Float（浮点数）。\",\"-r,--root <root/all> 指定使用哪个 root，仅对有 root 的操作（如广播或规约）有效。默认值：0。\",\"性能参数 \",\"-n,--iters <迭代次数> 迭代次数。默认值：20。\",\"-w,--warmup_iters <预热迭代次数> 预热迭代次数（不计时）。默认值：5。\",\"-m,--agg_iters <聚合次数> 每次迭代中聚合在一起的操作次数。默认值：1。\",\"-N,--run_cycles <循环次数> 运行并打印每个循环。默认值：1；0=无限循环。\",\"-a,--average <0/1/2/3> 将性能报告为所有节点的平均值（仅适用于 MPI=1）。<0=Rank0, 1=平均, 2=最小, 3=最大>。默认值：1（平均）。\",\"测试操作 \",\"-p,--parallel_init <0/1> 使用线程并行初始化 NCCL。默认值：0。\",\"-c,--check <检查迭代次数> 执行指定次数的迭代，每次迭代都检查结果的正确性。对于大量 GPU 来说，这可能非常慢。默认值：1。\",\"-z,--blocking <0/1> 使 NCCL 操作阻塞，即在每次操作后等待并同步 CPU。默认值：0。\",\"-G,--cudagraph <CUDA 图启动次数> 将迭代捕获为 CUDA 图，然后重复指定次数。默认值：0。\",\"-C,--report_cputime <0/1> 报告 CPU 时间而非延迟。默认值：0。\",\"-R,--local_register <1/0> 在发送/接收缓冲区上启用本地缓冲区注册。默认值：0。\",\"-T,--timeout <超时时间（秒）> 在指定秒数后对每个测试进行超时。默认值：禁用。\",\"def get_group_rank(group: ProcessGroup, global_rank: int) -> int: \\\"\\\"\\\" Translate a global rank into a group rank. ``global_rank`` must be part of ``group`` otherwise this raises RuntimeError. Args: group (ProcessGroup): ProcessGroup to find the relative rank. global_rank (int): Global rank to query. Returns: Group rank of ``global_rank`` relative to ``group`` N.B. calling this function on the default process group returns identity \\\"\\\"\\\" if group is GroupMember.WORLD: return global_rank if group not in _world.pg_group_ranks: raise ValueError( f\\\"Group {group} is not registered, please create group with torch.distributed.new_group API\\\" ) group_ranks = _world.pg_group_ranks[group] if global_rank not in group_ranks: raise ValueError(f\\\"Global rank {global_rank} is not part of group {group}\\\") return group_ranks[global_rank]\",\"这段代码的主要功能是将一个全局的 rank 转换为在某个进程组中的 rank。它实现了在分布式训练中，通过全局 rank 查询某个特定进程组内的相对 rank。如果 global_rank 不在给定的进程组 group 中，该函数会抛出 ValueError 异常。\"]},\"151\":{\"h\":\"具体工作原理\",\"t\":[\"判断是否为默认进程组：\",\"如果 group 是默认的进程组 GroupMember.WORLD，则直接返回 global_rank，因为默认进程组中的 rank 就是全局 rank，保持不变。\",\"检查组是否注册：\",\"如果 group 没有在 _world.pg_group_ranks 中找到，则抛出异常。_world.pg_group_ranks 存储了所有创建的进程组及其对应的 ranks。\",\"检查全局 rank 是否在该组中：\",\"如果 global_rank 不在 group_ranks 列表中，抛出异常。group_ranks 保存了 group 中的全局 rank 映射。\",\"返回相对 rank：\",\"最终根据 group_ranks 返回 global_rank 在 group 中的相对 rank。\"]},\"152\":{\"h\":\"参数说明：\",\"t\":[\"group (ProcessGroup)：PyTorch 分布式的进程组，通常由 torch.distributed.new_group 创建。\",\"global_rank (int)：全局 rank 值，通常是指分布式训练中全局进程的编号。\"]},\"153\":{\"h\":\"返回：\",\"t\":[\"返回值是 global_rank 在指定 group 中的 rank。\"]},\"154\":{\"h\":\"代码解释：\",\"t\":[\"if group is GroupMember.WORLD: return global_rank\",\"这段代码检查传入的 group 是否是默认的全局进程组。如果是的话，global_rank 和相对 rank 是一致的，直接返回。\",\"if group not in _world.pg_group_ranks: raise ValueError( f\\\"Group {group} is not registered, please create group with torch.distributed.new_group API\\\" )\",\"这里检查是否传入的 group 已经被注册到 _world.pg_group_ranks 中。如果没有注册，则抛出 ValueError，并提示用户需要通过 torch.distributed.new_group 来创建该组。\",\"group_ranks = _world.pg_group_ranks[group] if global_rank not in group_ranks: raise ValueError(f\\\"Global rank {global_rank} is not part of group {group}\\\")\",\"这段代码从 _world.pg_group_ranks 获取当前 group 的所有全局 rank。如果 global_rank 不在该组中，则抛出异常。\",\"return group_ranks[global_rank]\",\"最终返回 global_rank 在 group 中的相对 rank。\"]},\"155\":{\"h\":\"应用场景\",\"t\":[\"此功能非常适用于在分布式训练中处理多个进程组的情况，用户可以轻松找到某个全局 rank 在特定组内的 rank，从而进行更细粒度的进程控制或通信。\"]},\"156\":{\"h\":\"torch/cuda/nccl.py\",\"t\":[\"# `output` used to be `outputs`, taking in a list of tensors. So we have two # arguments for BC reasons. def reduce( inputs: Sequence[torch.Tensor], output: Optional[Union[torch.Tensor, Sequence[torch.Tensor]]] = None, root: int = 0, op: int = SUM, streams: Optional[Sequence[torch.cuda.Stream]] = None, comms=None, *, outputs: Optional[Sequence[torch.Tensor]] = None, ) -> None: _check_sequence_type(inputs) _output: torch.Tensor if outputs is not None: if output is not None: raise ValueError( \\\"'output' and 'outputs' can not be both specified. 'outputs' is deprecated in \\\" \\\"favor of 'output', taking in a single output tensor. The signature of reduce is: \\\" \\\"reduce(inputs, output=None, root=0, op=SUM, streams=None, comms=None).\\\" ) else: warnings.warn( \\\"`nccl.reduce` with an output tensor list is deprecated. \\\" \\\"Please specify a single output tensor with argument 'output' instead instead.\\\", FutureWarning, stacklevel=2, ) _output = outputs[root] elif not isinstance(output, torch.Tensor) and isinstance( output, collections.abc.Sequence ): # User called old API with positional arguments of list of output tensors. warnings.warn( \\\"nccl.reduce with an output tensor list is deprecated. \\\" \\\"Please specify a single output tensor.\\\", FutureWarning, stacklevel=2, ) _output = output[root] else: _output = inputs[root] if output is None else output torch._C._nccl_reduce(inputs, _output, root, op, streams, comms)\",\"这段代码实现了 reduce 函数的分布式操作，用于将多个 GPU 的张量根据某种操作（如求和）合并到一个目标张量中，特别是在使用 PyTorch 的 NCCL 后端时。这是常见的分布式通信操作，例如在多卡训练中汇总各个设备上的张量。\"]},\"157\":{\"h\":\"核心功能\",\"t\":[\"该函数通过调用 torch._C._nccl_reduce 来实现具体的 reduce 操作，该函数执行 GPU 间张量的归约（如求和、乘积等操作），并将结果存储在某个 root 节点的目标张量中。\"]},\"158\":{\"h\":\"参数解析\",\"t\":[\"inputs:\",\"Sequence[torch.Tensor]，表示输入的张量序列，来自不同的 GPU。每个张量包含设备上局部计算的结果。\",\"output:\",\"Optional[Union[torch.Tensor, Sequence[torch.Tensor]]]，可选参数，用于存放归约操作的结果。如果没有提供，将使用 root 节点上的输入张量。\",\"root:\",\"int，表示哪个 GPU 作为 root，将接收所有 GPU 的归约结果。默认是 0。\",\"op:\",\"int，指定归约操作，默认为 SUM（加法）。其它可能的操作有 PROD（乘法）、MIN（最小值）、MAX（最大值）等。\",\"streams:\",\"Optional[Sequence[torch.cuda.Stream]]，可以为每个 GPU 提供 CUDA 流，方便在不同 CUDA 流上进行归约操作。默认为空，即使用默认流。\",\"comms:\",\"可选的通信器对象，负责管理 GPU 间的通信。\",\"outputs:\",\"Optional[Sequence[torch.Tensor]]，这是一个过时参数，用于指定多个输出张量的列表。新的 API 只需要传入一个单一的 output，如果同时传入 outputs 和 output，则会报错。\"]},\"159\":{\"h\":\"核心逻辑\",\"t\":[\"处理参数的兼容性:\",\"首先检查 inputs 的类型是否正确。接着处理参数 outputs 和 output 的兼容性，确保两者不会同时传入。如果用户使用了旧版 API (outputs)，会抛出警告，提醒用户该功能将被弃用。\",\"处理旧 API:\",\"如果 output 是一个张量序列而不是单个张量，函数会继续支持这种旧的用法，但是同样会抛出警告，提示用户迁移到新的 API。\",\"调用底层 NCCL 函数:\",\"最后，函数调用 torch._C._nccl_reduce 执行真正的张量归约操作，使用给定的 inputs、_output、root、op 和其他可选参数。\"]},\"160\":{\"h\":\"示例\",\"t\":[\"假设我们在分布式训练中使用 4 个 GPU，执行 reduce 操作：\",\"inputs = [torch.tensor([1.0]).cuda(i) for i in range(4)] # 各个 GPU 上的张量 output = torch.tensor([0.0]).cuda(0) # root GPU 上的输出张量 reduce(inputs, output=output, root=0) print(output) # 输出归约后的结果\",\"这段代码将各个 GPU 上的张量相加，并将结果存储在 root GPU（GPU 0）的 output 张量中。\"]},\"161\":{\"h\":\"torch/csrc/cuda/python_nccl.cpp\",\"t\":[\"PyObject* THCPModule_nccl_reduce(PyObject* self, PyObject* args) { HANDLE_TH_ERRORS PyObject *_inputs = nullptr, *_output = nullptr, *_streams = nullptr, *_comms = nullptr; int root = 0, op = 0; if (!PyArg_ParseTuple( args, \\\"OOiiOO\\\", &_inputs, &_output, &root, &op, &_streams, &_comms)) { THPUtils_invalidArguments( args, nullptr, \\\"nccl_reduce\\\", 1, \\\"(sequence[Tensor] inputs, Tensor output, int root,\\\" \\\" int op, sequence[torch.cuda.Stream or None]\\\"); return nullptr; } std::vector<at::Tensor> inputs = extract_tensors(_inputs); auto output = extract_tensor(_output); std::vector<std::optional<at::cuda::CUDAStream>> streams = unpack_streams(_streams, inputs.size()); auto user_comms = unpack_comms(_comms, inputs.size()); { pybind11::gil_scoped_release no_gil; torch::cuda::nccl::reduce(inputs, output, root, op, streams, user_comms); } Py_RETURN_NONE; END_HANDLE_TH_ERRORS }\",\"上述代码是 PyTorch 中一个 C++ 函数，它通过 Python 的 C API 实现了 NCCL reduce 操作的接口。这个函数可以在 Python 中调用，从而完成 NCCL 的 reduce 操作。NCCL（NVIDIA Collective Communications Library）是一种用于多 GPU 间高效通信的库，特别适用于深度学习框架中的集体通信操作，如 reduce、allreduce 等。\"]},\"162\":{\"h\":\"代码解析\",\"t\":[\"函数定义:\",\"PyObject* THCPModule_nccl_reduce(PyObject* self, PyObject* args)\",\"这是一个 Python C API 的函数，PyObject* 是 Python 对象的通用类型，self 通常指模块对象，而 args 是从 Python 传递给这个函数的参数。\",\"参数解析:\",\"if (!PyArg_ParseTuple( args, \\\"OOiiOO\\\", &_inputs, &_output, &root, &op, &_streams, &_comms))\",\"PyArg_ParseTuple 用于从 Python 参数 args 中解析出输入的值。格式化字符串 \\\"OOiiOO\\\" 表示该函数期望接收的参数类型依次是：\",\"O: Python 对象（_inputs）\",\"O: Python 对象（_output）\",\"i: 整数（root，指定哪个 GPU 是 root 节点）\",\"i: 整数（op，指定 NCCL 操作类型，如 SUM 或 MAX 等）\",\"O: Python 对象（_streams）\",\"O: Python 对象（_comms，通信对象）\",\"如果参数无法解析，将返回 nullptr，并抛出错误。\",\"参数转换:\",\"extract_tensors(_inputs) 和 extract_tensor(_output) 是从 Python 对象中提取张量的自定义函数。\",\"unpack_streams(_streams, inputs.size()) 是将 streams 从 Python 对象中解包成 CUDAStream 对象。\",\"unpack_comms(_comms, inputs.size()) 同样用于将通信器对象解包。\",\"释放 GIL 锁:\",\"pybind11::gil_scoped_release no_gil;\",\"pybind11::gil_scoped_release 用于释放 Python 的全局解释器锁（GIL），允许并行执行。因为 NCCL 操作是 GPU 通信操作，可能耗时较长，所以在执行这些操作前释放 GIL 是必要的。\",\"调用 NCCL reduce:\",\"torch::cuda::nccl::reduce(inputs, output, root, op, streams, user_comms);\",\"调用了 PyTorch CUDA 模块中的 NCCL reduce 函数，将输入张量 inputs 通过 NCCL 通信操作聚合成 output 张量，root 指定了哪块 GPU 是主节点（负责聚合结果），op 指定了操作类型，如 SUM。\",\"返回 None:\",\"Py_RETURN_NONE;\",\"函数完成后，返回 None，表示没有返回值。\",\"错误处理:\",\"HANDLE_TH_ERRORS 和 END_HANDLE_TH_ERRORS 是用于捕获和处理 C++ 异常的宏。如果在函数执行过程中发生异常，它们将自动捕捉并将错误报告给 Python 层。\"]},\"163\":{\"h\":\"总结\",\"t\":[\"此函数的作用是在 Python 层提供了 NCCL reduce 操作的接口，允许用户在 Python 中调用 NCCL 底层的 C++ 实现，以高效地在多 GPU 间进行通信和数据聚合。整个过程中，C++ 代码负责参数解析、执行 NCCL 操作并返回结果，而 Python 代码则以封装的方式调用这些底层实现。这种模式在深度学习框架中非常常见，尤其是在需要加速的分布式训练场景下。\"]},\"164\":{\"h\":\"torch/csrc/cuda/Module.cpp\",\"t\":[\"#ifdef USE_NCCL {\\\"_nccl_version\\\", THCPModule_nccl_version, METH_NOARGS, nullptr}, {\\\"_nccl_version_suffix\\\", THCPModule_nccl_version_suffix, METH_NOARGS, nullptr}, {\\\"_nccl_unique_id\\\", THCPModule_nccl_unique_id, METH_NOARGS, nullptr}, {\\\"_nccl_init_rank\\\", THCPModule_nccl_init_rank, METH_VARARGS, nullptr}, {\\\"_nccl_reduce\\\", THCPModule_nccl_reduce, METH_VARARGS, nullptr}, {\\\"_nccl_all_reduce\\\", THCPModule_nccl_all_reduce, METH_VARARGS, nullptr}, {\\\"_nccl_broadcast\\\", THCPModule_nccl_broadcast, METH_VARARGS, nullptr}, {\\\"_nccl_all_gather\\\", THCPModule_nccl_all_gather, METH_VARARGS, nullptr}, {\\\"_nccl_reduce_scatter\\\", THCPModule_nccl_reduce_scatter, METH_VARARGS, nullptr}, #endif\",\"这段代码是 PyTorch 的 C++ 代码片段，主要用于注册与 NCCL（NVIDIA Collective Communications Library）相关的 Python API 函数。通过这些函数，用户可以在 Python 中调用 NCCL 的功能，如初始化 NCCL、执行集合操作等。下面是对代码的逐行分析：\"]},\"165\":{\"h\":\"代码结构和功能\",\"t\":[\"#ifdef USE_NCCL\",\"这一行使用条件编译指令来检查是否启用了 NCCL 支持。如果编译时定义了 USE_NCCL，则编译器会包含以下代码块。\",\" {\\\"_nccl_version\\\", THCPModule_nccl_version, METH_NOARGS, nullptr},\",\"这一行注册了 _nccl_version 函数，该函数将返回 NCCL 的版本信息。METH_NOARGS 表示该函数不接受任何参数。\",\" {\\\"_nccl_version_suffix\\\", THCPModule_nccl_version_suffix, METH_NOARGS, nullptr},\",\"注册了 _nccl_version_suffix 函数，返回 NCCL 版本的后缀。\",\" {\\\"_nccl_unique_id\\\", THCPModule_nccl_unique_id, METH_NOARGS, nullptr},\",\"注册了 _nccl_unique_id 函数，用于生成 NCCL 的唯一标识符（Unique ID）。\",\" {\\\"_nccl_init_rank\\\", THCPModule_nccl_init_rank, METH_VARARGS, nullptr},\",\"注册了 _nccl_init_rank 函数，接受参数并用于初始化 NCCL 通信。\",\" {\\\"_nccl_reduce\\\", THCPModule_nccl_reduce, METH_VARARGS, nullptr},\",\"注册了 _nccl_reduce 函数，用于执行 NCCL 的 reduce 操作，接受一组输入张量和输出张量。\",\" {\\\"_nccl_all_reduce\\\", THCPModule_nccl_all_reduce, METH_VARARGS, nullptr},\",\"注册了 _nccl_all_reduce 函数，用于执行所有进程的 reduce 操作。\",\" {\\\"_nccl_broadcast\\\", THCPModule_nccl_broadcast, METH_VARARGS, nullptr},\",\"注册了 _nccl_broadcast 函数，用于执行广播操作，将数据从一个进程传递到所有其他进程。\",\" {\\\"_nccl_all_gather\\\", THCPModule_nccl_all_gather, METH_VARARGS, nullptr},\",\"注册了 _nccl_all_gather 函数，用于收集所有进程的数据到每个进程中。\",\" {\\\"_nccl_reduce_scatter\\\", THCPModule_nccl_reduce_scatter, METH_VARARGS, nullptr},\",\"注册了 _nccl_reduce_scatter 函数，用于执行 reduce scatter 操作，将数据先进行 reduce，然后再分散到所有进程。\"]},\"166\":{\"h\":\"总结\",\"t\":[\"这段代码负责将 NCCL 的相关操作函数注册到 PyTorch 的 Python 接口中。这样用户在使用 PyTorch 时，可以方便地调用这些 NCCL 的操作来进行高效的多GPU并行计算。这种设计使得 PyTorch 的 CUDA 加速功能与 NCCL 库的集体通信能力紧密集成。\"]},\"167\":{\"h\":\"torch_dynamo\\\\trace_rules.py\",\"t\":[\"def _load_obj_from_str(fully_qualified_name): module, obj_name = fully_qualified_name.rsplit(\\\".\\\", maxsplit=1) return getattr(importlib.import_module(module), obj_name)\",\"这个 Python 函数 _load_obj_from_str 用于根据一个完全限定的对象名称（通常是模块路径和对象名称的组合）动态地加载模块中的对象。下面是对该函数的逐行分析：\"]},\"168\":{\"h\":\"代码解析\",\"t\":[\"def _load_obj_from_str(fully_qualified_name):\",\"定义了一个名为 _load_obj_from_str 的函数，接受一个参数 fully_qualified_name，这是一个字符串，包含模块路径和对象名称，例如 module.submodule.ClassName。\",\" module, obj_name = fully_qualified_name.rsplit(\\\".\\\", maxsplit=1)\",\"使用 rsplit 方法将 fully_qualified_name 从右侧分割成模块名和对象名。maxsplit=1 参数确保只分割一次，这样得到的 module 是模块路径，而 obj_name 是模块中的对象名称。\",\" return getattr(importlib.import_module(module), obj_name)\",\"使用 importlib.import_module 动态导入指定的模块。\",\"使用 getattr 从导入的模块中获取指定的对象，返回这个对象。\"]},\"169\":{\"h\":\"示例用法\",\"t\":[\"假设你有一个模块结构如下：\",\"my_package/ __init__.py my_module.py\",\"my_module.py 内容如下：\",\"class MyClass: def greet(self): return \\\"Hello, world!\\\"\",\"你可以通过以下方式加载 MyClass：\",\"fully_qualified_name = \\\"my_package.my_module.MyClass\\\" MyClass = _load_obj_from_str(fully_qualified_name) instance = MyClass() print(instance.greet()) # 输出: Hello, world!\"]},\"170\":{\"h\":\"总结\",\"t\":[\"这个函数的主要作用是实现动态加载模块中的对象，允许你在运行时根据字符串路径获取对象。这种方法在需要根据配置文件或用户输入来加载类或函数时非常有用。\",\"#include <Python.h> extern PyObject* initModule(void); #ifndef _WIN32 #ifdef __cplusplus extern \\\"C\\\" #endif __attribute__((visibility(\\\"default\\\"))) PyObject* PyInit__C(void); #endif PyMODINIT_FUNC PyInit__C(void) { return initModule(); }\",\"python调用C/C++参考示例\",\"这段 C/C++ 代码片段展示了一个用于初始化 Python 扩展模块的函数实现。在 Python 中，C 扩展模块需要实现一个模块初始化函数，它会在 Python 加载模块时被调用。这段代码的主要目的是将 initModule 函数作为 Python 模块的初始化函数，并通过兼容不同平台的方式导出。\"]},\"171\":{\"h\":\"代码解析\",\"t\":[\"extern PyObject* initModule(void);:\",\"声明了一个外部的 C 函数 initModule，它返回一个 PyObject*，用于初始化模块。这个函数可能在别的地方定义，并负责创建和初始化模块对象。\",\"平台相关宏控制:\",\"#ifndef _WIN32：如果不是 Windows 平台，则会编译接下来的代码，这表明这个部分主要是为非 Windows 平台准备的。\",\"#ifdef __cplusplus 和 extern \\\"C\\\"：如果是在 C++ 中编译，这一部分会通过 extern \\\"C\\\" 指定 C 语言链接方式，确保 Python 模块能够以 C 语言的符号表被正确识别。\",\"__attribute__((visibility(\\\"default\\\")))：用于控制符号的可见性。它保证了 PyInit__C 函数在共享库中对外可见（动态链接时需要）。\",\"PyMODINIT_FUNC PyInit__C(void):\",\"PyMODINIT_FUNC 是一个宏，通常定义为 extern \\\"C\\\"，它用于标识 Python 扩展模块的初始化函数。\",\"Python 期望扩展模块的初始化函数遵循特定的命名规范。在 Python 3 中，初始化函数的名称应为 PyInit_<module_name>，这里是 PyInit__C，意味着 Python 加载的模块名称为 _C。\",\"这个函数返回一个 PyObject*，即模块对象，这个对象是通过调用 initModule() 获得的。\"]},\"172\":{\"h\":\"典型应用\",\"t\":[\"这种模块初始化机制在 C 扩展模块中很常见，特别是在涉及到 Python 与 C/C++ 互操作时。initModule() 通常会调用一系列的 C API 函数来创建 Python 对象，并将它们绑定到模块的命名空间中。\"]},\"173\":{\"h\":\"示例解释\",\"t\":[\"PyMODINIT_FUNC PyInit__C(void) { return initModule(); }\",\"当 Python 导入 _C 模块时，Python 解释器会调用 PyInit__C() 函数。这个函数又调用了 initModule()，返回初始化后的模块对象。\",\"这个模块对象包含了所有需要导出的 C 函数和对象，使得这些函数能够被 Python 调用。\"]},\"174\":{\"h\":\"总结\",\"t\":[\"这段代码展示了如何在非 Windows 环境下创建一个 C 扩展模块的初始化函数。它将 initModule 作为模块的实际初始化逻辑，用于设置模块的内容，并通过 PyInit__C 函数将其导出给 Python 使用。\"]},\"175\":{\"h\":\"nccl topo\",\"t\":[\"#define NCCL_TOPO_MAX_NODES 256 // Init search. Needs to be done before calling ncclTopoCompute ncclResult_t ncclTopoSearchInit(struct ncclTopoSystem* system); #define NCCL_TOPO_PATTERN_BALANCED_TREE 1 // Spread NIC traffic between two GPUs (Tree parent + one child on first GPU, second child on second GPU) #define NCCL_TOPO_PATTERN_SPLIT_TREE 2 // Spread NIC traffic between two GPUs (Tree parent on first GPU, tree children on the second GPU) #define NCCL_TOPO_PATTERN_TREE 3 // All NIC traffic going to/from the same GPU #define NCCL_TOPO_PATTERN_RING 4 // Ring #define NCCL_TOPO_PATTERN_NVLS 5 // NVLS+SHARP and NVLS+Tree #define NCCL_TOPO_PATTERN_COLLNET_DIRECT 6 // Collnet Direct\",\"NCCL（NVIDIA Collective Communications Library）拓扑结构的定义和初始化。这些定义用于描述不同的通信模式以及节点间的互联方式，尤其是如何在GPU之间分配网络接口卡（NIC）流量的策略。\"]},\"176\":{\"h\":\"代码解析：\",\"t\":[\"NCCL_TOPO_MAX_NODES 256： 这个宏定义了NCCL拓扑结构支持的最大节点数为256。这里的节点可以是GPU或网络设备（如NIC），意味着NCCL拓扑在设计上最多支持256个节点的互联。这与前面提到的NCCL理论上支持256卡互联是一致的。\",\"ncclTopoSearchInit(struct ncclTopoSystem* system)： 这个函数用于初始化NCCL拓扑搜索过程，准备计算通信拓扑。在调用 ncclTopoCompute 之前，必须先调用这个函数以初始化系统结构。\",\"拓扑通信模式定义： NCCL提供了多种通信模式（TOPO_PATTERN），这些模式定义了不同情况下网络流量如何在GPU之间分布：\",\"NCCL_TOPO_PATTERN_BALANCED_TREE (1): 平衡树形结构，NIC流量分布在两个GPU之间。树的父节点和一个子节点在第一个GPU上，第二个子节点在第二个GPU上。\",\"NCCL_TOPO_PATTERN_SPLIT_TREE (2): 拆分树形结构，NIC流量分布在两个GPU之间。树的父节点在第一个GPU上，子节点都在第二个GPU上。\",\"NCCL_TOPO_PATTERN_TREE (3): 所有的NIC流量都集中在同一个GPU上。\",\"NCCL_TOPO_PATTERN_RING (4): 环形结构，流量在GPU之间按顺序传递。\",\"NCCL_TOPO_PATTERN_NVLS (5): 结合NVLS（NVIDIA Virtual Link Switch）和SHARP（Scalable Hierarchical Aggregation and Reduction Protocol）技术，进行通信优化。\",\"NCCL_TOPO_PATTERN_COLLNET_DIRECT (6): CollNet直接通信模式，通常用于优化大规模集群中的点对点通信。\"]},\"177\":{\"h\":\"拓扑结构的意义：\",\"t\":[\"这些不同的拓扑模式允许NCCL根据具体的硬件拓扑和通信需求，选择最优的通信模式，以最大化带宽利用率、减少延迟，并优化多GPU、多节点的分布式训练任务。尤其在超大规模GPU集群中（例如256个GPU互联的场景），选择合适的拓扑模式对性能有显著影响。\",\"因此，在实际使用中，理解这些拓扑模式的定义，并结合硬件架构和通信需求，能够有效提升NCCL的通信性能。\"]},\"178\":{\"c\":[\"nccl\"]},\"179\":{\"c\":[\"nccl\"]},\"180\":{\"h\":\"PyTorch\",\"t\":[\"PyTorch c10d\",\"PyTorch 的 c10d 通信库是用于分布式计算的核心组件，特别是在需要跨多个设备（如多个GPU或多台机器）进行并行计算时。c10d 提供了分布式数据并行（Distributed Data Parallel, DDP）的底层实现，支持高效的数据同步和通信操作。\"]},\"181\":{\"h\":\"主要功能\",\"t\":[\"通信后端： c10d 支持多种通信后端（Backend），如：\",\"NCCL: 适用于GPU间通信，特别是在NVIDIA硬件上。\",\"GLOO: 适用于CPU和GPU的跨平台通信。\",\"MPI: 基于Message Passing Interface，适合大规模分布式系统。\",\"进程组（Process Group）： c10d 中的进程组是通信的基本单元，可以将多个进程组织成一个组，以便它们之间进行通信。可以在不同的进程组之间进行广播、归约、全归约等操作。\",\"广播和同步： c10d 提供了对数据进行广播和同步的接口，确保在多个进程或设备之间一致地传递数据。例如，在多GPU训练中，同步不同GPU上的模型参数。\",\"梯度同步： 在分布式数据并行训练中，c10d 自动同步各个设备计算出的梯度，从而确保在所有设备上更新后的模型参数保持一致。\",\"AllReduce操作： c10d 支持AllReduce操作，这是在分布式训练中非常常用的操作，能够高效地合并不同设备上的梯度并更新模型参数。\"]},\"182\":{\"h\":\"使用场景\",\"t\":[\"分布式训练：c10d 被广泛应用于分布式深度学习训练中，特别是在需要处理大规模数据集或模型时，能够显著缩短训练时间。\",\"多GPU训练：通过 c10d，用户可以方便地将训练任务分布在多个GPU上，从而充分利用硬件资源。\"]},\"183\":{\"h\":\"示例代码\",\"t\":[\"以下是一个简单的使用 c10d 进行广播操作的示例：\",\"import torch import torch.distributed as dist # 初始化通信库，选择GLOO后端 dist.init_process_group(backend='gloo') # 获取当前进程的rank rank = dist.get_rank() # 创建一个张量 tensor = torch.zeros(1) if rank == 0: tensor += 1 # 只有rank为0的进程修改张量 # 进行广播操作，将rank 0的张量值广播到所有进程 dist.broadcast(tensor, src=0) print(f\\\"Rank {rank} has tensor {tensor[0]}\\\")\"]},\"184\":{\"h\":\"总结\",\"t\":[\"c10d 是 PyTorch 中实现高效分布式计算的关键组件，通过提供灵活的通信后端和强大的同步机制，极大地简化了在多设备或多机器环境中进行并行计算的复杂性。\",\"SPMD 模型\",\"SPMD（Single Program, Multiple Data）模型是一种并行计算模型，在这种模型中，多个处理单元同时执行相同的程序代码，但每个处理单元处理不同的数据。这种模型广泛应用于高性能计算和分布式计算领域，特别适合需要大规模并行处理的任务。\"]},\"185\":{\"h\":\"SPMD 模型的核心思想\",\"t\":[\"单一程序： 在 SPMD 模型中，所有处理单元（通常是不同的CPU或GPU）执行相同的程序代码。这意味着每个处理单元的代码路径是相同的，但可以根据处理单元的ID或索引来执行不同的操作。\",\"多数据流： 尽管所有处理单元执行相同的程序代码，但每个处理单元处理的输入数据是不同的。这通常通过划分数据集来实现，每个处理单元处理其特定的数据子集。\",\"并行性： SPMD 模型通过同时在多个处理单元上执行相同的程序代码来实现并行性。这种并行性可以大幅提高计算效率，特别是在处理大规模数据集时。\",\"通信与同步： 在 SPMD 模型中，处理单元通常需要在某些阶段进行通信和同步。例如，处理单元可能需要共享部分计算结果或交换数据。为了确保数据的一致性，通常需要同步操作来协调各个处理单元的执行。\"]},\"186\":{\"h\":\"SPMD 与其他并行模型的比较\",\"t\":[\"SIMD（Single Instruction, Multiple Data）：与 SPMD 不同，SIMD 是在所有处理单元上执行相同的指令，并且每个处理单元处理不同的数据。在 SIMD 模型中，处理单元的操作是完全同步的。\",\"MIMD（Multiple Instruction, Multiple Data）：MIMD 模型允许每个处理单元执行不同的程序代码并处理不同的数据，与 SPMD 相比，MIMD 提供了更大的灵活性，但通常也更复杂。\"]},\"187\":{\"h\":\"应用场景\",\"t\":[\"SPMD 模型在许多并行计算任务中得到了广泛应用，典型的应用场景包括：\",\"分布式深度学习：在深度学习中，SPMD 模型通常用于分布式训练，每个处理单元（如 GPU）处理一部分数据集，并在训练过程中共享模型参数。\",\"科学计算：许多科学计算任务涉及大规模矩阵或向量操作，可以通过 SPMD 模型并行化这些操作，从而显著提高计算速度。\",\"数值模拟：SPMD 模型在气候模拟、物理仿真等领域中也得到广泛应用，允许并行处理不同区域或不同时间步的计算。\"]},\"188\":{\"h\":\"示例\",\"t\":[\"在分布式训练中，使用 SPMD 模型的一个简单示例可能是，每个 GPU 处理一个 mini-batch 的数据，然后通过通信操作将所有 GPU 的梯度进行合并并同步模型参数。\"]},\"189\":{\"h\":\"总结\",\"t\":[\"SPMD 模型是一种高效的并行计算模型，通过让多个处理单元执行相同的程序代码并处理不同的数据，能够大幅提高计算效率。它的简洁性和高效性使其成为许多并行和分布式计算任务的首选模型。\",\"MPMD\",\"MPMD（Multiple Program, Multiple Data）是一种并行计算模型，与 SPMD（Single Program, Multiple Data）模型相对应。在 MPMD 模型中，多个处理单元（如 CPU 核心或计算节点）可以执行不同的程序，并处理不同的数据集。这种模型适用于更复杂的并行计算任务，特别是在各个处理单元需要执行不同类型的计算时。\"]},\"190\":{\"h\":\"MPMD 模型的核心思想\",\"t\":[\"多个程序： 与 SPMD 模型不同，在 MPMD 模型中，每个处理单元可以运行不同的程序代码。这种灵活性允许处理单元根据任务需求执行不同的操作或算法。\",\"多数据流： 与多个程序相对应，每个处理单元处理不同的数据集。数据的划分方式可以根据具体应用进行调整，以实现负载均衡和计算资源的优化利用。\",\"并行性： MPMD 模型通过允许不同的处理单元并行执行不同的任务，最大化了计算资源的利用率。每个处理单元都可以独立处理自己的任务，互不干扰。\",\"通信与同步： 尽管处理单元运行不同的程序，但它们仍可能需要在某些阶段进行通信和数据交换。MPI（Message Passing Interface）等并行计算框架通常支持 MPMD 模型，通过消息传递机制实现进程间的通信与同步。\"]},\"191\":{\"h\":\"MPMD 与 SPMD 的比较\",\"t\":[\"灵活性：MPMD 提供了更大的灵活性，因为每个处理单元可以执行不同的程序。相比之下，SPMD 模型中所有处理单元执行相同的程序，只是数据不同。\",\"复杂性：由于 MPMD 允许不同的程序同时运行，因此任务协调和进程管理可能更加复杂。处理单元之间的通信需求可能更高，且需要精心设计。\",\"应用场景：MPMD 更适合那些需要同时执行多种任务的复杂应用。例如，某些科学计算或仿真任务可能需要不同的计算步骤，这些步骤可以由不同的程序在不同的处理单元上并行执行。\"]},\"192\":{\"h\":\"应用场景\",\"t\":[\"多物理场仿真：在一些复杂的物理仿真中，可能涉及多个物理场（如流体动力学和热传导）的计算。这些场的计算方法不同，可以在不同的处理单元上并行运行各自的程序。\",\"复杂工作流处理：在需要并行处理不同任务的工作流中，如在大规模数据处理或分析任务中，不同的处理单元可以负责不同的任务或数据集，从而加快整个工作流的执行。\",\"异构计算：在涉及多种计算架构（如 CPU 和 GPU）的应用中，MPMD 模型可以将不同的程序分配给不同的架构，以充分利用各自的计算优势。\"]},\"193\":{\"h\":\"示例场景\",\"t\":[\"假设有一个科学模拟项目，需要同时计算两个独立的物理过程。第一个进程在 CPU 上运行大气模拟程序，而第二个进程在 GPU 上运行海洋模拟程序。这两部分模拟数据可能会在某些阶段相互依赖，因此需要通过通信机制进行数据交换。使用 MPMD 模型可以分别启动两个不同的程序，并通过 MPI 等工具进行协调和通信。\"]},\"194\":{\"h\":\"实现 MPMD 的框架\",\"t\":[\"MPI 是最常用的实现 MPMD 模型的框架之一。MPI 允许用户在同一个应用程序中启动多个不同的程序实例，每个实例可以有自己的任务和数据，同时提供通信接口以在它们之间进行消息传递。\"]},\"195\":{\"h\":\"总结\",\"t\":[\"MPMD（Multiple Program, Multiple Data）模型是一种强大的并行计算模型，允许多个处理单元并行执行不同的程序，并处理不同的数据集。它的灵活性使其非常适合处理复杂的并行任务，特别是在不同任务需要不同计算资源或算法的情况下。MPI 等并行计算框架为 MPMD 模型提供了实现途径，广泛应用于科学计算、数据分析和异构计算等领域。\",\"MPI\",\"MPI（Message Passing Interface）是一种用于并行计算的标准接口，广泛应用于分布式计算和高性能计算（HPC）领域。MPI 提供了一组标准的 API，允许程序在多个处理单元（如 CPU 核心或计算节点）之间进行消息传递和协调，从而实现大规模并行计算。\"]},\"196\":{\"h\":\"MPI 的核心概念\",\"t\":[\"进程模型： MPI 采用进程并行模型，即每个并行任务在一个独立的进程中运行。进程之间通过消息传递进行通信，而不是共享内存。这种设计使得 MPI 非常适合在分布式内存系统（如计算集群）上运行。\",\"通信机制：\",\"点对点通信：两个进程之间直接进行消息传递，典型的函数有 MPI_Send 和 MPI_Recv，分别用于发送和接收消息。\",\"集体通信：MPI 提供了多种集体通信操作，如广播（broadcast）、归约（reduction）、散播（scatter）和聚集（gather），这些操作涉及多个进程之间的通信。\",\"进程组和通信域： MPI 中的进程可以组织成进程组，每个进程组拥有一个通信域（communicator）。MPI_COMM_WORLD 是所有 MPI 程序默认的通信域，包含了所有进程。用户也可以定义自己的进程组和通信域，以便更灵活地管理和组织进程。\",\"同步与异步通信： MPI 支持同步和异步的消息传递模式。同步通信要求发送方等待接收方确认消息接收，确保消息传递的顺序和一致性；异步通信则允许发送方在消息发送后立即继续执行，而不必等待接收方确认。\",\"并行I/O： MPI-IO 是 MPI 的一个子集，专门用于并行文件输入输出操作。MPI-IO 允许多个进程同时读写大规模数据集，为并行计算中的数据管理提供了高效的解决方案。\"]},\"197\":{\"h\":\"MPI 的主要功能\",\"t\":[\"并行计算：MPI 允许程序在多个处理单元上并行运行，从而加速计算任务的执行。适用于数值模拟、数据处理等需要处理大量计算的场景。\",\"跨平台兼容：MPI 是一种标准接口，支持多种硬件和操作系统平台。常见的 MPI 实现包括 OpenMPI、MPICH 等，它们在不同的计算环境中均能有效运行。\",\"高效的消息传递：MPI 针对不同的通信模式进行了优化，能够在高性能计算环境中提供低延迟和高带宽的通信服务。\"]},\"198\":{\"h\":\"使用场景\",\"t\":[\"数值模拟：在流体力学、气象预报、天体物理等领域，MPI 常用于实现复杂的数值模拟，这些任务通常需要处理非常大的数据集和复杂的计算过程。\",\"数据分析：在大规模数据分析任务中，MPI 可以将计算任务分布到多个节点，从而提高数据处理的速度和效率。\",\"机器学习和深度学习：MPI 也可以用于分布式机器学习，尤其是在需要跨多个节点或多个 GPU 进行训练的情况下，通过 MPI 实现模型的并行训练和参数同步。\"]},\"199\":{\"h\":\"示例代码\",\"t\":[\"以下是一个简单的 MPI 程序示例，展示了如何使用 MPI 实现基本的点对点通信：\",\"#include <mpi.h> #include <stdio.h> int main(int argc, char** argv) { MPI_Init(&argc, &argv); int world_rank; MPI_Comm_rank(MPI_COMM_WORLD, &world_rank); int world_size; MPI_Comm_size(MPI_COMM_WORLD, &world_size); if (world_rank == 0) { int data = 100; MPI_Send(&data, 1, MPI_INT, 1, 0, MPI_COMM_WORLD); printf(\\\"Process 0 sent data %d to process 1\\\\n\\\", data); } else if (world_rank == 1) { int data; MPI_Recv(&data, 1, MPI_INT, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE); printf(\\\"Process 1 received data %d from process 0\\\\n\\\", data); } MPI_Finalize(); return 0; }\"]},\"200\":{\"h\":\"总结\",\"t\":[\"MPI 是并行计算领域的重要工具，提供了灵活且高效的消息传递机制，使得程序能够在多处理单元环境中高效运行。MPI 的标准化设计和广泛支持使其成为高性能计算、分布式计算和大规模数据处理任务中的主流选择。\"]},\"201\":{\"h\":\"源码解读\"},\"202\":{\"h\":\"init_process_group\",\"t\":[\"torch\\\\distributed\\\\distributed_c10d.py\",\"@_exception_logger @_time_logger def init_process_group( backend: Optional[str] = None, init_method: Optional[str] = None, timeout: Optional[timedelta] = None, world_size: int = -1, rank: int = -1, store: Optional[Store] = None, group_name: str = \\\"\\\", pg_options: Optional[Any] = None, device_id: Optional[torch.device] = None, ) -> None:\",\"以下是函数 init_process_group 的翻译：\"]},\"203\":{\"h\":\"初始化默认的分布式进程组。\",\"t\":[\"这也将初始化分布式包。\",\"初始化进程组有两种主要方式：\",\"明确指定 store、rank 和 world_size。\",\"指定 init_method（一个 URL 字符串），用于指示在哪里/如何发现同伴。可以选择性地指定 rank 和 world_size，或在 URL 中编码所有必需参数并省略它们。\",\"如果两者都未指定，默认 init_method 为 \\\"env://\\\"。\"]},\"204\":{\"h\":\"参数说明：\",\"t\":[\"backend（字符串或 Backend，可选）：指定使用的后端。根据构建时的配置，有效值包括 mpi、gloo、nccl 和 ucc。如果未提供后端，将创建 gloo 和 nccl 两个后端。请注意，如果使用多个进程并且使用 nccl 后端，每个进程必须独占其使用的每个 GPU，否则可能会导致死锁。ucc 后端为实验性特性。\",\"init_method（字符串，可选）：指定如何初始化进程组的 URL。默认值为 \\\"env://\\\"（如果未指定 init_method 或 store）。与 store 互斥。\",\"world_size（整数，可选）：参与任务的进程数量。如果指定了 store，这是必需的。\",\"rank（整数，可选）：当前进程的编号（应为 0 到 world_size-1 之间的数字）。如果指定了 store，这是必需的。\",\"store（Store，可选）：可供所有工作者访问的键值存储，用于交换连接/地址信息。与 init_method 互斥。\",\"timeout（timedelta，可选）：在进程组上执行操作的超时时间。NCCL 后端的默认值为 10 分钟，其他后端为 30 分钟。这是异步中止集合操作的时间限制，操作失败后进程将崩溃。由于 CUDA 的异步执行，无法安全继续执行用户代码，可能导致后续的 CUDA 操作在损坏的数据上运行。当 TORCH_NCCL_BLOCKING_WAIT 被设置时，进程将阻塞并等待此超时时间。\",\"group_name（字符串，可选，已弃用）：进程组名称，此参数已被忽略。\",\"pg_options（ProcessGroupOptions，可选）：用于构建特定进程组的其他选项。目前支持的选项是 ProcessGroupNCCL.Options，如 is_high_priority_stream 可指定 NCCL 后端使用高优先级的 CUDA 流。其他配置选项请参考 NVIDIA NCCL 文档。\",\"device_id（torch.device，可选）：用于“绑定”当前进程的特定设备，允许进行后端优化。目前在 NCCL 下有两个效果：1) 通信器立即初始化，而不是通常的延迟调用；2) 当可能时，子组将使用 ncclCommSplit 以避免不必要的组创建开销。如果想提前知道 NCCL 初始化错误，也可以使用该参数。\"]},\"205\":{\"h\":\"Backend\",\"t\":[\"class Backend(str): \\\"\\\"\\\" An enum-like class for backends. Available backends: GLOO, NCCL, UCC, MPI, and other registered backends. The values of this class are lowercase strings, e.g., ``\\\"gloo\\\"``. They can be accessed as attributes, e.g., ``Backend.NCCL``. This class can be directly called to parse the string, e.g., ``Backend(backend_str)`` will check if ``backend_str`` is valid, and return the parsed lowercase string if so. It also accepts uppercase strings, e.g., ``Backend(\\\"GLOO\\\")`` returns ``\\\"gloo\\\"``. .. note:: The entry ``Backend.UNDEFINED`` is present but only used as initial value of some fields. Users should neither use it directly nor assume its existence. \\\"\\\"\\\"\"]},\"206\":{\"h\":\"Backend 类\",\"t\":[\"一个类似枚举的类，用于表示后端类型。\",\"可用的后端包括：GLOO、NCCL、UCC、MPI 以及其他已注册的后端。\",\"该类的值是小写字符串，例如 \\\"gloo\\\"。可以通过属性访问，例如 Backend.NCCL。\",\"此类还可以直接调用来解析字符串，例如，Backend(backend_str) 将检查 backend_str 是否有效，如果有效，返回解析后的小写字符串。它还接受大写字符串，例如，Backend(\\\"GLOO\\\") 将返回 \\\"gloo\\\"。\"]},\"207\":{\"h\":\"注意：\",\"t\":[\"条目 Backend.UNDEFINED 存在，但仅作为某些字段的初始值。用户不应直接使用它，也不应假设它的存在。\",\"这个 backend_capability 字典用于定义不同后端的支持能力。它以后端名称作为键，以支持的设备类型列表作为值。\",\"例如：\",\"GLOO 后端支持 cpu 和 cuda。\",\"NCCL 后端只支持 cuda。\",\"UCC 和 MPI 后端都支持 cpu 和 cuda。\",\"backend_capability: Dict[str, List[str]] = { GLOO: [\\\"cpu\\\", \\\"cuda\\\"], # GLOO 后端支持 CPU 和 CUDA NCCL: [\\\"cuda\\\"], # NCCL 后端只支持 CUDA UCC: [\\\"cpu\\\", \\\"cuda\\\"], # UCC 后端支持 CPU 和 CUDA MPI: [\\\"cpu\\\", \\\"cuda\\\"], # MPI 后端支持 CPU 和 CUDA }\",\"这个字典可以用于在代码中根据所选择的后端来决定可以在哪些设备上运行操作。\"]},\"208\":{\"c\":[\"分布式\"]},\"209\":{\"c\":[\"PyTorch\",\"c10d\"]},\"210\":{\"h\":\"Triton Inference Server\",\"t\":[\"Triton Inference Server\"]},\"211\":{\"h\":\"指标解释\",\"t\":[\"参考\",\"# Average percentage of time inference requests spend in queue (not including cache hits). - expr: rate(nv_inference_queue_duration_us[1m])/clamp_min(rate(nv_inference_compute_infer_duration_us[1m]),1) record: triton:queue_compute:ratio\",\"平均请求在队列中等待的时间百分比（不包括缓存命中）： \",\"expr: 使用 rate(nv_inference_queue_duration_us[1m]) 计算在过去1分钟内，推理请求在队列中等待的时间的速率。\",\"clamp_min(rate(nv_inference_compute_infer_duration_us[1m]),1): 计算在过去1分钟内，推理计算持续时间的速率，并确保其最小值为1，以避免除以零的情况。\",\"record: 这个结果被记录为 triton:queue_compute:ratio，用于后续的数据分析或监控。\",\"总体来说，这个表达式用于监控推理请求在队列中等待的时间相对于实际计算时间的比例，帮助评估系统的性能。\"]},\"212\":{\"h\":\"HPA\",\"t\":[\"参考\",\"Once the dashboard has been setup, you will be able to visualize the current state of your cluster. These visualizations can provide insight into why we've chosen to use the queue:compute ratio instead of GPU utilization as the metric used to control the behavior of the horizontal pod autoscaler.\",\"一旦仪表板设置完成，您将能够可视化集群的当前状态。这些可视化可以提供洞察，解释为什么我们选择使用队列计算比率（queue:compute ratio）而不是 GPU 利用率作为控制水平 Pod 自动缩放器行为的指标。\",\"这意味着，通过观察队列与计算的比率，可以更好地理解集群的性能和负载情况，从而做出更合理的扩展决策。\"]},\"213\":{\"c\":[\"AI Framework\"]},\"214\":{\"c\":[\"Triton\"]},\"215\":{\"h\":\"学习资料\",\"t\":[\"学习资料\"]},\"216\":{\"h\":\"\"},\"217\":{\"h\":\"项目简介\",\"t\":[\"随着ChatGPT的出圈，大语言模型层出不穷，并展现出非凡的能力，可以有效地解决各种问题。然而，这些模型通常需要大量的计算资源和内存，导致运行时资源消耗较高，限制了其在某些场景下的应用，让很多研究者望而却步。本项目使用通俗易懂的语言介绍模型的剪枝、量化、知识蒸馏等压缩方法，让更多的小白能更快了解到模型压缩技术。\",\"在线阅读地址: https://datawhalechina.github.io/awesome-compression\"]},\"218\":{\"h\":\"\",\"t\":[\"近年来，自然语言处理（NLP）领域随着 Transformer 架构的出现取得了突破性进展，HuggingFace 作为 NLP 社区的重要力量，提供了海量的预训练模型和众多强大易用的函数库，极大地降低了 NLP 应用开发的门槛。\",\"本项目旨在为学习者提供深入学习 HuggingFace😊 生态系统的教程，并通过完成生动有趣的具体项目提升学习者实践水平。\",\"unlock-hf在线阅读链接\"]},\"219\":{\"h\":\"\",\"t\":[\"本教程主要侧重于模型/LLM推理和部署理论与实践，旨在成为你掌握LLM推理与部署艺术的伙伴，无论你是初涉此领域的新人，还是寻求深化专业技能的资深人士，都能在此找到通往成功部署大型语言模型的关键路径。\"]},\"220\":{\"h\":\"\",\"t\":[\"本项目是一个围绕开源大模型、针对国内初学者、基于 Linux 平台的中国宝宝专属大模型教程，针对各类开源大模型提供包括环境配置、本地部署、高效微调等技能在内的全流程指导，简化开源大模型的部署、使用和应用流程，让更多的普通学生、研究者更好地使用开源大模型，帮助开源、自由的大模型更快融入到普通学习者的生活中。\",\"本项目的主要内容包括：\",\"基于 Linux 平台的开源 LLM 环境配置指南，针对不同模型要求提供不同的详细环境配置步骤； 针对国内外主流开源 LLM 的部署使用教程，包括 LLaMA、ChatGLM、InternLM 等； 开源 LLM 的部署应用指导，包括命令行调用、在线 Demo 部署、LangChain 框架集成等； 开源 LLM 的全量微调、高效微调方法，包括分布式全量微调、LoRA、ptuning 等。 项目的主要内容就是教程，让更多的学生和未来的从业者了解和熟悉开源大模型的食用方法！任何人都可以提出issue或是提交PR，共同构建维护这个项目。\"]},\"221\":{\"h\":\"\"},\"222\":{\"h\":\"项目简介\",\"t\":[\"本项目是一个面向小白开发者的大模型应用开发教程，旨在基于阿里云服务器，结合个人知识库助手项目，通过一个课程完成大模型开发的重点入门，主要内容包括：\"]},\"223\":{\"h\":\"大模型简介，何为大模型、大模型特点是什么、LangChain 是什么，如何开发一个 LLM 应用，针对小白开发者的简单介绍；\",\"t\":[\"如何调用大模型 API，本节介绍了国内外知名大模型产品 API 的多种调用方式，包括调用原生 API、封装为 LangChain LLM、封装为 Fastapi 等调用方式，同时将包括百度文心、讯飞星火、智谱AI等多种大模型 API 进行了统一形式封装； 知识库搭建，不同类型知识库文档的加载、处理，向量数据库的搭建； 构建 RAG 应用，包括将 LLM 接入到 LangChain 构建检索问答链，使用 Streamlit 进行应用部署 验证迭代，大模型开发如何实现验证迭代，一般的评估方法有什么； 本项目主要包括三部分内容：\",\"LLM 开发入门。V1 版本的简化版，旨在帮助初学者最快、最便捷地入门 LLM 开发，理解 LLM 开发的一般流程，可以搭建出一个简单的 Demo。 LLM 开发技巧。LLM 开发更进阶的技巧，包括但不限于：Prompt Engineering、多类型源数据的处理、优化检索、召回精排、Agent 框架等 LLM 应用实例。引入一些成功的开源案例，从本课程的角度出发，解析这些应用范例的 Idea、核心思路、实现框架，帮助初学者明白其可以通过 LLM 开发什么样的应用。\"]},\"224\":{\"h\":\"\",\"t\":[\"本项目是一个从原理出发、以“白盒”为导向、围绕大模型全链路的“手搓”大模型指南，旨在帮助有传统深度学习基础的读者从底层原理出发，“纯手搓”搭建一个清晰、可用的大模型系统，包括大模型本身、RAG 框架、Agent 系统及大模型评估体系。本项目将从基础原理出发，深入剖析每一个技术点并附以完整的代码实现，以细致讲解和代码注释帮助读者独立复现大模型核心部分，并在复现中实现对大模型的深入理解与掌握。\",\"本项目旨在为广大学习者搭建一个清晰的、可用的、可复现的大模型世界，帮助每一位有兴趣的学习者纯手工独立搭建自己的 Tiny LLM Universe。\",\"本项目的主要内容包括：\",\"深入剖析大模型原理——Qwen Blog 逐步预训练一个手搓大模型——Tiny Llama3 如何评估你的大模型——Tiny Eval 纯手工搭建 RAG 框架——Tiny RAG 手搓一个最小的 Agent 系统——Tiny Agent 深入理解大模型基础——Tiny Transformer\"]},\"225\":{\"h\":\"\",\"t\":[\"面向开发者的大模型手册 - LLM Cookbook\"]},\"226\":{\"h\":\"项目简介\",\"t\":[\"本项目是一个面向开发者的大模型手册，针对国内开发者的实际需求，主打 LLM 全方位入门实践。本项目基于吴恩达老师大模型系列课程内容，对原课程内容进行筛选、翻译、复现和调优，覆盖从 Prompt Engineering 到 RAG 开发、模型微调的全部流程，用最适合国内学习者的方式，指导国内开发者如何学习、入门 LLM 相关项目。\",\"针对不同内容的特点，我们对共计 11 门吴恩达老师的大模型课程进行了翻译复现，并结合国内学习者的实际情况，对不同课程进行了分级和排序，初学者可以先系统学习我们的必修类课程，掌握入门 LLM 所有方向都需要掌握的基础技能和概念，再选择性地学习我们的选修类课程，在自己感兴趣的方向上不断探索和学习。\",\"如果有你非常喜欢但我们还没有进行复现的吴恩达老师大模型课程，我们欢迎每一位开发者参考我们已有课程的格式和写法来对课程进行复现并提交 PR，在 PR 审核通过后，我们会根据课程内容将课程进行分级合并。欢迎每一位开发者的贡献！\",\"在线阅读地址：面向开发者的 LLM 入门课程-在线阅读\",\"PDF下载地址：面向开发者的 LLM 入门教程-PDF\",\"英文原版地址：吴恩达关于大模型的系列课程\"]},\"227\":{\"h\":\"\"},\"228\":{\"h\":\"项目简介\",\"t\":[\"动手学 Ollama 教程，轻松上手实现大模型本地化部署，快速在本地管理以及运行大模型，让 CPU 也可以玩转大模型推理部署！\",\"本教程涵盖从基础入门到进阶使用的全方位内容，并通过实际应用案例深入理解和掌握大模型部署以及应用技术。我们的教程提供清晰的步骤和实用的技巧，无论是刚刚接触大模型部署的小白，还是有一定经验的开发者，都可以从零开始学习 Ollama ，实现本地部署大模型以及相关应用。\",\"目录结构说明：\",\"docs ---------------------- Markdown 文档文件\",\"notebook ------------------ Notebook 源代码文件以及部分 Python、Java 和 JavaScript 源文件\",\"images -------------------- 图片\",\"在线阅读：https://datawhalechina.github.io/handy-ollama/\"]},\"229\":{\"h\":\"\",\"t\":[\"西瓜书代码实战\",\"本项目以西瓜书以及南瓜书为主要参考，其他资料为辅助，来进行常见机器学习代码的实战。主要特色为力求数码结合，即数学公式与相关代码的形神对应，能够帮助读者加深对公式的理解以及代码的熟练。\"]},\"230\":{\"h\":\"\"},\"231\":{\"h\":\"项目简介\",\"t\":[\"本项目旨在作为一个大规模预训练语言模型的教程，从数据准备、模型构建、训练策略到模型评估与改进，以及模型在安全、隐私、环境和法律道德方面的方面来提供开源知识。\",\"项目将以斯坦福大学大规模语言模型课程和李宏毅生成式AI课程为基础，结合来自开源贡献者的补充和完善，以及对前沿大模型知识的及时更新，为读者提供较为全面而深入的理论知识和实践方法。通过对模型构建、训练、评估与改进等方面的系统性讲解，以及代码的实战，我们希望建立一个具有广泛参考价值的项目。\",\"我们的项目团队成员将分工负责各个章节的内容梳理和撰写，并预计在三个月内完成初始版本内容。随后，我们将持续根据社区贡献和反馈进行内容的更新和优化，以确保项目的持续发展和知识的时效性。我们期待通过这个项目，为大型语言模型研究领域贡献一份宝贵的资源，推动相关技术的快速发展和广泛应用。\"]},\"232\":{\"h\":\"\",\"t\":[\"AIFoundation 主要是指AI系统遇到大模型，从底层到上层如何系统级地支持大模型训练和推理，全栈的核心技术。\",\"聚焦 AI Foundation，大模型系统。大模型是基于 AI 集群的全栈软硬件性能优化，通过最小的每一块 AI 芯片组成的 AI 集群，编译器使能到上层的 AI 框架，训练过程需要分布式并行、集群通信等算法支持，而且在大模型领域最近持续演进如智能体等新技术。\"]},\"233\":{\"h\":\"\",\"t\":[\"本开源课程主要是跟大家一起探讨和学习人工智能、深度学习的系统设计，而整个系统是围绕着 ZOMI 在工作当中所积累、梳理、构建 AI 系统全栈的内容。希望跟所有关注 AI 开源课程的好朋友一起探讨研究，共同促进学习讨论。\"]},\"234\":{\"h\":\"\"},\"235\":{\"c\":[\"资料\"]},\"236\":{\"c\":[\"学习资料\"]},\"237\":{\"h\":\"常用工具总结\"},\"238\":{\"h\":\"ubuntu\"},\"239\":{\"h\":\"ping 安装\",\"t\":[\"apt install iputils-ping\"]},\"240\":{\"h\":\"获取公网ip\",\"t\":[\"curl ip.sb curl ipinfo.io\"]},\"241\":{\"h\":\"ffmpeg\"},\"242\":{\"h\":\"视频抽帧转图片\",\"t\":[\"ffmpeg.exe -i C:\\\\Users\\\\Administrator\\\\Downloads\\\\分析.mp4 -r 5 -f image2 C:\\\\Users\\\\Administrator\\\\Pictures\\\\bg\\\\image-%03d.jpg\"]},\"243\":{\"c\":[\"工具\"]},\"244\":{\"c\":[\"skill\"]},\"245\":{\"h\":\"开源技术\",\"t\":[\"MInference：通过动态稀疏注意力加速长上下文 LLM 的预填充\"]},\"246\":{\"h\":\"地址\",\"t\":[\"https://github.com/microsoft/MInference\"]},\"247\":{\"h\":\"论文\",\"t\":[\"https://hqjiang.com/minference.html\"]},\"248\":{\"h\":\"介绍\",\"t\":[\"论文介绍了一种名为 MInference 的动态稀疏注意力方法，用于解决长上下文 LLM 推理中的问题，并通过多种实验和测试展示了其效果。\"]},\"249\":{\"h\":\"重要亮点\",\"t\":[\"MInference 的提出背景：长上下文 LLM 推理面临预填充阶段注意力延迟长、KV 缓存存储和传输成本高等挑战，之前方法难以低成本在单个 A100 GPU 实现百万级标记提示的可接受延迟，MInference 应运而生。\",\"MInference 的工作原理：利用动态稀疏注意的静态空间聚合模式，离线确定每个头的最佳动态稀疏模式，在推理中动态近似动态稀疏索引，使用优化的 GPU 内核执行高效计算，显著减少预填充阶段延迟。\",\"MInference 的主要贡献：加速长上下文 LLM 的预填充阶段多达 10 倍；将动态稀疏注意力分为三种模式并设计搜索算法；引入在线近似方法和优化内核，提出最佳推理代码库；通过四个基准测试评估，在成本效率和系统延迟方面表现出色。\",\"长上下文基准测试中的实验结果：在问答、编码、基于检索等一系列任务中测试 MInference，有效保留或扩展实际上下文窗口处理能力，在不同模型和方法对比中性能良好。\",\"内核中的延迟细分和稀疏模式：展示三种注意力模式和 FlashAttention 的微基准测试结果，Vertical-Slash 虽慢但仍有显著加速，还展示了 Vertical-Slash 头部 kernel 中的稀疏索引。\"]},\"250\":{\"c\":[\"开源技术\"]},\"251\":{\"c\":[\"推理引擎\"]},\"252\":{\"h\":\"操作系统\",\"t\":[\"strace命令\",\"strace 是一个用于跟踪系统调用和信号的工具，它可以帮助你诊断程序的行为或调试程序。-p 选项用于附加到一个正在运行的进程上，并实时显示它的系统调用。\"]},\"253\":{\"h\":\"解释命令：\",\"t\":[\"strace -p 871\",\"strace：调用 strace 工具。\",\"-p 871：指定进程ID（PID）为 871 的进程。strace 会附加到这个进程，并跟踪它的系统调用。\"]},\"254\":{\"h\":\"使用场景：\",\"t\":[\"实时跟踪系统调用：你可以看到进程 871 进行的每个系统调用，这有助于了解程序在做什么。\",\"调试和排错：如果某个进程表现异常，比如挂起、资源消耗过高等，通过 strace 可以查看它在调用哪些系统调用，以便分析问题的根本原因。\"]},\"255\":{\"h\":\"注意事项：\",\"t\":[\"权限：如果目标进程由另一个用户（比如 root）启动，可能需要相应的权限（例如通过 sudo）来使用 strace。\",\"性能影响：strace 会对被跟踪的进程产生一定的性能开销，尤其是在处理大量系统调用时，所以应在必要时使用。\",\"运行该命令后，你会看到进程871的系统调用输出，直到你停止 strace (通常通过 Ctrl+C)。\",\"top命令解释\",\"我们可以用上面这张图，把这些值挨个解释一下。\",\"假设一个用户程序开始运行了，那么就对应着第一个\\\"us\\\"框，\\\"us\\\"是\\\"user\\\"的缩写，代表 Linux 的用户态 CPU Usage。普通用户程序代码中，只要不是调用系统调用（System Call），这些代码的指令消耗的 CPU 就都属于\\\"us\\\"。\",\"当这个用户程序代码中调用了系统调用，比如说 read() 去读取一个文件，这时候这个用户进程就会从用户态切换到内核态。\",\"内核态 read() 系统调用在读到真正 disk 上的文件前，就会进行一些文件系统层的操作。那么这些代码指令的消耗就属于\\\"sy\\\"，这里就对应上面图里的第二个框。\\\"sy\\\"是 \\\"system\\\"的缩写，代表内核态 CPU 使用。\",\"接下来，这个 read() 系统调用会向 Linux 的 Block Layer 发出一个 I/O Request，触发一个真正的磁盘读取操作。\",\"这时候，这个进程一般会被置为 TASK_UNINTERRUPTIBLE。而 Linux 会把这段时间标示成\\\"wa\\\"，对应图中的第三个框。\\\"wa\\\"是\\\"iowait\\\"的缩写，代表等待 I/O 的时间，这里的 I/O 是指 Disk I/O。\",\"紧接着，当磁盘返回数据时，进程在内核态拿到数据，这里仍旧是内核态的 CPU 使用中的\\\"sy\\\"，也就是图中的第四个框。\",\"然后，进程再从内核态切换回用户态，在用户态得到文件数据，这里进程又回到用户态的 CPU 使用，\\\"us\\\"，对应图中第五个框。\",\"好，这里我们假设一下，这个用户进程在读取数据之后，没事可做就休眠了。并且我们可以进一步假设，这时在这个 CPU 上也没有其他需要运行的进程了，那么系统就会进入\\\"id\\\"这个步骤，也就是第六个框。\\\"id\\\"是\\\"idle\\\"的缩写，代表系统处于空闲状态。\",\"如果这时这台机器在网络收到一个网络数据包，网卡就会发出一个中断（interrupt）。相应地，CPU 会响应中断，然后进入中断服务程序。\",\"这时，CPU 就会进入\\\"hi\\\"，也就是第七个框。\\\"hi\\\"是\\\"hardware irq\\\"的缩写，代表 CPU 处理硬中断的开销。由于我们的中断服务处理需要关闭中断，所以这个硬中断的时间不能太长。\",\"但是，发生中断后的工作是必须要完成的，如果这些工作比较耗时那怎么办呢？Linux 中有一个软中断的概念（softirq），它可以完成这些耗时比较长的工作。\",\"你可以这样理解这个软中断，从网卡收到数据包的大部分工作，都是通过软中断来处理的。那么，CPU 就会进入到第八个框，\\\"si\\\"。这里\\\"si\\\"是\\\"softirq\\\"的缩写，代表 CPU 处理软中断的开销。\",\"这里你要注意，无论是\\\"hi\\\"还是\\\"si\\\"，它们的 CPU 时间都不会计入进程的 CPU 时间。这是因为本身它们在处理的时候就不属于任何一个进程。\",\"好了，通过这个场景假设，我们介绍了大部分的 Linux CPU 使用。\",\"不过，我们还剩两个类型的 CPU 使用没讲到，我想给你做个补充，一次性带你做个全面了解。这样以后你解决相关问题时，就不会再犹豫，这些值到底影不影响 CPU Cgroup 中的限制了。下面我给你具体讲一下。\",\"一个是\\\"ni\\\"，是\\\"nice\\\"的缩写，这里表示如果进程的 nice 值是正值（1-19），代表优先级比较低的进程运行时所占用的 CPU。\",\"另外一个是\\\"st\\\"，\\\"st\\\"是\\\"steal\\\"的缩写，是在虚拟机里用的一个 CPU 使用类型，表示有多少时间是被同一个宿主机上的其他虚拟机抢走的。\"]},\"256\":{\"h\":\"扩容磁盘\",\"t\":[\"要将 nvme0n1p1 的空间扩展到 /dev/mapper/centos-root，你需要执行以下步骤。这包括删除 nvme0n1p1 分区，重新分配空间，并将其添加到现有的 LVM 逻辑卷中。\"]},\"257\":{\"h\":\"1. 卸载并删除 分区\",\"t\":[\"首先，你需要确保 nvme0n1p1 上没有重要数据，并且它未被挂载。如果已经挂载，请先卸载：\",\"sudo umount /dev/nvme0n1p1\",\"然后，使用 fdisk 删除 nvme0n1p1 分区：\",\"sudo fdisk /dev/nvme0n1\",\"进入 fdisk 命令行后：\",\"输入 d 选择删除分区，然后输入分区号 1 删除 nvme0n1p1。\",\"输入 w 写入更改并退出 fdisk。\"]},\"258\":{\"h\":\"2. 创建新的分区并标记为 LVM\",\"t\":[\"在释放 nvme0n1p1 的空间后，你需要重新创建一个新的分区，覆盖以前的分区空间，并将其类型设置为 Linux LVM。\",\"仍然使用 fdisk 来创建新分区：\",\"sudo fdisk /dev/nvme0n1\",\"进入 fdisk 命令行后：\",\"输入 n 创建一个新的分区。\",\"使用默认的开始和结束扇区，覆盖以前的 nvme0n1p1 分区空间。\",\"输入 t 设置新分区的类型为 8e（Linux LVM）。\",\"输入 w 写入更改并退出 fdisk。\"]},\"259\":{\"h\":\"3. 将新分区添加到 LVM 物理卷\",\"t\":[\"新分区创建并标记为 LVM 后，将其添加到 LVM 的物理卷中：\",\"sudo pvcreate /dev/nvme0n1p1 sudo vgextend centos /dev/nvme0n1p1\"]},\"260\":{\"h\":\"4. 扩展逻辑卷\",\"t\":[\"现在，你可以将新的空间分配给逻辑卷 centos-root：\",\"sudo lvextend -l +100%FREE /dev/mapper/centos-root\"]},\"261\":{\"h\":\"5. 扩展 文件系统\",\"t\":[\"最后，使用 xfs_growfs 来扩展文件系统，使其利用新增的空间：\",\"sudo xfs_growfs /dev/mapper/centos-root\"]},\"262\":{\"h\":\"6. 验证扩展结果\",\"t\":[\"扩展完成后，使用 df -h / 来检查根文件系统的大小：\",\"df -h /\",\"这个命令将显示根文件系统的更新后的容量，确认 nvme0n1p1 的空间已经成功分配给 /dev/mapper/centos-root。\"]},\"263\":{\"h\":\"wsl 启用systemd\",\"t\":[\"解决Ubantu 报错：System has not been booted with systemd as init system (PID 1). Can‘t operate.\",\"若要启用 systemd，请使用sudo管理员权限在文本编辑器中打开文件wsl.conf，并将以下行添加到/etc/wsl.conf\",\"[boot] systemd=true\",\"然后，需要使用 PowerShell 关闭 WSL 分发 wsl.exe --shutdown 版来重启 WSL 实例。分发重启后，系统应运行。可以使用以下命令进行确认：systemctl list-unit-files --type=service这将显示服务的状态。\"]},\"264\":{\"h\":\"WSL2迁移至其他目录\",\"t\":[\"1） 停止正在运行的wsl\",\"wsl --shutdown\",\"2）将需要迁移的Linux，进行导出\",\"wsl --export Ubuntu-20.04 D:/ubuntu22.04.tar\",\"3）导出完成之后，将原有的Linux卸载\",\"wsl --unregister Ubuntu-20.04\",\"4） 然后将导出的文件放到需要保存的地方，进行导入即可\",\"wsl --import Ubuntu-20.04 D:\\\\ubuntu\\\\ D:/ubuntu/ubuntu22.04.tar --version 2\"]},\"265\":{\"c\":[\"操作系统\"]},\"266\":{\"c\":[\"操作系统\"]},\"267\":{\"h\":\"计算机网络\",\"t\":[\"http2与http1区别?\",\"HTTP/2 是对 HTTP/1.x 协议的重大升级，旨在提高网络性能和效率。以下是 HTTP/2 相对于 HTTP/1 的一些关键区别和改进：\"]},\"268\":{\"h\":\"1. 协议基础\",\"t\":[\"HTTP/1.x: 基于纯文本的协议，使用新行符分隔的文本消息进行通信。\",\"HTTP/2: 基于二进制的协议，使用二进制帧传输数据，更高效地解析和传输数据。\"]},\"269\":{\"h\":\"2. 连接管理\",\"t\":[\"HTTP/1.x:\",\"每个请求/响应对通常需要一个单独的TCP连接（HTTP/1.0）。\",\"HTTP/1.1 引入了连接保持（Keep-Alive），允许在同一个TCP连接上复用多个请求，但在同一时刻只能处理一个请求（串行化处理）。\",\"HTTP/2:\",\"单个TCP连接上可以处理多个并发的请求/响应对。\",\"使用流的概念，每个请求/响应对在一个单独的流中，流之间可以独立并行处理。\"]},\"270\":{\"h\":\"3. 多路复用\",\"t\":[\"HTTP/1.x: 在一个连接上，只有一个请求/响应对可以被处理（头部阻塞问题），需要等待当前请求完成后，才能开始下一个请求。\",\"HTTP/2: 允许多个请求/响应对在同一连接上的多个流中并发传输，不同的流可以独立处理，不会相互阻塞。\"]},\"271\":{\"h\":\"4. 头部压缩\",\"t\":[\"HTTP/1.x: HTTP头部是以纯文本格式传输的，每个请求都需要发送完整的头部信息，导致冗余和带宽浪费。\",\"HTTP/2: 使用 HPACK 算法对头部进行压缩，减少了传输数据量。头部信息仅在第一次请求时完整传输，后续请求只需发送差异部分。\"]},\"272\":{\"h\":\"5. 服务器推送\",\"t\":[\"HTTP/1.x: 客户端必须明确请求每个资源，服务器只能响应客户端的请求。\",\"HTTP/2: 支持服务器推送功能，服务器可以在客户端请求之前主动发送资源，这有助于减少延迟和提升性能。例如，当客户端请求HTML页面时，服务器可以主动推送相关的CSS和JavaScript文件。\"]},\"273\":{\"h\":\"6. 优先级和流控制\",\"t\":[\"HTTP/1.x: 没有内建的优先级控制机制，所有请求被平等对待。\",\"HTTP/2: 支持流的优先级，客户端可以指定不同流的优先级，允许更重要的请求先行处理。同时，HTTP/2 提供流量控制机制，确保没有流会独占带宽。\"]},\"274\":{\"h\":\"7. 加密和安全\",\"t\":[\"HTTP/1.x: 加密是可选的（通过HTTP或HTTPS），但非加密的HTTP请求仍然普遍存在。\",\"HTTP/2: 大多数实现强制要求使用加密（通过HTTPS），尽管协议本身不强制这一点。现代浏览器和服务器在实际应用中通常要求 HTTP/2 使用 TLS。\"]},\"275\":{\"h\":\"8. 协议扩展性\",\"t\":[\"HTTP/1.x: 由于是文本协议，扩展和添加新功能变得复杂。\",\"HTTP/2: 作为二进制协议，HTTP/2 更容易扩展，添加新功能可以通过新帧类型和更复杂的协议操作来实现，而不影响现有的功能。\"]},\"276\":{\"h\":\"9. 性能改进\",\"t\":[\"HTTP/1.x: 多个小的请求可能会因为串行化处理导致较高的延迟和低效的带宽利用。\",\"HTTP/2: 通过多路复用、头部压缩和服务器推送等功能，HTTP/2 显著降低了延迟，改善了带宽利用，提升了整体性能。\"]},\"277\":{\"h\":\"总结\",\"t\":[\"特性\",\"HTTP/1.x\",\"HTTP/2\",\"协议类型\",\"基于纯文本\",\"基于二进制\",\"连接管理\",\"每个请求通常需要一个TCP连接\",\"单个连接处理多个并发请求\",\"多路复用\",\"不支持（有头部阻塞问题）\",\"支持\",\"头部压缩\",\"不支持\",\"使用HPACK算法进行压缩\",\"服务器推送\",\"不支持\",\"支持\",\"优先级和流控制\",\"不支持\",\"支持\",\"加密和安全\",\"可选（但非强制）\",\"大多数实现要求加密（HTTPS）\",\"协议扩展性\",\"扩展复杂\",\"更容易扩展\",\"性能\",\"受限于串行化处理和头部阻塞\",\"显著提升（多路复用、压缩、推送）\",\"HTTP/2 带来了显著的改进和优化，使得网络应用能够更高效地传输数据，提升了用户体验和网络性能。\"]},\"278\":{\"h\":\"查看系统中已有的veth设备对或确认已创建的veth设备对，可以使用以下几种方法：\"},\"279\":{\"h\":\"使用 命令\",\"t\":[\"ip 命令是查看和管理网络设备的主要工具：\",\"列出所有网络接口：\",\"ip link show\",\"该命令会列出系统中所有的网络接口，包括veth设备对。\",\"过滤veth设备：\",\"ip link show | grep veth\",\"通过grep过滤出veth设备。\"]},\"280\":{\"h\":\"使用 命令\",\"t\":[\"ifconfig命令也可以用于查看网络接口：\",\"ifconfig\",\"同样，可以使用grep过滤出veth设备：\",\"ifconfig | grep veth\"]},\"281\":{\"h\":\"查看具体veth设备对的详细信息\",\"t\":[\"可以使用以下命令查看某个veth设备对的详细信息：\",\"ip link show veth0\"]},\"282\":{\"h\":\"示例\",\"t\":[\"假设创建了一个veth设备对：\",\"ip link add veth0 type veth peer name veth1\",\"然后，可以使用以下命令查看：\",\"ip link show | grep veth\",\"输出可能类似于：\",\"10: veth0@veth1: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000 11: veth1@veth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000\",\"这表明veth0和veth1是一对互相连接的虚拟以太网设备。\"]},\"283\":{\"h\":\"检查命名空间中的veth设备\",\"t\":[\"如果将veth设备移动到不同的命名空间，可以使用以下命令查看特定命名空间中的网络接口：\",\"ip netns exec ns1 ip link show ip netns exec ns1 ip link show 1: lo: <LOOPBACK> mtu 65536 qdisc noop state DOWN mode DEFAULT group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 28: veth1@if29: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP mode DEFAULT group default qlen 1000 link/ether 52:7e:e0:b6:47:d2 brd ff:ff:ff:ff:ff:ff link-netnsid 0 ip netns exec ns1 ip a 1: lo: <LOOPBACK> mtu 65536 qdisc noop state DOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 28: veth1@if29: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default qlen 1000 link/ether 52:7e:e0:b6:47:d2 brd ff:ff:ff:ff:ff:ff link-netnsid 0 inet 192.168.1.2/24 scope global veth1 valid_lft forever preferred_lft forever inet6 fe80::507e:e0ff:feb6:47d2/64 scope link valid_lft forever preferred_lft forever\",\"假设veth1被移动到命名空间ns1，可以在ns1命名空间中看到它。\",\"通过这些命令，可以方便地查看和管理系统中的veth设备对。\"]},\"284\":{\"h\":\"VLAN 与VXLAN\",\"t\":[\"VLAN（Virtual Local Area Network）和VXLAN（Virtual Extensible LAN）是两种用于网络分段和虚拟化的技术，它们各自有不同的应用场景和特点。以下是对它们的解析：\"]},\"285\":{\"h\":\"VLAN（Virtual Local Area Network）\",\"t\":[\"VLAN是一种用于在同一物理网络上创建多个逻辑网络的技术。它的主要特点和用途如下：\",\"网络分段：通过VLAN，可以将一个物理网络分割成多个逻辑网络，使得不同VLAN之间的通信受到限制，从而提高网络的安全性和性能。\",\"标记帧：VLAN使用IEEE 802.1Q标准，在以太网帧中添加一个4字节的标签，标记帧属于哪个VLAN。\",\"VLAN ID：每个VLAN都有一个唯一的VLAN ID，范围是1到4094。网络设备根据这个ID来区分不同的VLAN。\",\"配置简单：VLAN的配置相对简单，只需要在交换机上配置相关的端口或接口即可。\",\"常见用途：\",\"提高网络安全性，通过分割网络减少广播域。\",\"提高网络性能，通过减少广播流量和冲突域。\",\"提供灵活的网络管理和用户分组。\"]},\"286\":{\"h\":\"VXLAN（Virtual Extensible LAN）\",\"t\":[\"VXLAN是一种用于在大规模数据中心和云环境中创建虚拟网络的技术。它的主要特点和用途如下：\",\"扩展性：VXLAN使用24位的VNI（VXLAN Network Identifier），理论上支持多达1600万个虚拟网络，大大超过了VLAN的4094个限制。\",\"基于隧道：VXLAN通过UDP隧道封装，将二层以太网帧封装在三层IP包中，从而可以跨越传统的二层边界在IP网络上传输。\",\"分布式架构：VXLAN适用于大规模的分布式数据中心环境，支持跨多个物理位置的虚拟机迁移和负载均衡。\",\"网络虚拟化：VXLAN可以在现有的IP网络基础上创建虚拟网络，使得虚拟机和容器之间的通信更加灵活和高效。\",\"常见用途：\",\"数据中心和云环境中的大规模虚拟化网络。\",\"跨多个数据中心的虚拟机迁移和高可用性。\",\"支持多租户环境，每个租户可以有独立的虚拟网络。\"]},\"287\":{\"h\":\"对比\",\"t\":[\"特点\",\"VLAN\",\"VXLAN\",\"标识符\",\"12位VLAN ID（最多4094个）\",\"24位VNI（最多1600万个）\",\"封装层\",\"二层以太网（IEEE 802.1Q）\",\"三层IP（UDP隧道封装）\",\"应用场景\",\"小规模网络、局域网\",\"大规模数据中心、云环境、跨数据中心\",\"配置复杂度\",\"简单\",\"较复杂，需要配置隧道端点（VTEP）\",\"扩展性\",\"有限，最多4094个VLAN\",\"高扩展性，支持多达1600万个虚拟网络\"]},\"288\":{\"h\":\"总结\",\"t\":[\"VLAN适用于较小规模的网络分段和隔离，而VXLAN适用于大规模数据中心和云环境中的网络虚拟化和扩展。它们各自有不同的优缺点和应用场景，根据具体需求选择合适的技术可以提高网络的性能、安全性和管理灵活性。\"]},\"289\":{\"h\":\"VXLAN与VTEP\"},\"290\":{\"h\":\"VXLAN（Virtual Extensible LAN）\",\"t\":[\"VXLAN是一种用于扩展二层网络的技术，特别适合在大型数据中心和云环境中使用。其主要特性包括：\",\"扩展性：VXLAN使用24位的VNI（VXLAN Network Identifier），支持多达1600万个虚拟网络，远远超过传统VLAN的4094个限制。\",\"隧道封装：VXLAN通过UDP隧道封装将二层以太网帧封装在三层IP包中，从而可以在三层IP网络上进行传输。这种方式允许二层流量跨越不同的三层网络，使得虚拟机可以在不同的物理位置之间自由迁移。\",\"多租户支持：VXLAN允许在同一个物理网络基础设施上运行多个独立的虚拟网络，每个虚拟网络可以有自己的VNI，从而支持多租户环境。\",\"弹性和高可用性：VXLAN可以在现有的IP网络上实现二层网络的扩展和弹性，支持负载均衡和高可用性。\"]},\"291\":{\"h\":\"VTEP（VXLAN Tunnel Endpoint）\",\"t\":[\"VTEP是VXLAN架构中的关键组件，负责VXLAN隧道的端点操作。其主要功能包括：\",\"隧道端点：VTEP是VXLAN隧道的起点和终点，负责VXLAN包的封装和解封装。每个VTEP有两个主要接口：一个是连接到传统二层网络的接口，另一个是连接到IP网络的接口。\",\"封装和解封装：当VTEP接收到来自二层网络的以太网帧时，它将帧封装在UDP包中，附加上VNI，然后通过IP网络发送到目标VTEP。目标VTEP解封装UDP包，并将以太网帧发送到其二层网络接口。\",\"VNI映射：VTEP负责将二层网络中的VLAN ID映射到VXLAN的VNI，从而在VXLAN隧道中维护虚拟网络的隔离和标识。\",\"MAC地址学习：VTEP通过监听网络流量和ARP（Address Resolution Protocol）请求，学习和维护虚拟网络中MAC地址到VTEP的映射关系。这类似于传统二层交换机的MAC地址表。\"]},\"292\":{\"h\":\"VXLAN 和 VTEP 的工作流程\",\"t\":[\"帧封装：当主机A发送一个以太网帧给主机B时，该帧首先被发送到本地的VTEP。\",\"VXLAN包封装：VTEP将该帧封装到一个UDP包中，并附加上对应的VNI。UDP包的源IP和目的IP是VTEP的IP地址。\",\"通过IP网络传输：封装好的VXLAN包通过三层IP网络传输到目的VTEP。\",\"帧解封装：目的VTEP接收到VXLAN包后，解封装出原始的以太网帧。\",\"帧传递：解封装的以太网帧被发送到目标主机B所在的二层网络。\"]},\"293\":{\"h\":\"总结\",\"t\":[\"VXLAN通过在现有的三层IP网络上创建虚拟二层网络，实现了大规模的数据中心和云环境中的网络虚拟化和扩展。VTEP作为VXLAN架构中的关键组件，负责隧道的端点操作，完成VXLAN包的封装和解封装。VXLAN和VTEP的结合，使得跨越不同物理位置的虚拟机能够像在同一个二层网络中一样进行通信，从而实现了高效、灵活和可扩展的网络架构。\"]},\"294\":{\"h\":\"ip neigh show\",\"t\":[\"ip neigh show dev flannel.1命令用于显示指定网络设备（在这里是flannel.1）的邻居表项。邻居表存储了网络设备的邻居节点的信息，包括其IP地址和MAC地址。\",\"在使用flannel的Kubernetes集群中，flannel.1通常是用于Overlay网络的设备接口。运行这个命令会列出该接口的所有邻居节点的信息。每个邻居节点条目通常包含以下信息：\",\"IP地址：邻居节点的IP地址。\",\"MAC地址：邻居节点的MAC地址。\",\"状态：邻居节点的状态，例如REACHABLE（可达）、STALE（陈旧）、DELAY（延迟）、PROBE（探测）等。\",\"例如，运行ip neigh show dev flannel.1可能得到以下输出：\",\"10.244.2.1 dev flannel.1 lladdr 0a:58:0a:f4:02:01 REACHABLE 10.244.2.2 dev flannel.1 lladdr 0a:58:0a:f4:02:02 STALE\",\"在这个例子中：\",\"10.244.2.1 是一个邻居节点的IP地址，0a:58:0a:f4:02:01 是其MAC地址，状态是REACHABLE。\",\"10.244.2.2 是另一个邻居节点的IP地址，0a:58:0a:f4:02:02 是其MAC地址，状态是STALE。\"]},\"295\":{\"h\":\"总结\",\"t\":[\"ip neigh show dev flannel.1命令用于查看指定设备（如flannel.1）的邻居节点信息，帮助管理员了解当前网络设备与其他节点的连接状态和MAC地址映射情况。这对于排查网络问题和管理网络连接非常有用。\"]},\"296\":{\"h\":\"bridge fdb show\",\"t\":[\"bridge fdb show命令用于显示Linux桥接设备的前向数据库（Forwarding Database，FDB）。FDB记录了MAC地址与网络接口的映射关系，帮助桥接设备确定数据帧的转发路径。通过这个命令，可以查看桥接设备当前的MAC地址表，了解哪些MAC地址通过哪些接口连接。\"]},\"297\":{\"h\":\"示例输出\",\"t\":[\"运行bridge fdb show命令的示例输出可能如下所示：\",\"33:33:00:00:00:01 dev ens3 self permanent 01:00:5e:00:00:01 dev ens3 self permanent 02:42:ac:11:00:02 dev docker0 vlan 1 master docker0 02:42:ac:11:00:03 dev docker0 vlan 1 master docker0\"]},\"298\":{\"h\":\"输出字段解释\",\"t\":[\"MAC地址：如33:33:00:00:00:01，这是设备的MAC地址。\",\"dev：后面跟随的是设备名，如ens3或docker0，表示该MAC地址对应的设备。\",\"self：表示该条目是本地接口的MAC地址。\",\"permanent：表示该条目是永久性的，而不是动态学习到的。\",\"vlan：VLAN ID，表示该条目所属的VLAN。\",\"master：表示该设备所属的主设备。\"]},\"299\":{\"h\":\"常用选项\",\"t\":[\"bridge fdb show [dev DEVICE]：显示特定设备的FDB条目。例如，bridge fdb show dev br0显示设备br0的FDB。\",\"bridge fdb show [br BRIDGE]：显示特定桥接设备的FDB条目。\"]},\"300\":{\"h\":\"使用示例\",\"t\":[\"显示所有桥接设备的FDB条目：\",\"bridge fdb show\",\"显示特定设备的FDB条目：\",\"bridge fdb show dev br0\",\"显示特定桥接设备的FDB条目：\",\"bridge fdb show br br0\"]},\"301\":{\"h\":\"总结\",\"t\":[\"bridge fdb show命令用于查看Linux桥接设备的前向数据库，帮助管理员了解网络中MAC地址的分布情况和转发路径。这对于网络故障排查和性能优化非常有用。\"]},\"302\":{\"h\":\"ARP协议\",\"t\":[\"ARP（Address Resolution Protocol，地址解析协议）是一种用于在IPv4网络中将IP地址解析为物理地址（如MAC地址）的网络协议。它在以太网等局域网环境中起着关键作用，使得设备能够通过IP地址找到目标设备的物理地址，从而进行通信。\"]},\"303\":{\"h\":\"ARP 工作原理\",\"t\":[\"ARP 请求：\",\"当设备A需要向设备B发送数据时，它知道设备B的IP地址，但不知道设备B的MAC地址。设备A会先在本地的ARP缓存中查找设备B的IP地址对应的MAC地址。\",\"如果在ARP缓存中找不到设备B的MAC地址，设备A会广播一条ARP请求帧到网络中。该ARP请求包含设备B的IP地址，并询问“谁是这个IP地址的拥有者？请告诉我你的MAC地址。”\",\"ARP 响应：\",\"网络中的所有设备都会接收到这个ARP请求帧。当设备B接收到这个ARP请求时，它会检查其中的IP地址。\",\"如果设备B的IP地址与请求中的IP地址匹配，设备B会发送一条ARP响应帧。该响应帧包含设备B的MAC地址，并单播发送给设备A。\",\"更新ARP缓存：\",\"设备A接收到设备B的ARP响应后，会将设备B的IP地址和MAC地址映射关系存储在本地的ARP缓存中，以便后续通信时可以直接使用，而无需再次发送ARP请求。\"]},\"304\":{\"h\":\"ARP 报文格式\",\"t\":[\"ARP报文包含两个主要部分：ARP请求和ARP响应。其报文格式如下：\",\"硬件类型（Hardware Type）：通常为1，表示以太网。\",\"协议类型（Protocol Type）：通常为0x0800，表示IPv4。\",\"硬件地址长度（Hardware Address Length）：表示硬件地址的长度，通常为6（MAC地址长度）。\",\"协议地址长度（Protocol Address Length）：表示协议地址的长度，通常为4（IPv4地址长度）。\",\"操作码（Operation Code）：1表示ARP请求，2表示ARP响应。\",\"发送方硬件地址（Sender Hardware Address）：发送设备的MAC地址。\",\"发送方协议地址（Sender Protocol Address）：发送设备的IP地址。\",\"目标硬件地址（Target Hardware Address）：目标设备的MAC地址（ARP请求中该字段为空）。\",\"目标协议地址（Target Protocol Address）：目标设备的IP地址。\"]},\"305\":{\"h\":\"ARP 缓存\",\"t\":[\"为了提高效率，设备会将最近解析的IP地址和MAC地址映射关系存储在ARP缓存中。ARP缓存中的条目通常有一个生存时间（TTL），超过该时间后条目将被删除，以保证ARP缓存的最新性。\"]},\"306\":{\"h\":\"ARP的安全问题\",\"t\":[\"ARP协议本身没有安全机制，因此容易受到ARP欺骗（ARP Spoofing）攻击。攻击者可以发送伪造的ARP响应，将其MAC地址伪装成另一个设备的MAC地址，从而拦截或篡改网络通信。\"]},\"307\":{\"h\":\"ARP欺骗的防御措施\",\"t\":[\"静态ARP表：手动配置IP地址和MAC地址的映射，防止ARP欺骗。\",\"ARP检测：使用网络设备（如交换机）提供的ARP检测功能，过滤掉伪造的ARP报文。\",\"VPN：通过虚拟专用网络（VPN）加密通信，防止中间人攻击。\"]},\"308\":{\"h\":\"总结\",\"t\":[\"ARP协议在IPv4网络中起到了关键的地址解析作用，使设备能够通过IP地址找到目标设备的MAC地址，从而进行通信。虽然ARP协议本身存在安全隐患，但通过适当的防御措施可以有效防止ARP欺骗攻击。\"]},\"309\":{\"h\":\"BGP协议\",\"t\":[\"BGP（Border Gateway Protocol，边界网关协议）是互联网核心路由协议，用于在不同自治系统（AS, Autonomous Systems）之间交换路由信息。BGP是唯一能够处理互联网中如此大规模路由的协议，被广泛应用于ISP（互联网服务提供商）、大型企业和数据中心网络中。\"]},\"310\":{\"h\":\"BGP 的主要特性和工作原理\",\"t\":[\"自治系统（AS）：\",\"一个AS是一组由同一管理实体管理的IP网络和路由器。每个AS都有一个唯一的AS编号（ASN）。\",\"BGP 会话：\",\"BGP运行在TCP之上（端口179），通过建立BGP会话来交换路由信息。这些会话通常是静态配置的，由网络管理员手动设置。\",\"路径向量协议：\",\"BGP是一种路径向量协议，通过维护到达每个目标网络的路径信息来选择最佳路径。路径信息包括多个AS路径，以避免环路。\",\"路由选择：\",\"BGP使用一套复杂的路由选择规则来确定最佳路径。这些规则包括： \",\"最短的AS路径\",\"优先级最高的本地优先级（local preference）\",\"最小的多出口判别器（MED, Multi-Exit Discriminator）\",\"最稳定的路径（考虑路由抖动）\",\"最小的路由器ID\",\"策略控制：\",\"BGP允许网络管理员基于策略控制路由选择和路由传播。管理员可以设置各种策略，例如路由过滤、路由聚合和路由优先级，以满足特定的网络需求。\",\"类型：\",\"iBGP（内部BGP）：在同一AS内的路由器之间运行，用于传播内部路由信息。\",\"eBGP（外部BGP）：在不同AS之间的路由器之间运行，用于交换外部路由信息。\"]},\"311\":{\"h\":\"BGP 的工作过程\",\"t\":[\"建立BGP会话：\",\"两个BGP路由器（称为BGP对等体或邻居）首先建立TCP连接，然后交换BGP OPEN消息以建立BGP会话。\",\"交换路由信息：\",\"一旦会话建立，BGP对等体之间就开始交换完整的BGP路由表。之后，路由器仅在路由信息发生变化时交换更新。\",\"路由传播：\",\"BGP路由器根据接收到的路由信息更新其路由表，并根据策略决定是否将这些路由信息传播给其他对等体。\",\"路由更新和撤销：\",\"当网络拓扑发生变化时，BGP路由器会发送路由更新（UPDATE）或撤销（WITHDRAW）消息，以通知其他对等体。\"]},\"312\":{\"h\":\"BGP 的优势和挑战\"},\"313\":{\"h\":\"优势：\",\"t\":[\"可扩展性：BGP能够处理大量的路由信息，非常适合大规模的网络环境。\",\"灵活性：BGP允许管理员根据特定需求配置路由策略。\",\"稳定性：BGP设计用于在大型、复杂的网络环境中保持稳定和高效。\"]},\"314\":{\"h\":\"挑战：\",\"t\":[\"复杂性：BGP配置和管理相对复杂，需要深入的网络知识。\",\"收敛时间：BGP在处理大型网络拓扑变化时的收敛时间较长。\",\"安全性：BGP缺乏内置的安全机制，需要额外的配置和措施来防止路由劫持和攻击。\"]},\"315\":{\"h\":\"总结\",\"t\":[\"BGP是互联网的关键路由协议，负责在不同AS之间交换路由信息。它的路径向量机制、策略控制能力和高可扩展性使其成为管理互联网复杂路由需求的理想选择。然而，BGP的配置和管理也相对复杂，需要专业知识和经验。\"]},\"316\":{\"h\":\"、 、 、 和 是网络管理中常用的命令。它们各自有不同的功能，但一起使用时可以全面管理和配置网络接口、路由和防火墙规则。以下是这些命令的功能及其关系的详细介绍：\"},\"317\":{\"h\":\"\"},\"318\":{\"h\":\"功能：\",\"t\":[\"ifconfig 是一个传统的工具，用于配置网络接口。它可以查看和修改接口配置，包括 IP 地址、子网掩码、广播地址等。\"]},\"319\":{\"h\":\"用法：\",\"t\":[\"查看网络接口信息：\",\"ifconfig\",\"启用或禁用接口：\",\"sudo ifconfig eth0 up sudo ifconfig eth0 down\",\"配置 IP 地址：\",\"sudo ifconfig eth0 192.168.1.100 netmask 255.255.255.0\"]},\"320\":{\"h\":\"(也称 )\"},\"321\":{\"h\":\"功能：\",\"t\":[\"ip a 是 ip 命令套件的一部分，用于显示或修改网络接口的地址信息。相比 ifconfig，ip 提供了更丰富和更强大的功能。\"]},\"322\":{\"h\":\"用法：\",\"t\":[\"查看所有接口的地址信息：\",\"ip a\"]},\"323\":{\"h\":\"\"},\"324\":{\"h\":\"功能：\",\"t\":[\"ip link 是 ip 命令套件的一部分，用于显示和修改网络接口的属性。\"]},\"325\":{\"h\":\"用法：\",\"t\":[\"查看所有接口的链路状态：\",\"ip link show\",\"启用或禁用接口：\",\"sudo ip link set eth0 up sudo ip link set eth0 down\"]},\"326\":{\"h\":\"\"},\"327\":{\"h\":\"功能：\",\"t\":[\"ip route 用于显示和管理路由表。它可以添加、删除和查看路由规则。\"]},\"328\":{\"h\":\"用法：\",\"t\":[\"查看当前的路由表：\",\"ip route show\",\"添加路由：\",\"sudo ip route add 192.168.2.0/24 via 192.168.1.1 dev eth0\",\"删除路由：\",\"sudo ip route del 192.168.2.0/24\"]},\"329\":{\"h\":\"\"},\"330\":{\"h\":\"功能：\",\"t\":[\"iptables 是一个用户空间实用程序，用于配置 Linux 内核防火墙实现（在 netfilter 框架下）。它用于管理入站、出站和转发的数据包过滤规则。\"]},\"331\":{\"h\":\"用法：\",\"t\":[\"查看所有规则：\",\"sudo iptables -L -v -n\",\"添加规则：\",\"sudo iptables -A INPUT -p tcp --dport 22 -j ACCEPT\",\"删除规则：\",\"sudo iptables -D INPUT -p tcp --dport 22 -j ACCEPT\"]},\"332\":{\"h\":\"关系\",\"t\":[\"这些命令一起使用可以全面管理和配置网络：\",\"接口配置：使用 ifconfig、ip a 和 ip link 可以查看和配置网络接口的状态和地址。\",\"路由管理：使用 ip route 可以添加、删除和查看路由规则，决定数据包如何在网络中转发。\",\"防火墙规则：使用 iptables 可以设置防火墙规则，控制数据包的流入、流出和转发。\",\"ifconfig 是一个较老的工具，功能相对有限，但在某些系统上仍然可用。ip 命令套件（包括 ip a、ip link 和 ip route）是现代的、功能更强大的替代品。iptables 提供了强大的防火墙配置能力，可以与 ip 命令一起使用，实现全面的网络管理。\"]},\"333\":{\"h\":\"七层网络模型\",\"t\":[\"七层网络模型，也称为OSI（开放系统互连）模型，是由国际标准化组织（ISO）制定的一种网络通信标准框架。它将网络通信过程划分为七个层次，每个层次都有其特定的功能和协议。以下是七层网络模型的详细介绍：\"]},\"334\":{\"h\":\"1. 物理层（Physical Layer）\",\"t\":[\"功能：负责在物理介质上传输比特流，包括定义硬件设备的电气、机械、过程和功能特性。\",\"协议和设备：电缆、网卡、集线器（Hub）、传输介质（如双绞线、光纤）等。\"]},\"335\":{\"h\":\"2. 数据链路层（Data Link Layer）\",\"t\":[\"功能：提供节点之间的可靠数据传输，负责帧的创建、传输、错误检测和纠正。\",\"协议和设备：以太网（Ethernet）、Wi-Fi（802.11）、交换机（Switch）、网桥（Bridge）等。\"]},\"336\":{\"h\":\"3. 网络层（Network Layer）\",\"t\":[\"功能：负责逻辑地址的管理和数据包的路由选择，确保数据包从源节点到达目标节点。\",\"协议和设备：IP（互联网协议）、ICMP（Internet Control Message Protocol）、路由器（Router）等。\"]},\"337\":{\"h\":\"4. 传输层（Transport Layer）\",\"t\":[\"功能：提供端到端的通信服务，确保数据在主机之间可靠、有序地传输。主要负责流量控制、数据分段和重组、错误检测和恢复。\",\"协议和设备：TCP（传输控制协议）、UDP（用户数据报协议）。\"]},\"338\":{\"h\":\"5. 会话层（Session Layer）\",\"t\":[\"功能：管理应用程序之间的会话，负责建立、管理和终止会话。它还提供同步和对话控制。\",\"协议和设备：NetBIOS、RPC（远程过程调用）。\"]},\"339\":{\"h\":\"6. 表示层（Presentation Layer）\",\"t\":[\"功能：负责数据格式的转换和表示，包括数据加密、解密、压缩和解压缩。确保不同系统间的数据格式一致。\",\"协议和设备：SSL/TLS（安全套接层/传输层安全）、JPEG、MPEG、GIF。\"]},\"340\":{\"h\":\"7. 应用层（Application Layer）\",\"t\":[\"功能：提供网络服务和应用程序接口，是用户与网络交互的界面。负责识别通信伙伴、资源分配和同步通信。\",\"协议和设备：HTTP（超文本传输协议）、FTP（文件传输协议）、SMTP（简单邮件传输协议）、DNS（域名系统）等。\"]},\"341\":{\"h\":\"各层之间的关系\",\"t\":[\"层次依赖：每一层依赖于下一层提供的服务。例如，传输层依赖于网络层提供的路由和地址服务。\",\"封装和解封装：当数据从发送端传输到接收端时，每一层会添加或移除相应的协议头。这种过程称为封装和解封装。\"]},\"342\":{\"h\":\"应用示例\",\"t\":[\"网页浏览：用户在浏览器中输入网址，应用层的HTTP协议将请求传递到传输层的TCP协议，TCP将数据包分段并传递到网络层的IP协议，IP协议进行路由选择，将数据包通过数据链路层和物理层传输到目标服务器。服务器接收到数据后，逆向处理，最终将网页内容展示给用户。\"]},\"343\":{\"h\":\"总结\",\"t\":[\"OSI模型通过将网络通信过程划分为七个独立的层次，使得网络设计和实现更加模块化和清晰。这种分层模型有助于不同网络设备和协议的互操作性和标准化，从而促进了网络技术的发展和普及。\"]},\"344\":{\"h\":\"spine交换机 leaf 交换机 以及组网架构\",\"t\":[\"在现代数据中心和高性能网络中，Spine-Leaf 组网架构是最常见的一种拓扑结构。它解决了传统树形网络架构中的瓶颈问题，尤其适合需要高吞吐量和低延迟的环境。下面我们来介绍 Spine交换机、Leaf交换机 以及它们的组网架构。\"]},\"345\":{\"h\":\"1.\",\"t\":[\"定义：Spine（脊骨）交换机是网络架构中的核心交换设备，负责高性能的东西向流量转发。它位于组网架构的核心层或骨干层，连接多个Leaf（叶子）交换机。\",\"作用：Spine交换机的主要功能是提供高带宽和低延迟的骨干互联。在Spine-Leaf架构中，每个Leaf交换机都会连接到所有Spine交换机，形成多个等价的路径，从而确保网络流量可以快速而高效地在不同的Leaf交换机之间转发。\",\"特点： \",\"Spine交换机通常具有非常高的端口密度和带宽，支持多路并行流量转发。\",\"Spine交换机之间一般不直接连接，它们只连接到Leaf交换机。\",\"Spine交换机的数量通常比Leaf交换机少，因为它们是集中处理流量的设备。\"]},\"346\":{\"h\":\"2.\",\"t\":[\"定义：Leaf（叶子）交换机是网络架构中的接入层交换设备，通常连接服务器、存储设备和其他网络终端。\",\"作用：Leaf交换机主要用于南北向流量转发，也就是服务器到服务器、服务器到存储、服务器到外部网络的流量。在Spine-Leaf架构中，所有的Leaf交换机都会直接连接到上层的Spine交换机，实现南北向和东西向流量的高效转发。\",\"特点： \",\"Leaf交换机负责将服务器、存储设备等连接到网络，并将它们之间的通信转发到Spine交换机。\",\"每个Leaf交换机会连接到所有的Spine交换机，确保冗余和多路径。\",\"Leaf交换机数量通常较多，分布在数据中心的不同区域，为终端设备提供网络接入。\"]},\"347\":{\"h\":\"3.\",\"t\":[\"拓扑结构：Spine-Leaf架构采用了一种扁平化的双层网络拓扑：\",\"Leaf层：Leaf交换机位于网络的接入层，负责连接服务器、存储等终端设备。每个Leaf交换机与多个Spine交换机相连。\",\"Spine层：Spine交换机位于网络的骨干层，每个Spine交换机与所有的Leaf交换机相连，形成全互联的结构。\",\"特点：Leaf和Spine交换机之间形成多条等价路径，使用ECMP（Equal-Cost Multi-Path，等价多路径路由）协议来实现负载均衡，防止流量瓶颈。\",\"东西向和南北向流量：\",\"东西向流量：指数据中心内服务器之间的通信。例如，两个服务器之间的文件传输或数据库查询。东西向流量通常经过Leaf交换机到Spine交换机，再从Spine交换机到另一台Leaf交换机，最终到达目标服务器。\",\"南北向流量：指从数据中心内部到外部网络的流量或从外部网络到数据中心的流量。通常是通过Leaf交换机到外部的防火墙、路由器或网关。\",\"优势：\",\"高带宽：由于每个Leaf交换机连接到多个Spine交换机，网络具有高度的带宽冗余和路径选择能力。\",\"低延迟：架构扁平化，使得数据转发路径较短，减少了延迟。\",\"可扩展性：可以轻松扩展，通过增加Spine交换机来提高网络容量，或者通过增加Leaf交换机来连接更多设备。\",\"负载均衡：借助ECMP协议，Spine-Leaf架构可以在多个等价路径上分配流量，从而实现高效的负载均衡。\"]},\"348\":{\"h\":\"4.\",\"t\":[\"数据中心：Spine-Leaf架构非常适合现代云计算和大数据中心。它能有效处理大规模集群中的东西向流量（服务器间通信），并具有高带宽和低延迟的特点。\",\"高性能计算（HPC）：对于需要大量并行计算的场景，如科学计算和模拟仿真，Spine-Leaf架构提供了高效的网络通信。\",\"企业级网络：一些大型企业的网络也采用Spine-Leaf架构，以确保高可用性和扩展性。\"]},\"349\":{\"h\":\"总结\",\"t\":[\"Spine交换机位于网络的核心层，负责高效地处理和转发跨多个Leaf交换机的流量。\",\"Leaf交换机位于接入层，负责连接终端设备，并将流量转发给Spine交换机。\",\"Spine-Leaf组网架构是一种扁平化、可扩展、低延迟的网络拓扑，特别适合现代数据中心和高性能计算应用场景。\",\"这种架构通过提供多个冗余路径和均衡流量的能力，解决了传统树形架构中容易出现的瓶颈问题。\"]},\"350\":{\"h\":\"RDMA\",\"t\":[\"RDMA (Remote Direct Memory Access) 并不依赖 NVLink 或 NVSwitch。这三者是不同的技术，虽然它们都与数据传输和高性能计算相关，但它们的作用和使用场景不同。\"]},\"351\":{\"h\":\"RDMA 介绍\",\"t\":[\"RDMA 是一种允许计算机之间直接访问彼此内存的技术，绕过操作系统的网络协议栈，从而实现更低的延迟和更高的带宽。RDMA 常用于网络通信，特别是在高性能计算（HPC）、大规模数据中心、存储系统等场景中。RDMA 通过网络技术（如 InfiniBand、RoCE、iWARP）来实现，与物理内存和网络适配器（如 NIC）之间的高速数据传输密切相关。\",\"RDMA的关键特性： \",\"不依赖于CPU进行数据传输，因此降低了CPU负载。\",\"通过网络直接读取和写入远程内存，减少了数据传输的延迟。\"]},\"352\":{\"h\":\"NVLink 和 NVSwitch 介绍\",\"t\":[\"NVLink 和 NVSwitch 是 NVIDIA 开发的专有高速互连技术，主要用于 GPU 之间的通信，特别是多个 GPU 之间的数据交换。\",\"NVLink 是一种高带宽、低延迟的互连技术，允许多个 GPU 以及 GPU 与 CPU 之间快速交换数据。它为 GPU 提供比传统 PCIe 更快的连接通道，但它主要是用于同一台服务器内部的通信，不用于网络通信。\",\"NVSwitch 是 NVLink 的扩展版，允许多个 GPU（如 NVIDIA DGX 系统中使用的8个GPU）同时进行大规模的点对点通信。这是通过一个硬件交换设备实现的，进一步增强了大规模多GPU系统的通信能力。\"]},\"353\":{\"h\":\"NVLink/NVSwitch 与 RDMA 的区别\",\"t\":[\"RDMA 是一种网络通信技术，允许服务器之间通过网络交换数据，适用于集群环境和分布式系统。它与**网络接口卡（NIC）**和网络交换机有关，而不是与GPU的直接通信有关。\",\"NVLink 和 NVSwitch 则是用于同一服务器内部多个 GPU 或 GPU 与 CPU 之间的数据传输，而不涉及远程服务器或网络通信。\"]},\"354\":{\"h\":\"依赖关系\",\"t\":[\"RDMA 不依赖 NVLink 或 NVSwitch：RDMA 使用 InfiniBand、RoCE 或 iWARP 等网络技术实现高效的远程内存访问，与 NVLink 或 NVSwitch 无直接依赖关系。RDMA 的工作重点是通过网络快速访问远程服务器内存，而 NVLink 和 NVSwitch 的工作重点是提升 GPU 之间的通信效率，通常应用于同一个物理节点内的多个 GPU。\",\"NVLink 和 NVSwitch 不支持 RDMA：它们仅用于同一台服务器中的 GPU 或 GPU 和 CPU 之间的高速通信，无法在服务器之间通过网络进行通信，因此不支持 RDMA。\"]},\"355\":{\"h\":\"适用场景\",\"t\":[\"RDMA：分布式系统、存储系统、跨服务器的高效通信，特别适合集群和高性能计算环境。\",\"NVLink/NVSwitch：在单一服务器中多个 GPU 之间的高速通信，用于加速 GPU 计算密集型任务，如深度学习训练和大规模并行计算。\"]},\"356\":{\"h\":\"总结\",\"t\":[\"RDMA 是一种用于跨服务器网络通信的技术，而 NVLink 和 NVSwitch 是 GPU 之间的高速互连技术。RDMA 不依赖 NVLink 或 NVSwitch，它们各自用于不同的通信场景，RDMA 用于远程服务器之间的通信，而 NVLink/NVSwitch 则用于同一台服务器内部的多GPU通信。\"]},\"357\":{\"c\":[\"网络\"]},\"358\":{\"c\":[\"http\"]},\"359\":{\"h\":\"独立开发者一点思考\",\"t\":[\"杂谈之独立开发者一点思考\",\"https://indiehacker.one/\",\"全文总结 本文主要介绍了独立开发者的相关内容，包括什么是独立开发者、为什么要做独立开发者、有哪些牛逼的独立开发者、独立开发者面临的困境、独立开发的一些基本流程、想法、如何判断想法的是不是可以赚钱、三大核心问题、如何解决用户的问题、使用什么样的编程语言、采用什么样的产品形态、一个 MVP 产品最少需要做多少工作、一周开发一个新产品、三点金规铁律、发布、别人说你的产品是垃圾，伪需求怎么办、增长、心态、如何保持积极的心态、如何面对压力等。\",\"重要亮点\",\"什么是独立开发者：指的是一类独立的、自主运营并开发自己的在线业务以获得收入的人。\",\"为什么要做独立开发者：成为一名独立开发者可以提供很多传统工作所无法提供的优点，包括人身自由、财务自由、成长与学习、实现自己的想法等。\",\"有哪些牛逼的独立开发者：levelsio 和 Baye aka 威力狈是公认的独立开发者中的牛逼人物。\",\"独立开发者面临的困境：包括美工问题、营销问题、生活压力、保持动力等。\",\"独立开发的一些基本流程：包括想法、开发、发布等环节。\",\"想法：想法是一个产品的起始点，需要大致正确即可，在实践的过程中，想法可能会发生改变，产品方向也会发生改变。\",\"如何判断想法的是不是可以赚钱：做好一个 DEMO 页面，罗列你的想法和产品特点，中间加个具有号召性的按钮。然后把这个页面推广出去。最后做数据分析。根据分析结果，你很快就会知道你的想法是不是可以赚到钱。\",\"三大核心问题：包括产品有什么核心功能和特点、产品的目标客户是谁、目标客户会经常出现在那里。\",\"如何解决用户的问题：用户并不知道自己需要什么，直到我们拿出自己的产品，他们就会发现，这就是我想要的。\",\"使用什么样的编程语言：你会哪个就用哪个，熟悉哪个就用哪个。\",\"采用什么样的产品形态：需要考虑产品适合使用哪种产品形态、目标客户更愿意使用哪种产品、目前有能力提供哪种产品形态。\",\"一个 MVP 产品最少需要做多少工作：答案是 9 个页面和 9 个接口。\",\"一周开发一个新产品：对于一个中等水平的技术人员来说，一周的时间足够开发一个新产品。\",\"三点金规铁律：包括不要熬夜做产品、不做免费的产品、不做完美的产品。\",\"发布：当你的产品完成了最小 MVP 的时候，就可以发布了。\",\"别人说你的产品是垃圾，伪需求怎么办：需要重申审视是不是你的产品功能和特性不够，他是不是你的目标客户。\",\"如何保持积极的心态：积极是暂时的，不积极才是常态，关键是不要消极。\",\"如何面对压力：独立开发和创业一样有风险，需要有心理准备，最好有以下几方面准备：将独立开发当作\",\"全文总结 本文主要介绍了独立开发者的相关内容，包括什么是独立开发者、为什么要做独立开发者、有哪些牛逼的独立开发者、独立开发者面临的困境、独立开发的一些基本流程、想法、如何判断想法的是不是可以赚钱、三大核心问题、如何解决用户的问题、使用什么样的编程语言、采用什么样的产品形态、一个 MVP 产品最少需要做多少工作、一周开发一个新产品、三点金规铁律、发布、别人说你的产品是垃圾，伪需求怎么办、增长、心态、如何保持积极的心态、如何面对压力等。\",\"重要亮点\",\"什么是独立开发者：指的是一类独立的、自主运营并开发自己的在线业务以获得收入的人。\",\"为什么要做独立开发者：成为一名独立开发者可以提供很多传统工作所无法提供的优点，包括人身自由、财务自由、成长与学习、实现自己的想法等。\",\"有哪些牛逼的独立开发者：levelsio 和 Baye aka 威力狈是公认的独立开发者中的牛逼人物。\",\"独立开发者面临的困境：包括美工问题、营销问题、生活压力、保持动力等。\",\"独立开发的一些基本流程：包括想法、开发、发布等环节。\",\"想法：想法是一个产品的起始点，需要大致正确即可，在实践的过程中，想法可能会发生改变，产品方向也会发生改变。\",\"如何判断想法的是不是可以赚钱：做好一个 DEMO 页面，罗列你的想法和产品特点，中间加个具有号召性的按钮。然后把这个页面推广出去。最后做数据分析。根据分析结果，你很快就会知道你的想法是不是可以赚到钱。\",\"三大核心问题：包括产品有什么核心功能和特点、产品的目标客户是谁、目标客户会经常出现在那里。\",\"如何解决用户的问题：用户并不知道自己需要什么，直到我们拿出自己的产品，他们就会发现，这就是我想要的。\",\"使用什么样的编程语言：你会哪个就用哪个，熟悉哪个就用哪个。\",\"采用什么样的产品形态：需要考虑产品适合使用哪种产品形态、目标客户更愿意使用哪种产品、目前有能力提供哪种产品形态。\",\"一个 MVP 产品最少需要做多少工作：答案是 9 个页面和 9 个接口。\",\"一周开发一个新产品：对于一个中等水平的技术人员来说，一周的时间足够开发一个新产品。\",\"三点金规铁律：包括不要熬夜做产品、不做免费的产品、不做完美的产品。\",\"发布：当你的产品完成了最小 MVP 的时候，就可以发布了。\",\"别人说你的产品是垃圾，伪需求怎么办：需要重申审视是不是你的产品功能和特性不够，他是不是你的目标客户。\",\"如何保持积极的心态：积极是暂时的，不积极才是常态，关键是不要消极。\",\"如何面对压力：独立开发和创业一样有风险，需要有心理准备，最好有以下几方面准备：将独立开发当作\"]},\"360\":{\"c\":[\"杂谈\"]},\"361\":{\"c\":[\"独立开发者\"]},\"362\":{\"h\":\"FastGpt+chatgpt-on-web\",\"t\":[\"FastGpt\"]},\"363\":{\"h\":\"地址\",\"t\":[\"https://github.com/labring/FastGPT\"]},\"364\":{\"h\":\"文档\",\"t\":[\"https://doc.tryfastgpt.ai/docs/\"]},\"365\":{\"h\":\"配置\",\"t\":[\"// 已使用 json5 进行解析，会自动去掉注释，无需手动去除 { \\\"feConfigs\\\": { \\\"lafEnv\\\": \\\"https://laf.dev\\\" // laf环境。 https://laf.run （杭州阿里云） ,或者私有化的laf环境。如果使用 Laf openapi 功能，需要最新版的 laf 。 }, \\\"systemEnv\\\": { \\\"vectorMaxProcess\\\": 15, \\\"qaMaxProcess\\\": 15, \\\"pgHNSWEfSearch\\\": 100 // 向量搜索参数。越大，搜索越精确，但是速度越慢。设置为100，有99%+精度。 }, \\\"llmModels\\\": [ { \\\"model\\\": \\\"gpt-3.5-turbo\\\", // 模型名(对应OneAPI中渠道的模型名) \\\"name\\\": \\\"gpt-3.5-turbo\\\", // 模型别名 \\\"avatar\\\": \\\"/imgs/model/openai.svg\\\", // 模型的logo \\\"maxContext\\\": 125000, // 最大上下文 \\\"maxResponse\\\": 16000, // 最大回复 \\\"quoteMaxToken\\\": 120000, // 最大引用内容 \\\"maxTemperature\\\": 1.2, // 最大温度 \\\"charsPointsPrice\\\": 0, // n积分/1k token（商业版） \\\"censor\\\": false, // 是否开启敏感校验（商业版） \\\"vision\\\": true, // 是否支持图片输入 \\\"datasetProcess\\\": true, // 是否设置为知识库处理模型（QA），务必保证至少有一个为true，否则知识库会报错 \\\"usedInClassify\\\": true, // 是否用于问题分类（务必保证至少有一个为true） \\\"usedInExtractFields\\\": true, // 是否用于内容提取（务必保证至少有一个为true） \\\"usedInToolCall\\\": true, // 是否用于工具调用（务必保证至少有一个为true） \\\"usedInQueryExtension\\\": true, // 是否用于问题优化（务必保证至少有一个为true） \\\"toolChoice\\\": true, // 是否支持工具选择（分类，内容提取，工具调用会用到。目前只有gpt支持） \\\"functionCall\\\": false, // 是否支持函数调用（分类，内容提取，工具调用会用到。会优先使用 toolChoice，如果为false，则使用 functionCall，如果仍为 false，则使用提示词模式） \\\"customCQPrompt\\\": \\\"\\\", // 自定义文本分类提示词（不支持工具和函数调用的模型 \\\"customExtractPrompt\\\": \\\"\\\", // 自定义内容提取提示词 \\\"defaultSystemChatPrompt\\\": \\\"\\\", // 对话默认携带的系统提示词 \\\"defaultConfig\\\": {} // 请求API时，挟带一些默认配置（比如 GLM4 的 top_p） }, { \\\"model\\\": \\\"SparkDesk-v3.5\\\", \\\"name\\\": \\\"星火\\\", \\\"avatar\\\": \\\"/imgs/model/openai.svg\\\", \\\"maxContext\\\": 125000, \\\"maxResponse\\\": 4000, \\\"quoteMaxToken\\\": 120000, \\\"maxTemperature\\\": 1.2, \\\"charsPointsPrice\\\": 0, \\\"censor\\\": false, \\\"vision\\\": true, \\\"datasetProcess\\\": false, \\\"usedInClassify\\\": true, \\\"usedInExtractFields\\\": true, \\\"usedInToolCall\\\": true, \\\"usedInQueryExtension\\\": true, \\\"toolChoice\\\": true, \\\"functionCall\\\": false, \\\"customCQPrompt\\\": \\\"\\\", \\\"customExtractPrompt\\\": \\\"\\\", \\\"defaultSystemChatPrompt\\\": \\\"\\\", \\\"defaultConfig\\\": {} } ], \\\"vectorModels\\\": [ { \\\"model\\\": \\\"text-embedding-ada-002\\\", // 模型名（与OneAPI对应） \\\"name\\\": \\\"Embedding-2\\\", // 模型展示名 \\\"avatar\\\": \\\"/imgs/model/openai.svg\\\", // logo \\\"charsPointsPrice\\\": 0, // n积分/1k token \\\"defaultToken\\\": 700, // 默认文本分割时候的 token \\\"maxToken\\\": 3000, // 最大 token \\\"weight\\\": 100, // 优先训练权重 \\\"defaultConfig\\\": {}, // 自定义额外参数。例如，如果希望使用 embedding3-large 的话，可以传入 dimensions:1024，来返回1024维度的向量。（目前必须小于1536维度） \\\"dbConfig\\\": {}, // 存储时的额外参数（非对称向量模型时候需要用到） \\\"queryConfig\\\": {} // 参训时的额外参数 }, { \\\"model\\\": \\\"text-embedding-3-large\\\", \\\"name\\\": \\\"text-embedding-3-large\\\", \\\"avatar\\\": \\\"/imgs/model/openai.svg\\\", \\\"charsPointsPrice\\\": 0, \\\"defaultToken\\\": 512, \\\"maxToken\\\": 3000, \\\"weight\\\": 100, \\\"defaultConfig\\\": { \\\"dimensions\\\": 1024 } }, { \\\"model\\\": \\\"text-embedding-3-small\\\", \\\"name\\\": \\\"text-embedding-3-small\\\", \\\"avatar\\\": \\\"/imgs/model/openai.svg\\\", \\\"charsPointsPrice\\\": 0, \\\"defaultToken\\\": 512, \\\"maxToken\\\": 3000, \\\"weight\\\": 100 } ], \\\"reRankModels\\\": [], \\\"audioSpeechModels\\\": [ { \\\"model\\\": \\\"tts-1\\\", \\\"name\\\": \\\"OpenAI TTS1\\\", \\\"charsPointsPrice\\\": 0, \\\"voices\\\": [ { \\\"label\\\": \\\"Alloy\\\", \\\"value\\\": \\\"alloy\\\", \\\"bufferId\\\": \\\"openai-Alloy\\\" }, { \\\"label\\\": \\\"Echo\\\", \\\"value\\\": \\\"echo\\\", \\\"bufferId\\\": \\\"openai-Echo\\\" }, { \\\"label\\\": \\\"Fable\\\", \\\"value\\\": \\\"fable\\\", \\\"bufferId\\\": \\\"openai-Fable\\\" }, { \\\"label\\\": \\\"Onyx\\\", \\\"value\\\": \\\"onyx\\\", \\\"bufferId\\\": \\\"openai-Onyx\\\" }, { \\\"label\\\": \\\"Nova\\\", \\\"value\\\": \\\"nova\\\", \\\"bufferId\\\": \\\"openai-Nova\\\" }, { \\\"label\\\": \\\"Shimmer\\\", \\\"value\\\": \\\"shimmer\\\", \\\"bufferId\\\": \\\"openai-Shimmer\\\" } ] } ], \\\"whisperModel\\\": { \\\"model\\\": \\\"whisper-1\\\", \\\"name\\\": \\\"Whisper1\\\", \\\"charsPointsPrice\\\": 0 } }\"]},\"366\":{\"h\":\"docker-compose\",\"t\":[\"# 数据库的默认账号和密码仅首次运行时设置有效 # 如果修改了账号密码，记得改数据库和项目连接参数，别只改一处~ # 该配置文件只是给快速启动，测试使用。正式使用，记得务必修改账号密码，以及调整合适的知识库参数，共享内存等。 # 如何无法访问 dockerhub 和 git，可以用阿里云（阿里云没有arm包） version: '3.3' services: minio: container_name: minio image: minio/minio:RELEASE.2023-03-20T20-16-18Z environment: MINIO_ACCESS_KEY: minioadmin MINIO_SECRET_KEY: minioadmin ports: - '9001:9001' - '9000:9000' networks: - fastgpt volumes: - ./minio:/minio_data command: minio server /minio_data --console-address \\\":9001\\\" healthcheck: test: ['CMD', 'curl', '-f', 'http://localhost:9000/minio/health/live'] interval: 30s timeout: 20s retries: 3 # milvus milvusEtcd: container_name: milvusEtcd image: quay.io/coreos/etcd:v3.5.5 environment: - ETCD_AUTO_COMPACTION_MODE=revision - ETCD_AUTO_COMPACTION_RETENTION=1000 - ETCD_QUOTA_BACKEND_BYTES=4294967296 - ETCD_SNAPSHOT_COUNT=50000 networks: - fastgpt volumes: - ./milvus/etcd:/etcd command: etcd -advertise-client-urls=http://127.0.0.1:2379 -listen-client-urls http://0.0.0.0:2379 --data-dir /etcd healthcheck: test: ['CMD', 'etcdctl', 'endpoint', 'health'] interval: 30s timeout: 20s retries: 3 milvusStandalone: container_name: milvusStandalone image: milvusdb/milvus:v2.4.3 command: ['milvus', 'run', 'standalone'] security_opt: - seccomp:unconfined environment: ETCD_ENDPOINTS: milvusEtcd:2379 MINIO_ADDRESS: minio:9000 networks: - fastgpt volumes: - ./milvus/data:/var/lib/milvus healthcheck: test: ['CMD', 'curl', '-f', 'http://localhost:9091/healthz'] interval: 30s start_period: 90s timeout: 20s retries: 3 depends_on: - 'milvusEtcd' - 'minio' mongo: image: registry.cn-hangzhou.aliyuncs.com/fastgpt/mongo:5.0.18 # 阿里云 container_name: mongo restart: always ports: - 27017:27017 networks: - fastgpt command: mongod --keyFile /data/mongodb.key --replSet rs0 environment: - MONGO_INITDB_ROOT_USERNAME=myusername - MONGO_INITDB_ROOT_PASSWORD=mypassword volumes: - mongo_data:/data/db entrypoint: - bash - -c - | openssl rand -base64 128 > /data/mongodb.key chmod 400 /data/mongodb.key chown 999:999 /data/mongodb.key echo 'const isInited = rs.status().ok === 1 if(!isInited){ rs.initiate({ _id: \\\"rs0\\\", members: [ { _id: 0, host: \\\"mongo:27017\\\" } ] }) }' > /data/initReplicaSet.js # 启动MongoDB服务 exec docker-entrypoint.sh \\\"$$@\\\" & # 等待MongoDB服务启动 until mongo -u myusername -p mypassword --authenticationDatabase admin --eval \\\"print('waited for connection')\\\" > /dev/null 2>&1; do echo \\\"Waiting for MongoDB to start...\\\" sleep 2 done # 执行初始化副本集的脚本 mongo -u myusername -p mypassword --authenticationDatabase admin /data/initReplicaSet.js # 等待docker-entrypoint.sh脚本执行的MongoDB服务进程 wait $$! # fastgpt sandbox: container_name: sandbox image: ghcr.io/labring/fastgpt-sandbox:latest # git # image: registry.cn-hangzhou.aliyuncs.com/fastgpt/fastgpt-sandbox:latest # 阿里云 networks: - fastgpt restart: always fastgpt: container_name: fastgpt image: ghcr.io/labring/fastgpt:v4.8.9 # git # image: registry.cn-hangzhou.aliyuncs.com/fastgpt/fastgpt:v4.8.9 # 阿里云 ports: - 3000:3000 networks: - fastgpt depends_on: - mongo - milvusStandalone - sandbox restart: always environment: # root 密码，用户名为: root。如果需要修改 root 密码，直接修改这个环境变量，并重启即可。 - DEFAULT_ROOT_PSW=1234 # AI模型的API地址哦。务必加 /v1。这里默认填写了OneApi的访问地址。 - OPENAI_BASE_URL=http://oneapi:3000/v1 # AI模型的API Key。（这里默认填写了OneAPI的快速默认key，测试通后，务必及时修改） - CHAT_API_KEY=sk-Aq0UoGRk8uJSAZfy3e986c5993Bb4aF3A9C3Eb20708144F4 # 数据库最大连接数 - DB_MAX_LINK=30 # 登录凭证密钥 - TOKEN_KEY=any # root的密钥，常用于升级时候的初始化请求 - ROOT_KEY=root_key # 文件阅读加密 - FILE_TOKEN_KEY=filetoken # MongoDB 连接参数. 用户名myusername,密码mypassword。 - MONGODB_URI=mongodb://myusername:mypassword@mongo:27017/fastgpt?authSource=admin # zilliz 连接参数 - MILVUS_ADDRESS=http://milvusStandalone:19530 - MILVUS_TOKEN=none # sandbox 地址 - SANDBOX_URL=http://sandbox:3000 # 日志等级: debug, info, warn, error - LOG_LEVEL=info - STORE_LOG_LEVEL=warn volumes: - ./config.json:/app/data/config.json # oneapi mysql: image: mysql:5.7.16 # 阿里云 # image: mysql:8.0.36 container_name: mysql restart: always ports: - 3307:3306 networks: - fastgpt command: --default-authentication-plugin=mysql_native_password environment: # 默认root密码，仅首次运行有效 MYSQL_ROOT_PASSWORD: oneapimmysql MYSQL_DATABASE: oneapi volumes: - ./mysql:/var/lib/mysql oneapi: container_name: oneapi image: ghcr.io/songquanpeng/one-api:v0.6.7 # image: registry.cn-hangzhou.aliyuncs.com/fastgpt/one-api:v0.6.6 # 阿里云 ports: - 3001:3000 depends_on: - mysql networks: - fastgpt restart: always environment: # mysql 连接参数 - SQL_DSN=root:oneapimmysql@tcp(mysql:3306)/oneapi # 登录凭证加密密钥 - SESSION_SECRET=oneapikey # 内存缓存 - MEMORY_CACHE_ENABLED=true # 启动聚合更新，减少数据交互频率 - BATCH_UPDATE_ENABLED=true # 聚合更新时长 - BATCH_UPDATE_INTERVAL=10 # 初始化的 root 密钥（建议部署完后更改，否则容易泄露） - INITIAL_ROOT_TOKEN=fastgpt - http_proxy=http://192.168.6.10:7897 - https_proxy=http://192.168.6.10:7897 volumes: - ./oneapi:/data networks: fastgpt: volumes: mongo_data:\",\"上述fastgpt 配置的CHAT_API_KEY、OPENAI_BASE_URL是oneapi中的令牌地址 \"]},\"367\":{\"h\":\"访问\"},\"368\":{\"h\":\"fastgpt\",\"t\":[\"http://localhost:3000/app/list 账户密码：root/1234\"]},\"369\":{\"h\":\"oneapi\",\"t\":[\"http://localhost:3001/ 账户密码： root/12345678\"]},\"370\":{\"h\":\"地址\",\"t\":[\"https://github.com/zhayujie/chatgpt-on-wechat\"]},\"371\":{\"h\":\"文档\",\"t\":[\"https://docs.link-ai.tech/cow/quick-start\"]},\"372\":{\"h\":\"docker-compose\",\"t\":[\"version: '2.0' services: chatgpt-on-wechat: image: registry.cn-hangzhou.aliyuncs.com/software_hub/chatgpt-on-wechat:zhayujie-v1 container_name: chatgpt-on-wechat security_opt: - seccomp:unconfined environment: OPEN_AI_API_KEY: 'fastgpt-yvdq8kJ9kaFfDN9AgZHLDcu1vOVOGROVVabX1DD4mBGuDazLqIPfqWmIjS' OPEN_AI_API_BASE: 'http://fastgpt:3000/api/v1' MODEL: 'gpt-3.5-turbo' CHANNEL_TYPE: 'wx' PROXY: '' HOT_RELOAD: 'False' SINGLE_CHAT_PREFIX: '[\\\"bot\\\", \\\"@bot\\\"]' SINGLE_CHAT_REPLY_PREFIX: '\\\"[bot] \\\"' GROUP_CHAT_PREFIX: '[\\\"@bot\\\"]' GROUP_NAME_WHITE_LIST: '[\\\"ChatGPT测试群\\\", \\\"ChatGPT测试群2\\\", \\\"AI助手百科全书\\\", \\\"知识助手\\\", \\\"我的家人\\\"]' IMAGE_CREATE_PREFIX: '[\\\"画\\\", \\\"看\\\", \\\"找\\\"]' CONVERSATION_MAX_TOKENS: 1000 SPEECH_RECOGNITION: 'False' CHARACTER_DESC: '你是ChatGPT, 一个由OpenAI训练的大型语言模型, 你旨在回答并解决人们的任何问题，并且可以使用多种语言与人交流。' SUBSCRIBE_MSG: '感谢您的关注！\\\\n这里是ChatGPT，可以自由对话。\\\\n支持语音对话。\\\\n支持图片输入。\\\\n支持图片输出，画字开头的消息将按要求创作图片。\\\\n支持tool、角色扮演和文字冒险等丰富的插件。\\\\n输入{trigger_prefix}#help 查看详细指令。' EXPIRES_IN_SECONDS: 3600 USE_GLOBAL_PLUGIN_CONFIG: 'True' USE_LINKAI: 'False' LINKAI_API_KEY: '' networks: - fastgpt networks: fastgpt: name: fatgpt_fastgpt external: true\",\"使用fastgpt apikey \"]},\"373\":{\"h\":\"cosyvoice 部署\",\"t\":[\"git地址\",\"docker地址: registry.cn-hangzhou.aliyuncs.com/software_hub/cosyvoice:v1\"]},\"374\":{\"h\":\"模型下载\",\"t\":[\"git clone https://www.modelscope.cn/iic/CosyVoice-300M.git pretrained_models/CosyVoice-300M\"]},\"375\":{\"h\":\"镜像启动\",\"t\":[\"docker run -itd --name cosyvoice --gpus all -v /home/lsy/cosyvoice/model:/model -p 50000:50000 -v cosyvoice:v1\"]},\"376\":{\"h\":\"服务启动\",\"t\":[\" python3 webui.py --port 50000 --model_dir /model/pretrained_models/CosyVoice-300M\"]},\"377\":{\"c\":[\"AIGC\"]},\"378\":{\"c\":[\"FastGpt\",\"chatgpt-on-web\"]},\"379\":{\"h\":\"Lobechat\",\"t\":[\"Lobechat\"]},\"380\":{\"h\":\"部署文档\",\"t\":[\"使用 Docker Compose 部署 LobeChat 服务端数据库版本\"]},\"381\":{\"h\":\"docker-compose\",\"t\":[\"root@iZ2zei23h3vwykyqq9th6oZ:/home/lobe-chat/docker-compose/local# cat docker-compose.yml name: lobe-chat-database services: network-service: image: alpine container_name: lobe-network ports: - '${MINIO_PORT}:${MINIO_PORT}' # MinIO API - '9001:9001' # MinIO Console - '${CASDOOR_PORT}:8000' # Casdoor - '${LOBE_PORT}:3210' # LobeChat command: tail -f /dev/null networks: - lobe-network postgresql: image: pgvector/pgvector:pg16 container_name: lobe-postgres ports: - '5432:5432' volumes: - './data:/var/lib/postgresql/data' environment: - 'POSTGRES_DB=${LOBE_DB_NAME}' - 'POSTGRES_PASSWORD=${POSTGRES_PASSWORD}' healthcheck: test: ['CMD-SHELL', 'pg_isready -U postgres'] interval: 5s timeout: 5s retries: 5 restart: always networks: - lobe-network minio: image: minio/minio container_name: lobe-minio network_mode: 'service:network-service' volumes: - './s3_data:/etc/minio/data' environment: - 'MINIO_ROOT_USER=${MINIO_ROOT_USER}' - 'MINIO_ROOT_PASSWORD=${MINIO_ROOT_PASSWORD}' - 'MINIO_API_CORS_ALLOW_ORIGIN=http://182.92.116.31:${LOBE_PORT}' restart: always command: > server /etc/minio/data --address \\\":${MINIO_PORT}\\\" --console-address \\\":9001\\\" casdoor: image: casbin/casdoor container_name: lobe-casdoor entrypoint: /bin/sh -c './server --createDatabase=true' network_mode: 'service:network-service' depends_on: postgresql: condition: service_healthy environment: RUNNING_IN_DOCKER: 'true' driverName: 'postgres' dataSourceName: 'user=postgres password=${POSTGRES_PASSWORD} host=postgresql port=5432 sslmode=disable dbname=casdoor' origin: 'http://182.92.116.31:${CASDOOR_PORT}' runmode: 'dev' volumes: - ./init_data.json:/init_data.json lobe: image: lobehub/lobe-chat-database container_name: lobe-chat network_mode: 'service:network-service' depends_on: postgresql: condition: service_healthy network-service: condition: service_started minio: condition: service_started casdoor: condition: service_started environment: - 'APP_URL=http://182.92.116.31:3210' - 'NEXT_AUTH_SSO_PROVIDERS=casdoor' - 'KEY_VAULTS_SECRET=Kix2wcUONd4CX51E/ZPAd36BqM4wzJgKjPtz2sGztqQ=' - 'NEXT_AUTH_SECRET=QCtusYE5HEzg1IGy1BMbW4SNgF+yBkcKha4ghUyI6WY=' - 'AUTH_URL=http://182.92.116.31:8800/api/auth' - 'AUTH_CASDOOR_ISSUER=http://182.92.116.31:8800/' - 'DATABASE_URL=postgresql://postgres:${POSTGRES_PASSWORD}@postgresql:5432/${LOBE_DB_NAME}' - 'S3_ENDPOINT=http://182.92.116.31:${MINIO_PORT}' - 'S3_BUCKET=${MINIO_LOBE_BUCKET}' - 'S3_PUBLIC_DOMAIN=http://182.90.116.31:${MINIO_PORT}' - 'S3_ENABLE_PATH_STYLE=1' - 'LLM_VISION_IMAGE_USE_BASE64=1' env_file: - .env restart: always volumes: data: driver: local s3_data: driver: local networks: lobe-network: driver: bridge\"]},\"382\":{\"h\":\"env\",\"t\":[\"root@iZ2zei23h3vwykyqq9th6oZ:/home/lobe-chat/docker-compose/local# cat .env # Proxy, if you need it # HTTP_PROXY=http://localhost:7890 # HTTPS_PROXY=http://localhost:7890 # Other environment variables, as needed. You can refer to the environment variables configuration for the client version, making sure not to have ACCESS_CODE. # OPENAI_API_KEY=sk-xxxx # OPENAI_PROXY_URL=https://api.openai.com/v1 # OPENAI_MODEL_LIST=... # =========================== # ====== Preset config ====== # =========================== # if no special requirements, no need to change LOBE_PORT=3210 CASDOOR_PORT=8800 MINIO_PORT=9000 # Postgres related, which are the necessary environment variables for DB LOBE_DB_NAME=lobechat POSTGRES_PASSWORD=uWNZugjBqixf8dxC # Casdoor secret AUTH_CASDOOR_ID=a387a4892ee19b1a2249 AUTH_CASDOOR_SECRET=dbf205949d704de81b0b5b3603174e23fbecc354 # MinIO S3 configuration MINIO_ROOT_USER=YOUR_MINIO_USER MINIO_ROOT_PASSWORD=YOUR_MINIO_PASSWORD # Configure the bucket information of MinIO MINIO_LOBE_BUCKET=lobe S3_ACCESS_KEY_ID=soaucnP8Bip0TDdUjxng S3_SECRET_ACCESS_KEY=ZPUzvY34umfcfxvWKSv0P00vczVMB6YmgJS5J9eO\"]},\"383\":{\"h\":\"minio-bucket.config.json\",\"t\":[\"root@iZ2zei23h3vwykyqq9th6oZ:/home/lobe-chat/docker-compose# cat minio-bucket.config.json { \\\"Statement\\\": [ { \\\"Effect\\\": \\\"Allow\\\", \\\"Principal\\\": { \\\"AWS\\\": [\\\"*\\\"] }, \\\"Action\\\": [\\\"s3:GetBucketLocation\\\"], \\\"Resource\\\": [\\\"arn:aws:s3:::lobe\\\"] }, { \\\"Effect\\\": \\\"Allow\\\", \\\"Principal\\\": { \\\"AWS\\\": [\\\"*\\\"] }, \\\"Action\\\": [\\\"s3:ListBucket\\\"], \\\"Resource\\\": [\\\"arn:aws:s3:::lobe\\\"], \\\"Condition\\\": { \\\"StringEquals\\\": { \\\"s3:prefix\\\": [\\\"files/*\\\"] } } }, { \\\"Effect\\\": \\\"Allow\\\", \\\"Principal\\\": { \\\"AWS\\\": [\\\"*\\\"] }, \\\"Action\\\": [\\\"s3:PutObject\\\", \\\"s3:DeleteObject\\\", \\\"s3:GetObject\\\"], \\\"Resource\\\": [\\\"arn:aws:s3:::lobe/files/**\\\"] } ], \\\"Version\\\": \\\"2012-10-17\\\" }\"]},\"384\":{\"c\":[\"AIGC\"]},\"385\":{\"c\":[\"Lobechat\"]},\"386\":{\"h\":\"Auth\",\"t\":[\"Springboot Auth\"]},\"387\":{\"h\":\"Sringboot + Keycloak\",\"t\":[\"Keycloak admin client\",\"rest-authz-resource-server: Spring Boot REST Service Protected Using Keycloak Authorization Services\"]},\"388\":{\"h\":\"Springboot + casdoor\",\"t\":[\"Casdoor\"]},\"389\":{\"h\":\"Springboot + Logto\",\"t\":[\"Java Spring Boot integration guide\",\"spring-boot-sample\"]},\"390\":{\"h\":\"Springboot + Zitadel\",\"t\":[\"Zitadel\"]},\"391\":{\"c\":[\"Auth\"]},\"392\":{\"c\":[\"Auth\"]},\"393\":{\"h\":\"MPress 通过存储保存算子间并行性在多GPU服务器上实现十亿规模级模型训练的民主化\",\"t\":[\"MPress: Democratizing Billion-Scale Model Training on Multi-GPU Servers via Memory-Saving Inter-Operator Parallelism\",\"地址：https://par.nsf.gov/servlets/purl/10410479\",\"这篇论文的题目是《MPress: Democratizing Billion-Scale Model Training on Multi-GPU Servers via Memory-Saving Inter-Operator Parallelism》（MPress：通过节省内存的操作间并行化民主化十亿规模模型训练）。论文来自中国科学技术大学、安徵省高性能计算实验室和美国休斯顿大学。\"]},\"394\":{\"h\":\"问题背景：\",\"t\":[\"深度神经网络（DNN）模型的规模不断扩大，参数数量已经从百万级增长到数十亿级。这导致了GPU内存的极大需求，单一GPU无法满足如此大规模模型的训练需求。现有的一些内存节省技术如GPU-CPU交换、重计算等虽然可以减少部分内存消耗，但会带来额外的计算或通信开销。\"]},\"395\":{\"h\":\"论文创新点：\",\"t\":[\"MPress提出了一种新的单服务器多GPU系统，旨在突破十亿规模模型训练中的GPU内存壁垒，同时最小化额外的成本。它结合了多种内存优化技术，包括：\",\"操作间并行性，减少GPU间的通信开销。\",\"新的D2D交换技术，利用多条高速NVLink链路将张量交换至轻载GPU，以充分利用闲置的GPU内存。\",\"综合了重新计算、GPU-CPU交换和D2D交换的优势，通过智能调度优化性能和内存使用。\"]},\"396\":{\"h\":\"实验方法：\",\"t\":[\"MPress被集成到现有的两种操作间并行训练系统中（PipeDream和DAPPLE）。实验使用了BERT和GPT两种模型，分别在现代GPU服务器（如DGX-1和DGX-2）上进行训练。实验结果表明，MPress在相同内存优化下训练速度大幅提升，并且能够训练比基线更大的模型。\"]},\"397\":{\"h\":\"结论：\",\"t\":[\"MPress显著提升了多GPU服务器上十亿规模DNN模型的训练效率，能够在不牺牲性能的前提下，突破GPU内存瓶颈。\"]},\"398\":{\"h\":\"II. 背景与动机\",\"t\":[\"由于深度神经网络（DNN）计算资源的高需求，将模型训练任务并行化到多个GPU设备上已经成为常态。主要有三种并行训练方法，每种方法对应不同的分区策略，分别是通过输入样本分区（数据并行）、通过网络结构分区（模型并行）和通过层级分区（流水线并行）。为了便于理解模型并行和流水线并行的区别，本文参考了最近的Alpa工作，将现有解决方案分类为两种正交方向：即操作内并行和操作间并行。\",\"操作内并行依赖于一个操作符在具有多个维度的张量上工作，将张量沿某些维度进行分区，并将结果分配给多个设备。数据并行作为最简单的操作内并行，将输入张量进行分片，并将数据片段分配给GPU设备来训练共享的复制模型。与此不同，操作间并行训练将目标DNN模型划分为不相交的阶段，每个阶段对应一组连续的模型层，并映射到单独的GPU上进行计算。微批次训练数据通过这些阶段以流水线的方式进行处理。\",\"不幸的是，所有这些并行策略在支持十亿规模的单服务器训练时都会遇到GPU内存瓶颈。我们选择操作间并行作为研究的出发点，原因如下：\",\"首先，与其他两种方法相比，数据并行训练带来了最重的内存负担和跨GPU通信开销，因为每个GPU都会复制相同数量的模型数据，并定期交换与模型参数等大小的梯度。因此，单靠数据并行难以满足快速增长的模型规模所带来的巨大内存需求。操作内并行则通过将操作符拆分成更小的部分来工作，但它需要大量通信来收集和汇总部分结果，以触发后续的计算，而这些通信位于训练的关键路径上。\",\"相比之下，操作间并行训练引入的通信开销最少，因为对于大规模的自然语言处理模型，只有激活值在阶段之间传输，而且这些激活值通常很小。例如，对于Bert-0.64B模型，两个主机连续阶段的GPU之间仅交换每个微批次1.5MB的数据。此外，操作间并行已受到工业界和学术界的广泛关注，许多训练系统，如PipeDream、DAPPLE、GPipe、DeepSpeed和Megatron-LM，已经集成了该技术。因此，我们专注于通过操作间并行实现十亿规模模型的高效训练。\"]},\"399\":{\"h\":\"操作间并行\",\"t\":[\"图1展示了操作间并行DNN训练的工作流程。每个GPU设备（即“工人”）负责训练一个不相交的连续模型层集。每个训练数据的微批次被进一步分为多个子批次，进入整个执行流水线。工人1从第一微批次开始前向传播，并将计算传递给工人2，以启动第二阶段。同时，工人1处理第二个微批次。工人3则处理第三阶段的子批次。当工人3完成第一个微批次的前向传播计算后，立即开始相应的反向传播，并从工人3回流至工人1。\",\"在相邻的微批次之间有两种调度执行方式，即异步和同步模式。PipeDream中使用的异步模式允许第二个微批次的前向传播与第一个微批次的反向传播并行进行。例如，第二个微批次中的第七个子批次在第四个子批次的反向传播完成后立即由工人1执行。与此相反，GPipe和DAPPLE中使用的同步模式则要求不同微批次的计算是串行的。\"]},\"400\":{\"h\":\"GPU内存消耗的问题\",\"t\":[\"为了探索操作间并行训练中GPU内存的利用情况，我们使用PipeDream和DAPPLE两个代表性系统训练了两个流行的DNN模型Bert和GPT。在一台AWS EC2 p3dn.24xlarge GPU服务器上进行实验，该服务器配备了8个V100 GPU（每个GPU具有32GB内存），并设置了最大可持续的模型规模。\",\"对于PipeDream，设置微批次大小为12时，它能够支持训练参数最多为6亿的Bert模型，再往上则会出现GPU内存不足的错误。当微批次大小缩小到2时，PipeDream可以支持2亿参数的Bert模型。在相同的硬件配置下，DAPPLE能够训练最多具有53亿参数的GPT模型，微批次大小同样为2。PipeDream和DAPPLE之间可支持模型规模的差异在于，PipeDream使用异步调度，需要保存多版本的模型数据。\"]},\"401\":{\"h\":\"内存优化及其局限性\",\"t\":[\"内存平衡的分区策略能够解决GPU内存不平衡的问题。然而我们发现，采用这种分区策略付出的代价是计算时间不均衡，导致训练性能下降34%。重计算技术可以通过丢弃前向传播生成的激活值并在需要时重新计算，节省内存，并已被许多主流系统采用。然而，单靠重计算有两个主要缺点：一是它无法减少优化器状态、参数和梯度的内存消耗，而这些数据占用了大量GPU内存；二是重新执行前向传播会与反向传播竞争GPU资源，并引入额外的延迟，可能导致训练时间延长33%。\",\"GPU-CPU交换利用了CPU内存的大容量来扩展GPU内存空间，然而，由于PCIe带宽有限，GPU-CPU交换会大幅降低训练吞吐量。例如，在PipeDream中对39%的BERT数据应用GPU-CPU交换后，训练吞吐量降低了67%。ZeRO系列通过在数据并行训练中消除数据冗余来减少GPU内存消耗，但也引入了不可忽视的跨GPU通信开销。\"]},\"402\":{\"h\":\"硬件趋势与机遇\",\"t\":[\"随着硬件的快速发展，现代GPU服务器已经集成了超高速的GPU间互连。2016年，NVIDIA的P100 GPU引入了第一代NVLink，提供高达160GB/s的双向数据传输带宽，是PCIe Gen3x16带宽的近5倍。\",\"我们提出了一种新的GPU D2D交换技术，通过NVLink将张量从高内存压力的GPU卸载到有空闲内存的GPU，从而缓解GPU内存的限制。\"]},\"403\":{\"h\":\"III. MPress 内部原理\"},\"404\":{\"h\":\"A. 设计原则\",\"t\":[\"我们提出了MPress，这是一个高效的操作间并行深度神经网络（DNN）训练系统，使用异构内存优化技术来应对著名的GPU内存墙问题。MPress采用了一种新的设备间（D2D）交换技术，利用多个高带宽的NVLink互连将模型数据从内存压力较大的GPU卸载到轻负载的GPU。由于GPU资源有限，我们只对少量生命周期较短的模型数据应用D2D交换，这些数据的生命周期过短，无法承受重新计算或GPU-CPU交换的延迟。\",\"D2D交换的快速速度对于避免重新计算和GPU-CPU交换所带来的高额性能损失至关重要，并且允许D2D交换更好地与DNN计算重叠。通过精心映射流水线阶段到GPU设备，我们可以积极满足每个GPU的内存交换带宽需求。为了克服GPU总体交换空间有限的局限，MPress还采用了重新计算和GPU-CPU交换技术来进一步减少GPU内存消耗。\"]},\"405\":{\"h\":\"B. MPress的总体概述及工作流程\",\"t\":[\"图5展示了MPress系统架构的高级视图，MPress的逻辑横跨静态和运行时部分。静态部分的任务是生成内存节省计划，该计划确定在内存压力下应用内存优化的张量候选、应用哪种优化以及何时执行相应的优化或恢复被节省的张量。\",\"在MPress的静态部分，首先通过训练目标DNN模型，获取基础的张量大小、正向和反向计算的延迟等基本统计数据。表III展示了收集的统计数据示例。然后，规划器根据成本模型探索可能的配置，该模型比较不同优化方法的时间成本，以选择对性能影响最小的优化方法。\",\"随后，生成的初步计划将被传递给重写器，重写器进一步修改输入的数据流图，将这些优化策略嵌入到合适的位置，以符合操作的依赖关系。我们使用模拟器根据修改后的数据流图执行一次训练迭代，并收集GPU内存节省量及引入的开销。最终，反馈信息将从模拟器传递给规划器，以确定当前的配置是否接近最佳配置，并与之前的运行结果进行比较。\",\"需要注意的是，MPress静态部分是离线运行的，因此不会带来运行时开销。与实际训练可能需要运行数百万次迭代以实现模型收敛不同，模拟器只需要执行有限的几次训练步骤。\",\"MPress运行时部分与操作间并行训练框架的运行时部分共同工作，主要包括执行器、内存管理器和压缩库三个关键系统组件。首先，压缩库提供三种内存优化技术的高效实现，其中包括我们提出的D2D交换。同时，运行时流程如下：执行器接收来自MPress静态部分的仪器化数据流图，并触发启用了内存压缩的操作间并行训练。普通操作将直接通过底层训练框架运行时处理，而内存优化操作则由执行器执行，以释放已使用的GPU内存，并根据需要恢复状态。\"]},\"406\":{\"h\":\"C. D2D交换\",\"t\":[\"在设计D2D交换技术时，我们必须综合考虑以下两个关键因素：1）不同GPU之间的带宽和连接链路数量可能存在硬件异构性；2）内存交换需求与目标操作间并行训练任务中空闲GPU内存资源的多样性。\",\"为此，我们引入了以下两项关键技术来优化D2D交换。\",\"数据分条：每个GPU设备可以将张量交换到多个NVLink可达的轻负载GPU，因此我们引入了数据分条技术，将目标张量划分为若干子块，并通过不同链路并行传输。在对称NVLink拓扑结构中，GPU间完全通过同质的链路连接，我们将子块划分为等大小，并让其总数量与目标接收GPU的数量一致。\",\"在不对称的拓扑结构中（如DGX-1架构），GPU对之间的带宽可能会有所不同。为了反映这种差异，我们进一步演进了数据分条技术，结合NVLink链路带宽对子块大小进行加权，大小与链路带宽成正比。\",\"此外，我们还管理了一个元数据表，用于跟踪经过D2D交换的张量状态。对于每个张量，我们在执行交换操作之前记录子块数量、每个子块的大小和目标GPU设备的索引。\",\"设备映射：我们设计了一种设备-阶段映射算法，能够将轻负载的GPU分配到高内存压力的GPU附近，以最大化这些GPU的交换带宽。这个算法首先枚举所有可能的设备映射方案，并为每个映射方案确定合适的内存分配策略，最终选择时间成本最小的映射方案。\"]},\"407\":{\"h\":\"D. 内存压缩规划\",\"t\":[\"探索将D2D交换、GPU-CPU交换和重计算结合起来的最佳配置，以最大化GPU内存节省的同时最小化训练过程中引入的额外延迟是一个非常具有挑战性的问题。为了解决这一问题，我们提出了一个近似搜索算法，并基于以下几个关键观察来进行简化。\",\"与重计算相比，两种交换方法的优势在于它们不消耗GPU的计算资源，并且能够与GPU上的前向和后向计算并行运行。当被适当地应用时，也就是当目标张量的生命周期（即从生成到再次使用之间的时间）长于这两种交换方法的时间成本时，就不会引入额外的时间延迟。\",\"我们应该优先考虑对模型的后期层使用重计算来缓解内存限制，原因有两个：首先，反向传播首先从流水线执行的后半部分的后期层开始；其次，不可避免的额外重计算延迟会扩大早期层的生命周期，从而为应用GPU-CPU交换腾出更多空间。\",\"选择对连续层的张量应用重计算是一个不错的选择，这可以进一步减少除了第一层操作符的输入之外的内存消耗，因为第一层操作符的输出是前一层的输入。\",\"由于GPU的空闲内存资源有限，且D2D交换比GPU-CPU交换要快得多，为了发挥其全部潜力，我们应该只将D2D交换应用于性能至关重要的情况，以最大限度地减少GPU-CPU交换和重计算带来的额外延迟。\",\"基于以上观察和权衡，我们引入了一个近似的搜索算法，首先积极地为适当的张量分配GPU-CPU交换和重计算优化，然后通过逐步将部分GPU-CPU交换和重计算替换为D2D交换来优化配置。具体而言，我们首先执行生命周期变量分析来计算每个张量的生命周期。接着我们构建了初步配置，将GPU-CPU交换分配给生命周期特别长的张量，同时将重计算分配给激活张量，前提是重计算引入的额外延迟小于GPU-CPU交换的成本。最后，我们将GPU-CPU交换分配给剩余的张量，以满足目标内存节省需求。\",\"我们的算法会经历一些迭代步骤来逐步更新内存减少优化配置。在每个步骤中，我们使用模拟器运行最新的配置（仅需要执行一次训练迭代）来过滤出一组减少的张量，这些张量的优化引入了最大的额外开销。对于这些张量，我们尽量使用D2D交换来减少它们的内存占用，前提是存在空闲的GPU内存。如果新的配置比之前的配置性能更好，我们就接受它。该算法会在后续配置相较于前一个配置的性能提升不明显时终止。\"]},\"408\":{\"h\":\"E. 实现细节\",\"t\":[\"我们将上述设计原则集成到开源训练系统MPress中，该系统由2000行C++和Python代码组成。为了展示其在操作间并行训练中优化GPU内存使用的通用性，我们将MPress集成到了PipeDream和DAPPLE这两个最近的操作间并行训练系统中。其后端引擎是PyTorch。我们通过将PipeDream的原始PyTorch版本从1.1升级到1.2，并启用其NCCL库以使用NVLink在阶段之间传输数据，改进了PipeDream系统。需要注意的是，MPress是通用的，可以应用于其他操作间并行训练系统，如GPipe。我们将继续使MPress适用于这些系统。\",\"内存管理：我们的内存管理器负责为张量分配和释放GPU/CPU内存空间，并监控每个设备的内存使用情况。首先，针对GPU内存分配，管理器直接使用PyTorch中的原生GPU内存分配器。其次，在主机内存请求方面，考虑到固定内存（pinned memory）与GPU内存之间的数据传输速度快于普通可分页内存（pageable memory），我们决定使用固定内存作为交换空间。为了避免频繁分配和释放固定内存的高成本，我们进一步构建了一个独立于PyTorch运行时的主机固定内存池。\",\"内存交换：对于D2D交换，执行器为执行交换操作的swap-in和swap-out任务分别管理两个额外的线程，这些线程使用系统启动时通过调用cudaStreamCreate创建的不同CUDA流（streams）。这种设计允许执行器在不阻塞主线程的情况下，启动张量传输任务并与DNN计算同步检查其状态。因此，GPU之间的数据移动可以与DNN计算异步进行。\"]},\"409\":{\"h\":\"IV. 评估\",\"t\":[\"我们的评估旨在回答以下几个问题：\",\"MPress是否能有效缓解GPU内存限制，支持操作间并行训练中的大规模模型训练，同时比基线方法提供更好的训练性能？\",\"独立的D2D交换、设备映射和内存压缩策略的性能影响是什么？\",\"这三种内存优化技术对GPU内存节省的贡献各自是多少？\"]},\"410\":{\"h\":\"A. 实验设置\",\"t\":[\"机器配置：我们在DGX-1和DGX-2 GPU服务器上进行实验以评估MPress和基线方法。DGX-1服务器是AWS EC2 p3dn.24xlarge实例，配备96个虚拟CPU、8个NVIDIA Tesla V100 GPU（每个GPU的内存为32GB，连接方式为不对称的NVLink），以及768GB的CPU内存。我们还使用了另一台提供商的DGX-2服务器，因为AWS EC2上这种高端GPU服务器的配额非常有限，我们的配额申请多次失败。这台DGX-2服务器有164个虚拟CPU，8个NVIDIA Tesla A100 GPU（每个GPU的内存为40GB，连接方式为对称的NVLink），以及948GB的CPU内存和6TB的NVMe SSD。两台机器都运行了Ubuntu 18.04、CUDA 11.7、NCCL 2.8.4、PyTorch 1.2.0等软件。\",\"模型和数据集：我们选择了两个广泛使用的DNN模型BERT和GPT，它们都来自自然语言处理领域。我们使用SQuAD v1.1数据集训练BERT，使用维基百科数据集训练GPT。\",\"我们在PipeDream上运行MPress，训练了不同规模的BERT模型。根据文献，我们通过调整编码器层的数量和隐藏层的大小，使BERT模型变得更深、更宽。表II展示了我们使用的BERT变体的参数规模。BERT-0.35B表示最小的BERT模型，其总GPU内存需求为108.8GB，每个阶段最大内存需求为24.77GB。显然，这一GPU内存需求可以通过我们测试的GPU服务器在没有内存优化的情况下满足。BERT-0.64B是一个中等规模的模型，其最大和最小阶段内存需求分别高于和低于每个GPU的内存容量。此外，BERT模型的参数数量分别为1.67B和4B，表示内存需求超过每个GPU容量的大模型。最后，BERT-6.2B是一个超大模型，其总内存需求是服务器GPU内存供应量的5倍。我们将微批次大小设置为12，这是文献中推荐的大小。\",\"同样，我们使用调整后的参数对GPT及其变体进行训练，并在DAPPLE上运行MPress。如表II所示，GPT-5.3B是最小的模型，原生的DAPPLE可以训练该模型。然而，其他四个GPT配置的每阶段最大GPU内存需求为56.4-140.1GB，已超过单个GPU的容量。我们将微批次大小设置为2，这是DAPPLE文献中推荐的最小批次大小。\",\"基线和系统配置：对于基于PipeDream的操作间并行训练，我们使用原始的PipeDream作为没有内存优化的基线操作间并行训练系统。我们还部署了两种系统作为基线，分别是启用GPU-CPU交换的系统和启用重计算的系统，通过启用PipeDream中的内存交换和重计算优化实现内存压缩。此外，我们运行了两种MPress变体，其中一种仅使用D2D交换，另一种结合了三种内存优化技术。\",\"对于基于DAPPLE的MPress，我们将原始DAPPLE作为自然基线，并启用了高性能重计算的DAPPLE+Recomp。此外，我们还运行了两个最先进的训练系统，ZeRO-Offload和ZeRO-Infinity，它们可以通过数据并行进行大规模模型训练。\",\"我们使用BERT和GPT模型推荐的计算平衡阶段分区策略。此外，重计算基线系统按照文献的建议丢弃特定的张量。最后，MPress变体采用我们之前算法生成的设备映射和内存节省计划。\",\"评估指标：我们测量了每秒处理的样本总数、每秒浮点运算次数（FLOPS）、D2D交换、GPU-CPU交换和重计算的时间成本，以及三种方法各自的内存减少情况。类似于其他现有的FLOPS计算工具或方法，我们通过测量模型前向传播的FLOPS，并估算相应的反向传播的FLOPS为前向传播的两倍。\"]},\"411\":{\"h\":\"B. MPress在PipeDream上的性能\",\"t\":[\"图7对比了在五种不同系统配置下，使用不同规模的BERT变体进行操作间并行训练时的性能（用TFLOPS表示）。我们通过以下几个方面分析了结果：\",\"小规模模型：我们首先分析了参数规模为0.35B的最小BERT模型。五个系统都成功训练了该模型，且报告的性能数据相同。这是因为普通的操作间并行训练已经能够满足该模型的GPU内存需求，因此不需要触发任何内存压缩优化。\",\"中等规模模型：当模型从BERT-0.35B扩大到BERT-0.64B时，PipeDream出现了GPU内存不足的错误，而其他四个系统成功执行了训练任务。GPU-CPU交换的性能最差，因为PCIe带宽的限制导致交换操作非常慢，从而延迟了相应的DNN计算。重计算比GPU-CPU交换快了143.4%，因为重新计算丢弃激活值的前向传播引入的延迟通常远低于GPU-CPU交换。在这种情况下，两种MPress变体表现最好且性能相同。原因是D2D交换足够缓解内存限制，并且比重计算更快，因此MPress没有使用其他两种优化。\",\"大规模模型：当模型扩大到1.67B时，单独的D2D交换无法满足需求，因为在高内存压力下，空闲的GPU内存不足以容纳从负载较大的GPU卸载的张量。与GPU-CPU交换相比，重计算提高了125.4%的性能，但比MPress慢19.5%。此时，MPress结合了三种优化策略，GPU-CPU交换和重计算为D2D交换腾出了更多空间，提升了整体性能。\",\"有趣的是，重计算在BERT-4B及以上模型中失败了。这是预期中的结果，因为重计算只能减少前向传播生成的激活值的内存消耗，无法处理剩余的模型数据，如参数和梯度，这些数据占用了更多的内存资源。相比之下，GPU-CPU交换依然可行，因为它可以应用于所有类型的模型数据，只要有足够的主机内存空间。然而，通过优先使用更快的D2D交换和尽可能使用重计算，MPress相比GPU-CPU交换实现了1.8倍的训练性能提升。\",\"超大规模模型：最后，我们测试了参数规模为6.2B的BERT模型。在这种情况下，只有GPU-CPU交换和MPress能够成功执行训练任务，而其他系统因内存不足而失败。尽管GPU-CPU交换可以支持相同的超大模型，但MPress通过设备映射优化和三种优化策略的组合，训练性能提升了3.1倍。此外，与最先进的重计算系统相比，MPress支持的模型规模提高了2.7倍。\"]},\"412\":{\"h\":\"C. MPress在DAPPLE上的性能\",\"t\":[\"我们使用不同参数规模的GPT模型在DGX-1和DGX-2 GPU服务器上对MPress进行了测试。这里，我们将MPress与三个强大的基线系统进行了对比，这些系统应用了最先进的内存节省技术：\",\"DAPPLE+Recomp：启用了高性能重计算。\",\"ZeRO-Offload：将优化器状态从GPU卸载到CPU。\",\"ZeRO-Infinity：通过GPU-CPU交换并进一步扩展到NVMe设备。\",\"值得注意的是，ZeRO系列是DeepSpeed框架的一部分。我们在一台高端GPU服务器上运行测试，该服务器具有与前面实验相同的GPU配置，但拥有更大的CPU内存和额外的NVMe SSD存储空间。我们无法在上述Amazon EC2实例上进行这组实验，因为ZeRO-Infinity需要大量的CPU内存来进行初始化，并且需要额外的具有高I/O带宽的存储空间进行张量交换。\",\"图8a总结了在DGX-1 GPU服务器上的性能对比情况。DAPPLE无法支持超过5.3B参数规模的模型，因为其最大每GPU内存需求超过了32GB。与此不同，启用重计算的DAPPLE能够成功训练最多10.3B参数的模型，但其性能比MPress低19.2%。相比之下，ZeRO系列和MPress能够支持从5.3B到20.4B不等规模的所有训练任务。ZeRO-Infinity比ZeRO-Offload的GPU计算效率高出20.6%-23.8%，这是因为ZeRO-Offload将优化器状态卸载到CPU会在每个微批次中导致频繁的数据移动，而ZeRO-Infinity通过GPU-CPU交换取而代之。然而，MPress在模型规模上始终能够保持稳定的训练性能，这得益于D2D交换技术的使用，以及多种内存压缩优化技术的结合。此外，MPress比ZeRO-Infinity的性能提升了37.0%-40.8%。这意味着，仅靠GPU-CPU交换的方案可能可以支持非常大规模的模型训练，但需要牺牲训练速度。MPress通过进一步利用空闲的GPU内存资源，补充了它们的局限性。\",\"图8b展示了在DGX-2 GPU服务器上的类似趋势，性能提升幅度比DGX-1服务器翻了一倍多，原因是DGX-2上A100 GPU的计算密度高于DGX-1上的V100。此外，重计算能够支持模型规模达到15.4B，比在DGX-1上支持的规模更大，因为A100 GPU的内存为40GB，而V100的内存为32GB。与MPress相同，ZeRO系列可以支持参数规模最多达到25.5B的模型，但其训练性能分别比MPress降低了30.4%-44.8%和23.2%-70.0%。有趣的是，在大模型上，ZeRO-Infinity的表现不如ZeRO-Offload。这是因为我们租用的DGX-2服务器的SSD存储带宽显著低于DGX-1。然而，找到可公开访问的、具备可扩展GPU计算能力和存储容量的高端GPU服务器几乎不可能。需要注意的是，即使具有足够的SSD带宽，ZeRO-Infinity也不应显著优于ZeRO-Offload，这一点已被ZeRO-Infinity的原始论文和图8a中的结果验证。\",\"PipeDream和DAPPLE之间的结果差异：有趣的是，PipeDream和DAPPLE之间的模型规模和性能差距较大，这也影响了它们各自的MPress变体。模型规模的差异在前面已经解释过。至于性能差距，DAPPLE显著优于PipeDream，因为DAPPLE默认启用了FP16低精度训练功能。此外，DAPPLE比PipeDream晚了两年发布，并且吸收了来自深度学习社区的各种优化，例如更好的计算和通信重叠技术。\"]},\"413\":{\"h\":\"D. 敏感性分析\",\"t\":[\"为了更好地理解MPress相较于基线系统的优势，我们进行了敏感性分析，以探讨设备映射、独立的三种优化方法（即GPU-CPU交换、重计算、D2D交换）的开销比较，以及内存压缩计划的选择。\"]},\"414\":{\"h\":\"\",\"t\":[\"图9总结了通过逐步添加设备映射和数据分条优化后MPress的性能提升情况，数据是在前面的D2D交换默认设置基础上进行的。结果已被归一化为默认设置，其中阶段按DAPPLE的建议映射到设备，且D2D交换已启用但未进行数据分条。\",\"对于DGX-1服务器，设备映射优化提高了默认设置下的性能17.4%，而数据分条优化使性能进一步提高了33.3%。这是因为前者优化使交换操作能够通过可达的NVLink链路传输数据，而后者则进一步最大化了数据传输带宽。相比之下，在DGX-2服务器上，设备映射对性能没有影响，这在预期之中，因为对称的全互联NVLink连接使得每个GPU拥有相同数量的NVLink连接。然而，数据分条使MPress性能比默认设置提高了11.0%，这是由于数据分条技术利用了多条NVLink的聚合带宽，加速了模型数据的交换。\",\"我们还评估了运行设备映射算法的时间开销。首先，我们设计了一个极端案例，其复杂性远高于图7和图8中的所有实验，以此来测试我们的搜索算法。即使在单线程实现下，MPress也能在47秒内找到最优映射。此外，在我们的所有评估案例中，设备映射搜索仅需几秒钟即可完成。因此，我们得出结论：我们的搜索算法不会带来高额的开销。如果有必要，我们还可以将其优化为多线程版本。\"]},\"415\":{\"h\":\"\",\"t\":[\"表III报告了在BERT和GPT模型中，针对不同大小张量，三种内存优化方法的时间成本。显然，三种方法的性能差异显著，这在决定如何组合这些方法时起到了关键作用。\",\"首先，在BERT模型中，张量t1具有最长的生命周期，足以涵盖GPU-CPU交换和D2D交换的时间成本。因此，MPress会优先选择GPU-CPU交换，因为它的成本可以被隐藏起来，而D2D交换则可以用于其他对性能更关键的任务。对于张量t2，GPU-CPU交换和重计算都会带来额外开销，并会延迟操作间并行训练，因为前者的时间成本超过了t2的生命周期，而重计算引入了3毫秒的额外前向计算。因此，MPress会选择D2D交换，因为它的时间成本只有3毫秒，且能够被轻松隐藏。最后，对于t3，MPress会舍弃GPU-CPU交换，因为它过于缓慢，并优先选择重计算而不是D2D交换，尽管两者的额外开销相同（4毫秒），但重计算不会消耗有限的GPU空闲内存，这些内存或许能更好地用于其他张量。\",\"其次，GPT模型中的情况与BERT类似。对于张量t4，MPress会分配GPU-CPU交换，因为其生命周期较长。而对于t5，MPress优先选择D2D交换，因为它的性能比GPU-CPU交换快了7.6倍。最后，针对t6，MPress选择重计算，因为在三种方法中，重计算的额外开销最小。\"]},\"416\":{\"h\":\"\",\"t\":[\"表IV展示了MPress在高GPU内存压力下，为四个操作间并行训练任务（BERT-1.67B、BERT-6.2B、GPT-10.3B、GPT-20.4B）生成的最佳策略。我们还报告了每种优化方法对GPU内存减少的百分比贡献。在三种方法中，GPU-CPU交换对内存节省的贡献为0%-42.2%，而重计算的贡献最大，达到51.2%-90.6%。D2D交换的内存节省量为3.9%-23.4%，虽然通常少于重计算和GPU-CPU交换，但在避免GPU-CPU交换和重计算带来的额外开销或GPU资源争用方面起到了关键作用。\",\"对于BERT-1.67B，MPress没有使用GPU-CPU交换，因为其时间成本过高。相反，D2D交换节省了23.4%的GPU内存，并被用于将早期阶段的张量（阶段0-3）传输到后续阶段（阶段4-7）。重计算节省了阶段0-6的GPU内存，共减少了76.6%的内存。D2D交换和重计算的组合带来了最佳性能，D2D交换提升了19.5%的速度（见图7）。GPT-20.4B的表现则有所不同。首先，MPress选择对阶段0-7的242GB模型数据应用GPU-CPU交换，实现了42.2%的内存节省。其次，重计算减少了51.2%的GPU内存占用。最后，D2D交换节省了38GB的GPU内存，是这四个训练任务中D2D交换节省内存最多的一次。\"]},\"417\":{\"h\":\"V. 硬件见解\",\"t\":[\"尽管GPU的HBM（高带宽内存）提供了极高的带宽，但要满足未来不断增长的模型需求仍然是一个挑战，因为HBM成本昂贵（例如，最新的GPU只有80GB的HBM）。相比之下，CPU内存更便宜，扩展性更好。两者的价格和容量差异主要是由不同的制造工艺导致的。实际上，NVIDIA的Grace-Hopper架构已经为每个GPU支持专用的CPU侧内存，并通过高带宽（NVLink C2C）连接到GPU。因此，MPress展示了此类架构的潜在优势及其在低硬件成本下解决内存墙问题的示例应用。\",\"为了理解MPress在这种新架构下的优势，我们进行了简单的分析，预测了其理想的性能。我们发现，即使每个GPU拥有96GB（HBM）+ 512GB（Grace CPU内存）的设备内存，训练参数规模为175B的GPT-3模型依然会遇到OOM（内存不足）问题。然而，MPress可以解决这个问题。为了完全隐藏GPU-CPU交换的成本，我们预计每个GPU的PCIe带宽需要超过140GB/s，是Grace-Hopper目前64GB/s带宽的两倍多。因此，MPress中的D2D交换技术在这种情况下仍然有效，既可以节省重计算浪费的25%的资源，又可以避免通过超级芯片与PCIe连接的内存之间的交换所带来的13%的训练时间延长。此外，广泛采用新硬件技术需要时间。例如，AWS EC2上最新的GPU实例仍然使用DGX-2 A100，而且供应量非常有限。因此，MPress可以部分弥补当前硬件的局限性。\",\"最后，MPress为重新思考内存架构提供了帮助。考虑到张量的生命周期以及各种内存技术在成本、容量和带宽方面的权衡，扩展内存层次结构是有益的。最快的内存层存储的是计算立即需要的数据，而速度较慢的层存储生命周期较长的数据。每个内存层都可以有不同的访问带宽，以进一步降低成本。在这种情况下，MPress的规划算法可以扩展，以智能地将不同模型张量分配到合适的内存层。\"]},\"418\":{\"h\":\"VI. 相关工作\",\"t\":[\"我们将本文的相关工作分为以下几类进行讨论：模型并行化、流水线并行、内存优化、GPU-CPU交换和深度学习加速器。\",\"模型并行化：当模型规模超过单个设备的内存容量时，模型并行化将模型的不同部分分配给不同的设备进行计算。近年来，研究者们提出了多种形式的模型并行化。Megatron-LM、GShard等系统通过将每个层的矩阵乘法分块，在多个GPU之间分配模型参数，这种方式被称为张量并行。此外，PipeDream、GPipe和DAPPLE等系统采用了流水线并行，它将模型的不同层分配给不同的设备，以支持更大的模型。MPress与这些工作是互补的，它不仅能够利用现有的流水线并行，还通过进一步减少内存消耗来训练更大规模的模型。\",\"流水线并行：流水线并行是一种常见的训练大规模模型的技术，它通过将模型的层分成多个阶段，分别在不同的GPU上运行。GPipe首先引入了这种技术，随后PipeDream通过引入异步调度来改进GPipe的性能。DAPPLE进一步在流水线并行中添加了高效的调度和通信优化。与这些系统不同，MPress不局限于特定的调度策略，而是将D2D交换、GPU-CPU交换和重计算相结合，优化操作间并行的内存使用。\",\"内存优化：为了应对GPU内存的限制，研究者们提出了多种内存优化技术。重计算（recomputation）是最常见的技术，它通过丢弃中间激活值并在反向传播中重新计算它们，来节省内存。近年来，ZeRO系列通过分片优化器状态、梯度和参数，进一步减少了内存消耗。ZeRO-Offload和ZeRO-Infinity利用CPU内存和NVMe存储来扩展模型规模。然而，MPress通过D2D交换减少了GPU内存需求，并且只在必要时使用GPU-CPU交换，从而避免了过多的性能损失。\",\"GPU-CPU交换：一些研究工作探索了在GPU内存不足时，将张量交换到CPU内存的可能性。vDNN和SuperNeurons等系统在运行时根据内存使用情况，决定哪些张量需要交换到CPU。Tesseract进一步结合了流水线并行和GPU-CPU交换。然而，这些系统的性能往往受限于PCIe带宽，MPress通过优先使用NVLink进行D2D交换，避免了GPU-CPU交换的高延迟，进而提高了训练效率。\",\"深度学习加速器：近年来，Google TPU和Graphcore IPU等专用加速器的兴起，提供了替代传统GPU的硬件选择。它们通过自定义的内存架构和高效的并行计算，提升了训练大规模模型的效率。然而，这些硬件需要定制的软件支持，且不一定适用于现有的GPU计算框架。相比之下，MPress能够在现有的GPU硬件上运行，并且无需对硬件进行额外的修改或优化。\",\"总之，MPress与上述工作不同，它通过结合多种内存优化技术，提供了一种高效的解决方案，能够在现有的多GPU系统上训练超大规模的模型。\"]},\"419\":{\"h\":\"VII. 结论\",\"t\":[\"我们提出了MPress，这是一种新的单服务器多GPU系统，旨在通过节省内存的操作间并行化方法，解决十亿规模模型训练中的GPU内存壁垒问题。MPress结合了三种内存优化技术：重计算、GPU-CPU交换和我们新提出的D2D交换。通过综合运用这些技术，MPress能够高效地减少GPU内存消耗，同时保持较高的训练性能。\",\"我们通过在PipeDream和DAPPLE系统中集成MPress，评估了它在训练BERT和GPT等大规模DNN模型时的表现。实验结果表明，MPress显著提高了训练吞吐量，能够在同样的内存优化下，比现有的系统支持更大规模的模型训练。此外，MPress为未来高带宽异构计算环境中的大规模模型训练提供了设计思路。我们相信，MPress展示了在现有硬件约束下突破模型训练规模限制的潜力，为操作间并行训练和GPU内存优化提供了新的方向。\"]},\"420\":{\"c\":[\"MPress\"]},\"421\":{\"c\":[\"MPress\",\"GPU\"]},\"422\":{\"h\":\"nnScaler：重塑深度学习并行策略，大幅提升训练效率\",\"t\":[\"MPress: Democratizing Billion-Scale Model Training on Multi-GPU Servers via Memory-Saving Inter-Operator Parallelism\",\"地址：https://www.usenix.org/system/files/osdi24-lin-zhiqi.pdf\",\"中文解读：https://mp.weixin.qq.com/s/GV_CF9fPpxsPBNbEsvhS5g\"]},\"423\":{\"h\":\"摘要\",\"t\":[\"随着深度神经网络（DNN）模型规模的增长，深度学习训练越来越依赖手工设计的搜索空间来找到高效的并行执行计划。然而，我们的研究表明，现有的搜索空间忽略了一些重要的计划配置，这些配置在某些设置下（如处理大型嵌入表时）对著名DNN模型（例如AlphaFold2）的训练性能有显著影响。\",\"为了解决这个问题，我们提出了nnScaler，这是一个用于生成深度学习训练并行化计划的框架。nnScaler不依赖现有的搜索空间，而是通过三个原语（op-trans、op-assign和op-order），让领域专家能够构建自己的搜索空间。这些原语能够捕捉模型的转换以及任何并行化计划中转化模型的时空调度。为了避免搜索空间爆炸，nnScaler允许在构建空间时对这些原语应用约束。通过这些原语和约束，nnScaler不仅可以构建现有的搜索空间，还可以创建新的空间。实验表明，nnScaler能够在新的搜索空间中找到并行化计划，与DeepSpeed、Megatron-LM和Alpa等解决方案相比，对一些流行的DNN模型（如Swin-Transformer和AlphaFold2）实现了最高3.5倍的加速。\"]},\"424\":{\"h\":\"1. 引言\",\"t\":[\"近年来，深度神经网络（DNN）模型的规模迅速增长，训练这些模型的计算需求也随之大幅增加。为了满足这一需求，分布式训练成为了主流。分布式训练通过将计算任务分配到多个设备（通常是GPU）上来加速训练过程。这种并行化的效果依赖于如何将模型的计算操作有效地分配给多个设备，合理的分配计划可以显著提高训练性能。\",\"然而，设计高效的并行训练计划并非易事。现有的方法通常依赖于手工设计的搜索空间，这些搜索空间定义了并行化的各种配置。然而，我们的研究表明，这些搜索空间通常不够全面，忽略了许多潜在的计划配置。这些遗漏的配置在某些情况下对训练性能有很大的影响，尤其是在处理大型嵌入表或复杂模型（如AlphaFold2）时。\",\"为了填补这一空白，我们提出了nnScaler，一个新的框架，用于生成深度学习训练的并行化计划。nnScaler的核心思想是通过三个基本原语（op-trans、op-assign、op-order）让领域专家能够定义和构建自己的搜索空间。这些原语可以捕捉模型转换以及任何并行化计划中对模型的时空调度，从而避免了现有方法中过于狭窄的搜索空间。\",\"nnScaler不仅可以重现现有的搜索空间，还可以创建新的搜索空间，从而探索更多潜在的并行化配置。通过在构建空间时引入约束条件，nnScaler有效地避免了搜索空间爆炸的问题。\",\"我们的实验结果表明，nnScaler能够在这些新的搜索空间中找到高效的并行化计划，并在多个流行的DNN模型（如Swin-Transformer和AlphaFold2）上取得了显著的性能提升，最高加速达到3.5倍，优于现有的主流解决方案（如DeepSpeed、Megatron-LM和Alpa）。\"]},\"425\":{\"h\":\"2. 背景与动机\",\"t\":[\"并行化计划的搜索空间。并行化计划是指一种训练执行计划，它指定了在给定的 GPU 集合上模型的分区和相应的时空调度方案。训练一个拥有数百亿参数的大型模型需要数千个 GPU。一个大型模型可能由大约 100 层组成，每一层代表一个子神经架构（例如，注意力机制），其中包含处理具有数万维度大小的张量的多个操作符（例如，隐藏维度）。对于大型模型而言，广泛的分区选择和大量的时空调度选择结合在一起，形成了一个极其庞大且组合复杂的并行化计划搜索空间。\",\"现有的方法依赖于经过充分研究的手工并行化计划或搜索空间来解决这个问题。例如，数据并行性是一种特殊的并行化计划，它沿着与其相关的张量的批次维度对操作符进行分区。这些分区后的操作符随后在多个设备（GPU）上复制，并共享相同的模型参数（权重），以实现并发模型训练。张量并行性是一类更一般的计划，允许在不限于批次维度的维度上进行分区。这种方法允许将分区后的操作符分布在不同的设备上，以适应无法在单个设备上容纳的模型。\",\"由于大型深度神经网络（DNN）模型通常由多个层组成，因此也可以将模型分为多个阶段，每个阶段包含一个或多个层。各个阶段被放置在不同的设备上并以流水线方式执行，因此称为流水线并行性。为了提高流水线效率，训练样本的批次进一步被划分为微批次，并按照精心设计的时间顺序执行。\",\"上述并行化方案可以组合成一种新的方案，称为 3D 并行性，以进一步提高训练效率。Megatron-LM 集成了 3D 并行性，这种方法以参数化的方式结合了数据、张量和流水线并行性，以支持类似 GPT 的模型。给定 N 个设备，Megatron-LM 将模型分为 K 个阶段，每个阶段再分为 M 个分区。模型使用 K 阶段流水线并行性和 M 路张量并行性进行执行。对于足够大的 N，Megatron-LM 还可以采用 (N / (M * K))-路数据并行性，以进一步提高训练性能。3D 并行性代表了在大型搜索空间内几类经过充分研究的并行化计划。\",\"Alpa 进一步将这些并行化方案进行概括，手工构建了一个两级层次化搜索空间。这个层次结构使得可以使用动态规划等高效搜索技术。由于其更大的搜索空间，即 SPMD（广义张量并行空间）和流水线并行性的结合，Alpa 被证明能够产生更优的并行化计划。\"]},\"426\":{\"h\":\"2.1 现有搜索空间的局限性\",\"t\":[\"尽管现有的手工并行化搜索空间在具有相似模型架构的主流模型中显示出有效性，但它依赖于简化搜索和构建并行化计划的假设。然而，这些简化可能会排除一些有前景的计划。\",\"在张量并行性中，假设分区后的操作符及其对应的分割张量分布在不相交的设备上。例如，为了训练具有高保真图像的视觉模型，张量并行性将与大图像相关的大型张量进行分割，并将分割后的张量分配给不相交的设备。这排除了将分割操作符放置在较少设备上的情况，即多个操作符共享一个设备，并以流线化的方式计算，以同时减少内存消耗和设备间通信成本。\",\"流水线并行性假设训练涉及一次前向传播和一次反向传播。然而，像 AlphaFold2 这样的模型需要三次前向传播和一次反向传播。这种非常规的训练方法使得现有的流水线并行性无法适用。\",\"流水线并行性还假设不同的流水线阶段分布在不相交的设备上，并禁止任何两个阶段通过时间复用共享相同的设备集。例如，多语言大型语言模型（LLMs）通常在模型的早期计算阶段使用一个大型嵌入表。这导致显著的 GPU 内存消耗（超过 40%），但计算利用率却很低（不到 5%）。鉴于流水线并行性（以及张量并行性）中的不相交设备分配，硬件利用率的不平衡是不可避免的。\",\"后来的手工搜索空间（例如，结合张量和流水线并行性等的方案）继承了这些假设，因此也遭受了相同的局限性。这促使我们设计一种更灵活的空间构建方法，使领域专家能够为他们的模型找到更有效的训练计划。\"]},\"427\":{\"h\":\"2.2 由于灵活性带来的新挑战\",\"t\":[\"引入一种更灵活的方式来构建并行化计划空间带来了新的挑战。现有的框架，如 Megatron-LM、Alpa 和 DeepSpeed，仅实现了一些经过充分研究的分区、调度和通信方案，这些方案支持在已知的并行化空间内的并行化计划。然而，新的空间可能会揭示操作符分区的新方法，以及具有非常规通信模式的新操作符调度。此外，更灵活的并行化计划研究较少，因此可能容易出错。\",\"为了解决上述挑战，我们设计了一个编译过程，以检测和防止并行化计划中的潜在错误（例如，转换后的数据流图中的循环），并为发现的并行化计划生成具有高效通信操作的运行时代码。\"]},\"428\":{\"h\":\"3. 并行化搜索空间构建\",\"t\":[\"并行化计划可以自然地通过模型分区和分区模型的时空调度来表达。因此，nnScaler 提出了三个原语：op-trans、op-assign 和 op-order（见表 1），以捕捉并行化计划的三个方面。将这些原语结合起来，可以为任意模型和加速器设备构建任何并行化计划的搜索空间。\"]},\"429\":{\"h\":\"op-trans\",\"t\":[\"op-trans(op, algo, n) 根据选定的转换算法 algo 将操作符 op 转换为 n 个子操作符，该算法从与 op 类型相对应的算法集中选择。例如，矩阵乘法操作符 matmul(Ai,k,Bk,j) 可以沿着张量 A 的维度 i 将其分区为两个 matmul 操作符，同时复制张量 B。实际上，大多数操作符可以沿着其相关张量的某个维度（例如 A 或 B 的 i 或 k）进行分区，并且分区后的（子）操作符的计算与原始操作符的计算保持一致。\",\"基于这一观察，nnScaler 实现了大多数深度神经网络（DNN）模型中主要操作符的分区算法。领域专家可以通过 algos() 接口重用所需的算法。nnScaler 还可以集成自定义转换算法，例如由领域专家开发的算法，适用于任何给定的操作符。需要注意的是，转换算法不仅限于操作符分区。例如，可以通过增加一个额外的重新计算操作符或内存交换操作符来增强操作符，以节省内存。在本文中，我们将“转换”和“分区”这两个术语互换使用。\"]},\"430\":{\"h\":\"op-assign\",\"t\":[\"给定一组设备 D 和一个操作符 op，op-assign(op, d) 表示操作符 op 将在 D 中的第 d 个设备上执行。\"]},\"431\":{\"h\":\"op-order\",\"t\":[\"当非依赖操作符（例如 op1 和 op2）被分配到同一设备时，op-order(op1, op2) 确保op1 必须在 op2 之前执行。非依赖操作符的执行顺序在训练性能中可以发挥至关重要的作用。例如，在流水线并行性中，流水线阶段中的一个操作符可以沿着批次维度分区成多个微批次。我们把这些（子）操作符表示为 op.mb1、op.mb2 等，其中 mbi 表示相应的微批次 ID。这些操作符 op.mbi 可以在任意顺序下相对于 op.mbj（i ≠ j）执行。\",\"然而，各种研究表明，一旦这些操作符在时间维度上被精心编排，就有可能最小化流水线“气泡” [24, 54]，从而显著提高训练效率。\",\"使用上述提到的三个原语，领域专家可以编写 Python 代码来为任何深度神经网络（DNN）模型构建任意并行化计划的搜索空间。这些代码不一定与特定的 DNN 模型绑定。因此，nnScaler 将模型代码与搜索空间和搜索策略相关的代码分离。请注意，为了简化编程工作，原语中的 op 可以代表一个子图，其中原语适用于子图中的每个操作符。\",\"由于原语的灵活性和大型 DNN 模型的规模，构建的并行化搜索空间通常包含数百甚至数千个操作符，具有组合搜索复杂性。为了解决这个问题，nnScaler 允许领域专家在应用这些原语时施加约束。这些约束可以显著减少搜索空间（第 4 节），从而使得有效的搜索方法（第 5 节）成为可能。\"]},\"432\":{\"h\":\"4. 在搜索空间中应用约束\",\"t\":[\"在 nnScaler 中，约束被表达为表 1 中原语的参数化参数。当所有参数都变为具体值时，整个空间就缩减为一个具体的并行化计划。以下，我们将说明如何使用三个原语和约束（第 4.1 节）来表达像数据、张量和流水线并行性这样的经过充分研究的并行化计划。第 4.2 节讨论了导致新颖并行化计划的一些新约束。\"]},\"433\":{\"h\":\"4.1 现有搜索空间的约束\",\"t\":[\"数据并行和张量并行的约束。表2显示了数据并行和张量并行相关的基本操作和约束。数据并行和张量并行都将算子均匀地分成n个部分。该分割沿某一维度进行，由algo描述，每个被分割的子算子被分配到不同的设备上并发执行，即表2中的约束2和3。注意，数据并行始终沿着批次维度进行分割，因此algo的选择比张量并行更为受限。\",\"Table 2: Constraints for data and tensor parallelisms.\",\"Primitives\",\"Constraints\",\"1 sub-ops = op-trans(op,algo,n)\",\"n =| D |\",\"2 op-assign(sub-opi,di)\",\"di,dj ∈ D\",\"3 op-assign(sub-opj,dj)\",\"di ̸= dj\",\"管道并行的约束。给定一组设备D，管道并行将模型G划分为子图Gi (0 ≤ i < |D|)，其中i表示第i个管道阶段。子图将被分配到不同的设备上，如表3所示。\",\"Table 3: Constraints for dividing a model G into |D| stages\",\"Primitives\",\"Constraints\",\"1 op-assign(Gi, di)\",\"di,dj ∈ D,\",\"2 op-assign(Gj, dj)\",\"di ̸= dj\",\"为了最小化“气泡”，管道并行将一批样本划分为多个微批次。子图(Gi,n)处理第n个微批次。我们进一步将正向子图表示为fGi，反向子图表示为bGi，著名的1F1B【24】管道并行的约束总结在表4中。\",\"Table 4: Constraints for 1F1B schedule.\",\"Primitives\",\"Constraints\",\"1 op-order((fGi,m),(fGi,n)) 2 op-order((bGi,m),(bGi,n))\",\"m < n\",\"3 op-order((fGi,m+ofst),(bGi,m)) 4 op-order((bGi,m),(fGi,m+ofst+1))\",\"ofst=|D| −i,m ≥ 0\",\"如图 1 所示，表 4 中的约束 1 和 2 确保了以下内容：在阶段 i 中，微批次的前向和反向传播的执行顺序必须相同。也就是说，对于任何两个微批次 m 和 n，其中 m < n，fGm 应该在 fGn 之前执行（1）。同样的规则也适用于反向传播中的 bGm 和 bGn（2）。\",\"表 4 中的约束 3 和 4 指定了 1F1B 的微妙调度顺序。它们定义了 ofst，即相对于当前阶段的偏移量。在流水线中越早的阶段，偏移量越大。因此，对于 Gi，较早的微批次的反向传播应该相对于前向传播执行得晚（3）。而较晚的微批次的前向传播应该在较早微批次的反向传播之后紧接着执行（4）。\"]},\"434\":{\"h\":\"4.2 新的约束\",\"t\":[\"除了现有的搜索空间之外，领域专家可以应用新的约束来构建自定义的搜索空间，以便为各种模型搜索新的、更高效的并行化方案，具体说明如下。\"]},\"435\":{\"h\":\"4.2.1 Swin-Transformer 的约束\",\"t\":[\"为了提升视觉任务的能力，越来越多的人选择采用更高分辨率的图像来训练大型视觉模型，例如 Swin Transformer。使用更大的图像会在训练过程中生成更大的中间张量，尤其是在注意力 (Attn) 和前馈 (FF) 算子中。这要求比单个 GPU 更大的内存才能容纳这些数据。\",\"张量并行是解决此问题的标准做法。对于一个流水线来说，Attn 和 FF 中的算子被分割并分配到 |Mi| 台设备上，Mi 是设备集，用于容纳第 i 阶段中的算子。张量并行分割的算子被放置在不同的设备上，因此每个设备只持有一个分割后的算子。然而，我们观察到，有时多个分割后的算子可以共享一个设备，从而以流水线方式进行计算，减少每个阶段所需的设备数量并降低内存消耗。尽管多个分割算子的流水线计算可能会减慢计算过程，但减少设备间的通信可以降低成本并加快整体过程。\",\"在阶段 i 中的任意 Attn 和 FF 算子 op 中，设 sub_op 为 op 任何一个经过转换的子算子。假设允许 C 个子算子共享一个设备，从而导致一个设备集 Di 被分配给第 i 阶段的算子，其中 |Di| < |Mi|。这些约束如表 5 所示。其他算子可以通过现有的搜索空间来描述，即文献 [65] 中定义的搜索空间。注意，C 是一个超参数，其值可以通过策略搜索确定（详见第 5 节）。\"]},\"436\":{\"h\":\"4.2.2 T5 的约束\",\"t\":[\"多语言模型如 T5 通常使用一个大型嵌入表 E，其中包含来自多种语言的词汇嵌入。E 只在 LLM 的第一个和最后一个层中使用，但它消耗了大量内存，计算成本却很低。管道并行会优先考虑分配设备以容纳 E，并将其余设备留给其他算子。这种安排会导致硬件利用率不平衡，包含 E 的设备 GPU 周期使用率很低，而内存使用率却很高。\",\"通过 nnScaler 提供的三个原语和约束，我们可以将 E 拆分到整个设备集 D 上。然后通过构建遵循常规搜索空间的搜索空间，其他算子可以共享 D 中剩余的资源。这些约束在表 6 中有突出体现，它打破了不同流水线阶段中的算子不能共享同一设备集的常规假设。类似的解决方案也适用于图神经网络的训练。\"]},\"437\":{\"h\":\"4.2.3 AlphaFold2 的约束\",\"t\":[\"在 AlphaFold2 中，每个微批次的训练需要三个前向传播和一个反向传播（即 3F1B）。传统的 1F1B 流水线并行无法支持这种模式。图 2 左侧显示了训练一个微批次后再训练另一个的朴素方法，这种方法由于流水线气泡和中间结果的积累效率低下。因此，我们决定在不同微批次中交错前向和反向传播，同时保持时间顺序上的约束。设 fpGi 表示第 i 个流水线阶段中的第 p 次前向传播子图，ofst 为 S-i，其中 S 表示流水线阶段的总数。表 7 中列出了 3F1B 的约束条件。\",\"表 7 中的约束 1 和 2 交错了连续微批次的三个前向传播，顺序为递减。约束 3 规定，在最后执行的前向传播完成后，对应的反向传播子图应该在具有相对当前阶段的偏移量（ofst）的微批次ID上执行。\"]},\"438\":{\"h\":\"4.3 讨论\",\"t\":[\"约束是定制各种并行化计划并定义其搜索空间的强大抽象工具。为了设计有效的约束，nnScaler 假设其用户，通常是领域专家，对模型架构和并行训练具有深入了解。有了这些知识，使用三个原语构建搜索空间就变得直观了。根据我们的经验，可以通过识别训练中的性能瓶颈（例如，过高的 GPU 内存使用、计算/通信不平衡）来推导出有效的约束。然后可以定义这些约束以缓解瓶颈。此外，随着约束调整后瓶颈的变化，约束可以迭代地细化。通过对约束的细化，nnScaler 使并行化计划的生成比以前的方法更加简单。\"]},\"439\":{\"h\":\"5. 计划搜索策略\",\"t\":[\"有了新的用户定义搜索空间后，nnScaler 引入了一个通用的策略框架来搜索高效的并行化计划。如算法1所示，策略将模型图 G 和用户指定的搜索空间作为输入。我们将搜索空间表示为 Ctrans、Cassign 和 Corder，它们分别对应三个原语：op-trans、op-assign 和 op-order，并带有与约束相关的增强。策略通过逐渐收紧约束来缩小空间，最终将其减少到唯一的并行化计划，即 Cfinal_trans、Cfinal_assign 和 Cfinal_order。\",\"策略框架的一个关键特点是，它允许开发者从新的搜索空间中“切割”出一个子空间，在这个子空间中可以应用现有的搜索策略。具体来说，搜索过程包括两个阶段：算子划分与放置搜索，以及时间顺序搜索。\"]},\"440\":{\"h\":\"5.1 算子划分与放置搜索\",\"t\":[\"这一阶段的目标是将计算均匀分配到多个设备上，同时最小化通信成本。一个算子的不同划分选项会带来不同的通信成本。例如，划分批次维度需要对参数执行全归约操作，而划分参数则需要在设备间复制输入激活张量。算子的不同放置选项也会导致各设备执行时间不同。因此，一个设备 d 上的执行时间为其分配的算子的计算时间 Compd 与相关通信时间 Commd 之和。整体运行时间由最慢的设备决定。\",\"minimize max {Compd + Commd}\",\"通过将划分和放置选项表示为整数，这个优化问题可以被看作是一个 NP 困难的整数线性规划问题。应用约束后，公式中的搜索空间可以大大缩小，从而加快搜索过程。\"]},\"441\":{\"h\":\"5.2 时间顺序搜索\",\"t\":[\"在算子变换与分配完成后，某些算子的时间顺序已由转换后的图中的数据依赖关系确定。然而，同一设备上的两个没有直接依赖关系的算子可以以任意顺序执行。此外，对于流水线并行，同一批次中的不同微批次上执行的同一算子的顺序未被指定。nnScaler 利用 Tessel，一个最先进的搜索策略来确定这些算子的执行顺序。\"]},\"442\":{\"h\":\"6. 并行化计划的编译\",\"t\":[\"Figure 3: System overview of nnScaler\",\"nnScaler 会将模型和生成的并行化计划编译为可执行代码，遵循图 3 中展示的端到端流程。系统首先将深度学习模型转换为数据流图（Graph IR）。通过原语和相关约束定义搜索空间，nnScaler 利用搜索策略生成并行化计划。计划编译接着将该计划定义的原语和约束应用于 Graph IR。在此步骤中，nnScaler 通过 vTensor 和 pTensor 抽象进行数据依赖追踪。生成的新数据依赖关系以及由于算子分布到多个设备而产生的额外通信操作会被反映到 Graph IR 中，最终这些内容会被物化为并行执行的可执行代码。\"]},\"443\":{\"h\":\"张量抽象 vTensor 和 pTensor\",\"t\":[\" vTensor 和 pTensor 被引入以追踪应用三个原语时数据依赖关系的变化。如图 4 所示，pTensor 表示逻辑模型中的张量，而 vTensor 则表示应用原语后产生的结果张量。vTensor 连接到 pTensor，并维护一个掩码，指示该 vTensor 所代表的 pTensor 部分。一个 pTensor 可以与多个算子相关联。在图 4 的顶部，算子 A 的输出作为算子 B 的输入，两个算子通过各自的 vTensor 连接到同一个 pTensor。\",\"通过 vTensor，每个算子都可以独立地进行变换、分配和排序。当应用 op-trans 时，nnScaler 通过 vTensor 的“掩码”划分 vTensor，而 pTensor 保持不变。例如，在图 4 中，算子 A 只会拆分自身及其输出的 vTensor，而算子 B 的 vTensor 不受影响。对于其他类型的原语，vTensor 的掩码保持不变。因此，nnScaler 可以通过计算生产者和消费者 vTensor 的掩码交集来检测它们之间是否存在数据依赖关系。运行时执行过程中，只有 vTensor 会被实例化为实际的 GPU 张量实例。\",\"借助 vTensor-pTensor 抽象进行数据流图转换时的依赖追踪，nnScaler 能够检测到新生成的图中的循环依赖，从而避免出现死锁，确保计划的有效性。\"]},\"444\":{\"h\":\"数据依赖的物化\",\"t\":[\"在应用了原语和约束后，nnScaler 将通过 vTensor-pTensor 物化新的数据依赖关系为具体的数据操作和通信操作。对于消费者 vTensor（如图 4 中的 B1），nnScaler 会识别出依赖的生产者 vTensor（如 A1 和 A2），并在物化过程中插入张量操作（例如 torch.split 或 torch.chunk）以提取相应的张量片段。当生产者和消费者位于不同设备上时（由于 op-assign 的作用），nnScaler 会在物化过程中插入点对点的发送-接收通信操作。\",\"为了提高通信效率，位于同一 pTensor 下的 vTensor 之间的某些通信模式可以通过集体通信原语（如 allgather、allreduce 或 alltoall）来实现。例如，图 4 中，A 的 vTensor3 和 vTensor4 与 B 的 vTensor5 和 vTensor6 之间的通信可以通过更高效的 alltoall 原语来物化。nnScaler 使用简单的模式匹配来识别每个 pTensor 及其相关 vTensor 的适当集体通信原语。\"]},\"445\":{\"h\":\"7. 实现与经验\",\"t\":[\"我们基于 PyTorch 实现了 nnScaler，代码量达到了 24,000 行 Python 代码。nnScaler 读取为单设备开发的 PyTorch 模型，并将其转换为中间图表示 (IR)。在进行转换、时空调度以及插入通信和张量操作后，每个设备将接收一个由 IR 表示的子图。nnScaler 然后将这些子图转换回 PyTorch 代码文件，并通过 torchrun 并行执行以进行分布式训练。\",\"为了支持各种 PyTorch 模型，nnScaler 基于 TorchFX 实现了增强的图转换器，包含 2,243 行 Python 代码。该转换器结合了 TorchFX 的符号执行和 torch.jit.trace 的值跟踪来处理控制流，这是将 PyTorch 模型转换为 TorchFX 时的典型障碍。默认情况下，PyTorch 模型通常只包含前向传播，nnScaler 自动使用链式法则的 autograd 功能完成反向传播。到目前为止，nnScaler 已成功转换了 HuggingFace 自然语言处理任务中的 84.1% 的 PyTorch 模型。转换失败的原因主要是由于某些不支持的算子（例如为特定模型设计的自定义算子）。我们正在积极探索支持更多算子及其对应的转换算法的方法。\"]},\"446\":{\"h\":\"7.1 实践经验\",\"t\":[\"nnScaler 已被 Microsoft 不同团队的多个项目使用，用于支持多代 NVIDIA 和 AMD GPU 上的下一代 DNN 模型的预训练和微调。这些模型包括 RetNet、YOCO、LongRoPE、Phi-3 系列以及一个由 Transformer 和图神经网络（GNN）组成的大型科学基础模型，模型参数范围从 30 亿到 920 亿不等。\",\"选择使用 nnScaler 的决定主要基于两个关键因素。首先，将新模型整合到现有的分布式训练框架中通常会遇到复杂的工程挑战，包括新模块的并行化、适当的划分选项以及确保端到端训练的正确性。这个过程通常需要两名有经验的工程师大约两个月的时间才能完成。此外，现有的并行化方案往往在新模型上表现不佳，导致模型 FLOPs 利用率 (MFU) 不理想。其次，研究新模型通常需要更改模型架构、配置和训练设置，这可能需要进一步调整并行化计划以提高训练效率。nnScaler 正是为了解决这些问题而设计的。\",\"此外，我们与这些团队的合作也带来了许多启示。\"]},\"447\":{\"h\":\"7.1.1 调试 nnScaler\",\"t\":[\"nnScaler 在模型训练中提供了很大的灵活性，但新的原语和约束也增加了系统的复杂性，使某些并行化计划容易出错。为了解决这个问题，nnScaler 采用了一种模块化的调试方法，允许将由新约束生成的较少研究的子图替换为经过充分测试的约束。例如，nnScaler 可以选择性地将数据并行性应用于模型的一部分，而其余部分保持现有的并行化计划不变。此调整不需要修改模型代码，只需重新配置预构建的并行化计划。通过迭代地更改计划中疑似有问题的模块，这种方法有助于定位问题模块。\"]},\"448\":{\"h\":\"7.1.2 模型准确性\",\"t\":[\"实现高模型准确性是训练的最终目标。然而，有时训练框架或模型代码中的一个小错误就会导致准确性下降。更复杂的是，在训练早期阶段，系统可能表现正常，但经过数千步的训练后，损失曲线可能恶化，最终出现发散。直接将损失和梯度值与经过充分测试的训练计划（如数据并行性）进行比较是不现实的。例如，在更复杂的计划中，诸如矩阵乘法 (matmul) 或全归约 (allreduce) 操作会因不同的加法顺序导致浮点值漂移，这是预期的行为。这使得很难分辨是预期中的数值偏差，还是语义错误。\",\"为了解决这个问题，nnScaler 首先通过减少模型的隐藏维度，使其适应单个设备的训练，从而简化调试过程。由于模型代码与训练代码之间的清晰分离，这种模型更改可以很容易实现。接下来，我们将搜索到的并行化计划应用于简化后的模型，并通过比较损失曲线和梯度归一化曲线来评估其与数据并行训练的重叠情况。我们观察到，梯度归一化曲线是一个良好的指标，能够在早期放大偏差并预示系统中潜在的错误。\"]},\"449\":{\"h\":\"7.1.3 就地操作符\",\"t\":[\"为了提高训练性能，像 Tensor.add_ 这样的就地操作符会在原地更新张量。然而，对就地操作符进行划分可能会带来问题。例如，如果就地操作符的划分导致张量被克隆，而原本应在原地更新的操作变成了非就地操作，结果就不会保留原来就地操作符的效果。这是因为在混合使用就地操作符和非就地操作符时，会违反静态单一赋值 (SSA) 形式。为了避免这个问题，nnScaler 在图转换过程中遵循 SSA 规则，并在后期优化阶段将某些非就地操作符替换为原始的就地版本。\"]},\"450\":{\"h\":\"8. 评估\",\"t\":[\"对 nnScaler 的评估涵盖了并行化原语的表达能力以及带有约束的并行化计划搜索效率。更重要的是，我们对实际模型的性能进行了评估，以展示整个系统在实现新模型和设置的高效并行化方面的有效性。总结来说，评估结果表明：\",\"nnScaler 中的并行化原语可以构建各种并行化计划，包括现有的手工设计的计划（§8.1）和本文中介绍的创新计划（§8.2）。\",\"对 SwinTransformer、T5 和 AlphaFold2 的三个新并行化计划进行的端到端评估，显示它们相较于 Megatron-LM 、Alpa 、DeepSpeed 和 DAP 基线方案分别加速了 3.5×、2.5× 和 1.4×（§8.3）。\",\"带有约束的并行化空间帮助 nnScaler 快速发现高效计划，搜索速度提高了 11.7×，相比于无约束的搜索。\"]},\"451\":{\"h\":\"8.1 计划构建的表达能力\",\"t\":[\"我们通过实现表 8 中列出的流行手工并行化计划，评估了三种原语在计划构建中的表达能力。这些计划可以分解为操作符转换、放置和排序，与表 1 中的三种原语紧密对齐。nnScaler 成功支持了 17 个并行化计划中的 14 个。\",\"在 SPMD（单程序多数据）下的并行化计划是通过操作符转换实现的。数据并行性和灵活的张量并行性可以轻松支持。Transformer 并行性和 DAP 是为 Transformer 和 AlphaFold2 手工设计的张量并行性。序列并行性和 ZeRO stage-3 是特殊的张量并行性，它们解耦了操作符及其输入张量的划分，以优化内存使用。nnScaler 通过在输入张量和其操作符之间插入一个恒等操作符，通过操作符转换轻松实现了这种解耦。\",\"MPMD（多程序多数据）下的并行化计划是不同类型的手工流水线并行化。它们可以使用操作符排序来支持，无需实现新的执行引擎。值得注意的是，nnScaler 不支持 PipeDream，因为它采用的是异步训练方法，而 nnScaler 尊重模型的原始训练语义。对于 TeraPipe，nnScaler 目前缺乏访问张量中具体值的能力，因此无法在令牌级别确定数据依赖关系（即张量掩码），这是 TeraPipe 的一个要求。未来，nnScaler 可以通过深度学习模型的检测工具来实现 TeraPipe。\",\"除了并行化之外，nnScaler 还支持内存优化技术（如重计算、交换）和计算与通信的重叠。对重计算的支持依赖于操作符转换的自定义算法 .\"]},\"452\":{\"h\":\"8.2 计划搜索结果\",\"t\":[\"8.2 计划搜索结果\",\"根据第 4.2 节描述的新约束，nnScaler 在每个构建的空间内进行搜索，并发现了三种在训练性能上表现优越的并行化计划。\",\"Coshard：图 5 展示了 Coshard 计划，适用于像 SwinTransformer 这样包含大张量的模型。它可以与张量并行共存，以减少激活张量的峰值内存。例如，A1 被分割成两部分，放置在同一个设备上，并顺序执行。应用 A1 的重计算后，A1 的峰值激活大小减少了一半。由于峰值内存的减少，张量并行现在可以跨越更少的设备（例如，从 8 路减少到 4 路），从而降低通信成本。\",\"交错流水线：图 6 显示了在表 6 中指定约束下搜索到的流水线调度。嵌入层通过张量并行划分到四个设备上，剩余的非嵌入层组件则根据 staged_spmd 分配到不同的设备组。在排序搜索过程中，所有层组合成一个调度，该调度类似于执行嵌入层和 1F1B（一次正向传播一次反向传播）的时间共享模式。由于调度搜索，流水线能够在没有“气泡”的情况下达到稳定状态，如图右侧所示。\",\"3F1B 流水线：图 2 展示了第 4.2 节描述的 3F1B 流水线的时间轴。表 7 中概述的约束定义了正向和反向传递如何在流水线的稳定状态中交错执行。\"]},\"453\":{\"h\":\"8.3 端到端性能\",\"t\":[\"我们分别在 SwinTransformer、T5 和 AlphaFold2 上对三种新并行化计划进行了评估，涵盖不同的模型配置和 GPU 数量。\"]},\"454\":{\"h\":\"8.3.1 实验设置\",\"t\":[\"机器配置：我们的评估在配备 32 个 NVIDIA Tesla V100（32GB）的 DGX-2 集群上进行。每台服务器配备 16 个 GPU，使用 NVLink 互联。服务器之间通过 8 个 100 Gbps 的 InfiniBand 网络适配器互联。所有服务器均安装了 NCCL 2.14 和 PyTorch v2.0.1。\",\"模型配置：我们在 SwinTransformer、T5 和 AlphaFold2 的四种不同模型配置下进行实验，从小模型到大模型不等。每个配置都包含参数数量、层数、隐藏维度和头数。\",\"基线系统：我们将 nnScaler 与三个流行的分布式训练系统进行了比较：\",\"Megatron-LM：专为训练基于 Transformer 的模型设计，结合了流水线并行、数据并行和张量并行的三维并行化方式。对于流水线并行，它将模型层均匀划分为多个阶段，每个阶段可以进一步应用数据并行和张量并行。当 GPU 数量足够多时，Megatron-LM 还可以使用 M⋅KN​路数据并行来进一步提高训练性能。\",\"Alpa：一个针对深度学习模型的自动并行化系统，基于 TensorFlow，使用三维并行化空间。它的搜索算法和训练系统目前基于 TensorFlow。为了进行直接比较，我们在 nnScaler 中实现了 Alpa 的搜索算法，作为一种策略。\",\"DeepSpeed：与 Megatron-LM 类似的分布式训练系统，支持流水线并行、数据并行和张量并行。此外，DeepSpeed 集成了 ZeRO 和 ZeRO-Offload 等技术，以优化 GPU 内存使用。ZeRO 主要通过在数据并行模式下只保留优化器状态的单份拷贝来减少内存占用，而 ZeRO-Offload 则将权重卸载到 CPU 内存，从而减轻 GPU 的内存压力，并在需要时将其取回。\",\"Megatron-LM 和 DeepSpeed 都不具备在其支持的并行化空间内自动搜索并行化计划的功能。因此，我们通过分别遍历流水线并行、张量并行和数据并行的不同程度，手动找到了它们的最佳性能计划。在接下来的所有实验中，我们应用了逐层重计算【11】，以减少激活张量的内存消耗。按照常见做法【29, 65】，我们使用了累计的有效 TFLOPS 作为性能指标。\"]},\"455\":{\"h\":\"8.3.2 SwinTransformer 的结果\",\"t\":[\"图 7 展示了 SwinTransformer 在四个系统上的端到端训练吞吐量。由于激活张量的体积巨大（例如，一个 50 亿参数模型的第一个 Transformer 层的激活张量占用 21GB），即使应用了重计算，Megatron-LM 和 Alpa 也对所有模型配置使用了纯张量并行性。DeepSpeed 采用了 ZeRO-Offload 和 ZeRO stage 3 来优化内存使用，因此它能够在 4 个 GPU 设置中应用 2 路张量并行性，并在其余三种设置中应用 4 路张量并行性。为了扩展到所有可用的 GPU，还进一步应用了数据并行性。nnScaler 在 SwinTransformer 的前四层（Attention + MLP）上应用了 Coshard 计划，因为这些层由于激活张量占用了大量内存。nnScaler 分别对四种配置应用了 2 路、2 路、4 路和 8 路张量并行性，并分别结合了 2 路、4 路、4 路和 4 路流水线并行性。在 8 路 GPU 设置中，Coshard 对每个 GPU 顺序执行 6 个分区，而在其余三个设置中执行 4 个分区。\",\"如图 7 所示，nnScaler 在 8、16 和 32 个 GPU 上的速度分别比 DeepSpeed 快 1.2 倍、1.5 倍和 1.5 倍。\"]},\"456\":{\"h\":\"8.3.3 T5 的结果\",\"t\":[\"图 8 展示了 T5 的端到端训练吞吐量。对于 4 个 GPU，Megatron-LM 使用了 2 路张量并行性和 2 路流水线并行性，而对于 8、16 和 32 个 GPU，它只使用了纯张量并行性。Alpa 对于 4 个 GPU 使用了 3 路流水线并行性，且中间阶段应用了 2 路张量并行性。由于内存消耗较大，Alpa 必须在 8、16 和 32 个 GPU 上使用纯张量并行性。因为 T5 模型参数较小（3.9B），DeepSpeed 在 4 个 GPU 上可以使用数据并行性结合 ZeRO stage 3。在 8、16 和 32 个 GPU 上，它采用了 4 路张量并行性，并结合了 ZeRO-Offload 和 ZeRO stage 3。此外，还进一步应用了数据并行性扩展到所有可用 GPU。nnScaler 则应用了交错流水线，使用张量并行性处理大嵌入层，其他层则通过 4 路流水线并行性进行处理，每个阶段分别应用了 1 路、2 路、4 路和 8 路张量并行性，分别对应 4、8、16 和 32 个 GPU。\",\"nnScaler 在 8、16 和 32 个 GPU 上的表现分别比 DeepSpeed 快 1.5 倍、1.6 倍和 2.5 倍。\"]},\"457\":{\"h\":\"8.3.4 AlphaFold2 的结果\",\"t\":[\"图 9 显示了 AlphaFold2 的端到端训练吞吐量。在这个实验中，我们与两个基线进行了比较。一个是专门为 AlphaFold2 设计的手工张量并行方案 DAP（Deep Analysis Pipeline）。我们还应用了数据并行性来扩展 DAP，称为 DAP+DP。对于 4 和 8 个 GPU，DAP+DP 使用了纯数据并行性，因为模型较小。对于 16 个 GPU，它使用了 4 路张量并行性结合 4 路数据并行性。另一个基线是 DeepSpeed。由于 AlphaFold2 的模型尺寸比 SwinTransformer 和 T5 小得多，不需要使用 ZeRO-Offload。DeepSpeed 对于 4、8 和 16 个 GPU 使用了纯数据并行性结合 ZeRO stage 3，对于 32 个 GPU 使用了 2 路张量并行性和 16 路数据并行性。nnScaler 也在 4 和 8 个 GPU 上使用了纯数据并行性，而在 16 和 32 个 GPU 上应用了 3F1B 流水线。对于 16 个 GPU，nnScaler 使用了 4 路流水线并行性结合 4 路数据并行性；对于 32 个 GPU，它使用了 2 路张量并行性、2 路流水线并行性和 8 路数据并行性。\",\"nnScaler 在 16 个 GPU 上比 DAP+DP 提高了 1.5 倍的性能，在 32 个 GPU 上比 DeepSpeed 提高了 1.1 倍的性能。\"]},\"458\":{\"h\":\"8.3.5 性能较低硬件上的实验\",\"t\":[\"为了验证新并行化计划的有效性，并了解不同硬件对训练性能的影响，我们在 DGX-1 集群上对 SwinTransformer 和 AlphaFold2 进行了评估。图 10a 显示了 nnScaler 在 16 和 32 个 GPU 上分别比 DeepSpeed 快 1.9 倍和 3.5 倍。相比于图 7 中的数据，对于 32 个 GPU，nnScaler 的性能下降了 6%，而 DeepSpeed、Alpa 和 Megatron-LM 的性能分别下降了 60%、82% 和 82%。nnScaler 的性能下降较小，因为它使用的 Coshard 并行化计划优化了通信成本，能够适应通信带宽的变化。图 10b 显示了 AlphaFold2 在 DGX-1 上的结果。nnScaler 相对于 DeepSpeed 的相对性能增益在 16 和 32 个 GPU 上分别提高到 1.1 倍和 1.4 倍。\"]},\"459\":{\"h\":\"8.4 带有约束的搜索效率\",\"t\":[\"算法 1 表明，nnScaler 中并行化计划的搜索成本包括：（1）操作符转换和放置的成本（即算法 1 中的第 1-4 行），以及（2）操作符时间排序的成本（即第 5 行）。图 11 展示了端到端搜索成本以及三种自定义空间（定义于第 4.2 节）的搜索时间细分。对于不同的模型配置，搜索策略如第 5 节所述。SwinTransformer 的搜索时间小于 150 秒。随着模型尺寸增加，操作符数量增加，搜索时间也相应增加。T5 的排序搜索时间约为 150 秒，因为 T5 的空间中没有约束条件。对于 SwinTransformer 和 AlphaFold2 来说，几乎没有排序搜索的成本。对于 SwinTransformer，顺序基本上由数据依赖关系决定；对于 AlphaFold2，排序约束大大减少了搜索空间。\",\"图 12 进一步展示了 3F1B 调度在有约束和无约束情况下的时间排序搜索时间。左图显示，随着阶段数量的增加，搜索时间呈指数级增长。然而，应用约束后，搜索时间保持在 60 秒以内，从而在 4 个阶段的时间排序中实现了 11.7 倍的加速。这归因于表 7 中的时间排序约束，明确规定了来自不同微批次的独立正向和反向操作符的顺序，从而显著减少了搜索算法（如 Tessel）需要处理的搜索空间。\",\"对于 4 个阶段的情况，右图进一步展示了每个来自表 7 的排序约束逐个应用时的搜索时间。第一个约束将搜索时间减少了 100 秒，第二个约束进一步将搜索时间减少了 50%。这表明了约束的重要性。\"]},\"460\":{\"c\":[\"nnScaler\"]},\"461\":{\"c\":[\"nnScaler\",\"GPU\"]},\"462\":{\"h\":\"\",\"t\":[\"404 Not Found\"]},\"463\":{\"h\":\"云原生\"},\"464\":{\"h\":\"介绍\"},\"465\":{\"h\":\"工具\"},\"466\":{\"h\":\"异构计算\"},\"467\":{\"h\":\"技术科普\"},\"468\":{\"h\":\"杂谈\"},\"469\":{\"h\":\"AI大模型部署\"},\"470\":{\"h\":\"Springboot\"}},\"dirtCount\":0,\"index\":[[\"右图进一步展示了每个来自表\",{\"1\":{\"459\":1}}],[\"明确规定了来自不同微批次的独立正向和反向操作符的顺序\",{\"1\":{\"459\":1}}],[\"明确指定\",{\"1\":{\"203\":1}}],[\"左图显示\",{\"1\":{\"459\":1}}],[\"左侧显示了训练一个微批次后再训练另一个的朴素方法\",{\"1\":{\"437\":1}}],[\"排序约束大大减少了搜索空间\",{\"1\":{\"459\":1}}],[\"几乎没有排序搜索的成本\",{\"1\":{\"459\":1}}],[\"几乎兼容任何多\",{\"1\":{\"143\":1}}],[\"小得多\",{\"1\":{\"457\":1}}],[\"小规模模型\",{\"1\":{\"411\":1}}],[\"小规模网络\",{\"1\":{\"287\":1}}],[\"快\",{\"1\":{\"455\":1,\"456\":1,\"458\":1}}],[\"快速发现高效计划\",{\"1\":{\"450\":1}}],[\"快速在本地管理以及运行大模型\",{\"1\":{\"228\":1}}],[\"快速决策或不同运行间的比较\",{\"1\":{\"95\":1}}],[\"顺序基本上由数据依赖关系决定\",{\"1\":{\"459\":1}}],[\"顺序执行\",{\"1\":{\"455\":1}}],[\"顺序为递减\",{\"1\":{\"437\":1}}],[\"按照常见做法\",{\"1\":{\"454\":1}}],[\"按照kong官方文档安装指南安装了kong\",{\"1\":{\"67\":1}}],[\"剩余的非嵌入层组件则根据\",{\"1\":{\"452\":1}}],[\"嵌入层通过张量并行划分到四个设备上\",{\"1\":{\"452\":1}}],[\"放置在同一个设备上\",{\"1\":{\"452\":1}}],[\"放置和排序\",{\"1\":{\"451\":1}}],[\"未来\",{\"1\":{\"451\":1}}],[\"未获得锁的\",{\"1\":{\"5\":1}}],[\"尊重模型的原始训练语义\",{\"1\":{\"451\":1}}],[\"序列并行性和\",{\"1\":{\"451\":1}}],[\"带有约束的搜索效率\",{\"0\":{\"459\":1}}],[\"带有约束的并行化空间帮助\",{\"1\":{\"450\":1}}],[\"带来了显著的改进和优化\",{\"1\":{\"277\":1}}],[\"形式\",{\"1\":{\"449\":1}}],[\"形成了一个极其庞大且组合复杂的并行化计划搜索空间\",{\"1\":{\"425\":1}}],[\"形成全互联的结构\",{\"1\":{\"347\":1}}],[\"形成多个等价的路径\",{\"1\":{\"345\":1}}],[\"形成完整的机器学习工作流管理平台\",{\"1\":{\"97\":1}}],[\"诸如矩阵乘法\",{\"1\":{\"448\":1}}],[\"损失曲线可能恶化\",{\"1\":{\"448\":1}}],[\"研究新模型通常需要更改模型架构\",{\"1\":{\"446\":1}}],[\"研究者们提出了多种内存优化技术\",{\"1\":{\"418\":1}}],[\"研究者们提出了多种形式的模型并行化\",{\"1\":{\"418\":1}}],[\"研究者更好地使用开源大模型\",{\"1\":{\"220\":1}}],[\"亿参数模型的第一个\",{\"1\":{\"455\":1}}],[\"亿不等\",{\"1\":{\"446\":1}}],[\"亿到\",{\"1\":{\"446\":1}}],[\"系列以及一个由\",{\"1\":{\"446\":1}}],[\"系统可能表现正常\",{\"1\":{\"448\":1}}],[\"系统首先将深度学习模型转换为数据流图\",{\"1\":{\"442\":1}}],[\"系统中使用的8个gpu\",{\"1\":{\"352\":1}}],[\"系统中的组件\",{\"1\":{\"92\":1}}],[\"系统应运行\",{\"1\":{\"263\":1}}],[\"系统调用会向\",{\"1\":{\"255\":1}}],[\"系统调用在读到真正\",{\"1\":{\"255\":1}}],[\"系统全栈的内容\",{\"1\":{\"233\":1}}],[\"系统\",{\"1\":{\"224\":1}}],[\"系统及大模型评估体系\",{\"1\":{\"224\":1}}],[\"系统会启动一个或多个\",{\"1\":{\"89\":1}}],[\"系统组件的平台\",{\"1\":{\"79\":1}}],[\"系统部署到各种环境以进行开发\",{\"1\":{\"78\":1}}],[\"行\",{\"1\":{\"445\":2,\"459\":2}}],[\"及其相关\",{\"1\":{\"444\":1}}],[\"位于同一\",{\"1\":{\"444\":1}}],[\"物化新的数据依赖关系为具体的数据操作和通信操作\",{\"1\":{\"444\":1}}],[\"物理层\",{\"0\":{\"334\":1}}],[\"物理卷\",{\"0\":{\"259\":1}}],[\"物理仿真等领域中也得到广泛应用\",{\"1\":{\"187\":1}}],[\"抽象进行数据流图转换时的依赖追踪\",{\"1\":{\"443\":1}}],[\"抽象进行数据依赖追踪\",{\"1\":{\"442\":1}}],[\"借助\",{\"1\":{\"443\":1}}],[\"借助ecmp协议\",{\"1\":{\"347\":1}}],[\"掩码\",{\"1\":{\"443\":1}}],[\"部分\",{\"1\":{\"443\":1}}],[\"部署文档\",{\"0\":{\"380\":1}}],[\"部署提供一体化解决方案\",{\"1\":{\"129\":1}}],[\"部署\",{\"0\":{\"373\":1},\"1\":{\"116\":1,\"118\":2,\"220\":1,\"380\":1}}],[\"部署和管理\",{\"1\":{\"33\":1}}],[\"遵循图\",{\"1\":{\"442\":1}}],[\"公式中的搜索空间可以大大缩小\",{\"1\":{\"440\":1}}],[\"困难的整数线性规划问题\",{\"1\":{\"440\":1}}],[\"划分\",{\"1\":{\"443\":1}}],[\"划分批次维度需要对参数执行全归约操作\",{\"1\":{\"440\":1}}],[\"划分的主要应用场景\",{\"1\":{\"51\":1}}],[\"搜索时间保持在\",{\"1\":{\"459\":1}}],[\"搜索时间呈指数级增长\",{\"1\":{\"459\":1}}],[\"搜索时间也相应增加\",{\"1\":{\"459\":1}}],[\"搜索策略如第\",{\"1\":{\"459\":1}}],[\"搜索速度提高了\",{\"1\":{\"450\":1}}],[\"搜索过程包括两个阶段\",{\"1\":{\"439\":1}}],[\"搜索越精确\",{\"1\":{\"365\":1}}],[\"切割\",{\"1\":{\"439\":1}}],[\"策略框架的一个关键特点是\",{\"1\":{\"439\":1}}],[\"策略通过逐渐收紧约束来缩小空间\",{\"1\":{\"439\":1}}],[\"策略将模型图\",{\"1\":{\"439\":1}}],[\"策略控制能力和高可扩展性使其成为管理互联网复杂路由需求的理想选择\",{\"1\":{\"315\":1}}],[\"策略控制\",{\"1\":{\"310\":1}}],[\"计划\",{\"1\":{\"452\":1,\"455\":1}}],[\"计划搜索结果\",{\"0\":{\"452\":1},\"1\":{\"452\":1}}],[\"计划搜索策略\",{\"0\":{\"439\":1}}],[\"计划构建的表达能力\",{\"0\":{\"451\":1}}],[\"计划编译接着将该计划定义的原语和约束应用于\",{\"1\":{\"442\":1}}],[\"计算成本却很低\",{\"1\":{\"436\":1}}],[\"计算资源的高需求\",{\"1\":{\"398\":1}}],[\"计算密集型任务\",{\"1\":{\"355\":1}}],[\"计算机网络\",{\"0\":{\"267\":1}}],[\"计算在过去1分钟内\",{\"1\":{\"211\":2}}],[\"计算\",{\"1\":{\"51\":1,\"438\":1}}],[\"讨论\",{\"0\":{\"438\":1}}],[\"约束可以迭代地细化\",{\"1\":{\"438\":1}}],[\"约束是定制各种并行化计划并定义其搜索空间的强大抽象工具\",{\"1\":{\"438\":1}}],[\"约束\",{\"1\":{\"437\":1}}],[\"约束被表达为表\",{\"1\":{\"432\":1}}],[\"次前向传播子图\",{\"1\":{\"437\":1}}],[\"拆分到整个设备集\",{\"1\":{\"436\":1}}],[\"拆分树形结构\",{\"1\":{\"176\":1}}],[\"周期使用率很低\",{\"1\":{\"436\":1}}],[\"周期性\",{\"1\":{\"95\":1}}],[\"详见第\",{\"1\":{\"435\":1}}],[\"台设备上\",{\"1\":{\"435\":1}}],[\"算子的不同放置选项也会导致各设备执行时间不同\",{\"1\":{\"440\":1}}],[\"算子划分与放置搜索\",{\"0\":{\"440\":1},\"1\":{\"439\":1}}],[\"算子\",{\"1\":{\"435\":1,\"443\":2}}],[\"算子中\",{\"1\":{\"435\":1}}],[\"算法对头部进行压缩\",{\"1\":{\"271\":1}}],[\"算法\",{\"1\":{\"105\":1,\"459\":1}}],[\"越来越多的人选择采用更高分辨率的图像来训练大型视觉模型\",{\"1\":{\"435\":1}}],[\"越大\",{\"1\":{\"365\":1}}],[\"较早的微批次的反向传播应该相对于前向传播执行得晚\",{\"1\":{\"433\":1}}],[\"较复杂\",{\"1\":{\"287\":1}}],[\"偏移量越大\",{\"1\":{\"433\":1}}],[\"≥\",{\"1\":{\"433\":1}}],[\"−i\",{\"1\":{\"433\":1}}],[\"著名的1f1b\",{\"1\":{\"433\":1}}],[\"≤\",{\"1\":{\"433\":1}}],[\"̸=\",{\"1\":{\"433\":2}}],[\"∈\",{\"1\":{\"433\":2}}],[\"气泡\",{\"1\":{\"431\":1,\"433\":1,\"452\":1}}],[\"气象预报\",{\"1\":{\"198\":1}}],[\"≠\",{\"1\":{\"431\":1}}],[\"矩阵乘法操作符\",{\"1\":{\"429\":1}}],[\"见表\",{\"1\":{\"428\":1}}],[\"见图7\",{\"1\":{\"416\":1}}],[\"继承了这些假设\",{\"1\":{\"426\":1}}],[\"鉴于流水线并行性\",{\"1\":{\"426\":1}}],[\"称为\",{\"1\":{\"425\":1,\"457\":1}}],[\"称为bgp对等体或邻居\",{\"1\":{\"311\":1}}],[\"权重\",{\"1\":{\"425\":1}}],[\"权限\",{\"1\":{\"255\":1}}],[\"隐藏维度和头数\",{\"1\":{\"454\":1}}],[\"隐藏维度\",{\"1\":{\"425\":1}}],[\"隐私\",{\"1\":{\"231\":1}}],[\"忽略了许多潜在的计划配置\",{\"1\":{\"424\":1}}],[\"合理的分配计划可以显著提高训练性能\",{\"1\":{\"424\":1}}],[\"合并到一个目标张量中\",{\"1\":{\"156\":1}}],[\"引言\",{\"0\":{\"424\":1}}],[\"引入一种更灵活的方式来构建并行化计划空间带来了新的挑战\",{\"1\":{\"427\":1}}],[\"引入一些成功的开源案例\",{\"1\":{\"223\":1}}],[\"引入在线近似方法和优化内核\",{\"1\":{\"249\":1}}],[\"引入了一个通用的策略框架来搜索高效的并行化计划\",{\"1\":{\"439\":1}}],[\"引入了连接保持\",{\"1\":{\"269\":1}}],[\"引入了\",{\"1\":{\"57\":1}}],[\"摘要\",{\"0\":{\"423\":1}}],[\"决定哪些张量需要交换到cpu\",{\"1\":{\"418\":1}}],[\"决定数据包如何在网络中转发\",{\"1\":{\"332\":1}}],[\"梯度归一化曲线是一个良好的指标\",{\"1\":{\"448\":1}}],[\"梯度和参数\",{\"1\":{\"418\":1}}],[\"梯度同步\",{\"1\":{\"181\":1}}],[\"容量和带宽方面的权衡\",{\"1\":{\"417\":1}}],[\"容器来执行超参数调优任务\",{\"1\":{\"106\":1}}],[\"容器化组件\",{\"0\":{\"93\":1}}],[\"容器\",{\"1\":{\"89\":1}}],[\"容器名\",{\"1\":{\"66\":1}}],[\"容器无法通过\",{\"1\":{\"47\":1}}],[\"容器需要通过\",{\"1\":{\"46\":1}}],[\"容器内的应用可以通过服务\",{\"1\":{\"46\":1}}],[\"容器的默认内存请求\",{\"1\":{\"25\":1}}],[\"容器的默认内存请求量\",{\"1\":{\"25\":1}}],[\"容器的默认\",{\"1\":{\"25\":2}}],[\"容器的最小内存使用量\",{\"1\":{\"25\":1}}],[\"容器的最小\",{\"1\":{\"25\":1}}],[\"容器的最大内存使用量\",{\"1\":{\"25\":1}}],[\"容器的最大\",{\"1\":{\"25\":1}}],[\"又可以避免通过超级芯片与pcie连接的内存之间的交换所带来的13\",{\"1\":{\"417\":1}}],[\"又从同一个网络接口回到容器内部\",{\"1\":{\"45\":1}}],[\"既可以节省重计算浪费的25\",{\"1\":{\"417\":1}}],[\"预测了其理想的性能\",{\"1\":{\"417\":1}}],[\"预热迭代次数\",{\"1\":{\"150\":1}}],[\"阶段的算子\",{\"1\":{\"435\":1}}],[\"阶段中的算子\",{\"1\":{\"435\":1}}],[\"阶段流水线并行性和\",{\"1\":{\"425\":1}}],[\"阶段4\",{\"1\":{\"416\":1}}],[\"阶段0\",{\"1\":{\"416\":1}}],[\"阶段映射算法\",{\"1\":{\"406\":1}}],[\"达到51\",{\"1\":{\"416\":1}}],[\"足以涵盖gpu\",{\"1\":{\"415\":1}}],[\"敏感性分析\",{\"0\":{\"413\":1}}],[\"至于性能差距\",{\"1\":{\"412\":1}}],[\"补充了它们的局限性\",{\"1\":{\"412\":1}}],[\"空闲的gpu内存不足以容纳从负载较大的gpu卸载的张量\",{\"1\":{\"411\":1}}],[\"五个系统都成功训练了该模型\",{\"1\":{\"411\":1}}],[\"配备96个虚拟cpu\",{\"1\":{\"410\":1}}],[\"配置和训练设置\",{\"1\":{\"446\":1}}],[\"配置的chat\",{\"1\":{\"366\":1}}],[\"配置复杂度\",{\"1\":{\"287\":1}}],[\"配置简单\",{\"1\":{\"285\":1}}],[\"配置中可能不适用\",{\"1\":{\"96\":1}}],[\"配置加密套件\",{\"1\":{\"75\":1}}],[\"配置文件中\",{\"1\":{\"48\":1}}],[\"配置\",{\"0\":{\"47\":1,\"365\":1},\"1\":{\"121\":1,\"319\":1}}],[\"配置示例\",{\"0\":{\"20\":1,\"25\":1,\"48\":1},\"1\":{\"20\":1,\"25\":1}}],[\"独立的三种优化方法\",{\"1\":{\"413\":1}}],[\"独立的d2d交换\",{\"1\":{\"409\":1}}],[\"独立开发和创业一样有风险\",{\"1\":{\"359\":2}}],[\"独立开发的一些基本流程\",{\"1\":{\"359\":4}}],[\"独立开发者\",{\"2\":{\"361\":1}}],[\"独立开发者面临的困境\",{\"1\":{\"359\":4}}],[\"独立开发者一点思考\",{\"0\":{\"359\":1}}],[\"评估了三种原语在计划构建中的表达能力\",{\"1\":{\"451\":1}}],[\"评估了它在训练bert和gpt等大规模dnn模型时的表现\",{\"1\":{\"419\":1}}],[\"评估结果表明\",{\"1\":{\"450\":1}}],[\"评估指标\",{\"1\":{\"410\":1}}],[\"评估\",{\"0\":{\"409\":1,\"450\":1}}],[\"评估与改进等方面的系统性讲解\",{\"1\":{\"231\":1}}],[\"考虑到张量的生命周期以及各种内存技术在成本\",{\"1\":{\"417\":1}}],[\"考虑到固定内存\",{\"1\":{\"408\":1}}],[\"考虑路由抖动\",{\"1\":{\"310\":1}}],[\"改进了pipedream系统\",{\"1\":{\"408\":1}}],[\"改善了带宽利用\",{\"1\":{\"276\":1}}],[\"前提是存在空闲的gpu内存\",{\"1\":{\"407\":1}}],[\"前提是重计算引入的额外延迟小于gpu\",{\"1\":{\"407\":1}}],[\"前端开发\",{\"0\":{\"130\":1}}],[\"长于这两种交换方法的时间成本时\",{\"1\":{\"407\":1}}],[\"长上下文基准测试中的实验结果\",{\"1\":{\"249\":1}}],[\"长上下文\",{\"1\":{\"249\":1}}],[\"探索将d2d交换\",{\"1\":{\"407\":1}}],[\"探测\",{\"1\":{\"294\":1}}],[\"普通操作将直接通过底层训练框架运行时处理\",{\"1\":{\"405\":1}}],[\"普通用户程序代码中\",{\"1\":{\"255\":1}}],[\"规则\",{\"1\":{\"449\":1}}],[\"规定\",{\"1\":{\"437\":1}}],[\"规划器根据成本模型探索可能的配置\",{\"1\":{\"405\":1}}],[\"规约并散播\",{\"1\":{\"143\":2}}],[\"规约\",{\"1\":{\"143\":2}}],[\"表明\",{\"1\":{\"459\":1}}],[\"表\",{\"1\":{\"433\":2,\"437\":2,\"452\":1}}],[\"表2显示了数据并行和张量并行相关的基本操作和约束\",{\"1\":{\"433\":1}}],[\"表iv展示了mpress在高gpu内存压力下\",{\"1\":{\"416\":1}}],[\"表iii报告了在bert和gpt模型中\",{\"1\":{\"415\":1}}],[\"表iii展示了收集的统计数据示例\",{\"1\":{\"405\":1}}],[\"表ii展示了我们使用的bert变体的参数规模\",{\"1\":{\"410\":1}}],[\"表示的子图\",{\"1\":{\"445\":1}}],[\"表示逻辑模型中的张量\",{\"1\":{\"443\":1}}],[\"表示流水线阶段的总数\",{\"1\":{\"437\":1}}],[\"表示第\",{\"1\":{\"437\":1}}],[\"表示相应的微批次\",{\"1\":{\"431\":1}}],[\"表示操作符\",{\"1\":{\"430\":1}}],[\"表示内存需求超过每个gpu容量的大模型\",{\"1\":{\"410\":1}}],[\"表示层\",{\"0\":{\"339\":1}}],[\"表示协议地址的长度\",{\"1\":{\"304\":1}}],[\"表示硬件地址的长度\",{\"1\":{\"304\":1}}],[\"表示ipv4\",{\"1\":{\"304\":1}}],[\"表示以太网\",{\"1\":{\"304\":1}}],[\"表示该设备所属的主设备\",{\"1\":{\"298\":1}}],[\"表示该条目所属的vlan\",{\"1\":{\"298\":1}}],[\"表示该条目是永久性的\",{\"1\":{\"298\":1}}],[\"表示该条目是本地接口的mac地址\",{\"1\":{\"298\":1}}],[\"表示该mac地址对应的设备\",{\"1\":{\"298\":1}}],[\"表示该函数不接受任何参数\",{\"1\":{\"165\":1}}],[\"表示该函数期望接收的参数类型依次是\",{\"1\":{\"162\":1}}],[\"表示有多少时间是被同一个宿主机上的其他虚拟机抢走的\",{\"1\":{\"255\":1}}],[\"表示没有返回值\",{\"1\":{\"162\":1}}],[\"表示哪个\",{\"1\":{\"158\":1}}],[\"表示输入的张量序列\",{\"1\":{\"158\":1}}],[\"表示接受跨域请求\",{\"1\":{\"75\":1}}],[\"表示所有\",{\"1\":{\"75\":2}}],[\"表示同一节点上的\",{\"1\":{\"58\":1}}],[\"表示约束作用在节点级别\",{\"1\":{\"54\":1}}],[\"表示这个节点对某些\",{\"1\":{\"36\":1}}],[\"二是重新执行前向传播会与反向传播竞争gpu资源\",{\"1\":{\"401\":1}}],[\"二层以太网\",{\"1\":{\"287\":1}}],[\"节所述\",{\"1\":{\"459\":1}}],[\"节描述的\",{\"1\":{\"452\":1}}],[\"节描述的新约束\",{\"1\":{\"452\":1}}],[\"节讨论了导致新颖并行化计划的一些新约束\",{\"1\":{\"432\":1}}],[\"节\",{\"1\":{\"431\":2,\"432\":1,\"435\":1,\"459\":1}}],[\"节省内存\",{\"1\":{\"401\":1}}],[\"节点\",{\"1\":{\"162\":1}}],[\"节点上的输入张量\",{\"1\":{\"158\":1}}],[\"节点的目标张量中\",{\"1\":{\"157\":1}}],[\"节点可能会被跳过\",{\"1\":{\"94\":1}}],[\"节点亲和性\",{\"0\":{\"55\":1}}],[\"节点设置taint\",{\"1\":{\"36\":1}}],[\"立即开始相应的反向传播\",{\"1\":{\"399\":1}}],[\"许多训练系统\",{\"1\":{\"398\":1}}],[\"许多科学计算任务涉及大规模矩阵或向量操作\",{\"1\":{\"187\":1}}],[\"原语来物化\",{\"1\":{\"444\":1}}],[\"原语中的\",{\"1\":{\"431\":1}}],[\"原因是dgx\",{\"1\":{\"412\":1}}],[\"原因是d2d交换足够缓解内存限制\",{\"1\":{\"411\":1}}],[\"原因有两个\",{\"1\":{\"407\":1}}],[\"原因如下\",{\"1\":{\"398\":1}}],[\"原生的dapple可以训练该模型\",{\"1\":{\"410\":1}}],[\"原生的\",{\"1\":{\"116\":1}}],[\"微批次的前向和反向传播的执行顺序必须相同\",{\"1\":{\"433\":1}}],[\"微批次大小同样为2\",{\"1\":{\"400\":1}}],[\"微批次训练数据通过这些阶段以流水线的方式进行处理\",{\"1\":{\"398\":1}}],[\"微信\",{\"1\":{\"132\":1}}],[\"背景与动机\",{\"0\":{\"398\":1,\"425\":1}}],[\"突破gpu内存瓶颈\",{\"1\":{\"397\":1}}],[\"综合了重新计算\",{\"1\":{\"395\":1}}],[\"角色扮演和文字冒险等丰富的插件\",{\"1\":{\"372\":1}}],[\"感谢您的关注\",{\"1\":{\"372\":1}}],[\"找到可公开访问的\",{\"1\":{\"412\":1}}],[\"找\",{\"1\":{\"372\":1}}],[\"看\",{\"1\":{\"372\":1}}],[\"画字开头的消息将按要求创作图片\",{\"1\":{\"372\":1}}],[\"画\",{\"1\":{\"372\":1}}],[\"账户密码\",{\"1\":{\"368\":1,\"369\":1}}],[\"建议部署完后更改\",{\"1\":{\"366\":1}}],[\"建立bgp会话\",{\"1\":{\"311\":1}}],[\"密钥\",{\"1\":{\"366\":1}}],[\"密码mypassword\",{\"1\":{\"366\":1}}],[\"密码\",{\"1\":{\"366\":2}}],[\"聚合更新时长\",{\"1\":{\"366\":1}}],[\"聚焦\",{\"1\":{\"232\":1}}],[\"登录凭证加密密钥\",{\"1\":{\"366\":1}}],[\"登录凭证密钥\",{\"1\":{\"366\":1}}],[\"务必及时修改\",{\"1\":{\"366\":1}}],[\"务必加\",{\"1\":{\"366\":1}}],[\"务必保证至少有一个为true\",{\"1\":{\"365\":5}}],[\"阿里云\",{\"1\":{\"366\":5}}],[\"阿里云没有arm包\",{\"1\":{\"366\":1}}],[\"阿里大规模异构gpu集群中任务分析和调度\",{\"1\":{\"139\":1}}],[\"别只改一处~\",{\"1\":{\"366\":1}}],[\"别人说你的产品是垃圾\",{\"1\":{\"359\":4}}],[\"记得务必修改账号密码\",{\"1\":{\"366\":1}}],[\"记得改数据库和项目连接参数\",{\"1\":{\"366\":1}}],[\"记录\",{\"1\":{\"38\":1,\"44\":1}}],[\"星火\",{\"1\":{\"365\":1}}],[\"挟带一些默认配置\",{\"1\":{\"365\":1}}],[\"商业版\",{\"1\":{\"365\":2}}],[\"向量搜索参数\",{\"1\":{\"365\":1}}],[\"向量数据库的搭建\",{\"1\":{\"223\":1}}],[\"杭州阿里云\",{\"1\":{\"365\":1}}],[\"杂谈\",{\"0\":{\"468\":1},\"2\":{\"360\":1}}],[\"杂谈之独立开发者一点思考\",{\"1\":{\"359\":1}}],[\"积极是暂时的\",{\"1\":{\"359\":2}}],[\"他是不是你的目标客户\",{\"1\":{\"359\":2}}],[\"他们就会发现\",{\"1\":{\"359\":2}}],[\"答案是\",{\"1\":{\"359\":2}}],[\"罗列你的想法和产品特点\",{\"1\":{\"359\":2}}],[\"做好一个\",{\"1\":{\"359\":2}}],[\"产品的目标客户是谁\",{\"1\":{\"359\":2}}],[\"产品方向也会发生改变\",{\"1\":{\"359\":2}}],[\"产品最少需要做多少工作\",{\"1\":{\"359\":4}}],[\"营销问题\",{\"1\":{\"359\":2}}],[\"营销收入\",{\"1\":{\"131\":1}}],[\"威力狈是公认的独立开发者中的牛逼人物\",{\"1\":{\"359\":2}}],[\"财务自由\",{\"1\":{\"359\":2}}],[\"心态\",{\"1\":{\"359\":2}}],[\"增长\",{\"1\":{\"359\":2}}],[\"增强\",{\"1\":{\"120\":1}}],[\"伪需求怎么办\",{\"1\":{\"359\":4}}],[\"采用了\",{\"1\":{\"455\":1}}],[\"采用了一种模块化的调试方法\",{\"1\":{\"447\":1}}],[\"采用这种分区策略付出的代价是计算时间不均衡\",{\"1\":{\"401\":1}}],[\"采用什么样的产品形态\",{\"1\":{\"359\":4}}],[\"采用进程并行模型\",{\"1\":{\"196\":1}}],[\"三种方法的性能差异显著\",{\"1\":{\"415\":1}}],[\"三种内存优化方法的时间成本\",{\"1\":{\"415\":1}}],[\"三点金规铁律\",{\"1\":{\"359\":4}}],[\"三大核心问题\",{\"1\":{\"359\":4}}],[\"三层ip\",{\"1\":{\"287\":1}}],[\"想法可能会发生改变\",{\"1\":{\"359\":2}}],[\"想法是一个产品的起始点\",{\"1\":{\"359\":2}}],[\"想法\",{\"1\":{\"359\":4}}],[\"依赖关系\",{\"0\":{\"354\":1}}],[\"依赖于应用程序的进程管理系统和\",{\"1\":{\"143\":1}}],[\"依赖于一套独立的\",{\"1\":{\"61\":1}}],[\"绕过操作系统的网络协议栈\",{\"1\":{\"351\":1}}],[\"企业级网络\",{\"1\":{\"348\":1}}],[\"负载均衡\",{\"1\":{\"347\":1}}],[\"负责训练一个不相交的连续模型层集\",{\"1\":{\"399\":1}}],[\"负责连接终端设备\",{\"1\":{\"349\":1}}],[\"负责连接服务器\",{\"1\":{\"347\":1}}],[\"负责高效地处理和转发跨多个leaf交换机的流量\",{\"1\":{\"349\":1}}],[\"负责高性能的东西向流量转发\",{\"1\":{\"345\":1}}],[\"负责识别通信伙伴\",{\"1\":{\"340\":1}}],[\"负责数据格式的转换和表示\",{\"1\":{\"339\":1}}],[\"负责建立\",{\"1\":{\"338\":1}}],[\"负责逻辑地址的管理和数据包的路由选择\",{\"1\":{\"336\":1}}],[\"负责帧的创建\",{\"1\":{\"335\":1}}],[\"负责在物理介质上传输比特流\",{\"1\":{\"334\":1}}],[\"负责在不同as之间交换路由信息\",{\"1\":{\"315\":1}}],[\"负责隧道的端点操作\",{\"1\":{\"293\":1}}],[\"负责vxlan包的封装和解封装\",{\"1\":{\"291\":1}}],[\"负责vxlan隧道的端点操作\",{\"1\":{\"291\":1}}],[\"负责聚合结果\",{\"1\":{\"162\":1}}],[\"负责机器学习工作流的定义\",{\"1\":{\"97\":1}}],[\"负责将元数据写入到持久化存储中\",{\"1\":{\"97\":1}}],[\"负责将元数据写入到存储后端\",{\"1\":{\"97\":1}}],[\"负责调度和执行\",{\"1\":{\"97\":1}}],[\"负责管理和执行工作流任务\",{\"1\":{\"97\":2}}],[\"负责管理和调度超参数搜索任务\",{\"1\":{\"97\":1}}],[\"负责管理\",{\"1\":{\"97\":4,\"158\":1}}],[\"架构扁平化\",{\"1\":{\"347\":1}}],[\"架构的出现取得了突破性进展\",{\"1\":{\"218\":1}}],[\"低延迟的互连技术\",{\"1\":{\"352\":1}}],[\"低延迟的网络拓扑\",{\"1\":{\"349\":1}}],[\"低延迟\",{\"1\":{\"347\":1}}],[\"南北向流量\",{\"1\":{\"347\":1}}],[\"东西向流量通常经过leaf交换机到spine交换机\",{\"1\":{\"347\":1}}],[\"东西向流量\",{\"1\":{\"347\":1}}],[\"东西向和南北向流量\",{\"1\":{\"347\":1}}],[\"叶子\",{\"1\":{\"345\":1,\"346\":1}}],[\"连接到同一个\",{\"1\":{\"443\":1}}],[\"连接到\",{\"1\":{\"443\":1}}],[\"连接到gpu\",{\"1\":{\"417\":1}}],[\"连接方式为对称的nvlink\",{\"1\":{\"410\":1}}],[\"连接方式为不对称的nvlink\",{\"1\":{\"410\":1}}],[\"连接参数\",{\"1\":{\"366\":3}}],[\"连接多个leaf\",{\"1\":{\"345\":1}}],[\"连接管理\",{\"0\":{\"269\":1},\"1\":{\"277\":1}}],[\"脊骨\",{\"1\":{\"345\":1}}],[\"逆向处理\",{\"1\":{\"342\":1}}],[\"域名系统\",{\"1\":{\"340\":1}}],[\"远程过程调用\",{\"1\":{\"338\":1}}],[\"远远超过传统vlan的4094个限制\",{\"1\":{\"290\":1}}],[\"错误检测和恢复\",{\"1\":{\"337\":1}}],[\"错误检测和纠正\",{\"1\":{\"335\":1}}],[\"错误处理\",{\"1\":{\"162\":1}}],[\"光纤\",{\"1\":{\"334\":1}}],[\"电缆\",{\"1\":{\"334\":1}}],[\"制定的一种网络通信标准框架\",{\"1\":{\"333\":1}}],[\"七层网络模型\",{\"0\":{\"333\":1},\"1\":{\"333\":1}}],[\"防火墙规则\",{\"1\":{\"332\":1}}],[\"防止流量瓶颈\",{\"1\":{\"347\":1}}],[\"防止中间人攻击\",{\"1\":{\"307\":1}}],[\"防止arp欺骗\",{\"1\":{\"307\":1}}],[\"防止个体资源过度消耗\",{\"1\":{\"28\":1}}],[\"防止过多的资源消耗影响整个集群的性能\",{\"1\":{\"24\":1}}],[\"防止资源过度配置或资源不足\",{\"1\":{\"27\":1}}],[\"防止资源过度消耗\",{\"1\":{\"24\":1}}],[\"防止资源耗尽\",{\"1\":{\"19\":1}}],[\"出一个子空间\",{\"1\":{\"439\":1}}],[\"出站和转发的数据包过滤规则\",{\"1\":{\"330\":1}}],[\"出现\",{\"1\":{\"5\":1}}],[\"功能完成反向传播\",{\"1\":{\"445\":1}}],[\"功能更强大的替代品\",{\"1\":{\"332\":1}}],[\"功能相对有限\",{\"1\":{\"332\":1}}],[\"功能\",{\"0\":{\"318\":1,\"321\":1,\"324\":1,\"327\":1,\"330\":1},\"1\":{\"334\":1,\"335\":1,\"336\":1,\"337\":1,\"338\":1,\"339\":1,\"340\":1,\"365\":1}}],[\"收敛时间\",{\"1\":{\"314\":1}}],[\"收集工件\",{\"1\":{\"95\":1}}],[\"挑战\",{\"0\":{\"314\":1}}],[\"稳定性\",{\"1\":{\"313\":1}}],[\"稳定的底层代码\",{\"1\":{\"127\":1}}],[\"交错流水线\",{\"1\":{\"452\":1}}],[\"交错了连续微批次的三个前向传播\",{\"1\":{\"437\":1}}],[\"交换\",{\"1\":{\"451\":1}}],[\"交换技术\",{\"1\":{\"404\":1}}],[\"交换机是网络架构中的接入层交换设备\",{\"1\":{\"346\":1}}],[\"交换机是网络架构中的核心交换设备\",{\"1\":{\"345\":1}}],[\"交换机\",{\"0\":{\"344\":1},\"1\":{\"335\":1,\"345\":1}}],[\"交换路由信息\",{\"1\":{\"311\":1}}],[\"交互的\",{\"1\":{\"103\":1}}],[\"外部bgp\",{\"1\":{\"310\":1}}],[\"路流水线并行性和\",{\"1\":{\"457\":1}}],[\"路流水线并行性结合\",{\"1\":{\"457\":1}}],[\"路流水线并行性进行处理\",{\"1\":{\"456\":1}}],[\"路流水线并行性\",{\"1\":{\"455\":1,\"456\":2}}],[\"路和\",{\"1\":{\"455\":2,\"456\":1}}],[\"路张量并行性结合\",{\"1\":{\"457\":1}}],[\"路张量并行性和\",{\"1\":{\"456\":1,\"457\":1}}],[\"路张量并行性\",{\"1\":{\"455\":3,\"456\":3,\"457\":1}}],[\"路张量并行性进行执行\",{\"1\":{\"425\":1}}],[\"路\",{\"1\":{\"452\":1,\"455\":5,\"456\":2}}],[\"路减少到\",{\"1\":{\"452\":1}}],[\"路数据并行性\",{\"1\":{\"425\":1,\"457\":4}}],[\"路由器或网关\",{\"1\":{\"347\":1}}],[\"路由器\",{\"1\":{\"336\":1}}],[\"路由器仅在路由信息发生变化时交换更新\",{\"1\":{\"311\":1}}],[\"路由管理\",{\"1\":{\"332\":1}}],[\"路由和防火墙规则\",{\"0\":{\"316\":1}}],[\"路由更新和撤销\",{\"1\":{\"311\":1}}],[\"路由传播\",{\"1\":{\"311\":1}}],[\"路由聚合和路由优先级\",{\"1\":{\"310\":1}}],[\"路由选择\",{\"1\":{\"310\":1}}],[\"路径信息包括多个as路径\",{\"1\":{\"310\":1}}],[\"路径向量协议\",{\"1\":{\"310\":1}}],[\"边界网关协议\",{\"1\":{\"309\":1}}],[\"虽然通常少于重计算和gpu\",{\"1\":{\"416\":1}}],[\"虽然它们都与数据传输和高性能计算相关\",{\"1\":{\"350\":1}}],[\"虽然arp协议本身存在安全隐患\",{\"1\":{\"308\":1}}],[\"虽慢但仍有显著加速\",{\"1\":{\"249\":1}}],[\"手动找到了它们的最佳性能计划\",{\"1\":{\"454\":1}}],[\"手动配置ip地址和mac地址的映射\",{\"1\":{\"307\":1}}],[\"手工设计的张量并行性\",{\"1\":{\"451\":1}}],[\"手工构建了一个两级层次化搜索空间\",{\"1\":{\"425\":1}}],[\"手搓一个最小的\",{\"1\":{\"224\":1}}],[\"手搓\",{\"1\":{\"224\":1}}],[\"攻击者可以发送伪造的arp响应\",{\"1\":{\"306\":1}}],[\"攻击\",{\"1\":{\"306\":1}}],[\"超过\",{\"1\":{\"426\":1}}],[\"超过该时间后条目将被删除\",{\"1\":{\"305\":1}}],[\"超大规模模型\",{\"1\":{\"411\":1}}],[\"超文本传输协议\",{\"1\":{\"340\":1}}],[\"超参数调优工具\",{\"1\":{\"97\":1}}],[\"缓存\",{\"0\":{\"305\":1}}],[\"缓存存储和传输成本高等挑战\",{\"1\":{\"249\":1}}],[\"硬件利用率的不平衡是不可避免的\",{\"1\":{\"426\":1}}],[\"硬件见解\",{\"0\":{\"417\":1}}],[\"硬件趋势与机遇\",{\"0\":{\"402\":1}}],[\"硬件地址长度\",{\"1\":{\"304\":1}}],[\"硬件类型\",{\"1\":{\"304\":1}}],[\"谁是这个ip地址的拥有者\",{\"1\":{\"303\":1}}],[\"显然\",{\"1\":{\"410\":1,\"415\":1}}],[\"显示了\",{\"1\":{\"457\":1,\"458\":2}}],[\"显示了在表\",{\"1\":{\"452\":1}}],[\"显示它们相较于\",{\"1\":{\"450\":1}}],[\"显示所有桥接设备的fdb条目\",{\"1\":{\"300\":1}}],[\"显示特定桥接设备的fdb条目\",{\"1\":{\"299\":1,\"300\":1}}],[\"显示特定设备的fdb条目\",{\"1\":{\"299\":1,\"300\":1}}],[\"显著提升\",{\"1\":{\"277\":1}}],[\"显著降低了延迟\",{\"1\":{\"276\":1}}],[\"显著减少预填充阶段延迟\",{\"1\":{\"249\":1}}],[\"延迟\",{\"1\":{\"294\":1}}],[\"陈旧\",{\"1\":{\"294\":1}}],[\"邻居节点的状态\",{\"1\":{\"294\":1}}],[\"邻居节点的mac地址\",{\"1\":{\"294\":1}}],[\"邻居节点的ip地址\",{\"1\":{\"294\":1}}],[\"邻居表存储了网络设备的邻居节点的信息\",{\"1\":{\"294\":1}}],[\"灵活和可扩展的网络架构\",{\"1\":{\"293\":1}}],[\"灵活性\",{\"1\":{\"191\":1,\"313\":1}}],[\"完成vxlan包的封装和解封装\",{\"1\":{\"293\":1}}],[\"完全可以由\",{\"1\":{\"61\":1}}],[\"帧传递\",{\"1\":{\"292\":1}}],[\"帧解封装\",{\"1\":{\"292\":1}}],[\"帧封装\",{\"1\":{\"292\":1}}],[\"学习和维护虚拟网络中mac地址到vtep的映射关系\",{\"1\":{\"291\":1}}],[\"学习资料\",{\"0\":{\"215\":1},\"1\":{\"215\":1},\"2\":{\"236\":1}}],[\"附加上vni\",{\"1\":{\"291\":1}}],[\"另一个基线是\",{\"1\":{\"457\":1}}],[\"另一个是连接到ip网络的接口\",{\"1\":{\"291\":1}}],[\"另一种结合了三种内存优化技术\",{\"1\":{\"410\":1}}],[\"另外一个是\",{\"1\":{\"255\":1}}],[\"隧道端点\",{\"1\":{\"291\":1}}],[\"隧道封装\",{\"1\":{\"290\":1}}],[\"弹性和高可用性\",{\"1\":{\"290\":1}}],[\"云环境\",{\"1\":{\"287\":1}}],[\"云原生\",{\"0\":{\"463\":1},\"2\":{\"114\":1,\"124\":1}}],[\"云原生之kubeflow\",{\"1\":{\"78\":1}}],[\"局域网\",{\"1\":{\"287\":1}}],[\"封装好的vxlan包通过三层ip网络传输到目的vtep\",{\"1\":{\"292\":1}}],[\"封装和解封装\",{\"1\":{\"291\":1,\"341\":1}}],[\"封装层\",{\"1\":{\"287\":1}}],[\"封装为\",{\"1\":{\"223\":2}}],[\"跨服务器的高效通信\",{\"1\":{\"355\":1}}],[\"跨数据中心\",{\"1\":{\"287\":1}}],[\"跨多个数据中心的虚拟机迁移和高可用性\",{\"1\":{\"286\":1}}],[\"跨平台兼容\",{\"1\":{\"197\":1}}],[\"理论上支持多达1600万个虚拟网络\",{\"1\":{\"286\":1}}],[\"理解\",{\"1\":{\"223\":1}}],[\"理解这些拓扑模式的定义\",{\"1\":{\"177\":1}}],[\"过高的\",{\"1\":{\"438\":1}}],[\"过滤掉伪造的arp报文\",{\"1\":{\"307\":1}}],[\"过滤veth设备\",{\"1\":{\"279\":1}}],[\"过程和功能特性\",{\"1\":{\"334\":1}}],[\"过程就会在阈值达到之后立刻开始\",{\"1\":{\"51\":1}}],[\"过程设置一段\",{\"1\":{\"51\":1}}],[\"列出所有网络接口\",{\"1\":{\"279\":1}}],[\"列表中\",{\"1\":{\"151\":1}}],[\"压缩库提供三种内存优化技术的高效实现\",{\"1\":{\"405\":1}}],[\"压缩和解压缩\",{\"1\":{\"339\":1}}],[\"压缩\",{\"1\":{\"277\":1}}],[\"受限于串行化处理和头部阻塞\",{\"1\":{\"277\":1}}],[\"现有搜索空间的约束\",{\"0\":{\"433\":1}}],[\"现有搜索空间的局限性\",{\"0\":{\"426\":1}}],[\"现有的并行化方案往往在新模型上表现不佳\",{\"1\":{\"446\":1}}],[\"现有的框架\",{\"1\":{\"427\":1}}],[\"现有的方法依赖于经过充分研究的手工并行化计划或搜索空间来解决这个问题\",{\"1\":{\"425\":1}}],[\"现有的方法通常依赖于手工设计的搜索空间\",{\"1\":{\"424\":1}}],[\"现有的搜索空间忽略了一些重要的计划配置\",{\"1\":{\"423\":1}}],[\"现有的一些内存节省技术如gpu\",{\"1\":{\"394\":1}}],[\"现代gpu服务器已经集成了超高速的gpu间互连\",{\"1\":{\"402\":1}}],[\"现代浏览器和服务器在实际应用中通常要求\",{\"1\":{\"274\":1}}],[\"现在\",{\"1\":{\"260\":1}}],[\"客户端可以指定不同流的优先级\",{\"1\":{\"273\":1}}],[\"客户端必须明确请求每个资源\",{\"1\":{\"272\":1}}],[\"客户端代码\",{\"1\":{\"91\":1}}],[\"串行化处理\",{\"1\":{\"269\":1}}],[\"协议来实现负载均衡\",{\"1\":{\"347\":1}}],[\"协议和设备\",{\"1\":{\"334\":1,\"335\":1,\"336\":1,\"337\":1,\"338\":1,\"339\":1,\"340\":1}}],[\"协议地址长度\",{\"1\":{\"304\":1}}],[\"协议类型\",{\"1\":{\"277\":1,\"304\":1}}],[\"协议扩展性\",{\"0\":{\"275\":1},\"1\":{\"277\":1}}],[\"协议基础\",{\"0\":{\"268\":1}}],[\"协议的重大升级\",{\"1\":{\"267\":1}}],[\"协方差矩阵自适应进化策略\",{\"1\":{\"105\":1}}],[\"停止正在运行的wsl\",{\"1\":{\"264\":1}}],[\"版来重启\",{\"1\":{\"263\":1}}],[\"版本的简化版\",{\"1\":{\"223\":1}}],[\"版本的后缀\",{\"1\":{\"165\":1}}],[\"关键是不要消极\",{\"1\":{\"359\":2}}],[\"关系\",{\"0\":{\"332\":1}}],[\"关闭\",{\"1\":{\"263\":1}}],[\"关于客户端代码和运行时代码的命名约定\",{\"1\":{\"91\":1}}],[\"若要启用\",{\"1\":{\"263\":1}}],[\"若二维码失效\",{\"1\":{\"138\":1}}],[\"报文格式\",{\"0\":{\"304\":1}}],[\"报错\",{\"1\":{\"263\":1}}],[\"报告\",{\"1\":{\"150\":1}}],[\"报告生成\",{\"1\":{\"111\":1}}],[\"报告服务\",{\"1\":{\"108\":1}}],[\"确认\",{\"1\":{\"262\":1}}],[\"确保计划的有效性\",{\"1\":{\"443\":1}}],[\"确保了以下内容\",{\"1\":{\"433\":1}}],[\"确保op1\",{\"1\":{\"431\":1}}],[\"确保冗余和多路径\",{\"1\":{\"346\":1}}],[\"确保不同系统间的数据格式一致\",{\"1\":{\"339\":1}}],[\"确保数据在主机之间可靠\",{\"1\":{\"337\":1}}],[\"确保数据包从源节点到达目标节点\",{\"1\":{\"336\":1}}],[\"确保没有流会独占带宽\",{\"1\":{\"273\":1}}],[\"确保消息传递的顺序和一致性\",{\"1\":{\"196\":1}}],[\"确保在多个进程或设备之间一致地传递数据\",{\"1\":{\"181\":1}}],[\"确保两者不会同时传入\",{\"1\":{\"159\":1}}],[\"确保前端应用的可维护性和稳定性\",{\"1\":{\"130\":1}}],[\"确保项目能够快速上线并稳定运行\",{\"1\":{\"128\":1}}],[\"确保高可用性和数据一致性\",{\"1\":{\"121\":1}}],[\"确保工作流按照定义的步骤顺利执行\",{\"1\":{\"97\":1}}],[\"确保其他\",{\"1\":{\"97\":1}}],[\"确保配置正确\",{\"1\":{\"75\":1}}],[\"确保\",{\"1\":{\"57\":1,\"171\":1}}],[\"确保关键组件能够独立于\",{\"1\":{\"33\":1}}],[\"确保资源的公平分配和高效使用\",{\"1\":{\"28\":1}}],[\"确保资源的合理分配和使用\",{\"1\":{\"27\":1}}],[\"确保集群资源的公平分配和高效利用\",{\"1\":{\"28\":1}}],[\"确保所有容器符合预期的资源使用模式\",{\"1\":{\"27\":1}}],[\"确保每个命名空间不会消耗超过指定的资源限额\",{\"1\":{\"19\":1}}],[\"仍然使用\",{\"1\":{\"258\":1}}],[\"覆盖以前的\",{\"1\":{\"258\":1}}],[\"覆盖以前的分区空间\",{\"1\":{\"258\":1}}],[\"覆盖从\",{\"1\":{\"226\":1}}],[\"写入更改并退出\",{\"1\":{\"257\":1,\"258\":1}}],[\"写法遵循\",{\"1\":{\"75\":1}}],[\"卸载并删除\",{\"0\":{\"257\":1}}],[\"逻辑卷中\",{\"1\":{\"256\":1}}],[\"扩容磁盘\",{\"0\":{\"256\":1}}],[\"扩展内存层次结构是有益的\",{\"1\":{\"417\":1}}],[\"扩展性更好\",{\"1\":{\"417\":1}}],[\"扩展性\",{\"1\":{\"286\":1,\"287\":1,\"290\":1}}],[\"扩展复杂\",{\"1\":{\"277\":1}}],[\"扩展和添加新功能变得复杂\",{\"1\":{\"275\":1}}],[\"扩展和管理容器化应用程序\",{\"1\":{\"100\":1}}],[\"扩展完成后\",{\"1\":{\"262\":1}}],[\"扩展逻辑卷\",{\"0\":{\"260\":1}}],[\"扩展模块中很常见\",{\"1\":{\"172\":1}}],[\"扩展模块的初始化函数\",{\"1\":{\"171\":1,\"174\":1}}],[\"扩展模块的函数实现\",{\"1\":{\"170\":1}}],[\"扩展模块需要实现一个模块初始化函数\",{\"1\":{\"170\":1}}],[\"扩展\",{\"0\":{\"261\":1},\"1\":{\"122\":1}}],[\"网页浏览\",{\"1\":{\"342\":1}}],[\"网桥\",{\"1\":{\"335\":1}}],[\"网卡\",{\"1\":{\"334\":1}}],[\"网卡就会发出一个中断\",{\"1\":{\"255\":1}}],[\"网络适配器互联\",{\"1\":{\"454\":1}}],[\"网络接口卡\",{\"1\":{\"353\":1}}],[\"网络具有高度的带宽冗余和路径选择能力\",{\"1\":{\"347\":1}}],[\"网络层\",{\"0\":{\"336\":1}}],[\"网络中的所有设备都会接收到这个arp请求帧\",{\"1\":{\"303\":1}}],[\"网络虚拟化\",{\"1\":{\"286\":1}}],[\"网络设备根据这个id来区分不同的vlan\",{\"1\":{\"285\":1}}],[\"网络分段\",{\"1\":{\"285\":1}}],[\"网络\",{\"1\":{\"66\":1},\"2\":{\"357\":1}}],[\"没事可做就休眠了\",{\"1\":{\"255\":1}}],[\"没有内建的优先级控制机制\",{\"1\":{\"273\":1}}],[\"没有在\",{\"1\":{\"151\":1}}],[\"没有\",{\"1\":{\"31\":1,\"38\":1,\"40\":1}}],[\"好了\",{\"1\":{\"255\":1}}],[\"好\",{\"1\":{\"255\":1}}],[\"紧接着\",{\"1\":{\"255\":1}}],[\"紧密遵循\",{\"1\":{\"143\":1}}],[\"触发一个真正的磁盘读取操作\",{\"1\":{\"255\":1}}],[\"去读取一个文件\",{\"1\":{\"255\":1}}],[\"去监听比自己小的\",{\"1\":{\"5\":1}}],[\"框\",{\"1\":{\"255\":1}}],[\"框架下\",{\"1\":{\"330\":1}}],[\"框架等\",{\"1\":{\"223\":1}}],[\"框架集成等\",{\"1\":{\"220\":1}}],[\"框架\",{\"1\":{\"105\":1,\"224\":2,\"232\":1}}],[\"框架无关的项目\",{\"1\":{\"105\":1}}],[\"把这些值挨个解释一下\",{\"1\":{\"255\":1}}],[\"性能较低硬件上的实验\",{\"0\":{\"458\":1}}],[\"性能提升幅度比dgx\",{\"1\":{\"412\":1}}],[\"性能\",{\"1\":{\"277\":1}}],[\"性能改进\",{\"0\":{\"276\":1}}],[\"性能影响\",{\"1\":{\"255\":1}}],[\"性能参数\",{\"1\":{\"150\":1}}],[\"选项用于附加到一个正在运行的进程上\",{\"1\":{\"252\":1}}],[\"选择使用\",{\"1\":{\"446\":1}}],[\"选择对连续层的张量应用重计算是一个不错的选择\",{\"1\":{\"407\":1}}],[\"选择删除分区\",{\"1\":{\"257\":1}}],[\"选择gloo后端\",{\"1\":{\"183\":1}}],[\"选择合适的拓扑模式对性能有显著影响\",{\"1\":{\"177\":1}}],[\"选择合适的工作流执行器取决于工作流的具体需求和集群环境\",{\"1\":{\"97\":1}}],[\"选择最优的通信模式\",{\"1\":{\"177\":1}}],[\"选择\",{\"1\":{\"97\":3}}],[\"头部信息仅在第一次请求时完整传输\",{\"1\":{\"271\":1}}],[\"头部压缩和服务器推送等功能\",{\"1\":{\"276\":1}}],[\"头部压缩\",{\"0\":{\"271\":1},\"1\":{\"277\":1}}],[\"头部阻塞问题\",{\"1\":{\"270\":1}}],[\"头部\",{\"1\":{\"249\":1}}],[\"倍的加速\",{\"1\":{\"459\":1}}],[\"倍的性能\",{\"1\":{\"457\":2}}],[\"倍和\",{\"1\":{\"455\":1,\"456\":1,\"458\":2}}],[\"倍\",{\"1\":{\"249\":1,\"455\":2,\"456\":2,\"458\":2}}],[\"离线确定每个头的最佳动态稀疏模式\",{\"1\":{\"249\":1}}],[\"利用率\",{\"1\":{\"446\":1}}],[\"利用率作为控制水平\",{\"1\":{\"212\":1}}],[\"利用搜索策略生成并行化计划\",{\"1\":{\"442\":1}}],[\"利用\",{\"1\":{\"441\":1}}],[\"利用多个高带宽的nvlink互连将模型数据从内存压力较大的gpu卸载到轻负载的gpu\",{\"1\":{\"404\":1}}],[\"利用多条高速nvlink链路将张量交换至轻载gpu\",{\"1\":{\"395\":1}}],[\"利用动态稀疏注意的静态空间聚合模式\",{\"1\":{\"249\":1}}],[\"重塑深度学习并行策略\",{\"0\":{\"422\":1}}],[\"重写器进一步修改输入的数据流图\",{\"1\":{\"405\":1}}],[\"重计算减少了51\",{\"1\":{\"416\":1}}],[\"重计算节省了阶段0\",{\"1\":{\"416\":1}}],[\"重计算的额外开销最小\",{\"1\":{\"415\":1}}],[\"重计算\",{\"1\":{\"413\":1,\"418\":1,\"419\":1}}],[\"重计算能够支持模型规模达到15\",{\"1\":{\"412\":1}}],[\"重计算在bert\",{\"1\":{\"411\":1}}],[\"重计算提高了125\",{\"1\":{\"411\":1}}],[\"重计算比gpu\",{\"1\":{\"411\":1}}],[\"重计算基线系统按照文献的建议丢弃特定的张量\",{\"1\":{\"410\":1}}],[\"重计算技术可以通过丢弃前向传播生成的激活值并在需要时重新计算\",{\"1\":{\"401\":1}}],[\"重计算等虽然可以减少部分内存消耗\",{\"1\":{\"394\":1}}],[\"重新分配空间\",{\"1\":{\"256\":1}}],[\"重新绑定\",{\"1\":{\"14\":1}}],[\"重要亮点\",{\"0\":{\"249\":1},\"1\":{\"359\":2}}],[\"介绍\",{\"0\":{\"248\":1,\"351\":1,\"352\":1,\"464\":1}}],[\"地址解析协议\",{\"1\":{\"302\":1}}],[\"地址\",{\"0\":{\"246\":1,\"363\":1,\"370\":1},\"1\":{\"318\":1,\"319\":1,\"366\":1,\"393\":1,\"422\":1}}],[\"地址信息\",{\"1\":{\"204\":1}}],[\"视频抽帧转图片\",{\"0\":{\"242\":1}}],[\"视图\",{\"1\":{\"97\":1}}],[\"视图和大规模指标\",{\"1\":{\"86\":1}}],[\"资料\",{\"2\":{\"235\":1}}],[\"资源分配和同步通信\",{\"1\":{\"340\":1}}],[\"资源消耗过高等\",{\"1\":{\"254\":1}}],[\"资源短缺\",{\"0\":{\"51\":1}}],[\"资源优化\",{\"1\":{\"27\":1}}],[\"梳理\",{\"1\":{\"233\":1}}],[\"深度学习训练越来越依赖手工设计的搜索空间来找到高效的并行执行计划\",{\"1\":{\"423\":1}}],[\"深度学习加速器\",{\"1\":{\"418\":1}}],[\"深度学习的系统设计\",{\"1\":{\"233\":1}}],[\"深度神经网络\",{\"1\":{\"394\":1,\"424\":1}}],[\"深入理解大模型基础\",{\"1\":{\"224\":1}}],[\"深入理解spring\",{\"1\":{\"128\":1}}],[\"深入剖析大模型原理\",{\"1\":{\"224\":1}}],[\"深入剖析每一个技术点并附以完整的代码实现\",{\"1\":{\"224\":1}}],[\"芯片组成的\",{\"1\":{\"232\":1}}],[\"推送\",{\"1\":{\"277\":1}}],[\"推动相关技术的快速发展和广泛应用\",{\"1\":{\"231\":1}}],[\"推理引擎\",{\"2\":{\"251\":1}}],[\"推理面临预填充阶段注意力延迟长\",{\"1\":{\"249\":1}}],[\"推理中的问题\",{\"1\":{\"248\":1}}],[\"推理计算持续时间的速率\",{\"1\":{\"211\":1}}],[\"推理请求在队列中等待的时间的速率\",{\"1\":{\"211\":1}}],[\"西瓜书代码实战\",{\"1\":{\"229\":1}}],[\"源文件\",{\"1\":{\"228\":1}}],[\"源代码文件以及部分\",{\"1\":{\"228\":1}}],[\"源码解读\",{\"0\":{\"201\":1}}],[\"轻松上手实现大模型本地化部署\",{\"1\":{\"228\":1}}],[\"教程\",{\"1\":{\"228\":1}}],[\"动手学\",{\"1\":{\"228\":1}}],[\"动态链接时需要\",{\"1\":{\"171\":1}}],[\"动态导入指定的模块\",{\"1\":{\"168\":1}}],[\"动态地加载模块中的对象\",{\"1\":{\"167\":1}}],[\"吴恩达关于大模型的系列课程\",{\"1\":{\"226\":1}}],[\"英文原版地址\",{\"1\":{\"226\":1}}],[\"面向开发者的\",{\"1\":{\"226\":2}}],[\"面向开发者的大模型手册\",{\"1\":{\"225\":1}}],[\"欢迎每一位开发者的贡献\",{\"1\":{\"226\":1}}],[\"欢迎联系我\",{\"1\":{\"131\":1}}],[\"审核通过后\",{\"1\":{\"226\":1}}],[\"掌握入门\",{\"1\":{\"226\":1}}],[\"掌握html的各种技术细节\",{\"1\":{\"130\":1}}],[\"初学者可以先系统学习我们的必修类课程\",{\"1\":{\"226\":1}}],[\"初始化的\",{\"1\":{\"366\":1}}],[\"初始化错误\",{\"1\":{\"204\":1}}],[\"初始化进程组有两种主要方式\",{\"1\":{\"203\":1}}],[\"初始化默认的分布式进程组\",{\"0\":{\"203\":1}}],[\"初始化通信库\",{\"1\":{\"183\":1}}],[\"初始化函数的名称应为\",{\"1\":{\"171\":1}}],[\"初始状态\",{\"1\":{\"16\":1}}],[\"门吴恩达老师的大模型课程进行了翻译复现\",{\"1\":{\"226\":1}}],[\"入门教程\",{\"1\":{\"226\":1}}],[\"入门课程\",{\"1\":{\"226\":1}}],[\"入门\",{\"1\":{\"226\":1}}],[\"入门指南\",{\"1\":{\"95\":1}}],[\"翻译\",{\"1\":{\"226\":1}}],[\"纯手工搭建\",{\"1\":{\"224\":1}}],[\"纯手搓\",{\"1\":{\"224\":1}}],[\"逐步预训练一个手搓大模型\",{\"1\":{\"224\":1}}],[\"逐步深入理解其背后的原理和应用场景\",{\"1\":{\"123\":1}}],[\"搭建一个清晰\",{\"1\":{\"224\":1}}],[\"围绕大模型全链路的\",{\"1\":{\"224\":1}}],[\"白盒\",{\"1\":{\"224\":1}}],[\"召回精排\",{\"1\":{\"223\":1}}],[\"验证扩展结果\",{\"0\":{\"262\":1}}],[\"验证迭代\",{\"1\":{\"223\":1}}],[\"验证和管理\",{\"1\":{\"75\":1}}],[\"知识助手\",{\"1\":{\"372\":1}}],[\"知识库搭建\",{\"1\":{\"223\":1}}],[\"知识蒸馏等压缩方法\",{\"1\":{\"217\":1}}],[\"智谱ai等多种大模型\",{\"1\":{\"223\":1}}],[\"讯飞星火\",{\"1\":{\"223\":1}}],[\"何为大模型\",{\"0\":{\"223\":1}}],[\"旨在通过节省内存的操作间并行化方法\",{\"1\":{\"419\":1}}],[\"旨在突破十亿规模模型训练中的gpu内存壁垒\",{\"1\":{\"395\":1}}],[\"旨在提高网络性能和效率\",{\"1\":{\"267\":1}}],[\"旨在帮助有传统深度学习基础的读者从底层原理出发\",{\"1\":{\"224\":1}}],[\"旨在帮助初学者最快\",{\"1\":{\"223\":1}}],[\"旨在基于阿里云服务器\",{\"1\":{\"222\":1}}],[\"旨在成为你掌握llm推理与部署艺术的伙伴\",{\"1\":{\"219\":1}}],[\"任何一个经过转换的子算子\",{\"1\":{\"435\":1}}],[\"任何人都可以提出issue或是提交pr\",{\"1\":{\"220\":1}}],[\"任务管理\",{\"1\":{\"111\":1}}],[\"任务服务\",{\"1\":{\"108\":1}}],[\"针对t6\",{\"1\":{\"415\":1}}],[\"针对gpu内存分配\",{\"1\":{\"408\":1}}],[\"针对小白开发者的简单介绍\",{\"0\":{\"223\":1}}],[\"针对国内开发者的实际需求\",{\"1\":{\"226\":1}}],[\"针对国内外主流开源\",{\"1\":{\"220\":1}}],[\"针对国内初学者\",{\"1\":{\"220\":1}}],[\"针对不同大小张量\",{\"1\":{\"415\":1}}],[\"针对不同内容的特点\",{\"1\":{\"226\":1}}],[\"针对不同模型要求提供不同的详细环境配置步骤\",{\"1\":{\"220\":1}}],[\"针对不同的通信模式进行了优化\",{\"1\":{\"197\":1}}],[\"针对各类开源大模型提供包括环境配置\",{\"1\":{\"220\":1}}],[\"生成的新数据依赖关系以及由于算子分布到多个设备而产生的额外通信操作会被反映到\",{\"1\":{\"442\":1}}],[\"生成的最佳策略\",{\"1\":{\"416\":1}}],[\"生成的初步计划将被传递给重写器\",{\"1\":{\"405\":1}}],[\"生活压力\",{\"1\":{\"359\":2}}],[\"生态系统的教程\",{\"1\":{\"218\":1}}],[\"生命周期中的自动化机器学习\",{\"1\":{\"106\":1}}],[\"生命周期的每个步骤\",{\"1\":{\"78\":1}}],[\"极大地降低了\",{\"1\":{\"218\":1}}],[\"极大地简化了在多设备或多机器环境中进行并行计算的复杂性\",{\"1\":{\"184\":1}}],[\"社区的重要力量\",{\"1\":{\"218\":1}}],[\"近年来\",{\"1\":{\"218\":1,\"418\":3,\"424\":1}}],[\"让领域专家能够定义和构建自己的搜索空间\",{\"1\":{\"424\":1}}],[\"让领域专家能够构建自己的搜索空间\",{\"1\":{\"423\":1}}],[\"让\",{\"1\":{\"228\":1}}],[\"让更多的学生和未来的从业者了解和熟悉开源大模型的食用方法\",{\"1\":{\"220\":1}}],[\"让更多的普通学生\",{\"1\":{\"220\":1}}],[\"让更多的小白能更快了解到模型压缩技术\",{\"1\":{\"217\":1}}],[\"让很多研究者望而却步\",{\"1\":{\"217\":1}}],[\"量化\",{\"1\":{\"217\":1}}],[\"导致模型\",{\"1\":{\"446\":1}}],[\"导致训练性能下降34\",{\"1\":{\"401\":1}}],[\"导致冗余和带宽浪费\",{\"1\":{\"271\":1}}],[\"导致运行时资源消耗较高\",{\"1\":{\"217\":1}}],[\"导出完成之后\",{\"1\":{\"264\":1}}],[\"导入\",{\"1\":{\"173\":1}}],[\"随着阶段数量的增加\",{\"1\":{\"459\":1}}],[\"随着模型尺寸增加\",{\"1\":{\"459\":1}}],[\"随着约束调整后瓶颈的变化\",{\"1\":{\"438\":1}}],[\"随着深度神经网络\",{\"1\":{\"423\":1}}],[\"随着硬件的快速发展\",{\"1\":{\"402\":1}}],[\"随着chatgpt的出圈\",{\"1\":{\"217\":1}}],[\"随后pipedream通过引入异步调度来改进gpipe的性能\",{\"1\":{\"418\":1}}],[\"随后\",{\"1\":{\"231\":1,\"405\":1}}],[\"随机搜索\",{\"1\":{\"105\":1}}],[\"您将能够可视化集群的当前状态\",{\"1\":{\"212\":1}}],[\"帮助管理员了解网络中mac地址的分布情况和转发路径\",{\"1\":{\"301\":1}}],[\"帮助管理员了解当前网络设备与其他节点的连接状态和mac地址映射情况\",{\"1\":{\"295\":1}}],[\"帮助桥接设备确定数据帧的转发路径\",{\"1\":{\"296\":1}}],[\"帮助每一位有兴趣的学习者纯手工独立搭建自己的\",{\"1\":{\"224\":1}}],[\"帮助初学者明白其可以通过\",{\"1\":{\"223\":1}}],[\"帮助开源\",{\"1\":{\"220\":1}}],[\"帮助评估系统的性能\",{\"1\":{\"211\":1}}],[\"帮助它们查询和理解支持应用程序的对象\",{\"1\":{\"101\":1}}],[\"条目\",{\"1\":{\"207\":1}}],[\"文档文件\",{\"1\":{\"228\":1}}],[\"文档\",{\"0\":{\"364\":1,\"371\":1},\"1\":{\"204\":1}}],[\"文件阅读加密\",{\"1\":{\"366\":1}}],[\"文件传输协议\",{\"1\":{\"340\":1}}],[\"文件系统\",{\"0\":{\"261\":1}}],[\"文件保存到节点的\",{\"1\":{\"32\":1}}],[\"文件路径\",{\"1\":{\"32\":1}}],[\"文件\",{\"1\":{\"32\":1,\"34\":1,\"68\":1}}],[\"到目前为止\",{\"1\":{\"445\":1}}],[\"到\",{\"1\":{\"204\":1,\"226\":1}}],[\"否则容易泄露\",{\"1\":{\"366\":1}}],[\"否则知识库会报错\",{\"1\":{\"365\":1}}],[\"否则可能会导致死锁\",{\"1\":{\"204\":1}}],[\"否则post请求无法进行跨域\",{\"1\":{\"75\":1}}],[\"根据第\",{\"1\":{\"452\":1}}],[\"根据我们的经验\",{\"1\":{\"438\":1}}],[\"根据选定的转换算法\",{\"1\":{\"429\":1}}],[\"根据文献\",{\"1\":{\"410\":1}}],[\"根据分析结果\",{\"1\":{\"359\":2}}],[\"根据具体需求选择合适的技术可以提高网络的性能\",{\"1\":{\"288\":1}}],[\"根据具体的应用场景和需求\",{\"1\":{\"50\":1}}],[\"根据构建时的配置\",{\"1\":{\"204\":1}}],[\"字典用于定义不同后端的支持能力\",{\"1\":{\"207\":1}}],[\"字符串或\",{\"1\":{\"204\":1}}],[\"字符串\",{\"1\":{\"203\":1,\"204\":2}}],[\"字段设置为\",{\"1\":{\"38\":1}}],[\"字段来表示\",{\"1\":{\"11\":1}}],[\"天体物理等领域\",{\"1\":{\"198\":1}}],[\"程序示例\",{\"1\":{\"199\":1}}],[\"程序默认的通信域\",{\"1\":{\"196\":1}}],[\"程序包含客户端代码\",{\"1\":{\"91\":1}}],[\"散播\",{\"1\":{\"196\":1}}],[\"点对点通信\",{\"1\":{\"196\":1}}],[\"领域专家可以应用新的约束来构建自定义的搜索空间\",{\"1\":{\"434\":1}}],[\"领域专家可以编写\",{\"1\":{\"431\":1}}],[\"领域专家可以通过\",{\"1\":{\"429\":1}}],[\"领域随着\",{\"1\":{\"218\":1}}],[\"领域\",{\"1\":{\"195\":1}}],[\"广义张量并行空间\",{\"1\":{\"425\":1}}],[\"广泛的分区选择和大量的时空调度选择结合在一起\",{\"1\":{\"425\":1}}],[\"广泛采用新硬件技术需要时间\",{\"1\":{\"417\":1}}],[\"广泛应用于分布式计算和高性能计算\",{\"1\":{\"195\":1}}],[\"广泛应用于科学计算\",{\"1\":{\"195\":1}}],[\"广播地址等\",{\"1\":{\"318\":1}}],[\"广播和同步\",{\"1\":{\"181\":1}}],[\"广播\",{\"1\":{\"143\":2}}],[\"第一个约束将搜索时间减少了\",{\"1\":{\"459\":1}}],[\"第一个进程在\",{\"1\":{\"193\":1}}],[\"第\",{\"1\":{\"431\":2,\"432\":2}}],[\"第二个约束进一步将搜索时间减少了\",{\"1\":{\"459\":1}}],[\"第二个微批次中的第七个子批次在第四个子批次的反向传播完成后立即由工人1执行\",{\"1\":{\"399\":1}}],[\"第二个子节点在第二个gpu上\",{\"1\":{\"176\":1}}],[\"且中间阶段应用了\",{\"1\":{\"456\":1}}],[\"且不一定适用于现有的gpu计算框架\",{\"1\":{\"418\":1}}],[\"且能够被轻松隐藏\",{\"1\":{\"415\":1}}],[\"且d2d交换已启用但未进行数据分条\",{\"1\":{\"414\":1}}],[\"且d2d交换比gpu\",{\"1\":{\"407\":1}}],[\"且报告的性能数据相同\",{\"1\":{\"411\":1}}],[\"且需要精心设计\",{\"1\":{\"191\":1}}],[\"且正被\",{\"1\":{\"13\":1}}],[\"复现和调优\",{\"1\":{\"226\":1}}],[\"复杂的网络环境中保持稳定和高效\",{\"1\":{\"313\":1}}],[\"复杂工作流处理\",{\"1\":{\"192\":1}}],[\"复杂性\",{\"1\":{\"191\":1,\"314\":1}}],[\"复制等任务都可以通过\",{\"1\":{\"119\":1}}],[\"科学计算\",{\"1\":{\"187\":1}}],[\"尽管多个分割算子的流水线计算可能会减慢计算过程\",{\"1\":{\"435\":1}}],[\"尽管现有的手工并行化搜索空间在具有相似模型架构的主流模型中显示出有效性\",{\"1\":{\"426\":1}}],[\"尽管两者的额外开销相同\",{\"1\":{\"415\":1}}],[\"尽管gpu的hbm\",{\"1\":{\"417\":1}}],[\"尽管gpu\",{\"1\":{\"411\":1}}],[\"尽管协议本身不强制这一点\",{\"1\":{\"274\":1}}],[\"尽管处理单元运行不同的程序\",{\"1\":{\"190\":1}}],[\"尽管所有处理单元执行相同的程序代码\",{\"1\":{\"185\":1}}],[\"尽量避免将新的\",{\"1\":{\"36\":1}}],[\"单程序多数据\",{\"1\":{\"451\":1}}],[\"单独的d2d交换无法满足需求\",{\"1\":{\"411\":1}}],[\"单靠重计算有两个主要缺点\",{\"1\":{\"401\":1}}],[\"单靠数据并行难以满足快速增长的模型规模所带来的巨大内存需求\",{\"1\":{\"398\":1}}],[\"单一gpu无法满足如此大规模模型的训练需求\",{\"1\":{\"394\":1}}],[\"单一程序\",{\"1\":{\"185\":1}}],[\"单个连接处理多个并发请求\",{\"1\":{\"277\":1}}],[\"单个tcp连接上可以处理多个并发的请求\",{\"1\":{\"269\":1}}],[\"单线程控制所有\",{\"1\":{\"143\":1}}],[\"归约\",{\"1\":{\"181\":1,\"196\":1}}],[\"进而提高了训练效率\",{\"1\":{\"418\":1}}],[\"进一步展示了\",{\"1\":{\"459\":1}}],[\"进一步将这些并行化方案进行概括\",{\"1\":{\"425\":1}}],[\"进一步减少了内存消耗\",{\"1\":{\"418\":1}}],[\"进一步增强了大规模多gpu系统的通信能力\",{\"1\":{\"352\":1}}],[\"进入整个执行流水线\",{\"1\":{\"399\":1}}],[\"进入\",{\"1\":{\"257\":1,\"258\":1}}],[\"进程再从内核态切换回用户态\",{\"1\":{\"255\":1}}],[\"进程在内核态拿到数据\",{\"1\":{\"255\":1}}],[\"进程将阻塞并等待此超时时间\",{\"1\":{\"204\":1}}],[\"进程之间通过消息传递进行通信\",{\"1\":{\"196\":1}}],[\"进程模型\",{\"1\":{\"196\":1}}],[\"进程组名称\",{\"1\":{\"204\":1}}],[\"进程组和通信域\",{\"1\":{\"196\":1}}],[\"进程组\",{\"1\":{\"181\":1}}],[\"进行了评估\",{\"1\":{\"458\":1}}],[\"进行了统一形式封装\",{\"1\":{\"223\":1}}],[\"进行比较是不现实的\",{\"1\":{\"448\":1}}],[\"进行分区\",{\"1\":{\"429\":1}}],[\"进行解析\",{\"1\":{\"365\":1}}],[\"进行导入即可\",{\"1\":{\"264\":1}}],[\"进行导出\",{\"1\":{\"264\":1}}],[\"进行的每个系统调用\",{\"1\":{\"254\":1}}],[\"进行应用部署\",{\"1\":{\"223\":1}}],[\"进行训练的情况下\",{\"1\":{\"198\":1}}],[\"进行广播操作\",{\"1\":{\"183\":1}}],[\"进行广播操作的示例\",{\"1\":{\"183\":1}}],[\"进行并行计算时\",{\"1\":{\"180\":1}}],[\"进行调度\",{\"1\":{\"56\":1}}],[\"进行\",{\"1\":{\"51\":1}}],[\"进行自访问和内部通信\",{\"1\":{\"50\":1}}],[\"进行通信优化\",{\"1\":{\"176\":1}}],[\"进行通信\",{\"1\":{\"49\":1}}],[\"进行通信的场景非常有用\",{\"1\":{\"38\":1}}],[\"进行健康检查\",{\"1\":{\"46\":1}}],[\"适当的划分选项以及确保端到端训练的正确性\",{\"1\":{\"446\":1}}],[\"适合大规模分布式系统\",{\"1\":{\"181\":1}}],[\"适用场景\",{\"0\":{\"355\":1}}],[\"适用于像\",{\"1\":{\"452\":1}}],[\"适用于任何给定的操作符\",{\"1\":{\"429\":1}}],[\"适用于集群环境和分布式系统\",{\"1\":{\"353\":1}}],[\"适用于数值模拟\",{\"1\":{\"197\":1}}],[\"适用于cpu和gpu的跨平台通信\",{\"1\":{\"181\":1}}],[\"适用于gpu间通信\",{\"1\":{\"181\":1}}],[\"适用于需要高效处理大量小文件的工作流\",{\"1\":{\"96\":1}}],[\"适用于需要直接访问每个\",{\"1\":{\"44\":1}}],[\"适用于大多数场景\",{\"1\":{\"96\":1}}],[\"适用于单个\",{\"1\":{\"28\":1}}],[\"适用于整个命名空间的资源总量\",{\"1\":{\"28\":1}}],[\"适用的对象范围\",{\"1\":{\"21\":1}}],[\"减少每个阶段所需的设备数量并降低内存消耗\",{\"1\":{\"435\":1}}],[\"减少gpu间的通信开销\",{\"1\":{\"395\":1}}],[\"减少数据交互频率\",{\"1\":{\"366\":1}}],[\"减少了数据传输的延迟\",{\"1\":{\"351\":1}}],[\"减少了延迟\",{\"1\":{\"347\":1}}],[\"减少了传输数据量\",{\"1\":{\"271\":1}}],[\"减少了人为操作的复杂性和风险\",{\"1\":{\"120\":1}}],[\"减少延迟\",{\"1\":{\"177\":1}}],[\"技术科普\",{\"0\":{\"467\":1}}],[\"技术\",{\"1\":{\"176\":1}}],[\"技术栈\",{\"0\":{\"128\":1}}],[\"环境和法律道德方面的方面来提供开源知识\",{\"1\":{\"231\":1}}],[\"环境配置指南\",{\"1\":{\"220\":1}}],[\"环境下创建一个\",{\"1\":{\"174\":1}}],[\"环形结构\",{\"1\":{\"176\":1}}],[\"子图\",{\"1\":{\"433\":1}}],[\"子图将被分配到不同的设备上\",{\"1\":{\"433\":1}}],[\"子\",{\"1\":{\"429\":1,\"431\":1}}],[\"子网掩码\",{\"1\":{\"318\":1}}],[\"子组将使用\",{\"1\":{\"204\":1}}],[\"子节点都在第二个gpu上\",{\"1\":{\"176\":1}}],[\"子关系\",{\"1\":{\"94\":1}}],[\"树的父节点在第一个gpu上\",{\"1\":{\"176\":1}}],[\"树的父节点和一个子节点在第一个gpu上\",{\"1\":{\"176\":1}}],[\"拓扑结构\",{\"1\":{\"347\":1}}],[\"拓扑结构的意义\",{\"0\":{\"177\":1}}],[\"拓扑结构的定义和初始化\",{\"1\":{\"175\":1}}],[\"拓扑通信模式定义\",{\"1\":{\"176\":1}}],[\"必须在\",{\"1\":{\"431\":1,\"456\":1}}],[\"必须先调用这个函数以初始化系统结构\",{\"1\":{\"176\":1}}],[\"必须反序列化这些数据以供下游组件使用\",{\"1\":{\"93\":1}}],[\"准备计算通信拓扑\",{\"1\":{\"176\":1}}],[\"准备好用于新的\",{\"1\":{\"12\":1}}],[\"互联\",{\"1\":{\"454\":1}}],[\"互联网协议\",{\"1\":{\"336\":1}}],[\"互联网服务提供商\",{\"1\":{\"309\":1}}],[\"互斥\",{\"1\":{\"204\":2}}],[\"互斥性\",{\"1\":{\"5\":1}}],[\"互不干扰\",{\"1\":{\"190\":1}}],[\"互操作时\",{\"1\":{\"172\":1}}],[\"典型的函数有\",{\"1\":{\"196\":1}}],[\"典型的应用场景包括\",{\"1\":{\"187\":1}}],[\"典型应用\",{\"0\":{\"172\":1}}],[\"典型场景\",{\"1\":{\"28\":2}}],[\"意味着nccl拓扑在设计上最多支持256个节点的互联\",{\"1\":{\"176\":1}}],[\"意味着\",{\"1\":{\"171\":1}}],[\"期望扩展模块的初始化函数遵循特定的命名规范\",{\"1\":{\"171\":1}}],[\"期待与您合作\",{\"1\":{\"131\":1}}],[\"声明了一个外部的\",{\"1\":{\"171\":1}}],[\"假设其用户\",{\"1\":{\"438\":1}}],[\"假设允许\",{\"1\":{\"435\":1}}],[\"假设分区后的操作符及其对应的分割张量分布在不相交的设备上\",{\"1\":{\"426\":1}}],[\"假设veth1被移动到命名空间ns1\",{\"1\":{\"283\":1}}],[\"假设创建了一个veth设备对\",{\"1\":{\"282\":1}}],[\"假设一个用户程序开始运行了\",{\"1\":{\"255\":1}}],[\"假设有一个科学模拟项目\",{\"1\":{\"193\":1}}],[\"假设你有一个模块结构如下\",{\"1\":{\"169\":1}}],[\"假设我们在分布式训练中使用\",{\"1\":{\"160\":1}}],[\"库的集体通信能力紧密集成\",{\"1\":{\"166\":1}}],[\"库来实现的\",{\"1\":{\"61\":1}}],[\"整体运行时间由最慢的设备决定\",{\"1\":{\"440\":1}}],[\"整个空间就缩减为一个具体的并行化计划\",{\"1\":{\"432\":1}}],[\"整个过程中\",{\"1\":{\"163\":1}}],[\"整数\",{\"1\":{\"162\":2,\"204\":2}}],[\"底层的\",{\"1\":{\"163\":1}}],[\"层的激活张量占用\",{\"1\":{\"455\":1}}],[\"层数\",{\"1\":{\"454\":1}}],[\"层组成\",{\"1\":{\"425\":1}}],[\"层次依赖\",{\"1\":{\"341\":1}}],[\"层提供了\",{\"1\":{\"163\":1}}],[\"层\",{\"1\":{\"162\":1}}],[\"张量实例\",{\"1\":{\"443\":1}}],[\"张量抽象\",{\"0\":{\"443\":1}}],[\"张量并行和数据并行的不同程度\",{\"1\":{\"454\":1}}],[\"张量并行现在可以跨越更少的设备\",{\"1\":{\"452\":1}}],[\"张量并行分割的算子被放置在不同的设备上\",{\"1\":{\"435\":1}}],[\"张量并行是解决此问题的标准做法\",{\"1\":{\"435\":1}}],[\"张量并行性将与大图像相关的大型张量进行分割\",{\"1\":{\"426\":1}}],[\"张量并行性是一类更一般的计划\",{\"1\":{\"425\":1}}],[\"张量和流水线并行性这样的经过充分研究的并行化计划\",{\"1\":{\"432\":1}}],[\"张量和流水线并行性\",{\"1\":{\"425\":1}}],[\"张量t1具有最长的生命周期\",{\"1\":{\"415\":1}}],[\"张量\",{\"1\":{\"162\":1}}],[\"张量中\",{\"1\":{\"160\":1}}],[\"锁\",{\"1\":{\"162\":1}}],[\"从小模型到大模型不等\",{\"1\":{\"454\":1}}],[\"从网卡收到数据包的大部分工作\",{\"1\":{\"255\":1}}],[\"从底层到上层如何系统级地支持大模型训练和推理\",{\"1\":{\"232\":1}}],[\"从数据准备\",{\"1\":{\"231\":1}}],[\"从本课程的角度出发\",{\"1\":{\"223\":1}}],[\"从导入的模块中获取指定的对象\",{\"1\":{\"168\":1}}],[\"从右侧分割成模块名和对象名\",{\"1\":{\"168\":1}}],[\"从\",{\"1\":{\"162\":1,\"452\":1}}],[\"从而显著减少了搜索算法\",{\"1\":{\"459\":1}}],[\"从而显著提高训练效率\",{\"1\":{\"431\":1}}],[\"从而显著提高计算速度\",{\"1\":{\"187\":1}}],[\"从而在\",{\"1\":{\"459\":1}}],[\"从而在vxlan隧道中维护虚拟网络的隔离和标识\",{\"1\":{\"291\":1}}],[\"从而减轻\",{\"1\":{\"454\":1}}],[\"从而降低通信成本\",{\"1\":{\"452\":1}}],[\"从而简化调试过程\",{\"1\":{\"448\":1}}],[\"从而避免出现死锁\",{\"1\":{\"443\":1}}],[\"从而避免了现有方法中过于狭窄的搜索空间\",{\"1\":{\"424\":1}}],[\"从而避免了过多的性能损失\",{\"1\":{\"418\":1}}],[\"从而导致一个设备集\",{\"1\":{\"435\":1}}],[\"从而以流水线方式进行计算\",{\"1\":{\"435\":1}}],[\"从而使得有效的搜索方法\",{\"1\":{\"431\":1}}],[\"从而探索更多潜在的并行化配置\",{\"1\":{\"424\":1}}],[\"从而延迟了相应的dnn计算\",{\"1\":{\"411\":1}}],[\"从而为应用gpu\",{\"1\":{\"407\":1}}],[\"从而缓解gpu内存的限制\",{\"1\":{\"402\":1}}],[\"从而确保网络流量可以快速而高效地在不同的leaf交换机之间转发\",{\"1\":{\"345\":1}}],[\"从而确保在所有设备上更新后的模型参数保持一致\",{\"1\":{\"181\":1}}],[\"从而促进了网络技术的发展和普及\",{\"1\":{\"343\":1}}],[\"从而拦截或篡改网络通信\",{\"1\":{\"306\":1}}],[\"从而进行通信\",{\"1\":{\"302\":1,\"308\":1}}],[\"从而进行更细粒度的进程控制或通信\",{\"1\":{\"155\":1}}],[\"从而实现更低的延迟和更高的带宽\",{\"1\":{\"351\":1}}],[\"从而实现高效的负载均衡\",{\"1\":{\"347\":1}}],[\"从而实现了高效\",{\"1\":{\"293\":1}}],[\"从而实现大规模并行计算\",{\"1\":{\"195\":1}}],[\"从而支持多租户环境\",{\"1\":{\"290\":1}}],[\"从而可以在三层ip网络上进行传输\",{\"1\":{\"290\":1}}],[\"从而可以跨越传统的二层边界在ip网络上传输\",{\"1\":{\"286\":1}}],[\"从而提高网络的安全性和性能\",{\"1\":{\"285\":1}}],[\"从而提高数据处理的速度和效率\",{\"1\":{\"198\":1}}],[\"从而做出更合理的扩展决策\",{\"1\":{\"212\":1}}],[\"从而加快搜索过程\",{\"1\":{\"440\":1}}],[\"从而加快整个工作流的执行\",{\"1\":{\"192\":1}}],[\"从而加速计算任务的执行\",{\"1\":{\"197\":1}}],[\"从而充分利用硬件资源\",{\"1\":{\"182\":1}}],[\"从而完成\",{\"1\":{\"161\":1}}],[\"从而优化集群性能和资源利用率\",{\"1\":{\"27\":1}}],[\"从而影响其他命名空间的正常运行\",{\"1\":{\"18\":1}}],[\"传统的\",{\"1\":{\"437\":1}}],[\"传统上\",{\"1\":{\"143\":1}}],[\"传输到后续阶段\",{\"1\":{\"416\":1}}],[\"传输控制协议\",{\"1\":{\"337\":1}}],[\"传输层依赖于网络层提供的路由和地址服务\",{\"1\":{\"341\":1}}],[\"传输层安全\",{\"1\":{\"339\":1}}],[\"传输层\",{\"0\":{\"337\":1}}],[\"传输\",{\"1\":{\"335\":1}}],[\"传输介质\",{\"1\":{\"334\":1}}],[\"传递给这个函数的参数\",{\"1\":{\"162\":1}}],[\"各种研究表明\",{\"1\":{\"431\":1}}],[\"各层之间的关系\",{\"0\":{\"341\":1}}],[\"各个阶段被放置在不同的设备上并以流水线方式执行\",{\"1\":{\"425\":1}}],[\"各个\",{\"1\":{\"160\":1}}],[\"各大小之间的乘法因子\",{\"1\":{\"150\":1}}],[\"各大小之间的固定增量\",{\"1\":{\"150\":1}}],[\"首先积极地为适当的张量分配gpu\",{\"1\":{\"407\":1}}],[\"首先建立tcp连接\",{\"1\":{\"311\":1}}],[\"首先\",{\"1\":{\"257\":1,\"398\":1,\"405\":1,\"407\":1,\"408\":1,\"414\":1,\"415\":1,\"416\":1,\"446\":1}}],[\"首先检查\",{\"1\":{\"159\":1}}],[\"首先通过减少模型的隐藏维度\",{\"1\":{\"448\":1}}],[\"首先通过训练目标dnn模型\",{\"1\":{\"405\":1}}],[\"首先通过\",{\"1\":{\"5\":1}}],[\"处理第n个微批次\",{\"1\":{\"433\":1}}],[\"处理软中断的开销\",{\"1\":{\"255\":1}}],[\"处理硬中断的开销\",{\"1\":{\"255\":1}}],[\"处理\",{\"1\":{\"223\":1}}],[\"处理一个\",{\"1\":{\"188\":1}}],[\"处理一部分数据集\",{\"1\":{\"187\":1}}],[\"处理单元之间的通信需求可能更高\",{\"1\":{\"191\":1}}],[\"处理单元的操作是完全同步的\",{\"1\":{\"186\":1}}],[\"处理单元可能需要共享部分计算结果或交换数据\",{\"1\":{\"185\":1}}],[\"处理单元通常需要在某些阶段进行通信和同步\",{\"1\":{\"185\":1}}],[\"处理旧\",{\"1\":{\"159\":1}}],[\"处理参数的兼容性\",{\"1\":{\"159\":1}}],[\"处于\",{\"1\":{\"12\":1,\"16\":1}}],[\"乘法\",{\"1\":{\"158\":1}}],[\"乘积等操作\",{\"1\":{\"157\":1}}],[\"特性\",{\"1\":{\"277\":1}}],[\"特别是多个\",{\"1\":{\"352\":1}}],[\"特别是在高性能计算\",{\"1\":{\"351\":1}}],[\"特别是在不同任务需要不同计算资源或算法的情况下\",{\"1\":{\"195\":1}}],[\"特别是在各个处理单元需要执行不同类型的计算时\",{\"1\":{\"189\":1}}],[\"特别是在处理大规模数据集时\",{\"1\":{\"185\":1}}],[\"特别是在需要处理大规模数据集或模型时\",{\"1\":{\"182\":1}}],[\"特别是在需要跨多个设备\",{\"1\":{\"180\":1}}],[\"特别是在nvidia硬件上\",{\"1\":{\"181\":1}}],[\"特别是在涉及到\",{\"1\":{\"172\":1}}],[\"特别是在使用\",{\"1\":{\"156\":1}}],[\"特别适合集群和高性能计算环境\",{\"1\":{\"355\":1}}],[\"特别适合现代数据中心和高性能计算应用场景\",{\"1\":{\"349\":1}}],[\"特别适合在大型数据中心和云环境中使用\",{\"1\":{\"290\":1}}],[\"特别适合需要大规模并行处理的任务\",{\"1\":{\"184\":1}}],[\"特别适用于深度学习框架中的集体通信操作\",{\"1\":{\"161\":1}}],[\"特点\",{\"1\":{\"12\":1,\"13\":1,\"14\":1,\"15\":1,\"287\":1,\"345\":1,\"346\":1,\"347\":1}}],[\"函数将其导出给\",{\"1\":{\"174\":1}}],[\"函数和对象\",{\"1\":{\"173\":1}}],[\"函数来创建\",{\"1\":{\"172\":1}}],[\"函数在共享库中对外可见\",{\"1\":{\"171\":1}}],[\"函数作为\",{\"1\":{\"170\":1}}],[\"函数完成后\",{\"1\":{\"162\":1}}],[\"函数定义\",{\"1\":{\"162\":1}}],[\"函数调用\",{\"1\":{\"159\":1}}],[\"函数\",{\"1\":{\"159\":1,\"161\":1,\"162\":1,\"164\":1,\"165\":9,\"167\":1,\"171\":1,\"173\":1}}],[\"函数会继续支持这种旧的用法\",{\"1\":{\"159\":1}}],[\"函数的分布式操作\",{\"1\":{\"156\":1}}],[\"函数中\",{\"1\":{\"107\":1,\"111\":1}}],[\"``backend\",{\"1\":{\"205\":5}}],[\"``\",{\"1\":{\"205\":6}}],[\"``group``\",{\"1\":{\"150\":2}}],[\"``global\",{\"1\":{\"150\":2}}],[\"`nccl\",{\"1\":{\"156\":1}}],[\"`outputs`\",{\"1\":{\"156\":1}}],[\"`output`\",{\"1\":{\"156\":1}}],[\"此调整不需要修改模型代码\",{\"1\":{\"447\":1}}],[\"此时\",{\"1\":{\"411\":1}}],[\"此类还可以直接调用来解析字符串\",{\"1\":{\"206\":1}}],[\"此参数已被忽略\",{\"1\":{\"204\":1}}],[\"此函数的作用是在\",{\"1\":{\"163\":1}}],[\"此功能非常适用于在分布式训练中处理多个进程组的情况\",{\"1\":{\"155\":1}}],[\"此外\",{\"1\":{\"61\":1,\"106\":1,\"143\":1,\"398\":1,\"406\":1,\"410\":4,\"411\":1,\"412\":3,\"414\":1,\"417\":1,\"418\":1,\"419\":1,\"427\":1,\"438\":1,\"441\":1,\"446\":2,\"454\":1,\"456\":1}}],[\"获取基础的张量大小\",{\"1\":{\"405\":1}}],[\"获取公网ip\",{\"0\":{\"240\":1}}],[\"获取当前进程的rank\",{\"1\":{\"183\":1}}],[\"获取当前\",{\"1\":{\"154\":1}}],[\"获得的\",{\"1\":{\"171\":1}}],[\"获得锁\",{\"1\":{\"5\":1}}],[\"获得\",{\"1\":{\"5\":1}}],[\"返回解析后的小写字符串\",{\"1\":{\"206\":1}}],[\"返回初始化后的模块对象\",{\"1\":{\"173\":1}}],[\"返回这个对象\",{\"1\":{\"168\":1}}],[\"返回值是\",{\"1\":{\"153\":1}}],[\"返回值和主体\",{\"1\":{\"90\":1}}],[\"返回\",{\"0\":{\"153\":1},\"1\":{\"151\":1,\"162\":2,\"165\":1}}],[\"返回相对\",{\"1\":{\"151\":1}}],[\"映射\",{\"1\":{\"151\":1}}],[\"抛出异常\",{\"1\":{\"151\":1}}],[\"检查命名空间中的veth设备\",{\"0\":{\"283\":1}}],[\"检查全局\",{\"1\":{\"151\":1}}],[\"检查组是否注册\",{\"1\":{\"151\":1}}],[\"判断是否为默认进程组\",{\"1\":{\"151\":1}}],[\"异步通信则允许发送方在消息发送后立即继续执行\",{\"1\":{\"196\":1}}],[\"异常的宏\",{\"1\":{\"162\":1}}],[\"异常\",{\"1\":{\"150\":1}}],[\"异构gpu集群上大模型训练推理\",{\"1\":{\"139\":1}}],[\"异构gpu集群上大模型训练推理续2\",{\"1\":{\"139\":1}}],[\"异构gpu集群上大模型训练推理续\",{\"1\":{\"139\":1}}],[\"异构万卡集群\",{\"1\":{\"139\":1}}],[\"异构计算交流\",{\"1\":{\"138\":2}}],[\"异构计算\",{\"0\":{\"138\":1,\"466\":1},\"1\":{\"192\":1},\"2\":{\"140\":1,\"141\":1}}],[\"秒以内\",{\"1\":{\"459\":1}}],[\"秒\",{\"1\":{\"150\":1,\"459\":3}}],[\"zhiqi\",{\"1\":{\"422\":1}}],[\"zhayujie\",{\"1\":{\"370\":1,\"372\":1}}],[\"zero系列通过分片优化器状态\",{\"1\":{\"418\":1}}],[\"zero系列通过在数据并行训练中消除数据冗余来减少gpu内存消耗\",{\"1\":{\"401\":1}}],[\"zero系列可以支持参数规模最多达到25\",{\"1\":{\"412\":1}}],[\"zero系列和mpress能够支持从5\",{\"1\":{\"412\":1}}],[\"zero系列是deepspeed框架的一部分\",{\"1\":{\"412\":1}}],[\"zero\",{\"1\":{\"410\":1,\"412\":5,\"418\":1,\"451\":1,\"454\":4,\"455\":2,\"456\":3,\"457\":2}}],[\"zeros\",{\"1\":{\"183\":1}}],[\"zitadel\",{\"0\":{\"390\":1},\"1\":{\"390\":1}}],[\"zilliz\",{\"1\":{\"366\":1}}],[\"zpad36bqm4wzjgkjptz2sgztqq=\",{\"1\":{\"381\":1}}],[\"zomi\",{\"1\":{\"233\":1}}],[\"z\",{\"1\":{\"150\":1}}],[\"测试通后\",{\"1\":{\"366\":1}}],[\"测试使用\",{\"1\":{\"366\":1}}],[\"测试操作\",{\"1\":{\"150\":1}}],[\"测试和生产级服务的\",{\"1\":{\"78\":1}}],[\"平衡树形结构\",{\"1\":{\"176\":1}}],[\"平均请求在队列中等待的时间百分比\",{\"1\":{\"211\":1}}],[\"平均\",{\"1\":{\"150\":1}}],[\"平台的开源\",{\"1\":{\"220\":1}}],[\"平台的中国宝宝专属大模型教程\",{\"1\":{\"220\":1}}],[\"平台准备的\",{\"1\":{\"171\":1}}],[\"平台相关宏控制\",{\"1\":{\"171\":1}}],[\"平台\",{\"1\":{\"97\":1,\"171\":1}}],[\"迭代次数\",{\"1\":{\"150\":1}}],[\"浮点数\",{\"1\":{\"150\":1}}],[\"求和\",{\"1\":{\"150\":1}}],[\"仅实现了一些经过充分研究的分区\",{\"1\":{\"427\":1}}],[\"仅靠gpu\",{\"1\":{\"412\":1}}],[\"仅需要执行一次训练迭代\",{\"1\":{\"407\":1}}],[\"仅首次运行有效\",{\"1\":{\"366\":1}}],[\"仅适用于\",{\"1\":{\"150\":1}}],[\"仅对有\",{\"1\":{\"150\":1}}],[\"仅对\",{\"1\":{\"150\":1}}],[\"仅应使用其中一种方式\",{\"1\":{\"150\":1}}],[\"递增方式可以是固定递增或乘法因子\",{\"1\":{\"150\":1}}],[\"扫描的大小范围\",{\"1\":{\"150\":1}}],[\"└──\",{\"1\":{\"145\":3}}],[\"│\",{\"1\":{\"145\":2}}],[\"├──\",{\"1\":{\"145\":7}}],[\"编码\",{\"1\":{\"249\":1}}],[\"编译器使能到上层的\",{\"1\":{\"232\":1}}],[\"编译\",{\"0\":{\"148\":1}}],[\"编译并安装\",{\"1\":{\"145\":1}}],[\"编程模型集成\",{\"1\":{\"143\":1}}],[\"编程语言\",{\"0\":{\"127\":1}}],[\"修改换行格式\",{\"1\":{\"145\":1}}],[\"端到端性能\",{\"0\":{\"453\":1}}],[\"端的通信系统来进行自启动\",{\"1\":{\"143\":1}}],[\"端口179\",{\"1\":{\"310\":1}}],[\"端口映射\",{\"1\":{\"66\":1}}],[\"端口\",{\"1\":{\"40\":1}}],[\"端口转发到\",{\"1\":{\"40\":1}}],[\"间进行通信和数据聚合\",{\"1\":{\"163\":1}}],[\"间高效通信的库\",{\"1\":{\"161\":1}}],[\"间的通信\",{\"1\":{\"158\":1}}],[\"间张量的归约\",{\"1\":{\"157\":1}}],[\"间优化通信\",{\"1\":{\"143\":1}}],[\"间通信的库\",{\"1\":{\"143\":1}}],[\"间通信原语\",{\"1\":{\"143\":1}}],[\"流出和转发\",{\"1\":{\"332\":1}}],[\"流之间可以独立并行处理\",{\"1\":{\"269\":1}}],[\"流量在gpu之间按顺序传递\",{\"1\":{\"176\":1}}],[\"流量的策略\",{\"1\":{\"175\":1}}],[\"流上进行归约操作\",{\"1\":{\"158\":1}}],[\"流\",{\"1\":{\"143\":1,\"158\":1,\"204\":1}}],[\"流水线的时间轴\",{\"1\":{\"452\":1}}],[\"流水线\",{\"1\":{\"452\":1,\"457\":1}}],[\"流水线能够在没有\",{\"1\":{\"452\":1}}],[\"流水线阶段中的一个操作符可以沿着批次维度分区成多个微批次\",{\"1\":{\"431\":1}}],[\"流水线并行无法支持这种模式\",{\"1\":{\"437\":1}}],[\"流水线并行性还假设不同的流水线阶段分布在不相交的设备上\",{\"1\":{\"426\":1}}],[\"流水线并行性假设训练涉及一次前向传播和一次反向传播\",{\"1\":{\"426\":1}}],[\"流水线并行是一种常见的训练大规模模型的技术\",{\"1\":{\"418\":1}}],[\"流水线并行\",{\"1\":{\"398\":1,\"418\":2}}],[\"流水线管理\",{\"1\":{\"111\":1}}],[\"流水线服务\",{\"1\":{\"108\":1,\"109\":1}}],[\"非依赖操作符的执行顺序在训练性能中可以发挥至关重要的作用\",{\"1\":{\"431\":1}}],[\"非对称向量模型时候需要用到\",{\"1\":{\"365\":1}}],[\"非常适合大规模的网络环境\",{\"1\":{\"313\":1}}],[\"非常适合在分布式内存系统\",{\"1\":{\"196\":1}}],[\"非常容易使用\",{\"1\":{\"143\":1}}],[\"非目标\",{\"0\":{\"104\":1}}],[\"消息\",{\"1\":{\"311\":1}}],[\"消息传递接口\",{\"1\":{\"143\":1}}],[\"消息队列\",{\"1\":{\"123\":1}}],[\"除了并行化之外\",{\"1\":{\"451\":1}}],[\"除了现有的搜索空间之外\",{\"1\":{\"434\":1}}],[\"除了性能\",{\"1\":{\"143\":1}}],[\"除非这些\",{\"1\":{\"36\":1}}],[\"套接字\",{\"1\":{\"143\":1}}],[\"套接字的网络平台上实现高带宽\",{\"1\":{\"143\":1}}],[\"方便在不同\",{\"1\":{\"158\":1}}],[\"方便地免除了开发人员为特定机器优化应用程序的需求\",{\"1\":{\"143\":1}}],[\"方法将\",{\"1\":{\"168\":1}}],[\"方法释放锁\",{\"1\":{\"5\":1}}],[\"方法尝试获取锁\",{\"1\":{\"5\":1}}],[\"方法创建\",{\"1\":{\"5\":1}}],[\"核心思路\",{\"1\":{\"223\":1}}],[\"核心或计算节点\",{\"1\":{\"189\":1,\"195\":1}}],[\"核心逻辑\",{\"0\":{\"159\":1}}],[\"核心功能\",{\"0\":{\"157\":1}}],[\"核心组件\",{\"1\":{\"97\":1}}],[\"核函数结合本地规约来实现\",{\"1\":{\"143\":1}}],[\"全文总结\",{\"1\":{\"359\":2}}],[\"全栈的核心技术\",{\"1\":{\"232\":1}}],[\"全方位入门实践\",{\"1\":{\"226\":1}}],[\"全归约等操作\",{\"1\":{\"181\":1}}],[\"全局\",{\"1\":{\"152\":1}}],[\"全规约\",{\"1\":{\"143\":1}}],[\"全收集\",{\"1\":{\"143\":2}}],[\"概述\",{\"1\":{\"143\":1}}],[\"概念概述\",{\"0\":{\"79\":1}}],[\"接着我们构建了初步配置\",{\"1\":{\"407\":1}}],[\"接着处理参数\",{\"1\":{\"159\":1}}],[\"接下来\",{\"1\":{\"255\":1,\"448\":1}}],[\"接入到\",{\"1\":{\"223\":1}}],[\"接受一个参数\",{\"1\":{\"168\":1}}],[\"接受一组输入张量和输出张量\",{\"1\":{\"165\":1}}],[\"接受参数并用于初始化\",{\"1\":{\"165\":1}}],[\"接收缓冲区上启用本地缓冲区注册\",{\"1\":{\"150\":1}}],[\"接收通信操作\",{\"1\":{\"444\":1}}],[\"接收通信\",{\"1\":{\"143\":1}}],[\"接收原语\",{\"1\":{\"143\":1}}],[\"接收的通信模式\",{\"1\":{\"143\":1}}],[\"接口重用所需的算法\",{\"1\":{\"429\":1}}],[\"接口配置\",{\"1\":{\"332\":1}}],[\"接口中\",{\"1\":{\"166\":1}}],[\"接口进行通信\",{\"1\":{\"97\":1}}],[\"接口\",{\"1\":{\"61\":1,\"92\":1,\"97\":1}}],[\"接口调用期间\",{\"1\":{\"61\":1}}],[\"谷歌大规模异构计算编排调度系统\",{\"1\":{\"139\":1}}],[\"论文创新点\",{\"0\":{\"395\":1}}],[\"论文来自中国科学技术大学\",{\"1\":{\"393\":1}}],[\"论文介绍了一种名为\",{\"1\":{\"248\":1}}],[\"论文\",{\"0\":{\"247\":1},\"1\":{\"139\":3}}],[\"备注\",{\"1\":{\"138\":1}}],[\"备份和恢复\",{\"1\":{\"119\":1,\"121\":1}}],[\"备份和故障处理等任务\",{\"1\":{\"116\":1}}],[\"代表优先级比较低的进程运行时所占用的\",{\"1\":{\"255\":1}}],[\"代表系统处于空闲状态\",{\"1\":{\"255\":1}}],[\"代表等待\",{\"1\":{\"255\":1}}],[\"代表内核态\",{\"1\":{\"255\":1}}],[\"代表\",{\"1\":{\"255\":3}}],[\"代理\",{\"2\":{\"136\":1}}],[\"代码文件\",{\"1\":{\"445\":1}}],[\"代码量达到了\",{\"1\":{\"445\":1}}],[\"代码来为任何深度神经网络\",{\"1\":{\"431\":1}}],[\"代码结构和功能\",{\"0\":{\"165\":1}}],[\"代码片段展示了一个用于初始化\",{\"1\":{\"170\":1}}],[\"代码片段\",{\"1\":{\"164\":1}}],[\"代码则以封装的方式调用这些底层实现\",{\"1\":{\"163\":1}}],[\"代码负责参数解析\",{\"1\":{\"163\":1}}],[\"代码解析\",{\"0\":{\"162\":1,\"168\":1,\"171\":1,\"176\":1}}],[\"代码解释\",{\"0\":{\"154\":1}}],[\"代码\",{\"1\":{\"91\":1,\"445\":2}}],[\"联系方式\",{\"0\":{\"132\":1}}],[\"吸引了大量用户并实现了显著的商业变现\",{\"1\":{\"131\":1}}],[\"累计注册用户\",{\"1\":{\"131\":1}}],[\"日活流量\",{\"1\":{\"131\":1}}],[\"日志等级\",{\"1\":{\"366\":1}}],[\"日志\",{\"1\":{\"95\":1}}],[\"日志查看\",{\"1\":{\"34\":1}}],[\"飞鸟云课堂\",{\"1\":{\"131\":2}}],[\"健壮的代码\",{\"1\":{\"130\":1}}],[\"响应\",{\"1\":{\"303\":1}}],[\"响应对在同一连接上的多个流中并发传输\",{\"1\":{\"270\":1}}],[\"响应对在一个单独的流中\",{\"1\":{\"269\":1}}],[\"响应对可以被处理\",{\"1\":{\"270\":1}}],[\"响应对\",{\"1\":{\"269\":1}}],[\"响应对通常需要一个单独的tcp连接\",{\"1\":{\"269\":1}}],[\"响应式的用户界面开发\",{\"1\":{\"130\":1}}],[\"响应头\",{\"1\":{\"75\":1}}],[\"训练样本的批次进一步被划分为微批次\",{\"1\":{\"425\":1}}],[\"训练一个拥有数百亿参数的大型模型需要数千个\",{\"1\":{\"425\":1}}],[\"训练这些模型的计算需求也随之大幅增加\",{\"1\":{\"424\":1}}],[\"训练参数规模为175b的gpt\",{\"1\":{\"417\":1}}],[\"训练性能提升了3\",{\"1\":{\"411\":1}}],[\"训练了不同规模的bert模型\",{\"1\":{\"410\":1}}],[\"训练系统\",{\"1\":{\"404\":1}}],[\"训练吞吐量降低了67\",{\"1\":{\"401\":1}}],[\"训练过程需要分布式并行\",{\"1\":{\"232\":1}}],[\"训练策略到模型评估与改进\",{\"1\":{\"231\":1}}],[\"训练\",{\"1\":{\"129\":1,\"231\":1}}],[\"训练框架一起使用\",{\"1\":{\"106\":1}}],[\"熟悉哪个就用哪个\",{\"1\":{\"359\":2}}],[\"熟悉nacos的服务发现与配置管理\",{\"1\":{\"128\":1}}],[\"熟练使用vue\",{\"1\":{\"130\":1}}],[\"熟练使用go语言开发高并发应用\",{\"1\":{\"127\":1}}],[\"熟练掌握容器编排技术\",{\"1\":{\"128\":1}}],[\"熟练掌握python\",{\"1\":{\"127\":1}}],[\"精通element\",{\"1\":{\"130\":1}}],[\"精通typescript\",{\"1\":{\"130\":1}}],[\"精通kubeflow流水线的设计与实现\",{\"1\":{\"129\":1}}],[\"精通mysql数据库的设计与性能优化\",{\"1\":{\"128\":1}}],[\"精通c语言\",{\"1\":{\"127\":1}}],[\"擅长从需求分析到产品落地的全流程开发\",{\"1\":{\"131\":1}}],[\"擅长利用redis进行高效的缓存与存储操作\",{\"1\":{\"128\":1}}],[\"擅长快速搭建和优化企业级应用\",{\"1\":{\"128\":1}}],[\"擅长底层系统开发\",{\"1\":{\"127\":1}}],[\"构建的并行化搜索空间通常包含数百甚至数千个操作符\",{\"1\":{\"431\":1}}],[\"构建检索问答链\",{\"1\":{\"223\":1}}],[\"构建\",{\"1\":{\"223\":1,\"233\":1}}],[\"构建产物如下\",{\"1\":{\"145\":1}}],[\"构建编译\",{\"0\":{\"145\":1}}],[\"构建稳定的后端服务\",{\"1\":{\"127\":1}}],[\"构建镜像\",{\"0\":{\"2\":1}}],[\"善于利用其高效的内存管理机制和原生的协程支持\",{\"1\":{\"127\":1}}],[\"机器配置\",{\"1\":{\"410\":1,\"454\":1}}],[\"机器学习和深度学习\",{\"1\":{\"198\":1}}],[\"机器学习领域有丰富经验\",{\"1\":{\"127\":1}}],[\"机械\",{\"1\":{\"334\":1}}],[\"机制\",{\"0\":{\"36\":1},\"1\":{\"61\":1}}],[\"机制各自监听\",{\"1\":{\"5\":1}}],[\"扎实的c++功底让我在系统级应用开发中游刃有余\",{\"1\":{\"127\":1}}],[\"尤其适合需要高吞吐量和低延迟的环境\",{\"1\":{\"344\":1}}],[\"尤其在超大规模gpu集群中\",{\"1\":{\"177\":1}}],[\"尤其在数据分析\",{\"1\":{\"127\":1}}],[\"尤其擅长使用spring\",{\"1\":{\"127\":1}}],[\"尤其是如何在gpu之间分配网络接口卡\",{\"1\":{\"175\":1}}],[\"尤其是小文件\",{\"1\":{\"97\":1}}],[\"尤其是在注意力\",{\"1\":{\"435\":1}}],[\"尤其是在处理大型嵌入表或复杂模型\",{\"1\":{\"424\":1}}],[\"尤其是在处理大量系统调用时\",{\"1\":{\"255\":1}}],[\"尤其是在需要跨多个节点或多个\",{\"1\":{\"198\":1}}],[\"尤其是在需要加速的分布式训练场景下\",{\"1\":{\"163\":1}}],[\"尤其是在\",{\"1\":{\"30\":1,\"44\":1}}],[\"优于现有的主流解决方案\",{\"1\":{\"424\":1}}],[\"优先训练权重\",{\"1\":{\"365\":1}}],[\"优先级最高的本地优先级\",{\"1\":{\"310\":1}}],[\"优先级和流控制\",{\"0\":{\"273\":1},\"1\":{\"277\":1}}],[\"优势\",{\"0\":{\"313\":1},\"1\":{\"347\":1}}],[\"优化操作间并行的内存使用\",{\"1\":{\"418\":1}}],[\"优化检索\",{\"1\":{\"223\":1}}],[\"优化用户体验\",{\"1\":{\"128\":1}}],[\"优质的代码解决复杂的业务问题\",{\"1\":{\"126\":1}}],[\"优雅时间\",{\"1\":{\"51\":1}}],[\"致力于通过高效\",{\"1\":{\"126\":1}}],[\"大多数操作符可以沿着其相关张量的某个维度\",{\"1\":{\"429\":1}}],[\"大多数实现要求加密\",{\"1\":{\"277\":1}}],[\"大多数实现强制要求使用加密\",{\"1\":{\"274\":1}}],[\"大幅提升训练效率\",{\"0\":{\"422\":1}}],[\"大规模模型\",{\"1\":{\"411\":1}}],[\"大规模数据中心\",{\"1\":{\"287\":1,\"351\":1}}],[\"大小与链路带宽成正比\",{\"1\":{\"406\":1}}],[\"大型企业和数据中心网络中\",{\"1\":{\"309\":1}}],[\"大大超过了vlan的4094个限制\",{\"1\":{\"286\":1}}],[\"大大增强了\",{\"1\":{\"123\":1}}],[\"大模型是基于\",{\"1\":{\"232\":1}}],[\"大模型系统\",{\"1\":{\"232\":1}}],[\"大模型指南\",{\"1\":{\"224\":1}}],[\"大模型开发如何实现验证迭代\",{\"1\":{\"223\":1}}],[\"大模型特点是什么\",{\"0\":{\"223\":1}}],[\"大模型简介\",{\"0\":{\"223\":1}}],[\"大语言模型层出不穷\",{\"1\":{\"217\":1}}],[\"大家好\",{\"1\":{\"126\":1}}],[\"个并行化计划中的\",{\"1\":{\"451\":1}}],[\"个流水线阶段中的第\",{\"1\":{\"437\":1}}],[\"个子算子共享一个设备\",{\"1\":{\"435\":1}}],[\"个子操作符\",{\"1\":{\"429\":1}}],[\"个分区\",{\"1\":{\"425\":1,\"455\":2}}],[\"个阶段的情况\",{\"1\":{\"459\":1}}],[\"个阶段的时间排序中实现了\",{\"1\":{\"459\":1}}],[\"个阶段\",{\"1\":{\"425\":1}}],[\"个设备上执行\",{\"1\":{\"430\":1}}],[\"个设备\",{\"1\":{\"425\":1}}],[\"个接口\",{\"1\":{\"359\":2}}],[\"个页面和\",{\"1\":{\"359\":2}}],[\"个\",{\"1\":{\"160\":1,\"451\":1,\"454\":3,\"455\":2,\"456\":8,\"457\":10,\"458\":3}}],[\"个人\",{\"2\":{\"134\":1}}],[\"个人简介\",{\"1\":{\"126\":1}}],[\"个人介绍\",{\"0\":{\"126\":1},\"2\":{\"133\":1}}],[\"个服务\",{\"1\":{\"111\":1}}],[\"有时训练框架或模型代码中的一个小错误就会导致准确性下降\",{\"1\":{\"448\":1}}],[\"有时多个分割后的算子可以共享一个设备\",{\"1\":{\"435\":1}}],[\"有了新的用户定义搜索空间后\",{\"1\":{\"439\":1}}],[\"有了这些知识\",{\"1\":{\"438\":1}}],[\"有趣的是\",{\"1\":{\"411\":1,\"412\":2}}],[\"有99\",{\"1\":{\"365\":1}}],[\"有哪些牛逼的独立开发者\",{\"1\":{\"359\":4}}],[\"有序地传输\",{\"1\":{\"337\":1}}],[\"有限\",{\"1\":{\"287\":1}}],[\"有头部阻塞问题\",{\"1\":{\"277\":1}}],[\"有效保留或扩展实际上下文窗口处理能力\",{\"1\":{\"249\":1}}],[\"有效值包括\",{\"1\":{\"204\":1}}],[\"有效\",{\"1\":{\"150\":1}}],[\"有兴趣\",{\"1\":{\"123\":1}}],[\"有关组件的完整定义\",{\"1\":{\"92\":1}}],[\"有关单个管道运行的执行状态\",{\"1\":{\"88\":1}}],[\"有关单个管道运行的调试信息\",{\"1\":{\"88\":1}}],[\"语言的符号表被正确识别\",{\"1\":{\"171\":1}}],[\"语言的开发框架和工具\",{\"1\":{\"122\":1}}],[\"语言链接方式\",{\"1\":{\"171\":1}}],[\"语义化的页面布局\",{\"1\":{\"130\":1}}],[\"语法调度运行\",{\"1\":{\"95\":1}}],[\"专为训练基于\",{\"1\":{\"454\":1}}],[\"专为高效的文件操作和网络操作设计\",{\"1\":{\"96\":1}}],[\"专门用于并行文件输入输出操作\",{\"1\":{\"196\":1}}],[\"专门用于管理自定义资源\",{\"1\":{\"117\":1}}],[\"结果就不会保留原来就地操作符的效果\",{\"1\":{\"449\":1}}],[\"结果已被归一化为默认设置\",{\"1\":{\"414\":1}}],[\"结论\",{\"0\":{\"397\":1,\"419\":1}}],[\"结合了流水线并行\",{\"1\":{\"454\":1}}],[\"结合张量和流水线并行性等的方案\",{\"1\":{\"426\":1}}],[\"结合nvlink链路带宽对子块大小进行加权\",{\"1\":{\"406\":1}}],[\"结合nvls\",{\"1\":{\"176\":1}}],[\"结合来自开源贡献者的补充和完善\",{\"1\":{\"231\":1}}],[\"结合个人知识库助手项目\",{\"1\":{\"222\":1}}],[\"结合使用\",{\"1\":{\"43\":1}}],[\"结束的最大大小\",{\"1\":{\"150\":1}}],[\"结构的机制\",{\"1\":{\"117\":1}}],[\"升级和扩展\",{\"1\":{\"121\":1}}],[\"升级\",{\"1\":{\"116\":1}}],[\"反向子图表示为bgi\",{\"1\":{\"433\":1}}],[\"反向传播首先从流水线执行的后半部分的后期层开始\",{\"1\":{\"407\":1}}],[\"反馈信息将从模拟器传递给规划器\",{\"1\":{\"405\":1}}],[\"反射服务\",{\"1\":{\"110\":1}}],[\"反亲和性是一种调度约束\",{\"1\":{\"53\":1}}],[\"反亲和性\",{\"0\":{\"53\":1}}],[\"认证服务\",{\"1\":{\"108\":1}}],[\"注\",{\"1\":{\"138\":1}}],[\"注册了\",{\"1\":{\"165\":8}}],[\"注册了以下\",{\"1\":{\"111\":1}}],[\"注册了以下服务\",{\"1\":{\"107\":1}}],[\"注册的服务\",{\"0\":{\"108\":1,\"109\":1}}],[\"注意力机制\",{\"1\":{\"425\":1}}],[\"注意事项\",{\"0\":{\"255\":1}}],[\"注意\",{\"0\":{\"207\":1},\"1\":{\"95\":1,\"97\":1,\"433\":1,\"435\":1}}],[\"丰富的优化算法支持\",{\"1\":{\"106\":1}}],[\"集合上模型的分区和相应的时空调度方案\",{\"1\":{\"425\":1}}],[\"集线器\",{\"1\":{\"334\":1}}],[\"集体通信\",{\"1\":{\"196\":1}}],[\"集体通信库\",{\"1\":{\"143\":1}}],[\"集体操作在神经网络训练中被广泛使用\",{\"1\":{\"143\":1}}],[\"集成了\",{\"1\":{\"425\":1,\"454\":1}}],[\"集成\",{\"1\":{\"106\":3}}],[\"集群上对\",{\"1\":{\"458\":1}}],[\"集群上进行\",{\"1\":{\"454\":1}}],[\"集群通信等算法支持\",{\"1\":{\"232\":1}}],[\"集群\",{\"1\":{\"232\":1}}],[\"集群的全栈软硬件性能优化\",{\"1\":{\"232\":1}}],[\"集群的部署\",{\"1\":{\"121\":1}}],[\"集群的部署和管理\",{\"1\":{\"121\":1}}],[\"集群安装\",{\"0\":{\"62\":1}}],[\"集群启动和恢复\",{\"1\":{\"33\":1}}],[\"集群中的服务和控制器进行通信和协调\",{\"1\":{\"97\":1}}],[\"集群中的各种控制器\",{\"1\":{\"97\":1}}],[\"集群中的控制器\",{\"1\":{\"97\":1}}],[\"集群中提供强大的资源管理能力\",{\"1\":{\"28\":1}}],[\"集群中\",{\"1\":{\"17\":1}}],[\"更重要的是\",{\"1\":{\"450\":1}}],[\"更复杂的是\",{\"1\":{\"448\":1}}],[\"更大的内存才能容纳这些数据\",{\"1\":{\"435\":1}}],[\"更高效的并行化方案\",{\"1\":{\"434\":1}}],[\"更高效地解析和传输数据\",{\"1\":{\"268\":1}}],[\"更灵活的并行化计划研究较少\",{\"1\":{\"427\":1}}],[\"更宽\",{\"1\":{\"410\":1}}],[\"更快的连接通道\",{\"1\":{\"352\":1}}],[\"更容易扩展\",{\"1\":{\"275\":1,\"277\":1}}],[\"更适合那些需要同时执行多种任务的复杂应用\",{\"1\":{\"191\":1}}],[\"更多算法支持即将推出\",{\"1\":{\"105\":1}}],[\"更新arp缓存\",{\"1\":{\"303\":1}}],[\"更新\",{\"1\":{\"34\":1}}],[\"帕尔森估计树\",{\"1\":{\"105\":1}}],[\"信息\",{\"1\":{\"105\":1}}],[\"什么是独立开发者\",{\"1\":{\"359\":2}}],[\"什么是\",{\"0\":{\"105\":1},\"1\":{\"116\":1}}],[\"促进\",{\"1\":{\"103\":1}}],[\"促进生态系统工具和\",{\"1\":{\"103\":1}}],[\"展示了端到端搜索成本以及三种自定义空间\",{\"1\":{\"459\":1}}],[\"展示了第\",{\"1\":{\"452\":1}}],[\"展示了\",{\"1\":{\"452\":1,\"455\":1,\"456\":1}}],[\"展示了如何使用\",{\"1\":{\"199\":1}}],[\"展示三种注意力模式和\",{\"1\":{\"249\":1}}],[\"展示基本的健康检查\",{\"1\":{\"103\":1}}],[\"展示自定义资源定义\",{\"1\":{\"97\":1}}],[\"查看详细指令\",{\"1\":{\"372\":1}}],[\"查看所有规则\",{\"1\":{\"331\":1}}],[\"查看所有接口的链路状态\",{\"1\":{\"325\":1}}],[\"查看所有接口的地址信息\",{\"1\":{\"322\":1}}],[\"查看当前的路由表\",{\"1\":{\"328\":1}}],[\"查看网络接口信息\",{\"1\":{\"319\":1}}],[\"查看具体veth设备对的详细信息\",{\"0\":{\"281\":1}}],[\"查看系统中已有的veth设备对或确认已创建的veth设备对\",{\"0\":{\"278\":1}}],[\"查看和管理应用程序的标准\",{\"1\":{\"103\":1}}],[\"查询某个特定进程组内的相对\",{\"1\":{\"150\":1}}],[\"查询路由\",{\"0\":{\"72\":1}}],[\"查询服务\",{\"0\":{\"69\":1}}],[\"希望跟所有关注\",{\"1\":{\"233\":1}}],[\"希望可视化应用程序\",{\"1\":{\"102\":1}}],[\"希望以应用程序为中心进行操作的应用程序运营商\",{\"1\":{\"102\":1}}],[\"像\",{\"1\":{\"102\":1,\"426\":1,\"449\":1}}],[\"很有用\",{\"1\":{\"101\":1}}],[\"即第\",{\"1\":{\"459\":1}}],[\"即算法\",{\"1\":{\"459\":1}}],[\"即张量掩码\",{\"1\":{\"451\":1}}],[\"即文献\",{\"1\":{\"435\":1}}],[\"即相对于当前阶段的偏移量\",{\"1\":{\"433\":1}}],[\"即表2中的约束2和3\",{\"1\":{\"433\":1}}],[\"即多个操作符共享一个设备\",{\"1\":{\"426\":1}}],[\"即gpu\",{\"1\":{\"413\":1}}],[\"即使应用了重计算\",{\"1\":{\"455\":1}}],[\"即使每个gpu拥有96gb\",{\"1\":{\"417\":1}}],[\"即使在单线程实现下\",{\"1\":{\"414\":1}}],[\"即使具有足够的ssd带宽\",{\"1\":{\"412\":1}}],[\"即使用默认流\",{\"1\":{\"158\":1}}],[\"即从生成到再次使用之间的时间\",{\"1\":{\"407\":1}}],[\"即异步和同步模式\",{\"1\":{\"399\":1}}],[\"即\",{\"1\":{\"399\":1,\"425\":1,\"437\":1,\"439\":1}}],[\"即操作内并行和操作间并行\",{\"1\":{\"398\":1}}],[\"即数学公式与相关代码的形神对应\",{\"1\":{\"229\":1}}],[\"即每个并行任务在一个独立的进程中运行\",{\"1\":{\"196\":1}}],[\"即模块对象\",{\"1\":{\"171\":1}}],[\"即在每次操作后等待并同步\",{\"1\":{\"150\":1}}],[\"即垃圾回收\",{\"1\":{\"101\":1}}],[\"即资源回收\",{\"1\":{\"51\":1}}],[\"然而我们发现\",{\"1\":{\"401\":1}}],[\"然而\",{\"1\":{\"100\":1,\"217\":1,\"315\":1,\"401\":2,\"410\":1,\"411\":1,\"412\":2,\"414\":1,\"417\":1,\"418\":3,\"423\":1,\"424\":2,\"426\":2,\"427\":1,\"431\":1,\"435\":1,\"441\":1,\"448\":1,\"449\":1,\"459\":1}}],[\"然后将这些子图转换回\",{\"1\":{\"445\":1}}],[\"然后将导出的文件放到需要保存的地方\",{\"1\":{\"264\":1}}],[\"然后可以定义这些约束以缓解瓶颈\",{\"1\":{\"438\":1}}],[\"然后把这个页面推广出去\",{\"1\":{\"359\":2}}],[\"然后交换bgp\",{\"1\":{\"311\":1}}],[\"然后输入分区号\",{\"1\":{\"257\":1}}],[\"然后进入中断服务程序\",{\"1\":{\"255\":1}}],[\"然后再分散到所有进程\",{\"1\":{\"165\":1}}],[\"然后重复指定次数\",{\"1\":{\"150\":1}}],[\"然后保存相关数据\",{\"1\":{\"113\":1}}],[\"然后\",{\"1\":{\"61\":1,\"93\":1,\"255\":1,\"257\":1,\"263\":1,\"282\":1,\"405\":1}}],[\"然后通过构建遵循常规搜索空间的搜索空间\",{\"1\":{\"436\":1}}],[\"然后通过逐步将部分gpu\",{\"1\":{\"407\":1}}],[\"然后通过ip网络发送到目标vtep\",{\"1\":{\"291\":1}}],[\"然后通过通信操作将所有\",{\"1\":{\"188\":1}}],[\"然后通过\",{\"1\":{\"5\":1}}],[\"官网地址\",{\"0\":{\"99\":1}}],[\"总之\",{\"1\":{\"418\":1}}],[\"总体来说\",{\"1\":{\"211\":1}}],[\"总体而言\",{\"1\":{\"97\":1}}],[\"总结来说\",{\"1\":{\"450\":1}}],[\"总结\",{\"0\":{\"44\":1,\"50\":1,\"75\":1,\"111\":1,\"123\":1,\"163\":1,\"166\":1,\"170\":1,\"174\":1,\"184\":1,\"189\":1,\"195\":1,\"200\":1,\"277\":1,\"288\":1,\"293\":1,\"295\":1,\"301\":1,\"308\":1,\"315\":1,\"343\":1,\"349\":1,\"356\":1}}],[\"支持流水线并行\",{\"1\":{\"454\":1}}],[\"支持流的优先级\",{\"1\":{\"273\":1}}],[\"支持操作间并行训练中的大规模模型训练\",{\"1\":{\"409\":1}}],[\"支持负载均衡和高可用性\",{\"1\":{\"290\":1}}],[\"支持多路并行流量转发\",{\"1\":{\"345\":1}}],[\"支持多达1600万个虚拟网络\",{\"1\":{\"287\":1,\"290\":1}}],[\"支持多租户环境\",{\"1\":{\"286\":1}}],[\"支持多种硬件和操作系统平台\",{\"1\":{\"197\":1}}],[\"支持多种通信后端\",{\"1\":{\"181\":1}}],[\"支持多种\",{\"1\":{\"105\":1}}],[\"支持跨多个物理位置的虚拟机迁移和负载均衡\",{\"1\":{\"286\":1}}],[\"支持服务器推送功能\",{\"1\":{\"272\":1}}],[\"支持同步和异步的消息传递模式\",{\"1\":{\"196\":1}}],[\"支持allreduce操作\",{\"1\":{\"181\":1}}],[\"支持高效的数据同步和通信操作\",{\"1\":{\"180\":1}}],[\"支持任意数量的\",{\"1\":{\"143\":1}}],[\"支持全规约\",{\"1\":{\"143\":1}}],[\"支持超参数调优\",{\"1\":{\"105\":1}}],[\"支持\",{\"1\":{\"97\":1,\"165\":1,\"277\":3}}],[\"支持其他工作流执行器\",{\"1\":{\"97\":1}}],[\"共减少了76\",{\"1\":{\"416\":1}}],[\"共享内存等\",{\"1\":{\"366\":1}}],[\"共同促进学习讨论\",{\"1\":{\"233\":1}}],[\"共同构建维护这个项目\",{\"1\":{\"220\":1}}],[\"共同实现卓越的技术和商业目标\",{\"1\":{\"131\":1}}],[\"共同实现超参数调优功能\",{\"1\":{\"97\":1}}],[\"共同提供了一个功能强大的机器学习工作流管理平台\",{\"1\":{\"97\":1}}],[\"共识算法实现的\",{\"1\":{\"5\":1}}],[\"组成的大型科学基础模型\",{\"1\":{\"446\":1}}],[\"组成了\",{\"1\":{\"97\":1}}],[\"组网架构是最常见的一种拓扑结构\",{\"1\":{\"344\":1}}],[\"组件紧密合作\",{\"1\":{\"97\":1}}],[\"组件可以在循环中多次执行\",{\"1\":{\"95\":1}}],[\"组件不会在同一进程中运行\",{\"1\":{\"93\":1}}],[\"组件代表容器内的特定程序或入口点\",{\"1\":{\"93\":1}}],[\"组件代码\",{\"0\":{\"91\":1}}],[\"组件定义包括以下部分\",{\"1\":{\"92\":1}}],[\"组件定义\",{\"0\":{\"92\":1}}],[\"组件类似于函数\",{\"1\":{\"90\":1}}],[\"组件是一个独立的代码集\",{\"1\":{\"90\":1}}],[\"组件\",{\"1\":{\"78\":1,\"89\":1,\"97\":2}}],[\"持久化代理\",{\"1\":{\"97\":1}}],[\"yoco\",{\"1\":{\"446\":1}}],[\"your\",{\"1\":{\"212\":1}}],[\"you\",{\"1\":{\"212\":1,\"382\":2}}],[\"yml\",{\"1\":{\"381\":1}}],[\"yvdq8kj9kaffdn9agzhldcu1vovogrovvabx1dd4mbgudazlqipfqwmijs\",{\"1\":{\"372\":1}}],[\"yigou\",{\"1\":{\"97\":1}}],[\"yaml\",{\"1\":{\"20\":1,\"25\":1,\"31\":1,\"32\":3,\"34\":1,\"40\":1,\"82\":1,\"92\":1}}],[\"团队仅推荐在\",{\"1\":{\"97\":1}}],[\"那么系统就会进入\",{\"1\":{\"255\":1}}],[\"那么这些代码指令的消耗就属于\",{\"1\":{\"255\":1}}],[\"那么就对应着第一个\",{\"1\":{\"255\":1}}],[\"那么\",{\"1\":{\"97\":1,\"255\":1}}],[\"守护进程交互来管理容器\",{\"1\":{\"96\":1}}],[\"正是为了解决这些问题而设计的\",{\"1\":{\"446\":1}}],[\"正向和反向计算的延迟等基本统计数据\",{\"1\":{\"405\":1}}],[\"正式使用\",{\"1\":{\"366\":1}}],[\"正式发布以来\",{\"1\":{\"96\":1}}],[\"正常启动\",{\"1\":{\"33\":1}}],[\"月\",{\"1\":{\"96\":1}}],[\"年\",{\"1\":{\"96\":1}}],[\"能够适应通信带宽的变化\",{\"1\":{\"458\":1}}],[\"能够检测到新生成的图中的循环依赖\",{\"1\":{\"443\":1}}],[\"能够将轻负载的gpu分配到高内存压力的gpu附近\",{\"1\":{\"406\":1}}],[\"能够将人类操作员的经验和最佳实践转化为自动化的操作流程\",{\"1\":{\"123\":1}}],[\"能够帮助读者加深对公式的理解以及代码的熟练\",{\"1\":{\"229\":1}}],[\"能够在早期放大偏差并预示系统中潜在的错误\",{\"1\":{\"448\":1}}],[\"能够在同样的内存优化下\",{\"1\":{\"419\":1}}],[\"能够在现有的多gpu系统上训练超大规模的模型\",{\"1\":{\"418\":1}}],[\"能够在不牺牲性能的前提下\",{\"1\":{\"397\":1}}],[\"能够在高性能计算环境中提供低延迟和高带宽的通信服务\",{\"1\":{\"197\":1}}],[\"能够在使用\",{\"1\":{\"143\":1}}],[\"能够大幅提高计算效率\",{\"1\":{\"189\":1}}],[\"能够显著缩短训练时间\",{\"1\":{\"182\":1}}],[\"能够显示应用程序的指标\",{\"1\":{\"104\":1}}],[\"能够高效地合并不同设备上的梯度并更新模型参数\",{\"1\":{\"181\":1}}],[\"能够高效部署和管理复杂的微服务架构\",{\"1\":{\"128\":1}}],[\"能够有效提升nccl的通信性能\",{\"1\":{\"177\":1}}],[\"能够方便地集成到应用程序中\",{\"1\":{\"143\":1}}],[\"能够实现高效\",{\"1\":{\"130\":1}}],[\"能够编写高质量\",{\"1\":{\"130\":1}}],[\"能够编写高效\",{\"1\":{\"127\":1}}],[\"能够设计出简洁美观且用户体验友好的前端页面\",{\"1\":{\"130\":1}}],[\"能够设计并实现高并发\",{\"1\":{\"127\":1}}],[\"能够为机器学习模型的开发\",{\"1\":{\"129\":1}}],[\"能够确保微服务架构中各组件的稳定运行与快速扩展\",{\"1\":{\"128\":1}}],[\"能够提升系统的数据处理能力\",{\"1\":{\"128\":1}}],[\"能够快速开发美观实用的前端组件\",{\"1\":{\"130\":1}}],[\"能够快速构建高效的分析和自动化工具\",{\"1\":{\"127\":1}}],[\"能够快速适应不同的项目需求\",{\"1\":{\"126\":1}}],[\"能够执行某些操作\",{\"1\":{\"95\":1}}],[\"能理解并呈现为丰富的可视化内容\",{\"1\":{\"95\":1}}],[\"了解哪些mac地址通过哪些接口连接\",{\"1\":{\"296\":1}}],[\"了解更多\",{\"1\":{\"105\":1}}],[\"了解更多信息\",{\"1\":{\"95\":1}}],[\"了解这些状态有助于掌握\",{\"1\":{\"11\":1}}],[\"转换失败的原因主要是由于某些不支持的算子\",{\"1\":{\"445\":1}}],[\"转换\",{\"1\":{\"429\":1}}],[\"转换算法不仅限于操作符分区\",{\"1\":{\"429\":1}}],[\"转换后的数据流图中的循环\",{\"1\":{\"427\":1}}],[\"转换为\",{\"1\":{\"429\":1}}],[\"转换为在某个进程组中的\",{\"1\":{\"150\":1}}],[\"转换为字符串或文件\",{\"1\":{\"93\":1}}],[\"转向使用\",{\"1\":{\"95\":1}}],[\"步骤中的超参数优化或神经架构搜索问题\",{\"1\":{\"106\":1}}],[\"步骤与其组件之间的关系是一种实例化关系\",{\"1\":{\"95\":1}}],[\"步骤\",{\"1\":{\"95\":1}}],[\"每台服务器配备\",{\"1\":{\"454\":1}}],[\"每秒浮点运算次数\",{\"1\":{\"410\":1}}],[\"每种方法对应不同的分区策略\",{\"1\":{\"398\":1}}],[\"每一层代表一个子神经架构\",{\"1\":{\"425\":1}}],[\"每一层会添加或移除相应的协议头\",{\"1\":{\"341\":1}}],[\"每一层依赖于下一层提供的服务\",{\"1\":{\"341\":1}}],[\"每次迭代都检查结果的正确性\",{\"1\":{\"150\":1}}],[\"每次迭代中聚合在一起的操作次数\",{\"1\":{\"150\":1}}],[\"每2小时或每45分钟\",{\"1\":{\"95\":1}}],[\"每个配置都包含参数数量\",{\"1\":{\"454\":1}}],[\"每个设备将接收一个由\",{\"1\":{\"445\":1}}],[\"每个算子都可以独立地进行变换\",{\"1\":{\"443\":1}}],[\"每个微批次的训练需要三个前向传播和一个反向传播\",{\"1\":{\"437\":1}}],[\"每个被分割的子算子被分配到不同的设备上并发执行\",{\"1\":{\"433\":1}}],[\"每个内存层都可以有不同的访问带宽\",{\"1\":{\"417\":1}}],[\"每个阶段分别应用了\",{\"1\":{\"456\":1}}],[\"每个阶段可以进一步应用数据并行和张量并行\",{\"1\":{\"454\":1}}],[\"每个阶段再分为\",{\"1\":{\"425\":1}}],[\"每个阶段包含一个或多个层\",{\"1\":{\"425\":1}}],[\"每个阶段最大内存需求为24\",{\"1\":{\"410\":1}}],[\"每个阶段对应一组连续的模型层\",{\"1\":{\"398\":1}}],[\"每个子块的大小和目标gpu设备的索引\",{\"1\":{\"406\":1}}],[\"每个gpu的内存为40gb\",{\"1\":{\"410\":1}}],[\"每个gpu的内存为32gb\",{\"1\":{\"410\":1}}],[\"每个gpu具有32gb内存\",{\"1\":{\"400\":1}}],[\"每个gpu设备可以将张量交换到多个nvlink可达的轻负载gpu\",{\"1\":{\"406\":1}}],[\"每个gpu设备\",{\"1\":{\"399\":1}}],[\"每个训练数据的微批次被进一步分为多个子批次\",{\"1\":{\"399\":1}}],[\"每个spine交换机与所有的leaf交换机相连\",{\"1\":{\"347\":1}}],[\"每个leaf交换机与多个spine交换机相连\",{\"1\":{\"347\":1}}],[\"每个leaf交换机会连接到所有的spine交换机\",{\"1\":{\"346\":1}}],[\"每个leaf交换机都会连接到所有spine交换机\",{\"1\":{\"345\":1}}],[\"每个层次都有其特定的功能和协议\",{\"1\":{\"333\":1}}],[\"每个as都有一个唯一的as编号\",{\"1\":{\"310\":1}}],[\"每个邻居节点条目通常包含以下信息\",{\"1\":{\"294\":1}}],[\"每个vtep有两个主要接口\",{\"1\":{\"291\":1}}],[\"每个vlan都有一个唯一的vlan\",{\"1\":{\"285\":1}}],[\"每个虚拟网络可以有自己的vni\",{\"1\":{\"290\":1}}],[\"每个租户可以有独立的虚拟网络\",{\"1\":{\"286\":1}}],[\"每个请求通常需要一个tcp连接\",{\"1\":{\"277\":1}}],[\"每个请求都需要发送完整的头部信息\",{\"1\":{\"271\":1}}],[\"每个请求\",{\"1\":{\"269\":2}}],[\"每个进程必须独占其使用的每个\",{\"1\":{\"204\":1}}],[\"每个进程组拥有一个通信域\",{\"1\":{\"196\":1}}],[\"每个进程的线程数\",{\"1\":{\"150\":1}}],[\"每个实例可以有自己的任务和数据\",{\"1\":{\"194\":1}}],[\"每个处理单元都可以独立处理自己的任务\",{\"1\":{\"190\":1}}],[\"每个处理单元处理不同的数据集\",{\"1\":{\"190\":1}}],[\"每个处理单元处理其特定的数据子集\",{\"1\":{\"185\":1}}],[\"每个处理单元可以运行不同的程序代码\",{\"1\":{\"190\":1}}],[\"每个处理单元\",{\"1\":{\"187\":1}}],[\"每个张量包含设备上局部计算的结果\",{\"1\":{\"158\":1}}],[\"每个线程使用的\",{\"1\":{\"150\":1}}],[\"每个节点的右上角有一个图标\",{\"1\":{\"94\":1}}],[\"每个组件的代码包括以下部分\",{\"1\":{\"91\":1}}],[\"每个\",{\"1\":{\"36\":1,\"38\":1,\"43\":1,\"143\":1,\"188\":1}}],[\"定时工作流\",{\"1\":{\"97\":1}}],[\"定期运行服务\",{\"1\":{\"109\":1}}],[\"定期运行的配置包括指定所有参数值的管道副本和运行触发器\",{\"1\":{\"95\":1}}],[\"定期运行\",{\"1\":{\"95\":1}}],[\"定义于第\",{\"1\":{\"459\":1}}],[\"定义\",{\"0\":{\"42\":1,\"43\":1},\"1\":{\"118\":1,\"345\":1,\"346\":1}}],[\"定义示例\",{\"1\":{\"40\":1}}],[\"定义的流行集体操作\",{\"1\":{\"143\":1}}],[\"定义的\",{\"1\":{\"32\":1}}],[\"定义文件\",{\"1\":{\"31\":1}}],[\"定义了一个名为\",{\"1\":{\"168\":1}}],[\"定义了资源的\",{\"1\":{\"118\":1}}],[\"定义了资源的硬性限制\",{\"1\":{\"21\":1}}],[\"定义了容器没有指定资源请求时的默认请求值\",{\"1\":{\"26\":1}}],[\"定义了容器没有指定资源请求和限制时的默认值\",{\"1\":{\"26\":1}}],[\"定义了单个容器必须请求的最小资源量\",{\"1\":{\"26\":1}}],[\"定义了单个容器可以请求的最大资源量\",{\"1\":{\"26\":1}}],[\"设\",{\"1\":{\"435\":1,\"437\":1}}],[\"设备映射搜索仅需几秒钟即可完成\",{\"1\":{\"414\":1}}],[\"设备映射对性能没有影响\",{\"1\":{\"414\":1}}],[\"设备映射优化提高了默认设置下的性能17\",{\"1\":{\"414\":1}}],[\"设备映射和内存压缩策略的性能影响是什么\",{\"1\":{\"409\":1}}],[\"设备映射\",{\"1\":{\"406\":1}}],[\"设备会将最近解析的ip地址和mac地址映射关系存储在arp缓存中\",{\"1\":{\"305\":1}}],[\"设备a接收到设备b的arp响应后\",{\"1\":{\"303\":1}}],[\"设备a会广播一条arp请求帧到网络中\",{\"1\":{\"303\":1}}],[\"设备a会先在本地的arp缓存中查找设备b的ip地址对应的mac地址\",{\"1\":{\"303\":1}}],[\"设备b会发送一条arp响应帧\",{\"1\":{\"303\":1}}],[\"设计的手工张量并行方案\",{\"1\":{\"457\":1}}],[\"设计的主要考虑因素之一\",{\"1\":{\"143\":1}}],[\"设计高效的并行训练计划并非易事\",{\"1\":{\"424\":1}}],[\"设计原则\",{\"0\":{\"404\":1}}],[\"设计为自包含的\",{\"1\":{\"95\":1}}],[\"设置中\",{\"1\":{\"455\":1}}],[\"设置中应用\",{\"1\":{\"455\":1}}],[\"设置微批次大小为12时\",{\"1\":{\"400\":1}}],[\"设置为100\",{\"1\":{\"365\":1}}],[\"设置新分区的类型为\",{\"1\":{\"258\":1}}],[\"设置路径为\",{\"1\":{\"71\":1}}],[\"设置资源使用的默认值和最大\",{\"1\":{\"28\":1}}],[\"设置默认资源限制\",{\"1\":{\"24\":1}}],[\"失败\",{\"1\":{\"94\":1}}],[\"箭头指示了管道组件之间的父\",{\"1\":{\"94\":1}}],[\"图9总结了通过逐步添加设备映射和数据分条优化后mpress的性能提升情况\",{\"1\":{\"414\":1}}],[\"图8b展示了在dgx\",{\"1\":{\"412\":1}}],[\"图8a总结了在dgx\",{\"1\":{\"412\":1}}],[\"图7对比了在五种不同系统配置下\",{\"1\":{\"411\":1}}],[\"图5展示了mpress系统架构的高级视图\",{\"1\":{\"405\":1}}],[\"图1展示了操作间并行dnn训练的工作流程\",{\"1\":{\"399\":1}}],[\"图片\",{\"1\":{\"228\":1}}],[\"图启动次数>\",{\"1\":{\"150\":1}}],[\"图中的每个节点对应管道中的一个步骤\",{\"1\":{\"94\":1}}],[\"图显示了管道运行已执行或正在执行的步骤\",{\"1\":{\"94\":1}}],[\"图\",{\"1\":{\"94\":1,\"150\":1,\"437\":1,\"444\":1,\"452\":3,\"455\":1,\"456\":1,\"457\":1,\"458\":2,\"459\":2}}],[\"镜像启动\",{\"0\":{\"375\":1}}],[\"镜像\",{\"1\":{\"93\":1}}],[\"请告诉我你的mac地址\",{\"1\":{\"303\":1}}],[\"请使用sudo管理员权限在文本编辑器中打开文件wsl\",{\"1\":{\"263\":1}}],[\"请先卸载\",{\"1\":{\"257\":1}}],[\"请注意\",{\"1\":{\"204\":1,\"431\":1}}],[\"请访问\",{\"1\":{\"105\":1}}],[\"请参阅\",{\"1\":{\"95\":1}}],[\"请参见组件规范\",{\"1\":{\"92\":1}}],[\"请求api时\",{\"1\":{\"365\":1}}],[\"请求apiserver\",{\"1\":{\"113\":1}}],[\"请求\",{\"1\":{\"25\":1,\"61\":1,\"291\":1,\"303\":1}}],[\"请求量\",{\"1\":{\"25\":1}}],[\"请求总量\",{\"1\":{\"20\":1}}],[\"请求匹配\",{\"1\":{\"16\":1}}],[\"类\",{\"0\":{\"206\":1}}],[\"类似的分布式训练系统\",{\"1\":{\"454\":1}}],[\"类似的解决方案也适用于图神经网络的训练\",{\"1\":{\"436\":1}}],[\"类似于其他现有的flops计算工具或方法\",{\"1\":{\"410\":1}}],[\"类似于运行与其管道之间的关系\",{\"1\":{\"95\":1}}],[\"类似子句后有条件地执行\",{\"1\":{\"95\":1}}],[\"类型相对应的算法集中选择\",{\"1\":{\"429\":1}}],[\"类型\",{\"1\":{\"92\":1,\"310\":1}}],[\"类别的\",{\"1\":{\"51\":1}}],[\"类别\",{\"1\":{\"51\":1}}],[\"元数据写入器\",{\"1\":{\"97\":1}}],[\"元数据服务\",{\"1\":{\"97\":2}}],[\"元数据\",{\"1\":{\"92\":1,\"97\":1}}],[\"用tflops表示\",{\"1\":{\"411\":1}}],[\"用法\",{\"0\":{\"319\":1,\"322\":1,\"325\":1,\"328\":1,\"331\":1}}],[\"用最适合国内学习者的方式\",{\"1\":{\"226\":1}}],[\"用户名myusername\",{\"1\":{\"366\":1}}],[\"用户名为\",{\"1\":{\"366\":1}}],[\"用户并不知道自己需要什么\",{\"1\":{\"359\":2}}],[\"用户在浏览器中输入网址\",{\"1\":{\"342\":1}}],[\"用户数据报协议\",{\"1\":{\"337\":1}}],[\"用户不应直接使用它\",{\"1\":{\"207\":1}}],[\"用户也可以定义自己的进程组和通信域\",{\"1\":{\"196\":1}}],[\"用户有责任确保\",{\"1\":{\"143\":1}}],[\"用户可以方便地将训练任务分布在多个gpu上\",{\"1\":{\"182\":1}}],[\"用户可以在\",{\"1\":{\"164\":1}}],[\"用户可以轻松找到某个全局\",{\"1\":{\"155\":1}}],[\"用户可以使用\",{\"1\":{\"118\":1}}],[\"用户可以创建和管理新的自定义资源\",{\"1\":{\"117\":1}}],[\"用户可以利用\",{\"1\":{\"106\":1}}],[\"用户可以根据具体需求和工作流特点选择合适的\",{\"1\":{\"97\":1}}],[\"用户甚至可以使用\",{\"1\":{\"106\":1}}],[\"用户界面\",{\"1\":{\"97\":6}}],[\"用户需要选择一个工作流执行器\",{\"1\":{\"95\":1}}],[\"用\",{\"1\":{\"92\":1}}],[\"用于支持多代\",{\"1\":{\"446\":1}}],[\"用于支持机器学习工作流的定义\",{\"1\":{\"97\":1}}],[\"用于容纳第\",{\"1\":{\"435\":1}}],[\"用于跟踪经过d2d交换的张量状态\",{\"1\":{\"406\":1}}],[\"用于远程服务器之间的通信\",{\"1\":{\"356\":1}}],[\"用于加速\",{\"1\":{\"355\":1}}],[\"用于配置\",{\"1\":{\"330\":1}}],[\"用于配置网络接口\",{\"1\":{\"318\":1}}],[\"用于显示和管理路由表\",{\"1\":{\"327\":1}}],[\"用于显示和修改网络接口的属性\",{\"1\":{\"324\":1}}],[\"用于显示或修改网络接口的地址信息\",{\"1\":{\"321\":1}}],[\"用于交换外部路由信息\",{\"1\":{\"310\":1}}],[\"用于交换连接\",{\"1\":{\"204\":1}}],[\"用于传播内部路由信息\",{\"1\":{\"310\":1}}],[\"用于在不同自治系统\",{\"1\":{\"309\":1}}],[\"用于解决长上下文\",{\"1\":{\"248\":1}}],[\"用于后续的数据分析或监控\",{\"1\":{\"211\":1}}],[\"用于表示后端类型\",{\"1\":{\"206\":1}}],[\"用于表示集群中持久化存储的详细信息和状态\",{\"1\":{\"11\":1}}],[\"用于\",{\"1\":{\"204\":1}}],[\"用于构建特定进程组的其他选项\",{\"1\":{\"204\":1}}],[\"用于指示在哪里\",{\"1\":{\"203\":1}}],[\"用于指定多个输出张量的列表\",{\"1\":{\"158\":1}}],[\"用于设置模块的内容\",{\"1\":{\"174\":1}}],[\"用于控制符号的可见性\",{\"1\":{\"171\":1}}],[\"用于控制容器是否能够通过\",{\"1\":{\"50\":1}}],[\"用于初始化模块\",{\"1\":{\"171\":1}}],[\"用于根据一个完全限定的对象名称\",{\"1\":{\"167\":1}}],[\"用于收集所有进程的数据到每个进程中\",{\"1\":{\"165\":1}}],[\"用于执行广播操作\",{\"1\":{\"165\":1}}],[\"用于执行所有进程的\",{\"1\":{\"165\":1}}],[\"用于执行\",{\"1\":{\"165\":2}}],[\"用于生成深度学习训练的并行化计划\",{\"1\":{\"424\":1}}],[\"用于生成\",{\"1\":{\"165\":1}}],[\"用于生成和管理\",{\"1\":{\"122\":1}}],[\"用于释放\",{\"1\":{\"162\":1}}],[\"用于从\",{\"1\":{\"162\":1}}],[\"用于存放归约操作的结果\",{\"1\":{\"158\":1}}],[\"用于将多个\",{\"1\":{\"156\":1}}],[\"用于简化\",{\"1\":{\"121\":1}}],[\"用于定义\",{\"1\":{\"117\":1}}],[\"用于定义访问路径\",{\"1\":{\"75\":1}}],[\"用于自动化部署\",{\"1\":{\"100\":1}}],[\"用于自定义\",{\"1\":{\"97\":1}}],[\"用于管理元数据\",{\"1\":{\"97\":1}}],[\"用于管理和代理请求\",{\"1\":{\"75\":1}}],[\"用于展示机器学习工作流的执行状态和结果\",{\"1\":{\"97\":1}}],[\"用于创建\",{\"1\":{\"97\":1}}],[\"用于查看和监控超参数调优任务的状态和结果\",{\"1\":{\"97\":1}}],[\"用于告知系统何时生成新的定期运行配置\",{\"1\":{\"95\":1}}],[\"用于提供静态文件\",{\"1\":{\"75\":1}}],[\"用于限制\",{\"1\":{\"35\":2}}],[\"用于确保关键组件的高可用性和独立性\",{\"1\":{\"34\":1}}],[\"执行初始化副本集的脚本\",{\"1\":{\"366\":1}}],[\"执行相同的程序代码\",{\"1\":{\"185\":1}}],[\"执行集合操作等\",{\"1\":{\"164\":1}}],[\"执行\",{\"1\":{\"160\":1,\"163\":1,\"431\":1}}],[\"执行真正的张量归约操作\",{\"1\":{\"159\":1}}],[\"执行指定次数的迭代\",{\"1\":{\"150\":1}}],[\"执行器为执行交换操作的swap\",{\"1\":{\"408\":1}}],[\"执行器接收来自mpress静态部分的仪器化数据流图\",{\"1\":{\"405\":1}}],[\"执行器之间进行选择\",{\"1\":{\"97\":1}}],[\"执行器和\",{\"1\":{\"97\":1}}],[\"执行器一直是\",{\"1\":{\"96\":1}}],[\"执行和监控容器\",{\"1\":{\"96\":1}}],[\"执行实际作业的代码\",{\"1\":{\"91\":1}}],[\"执行结果如下\",{\"1\":{\"1\":1}}],[\"运行bridge\",{\"1\":{\"297\":1}}],[\"运行ip\",{\"1\":{\"294\":1}}],[\"运行这个命令会列出该接口的所有邻居节点的信息\",{\"1\":{\"294\":1}}],[\"运行该命令后\",{\"1\":{\"255\":1}}],[\"运行并打印每个循环\",{\"1\":{\"150\":1}}],[\"运行管理\",{\"1\":{\"111\":1}}],[\"运行服务\",{\"1\":{\"108\":1,\"109\":1}}],[\"运行一个像\",{\"1\":{\"101\":1}}],[\"运行一开始\",{\"1\":{\"94\":1}}],[\"运行\",{\"0\":{\"149\":1},\"1\":{\"97\":1,\"106\":1}}],[\"运行和监控\",{\"1\":{\"97\":1}}],[\"运行和监控机器学习工作流\",{\"1\":{\"97\":1}}],[\"运行和监控功能\",{\"1\":{\"97\":1}}],[\"运行时执行过程中\",{\"1\":{\"443\":1}}],[\"运行时流程如下\",{\"1\":{\"405\":1}}],[\"运行时信息包括任务的状态\",{\"1\":{\"95\":1}}],[\"运行时代码\",{\"1\":{\"91\":1}}],[\"运行触发器是一个标志\",{\"1\":{\"95\":1}}],[\"运行包含你尝试的所有实验的不可变日志\",{\"1\":{\"95\":1}}],[\"运行中\",{\"1\":{\"94\":1}}],[\"运行在同一个节点上\",{\"1\":{\"53\":1}}],[\"模拟器只需要执行有限的几次训练步骤\",{\"1\":{\"405\":1}}],[\"模型参数较小\",{\"1\":{\"456\":1}}],[\"模型参数范围从\",{\"1\":{\"446\":1}}],[\"模型配置\",{\"1\":{\"454\":1}}],[\"模型准确性\",{\"0\":{\"448\":1}}],[\"模型转换为\",{\"1\":{\"445\":1}}],[\"模型绑定\",{\"1\":{\"431\":1}}],[\"模型使用\",{\"1\":{\"425\":1}}],[\"模型规模的增长\",{\"1\":{\"423\":1}}],[\"模型规模的差异在前面已经解释过\",{\"1\":{\"412\":1}}],[\"模型和数据集\",{\"1\":{\"410\":1}}],[\"模型并行化将模型的不同部分分配给不同的设备进行计算\",{\"1\":{\"418\":1}}],[\"模型并行化\",{\"1\":{\"418\":2}}],[\"模型并行化这些操作\",{\"1\":{\"187\":1}}],[\"模型并行\",{\"1\":{\"398\":1}}],[\"模型下载\",{\"0\":{\"374\":1}}],[\"模型展示名\",{\"1\":{\"365\":1}}],[\"模型别名\",{\"1\":{\"365\":1}}],[\"模型名\",{\"1\":{\"365\":2}}],[\"模型构建任意并行化计划的搜索空间\",{\"1\":{\"431\":1}}],[\"模型构建\",{\"1\":{\"231\":1}}],[\"模型微调的全部流程\",{\"1\":{\"226\":1}}],[\"模型提供了实现途径\",{\"1\":{\"195\":1}}],[\"模型可以分别启动两个不同的程序\",{\"1\":{\"193\":1}}],[\"模型可以将不同的程序分配给不同的架构\",{\"1\":{\"192\":1}}],[\"模型不同\",{\"1\":{\"190\":1}}],[\"模型相对应\",{\"1\":{\"189\":1}}],[\"模型是一种强大的并行计算模型\",{\"1\":{\"195\":1}}],[\"模型是一种高效的并行计算模型\",{\"1\":{\"189\":1}}],[\"模型是一种并行计算模型\",{\"1\":{\"184\":1}}],[\"模型的预训练和微调\",{\"1\":{\"446\":1}}],[\"模型的规模\",{\"1\":{\"431\":1}}],[\"模型的规模迅速增长\",{\"1\":{\"424\":1}}],[\"模型的规模不断扩大\",{\"1\":{\"394\":1}}],[\"模型的logo\",{\"1\":{\"365\":1}}],[\"模型的框架之一\",{\"1\":{\"194\":1}}],[\"模型的一个简单示例可能是\",{\"1\":{\"188\":1}}],[\"模型的核心思想\",{\"0\":{\"185\":1,\"190\":1}}],[\"模型在气候模拟\",{\"1\":{\"187\":1}}],[\"模型在许多并行计算任务中得到了广泛应用\",{\"1\":{\"187\":1}}],[\"模型通常只包含前向传播\",{\"1\":{\"445\":1}}],[\"模型通常由多个层组成\",{\"1\":{\"425\":1}}],[\"模型通常用于分布式训练\",{\"1\":{\"187\":1}}],[\"模型通过允许不同的处理单元并行执行不同的任务\",{\"1\":{\"190\":1}}],[\"模型通过同时在多个处理单元上执行相同的程序代码来实现并行性\",{\"1\":{\"185\":1}}],[\"模型允许每个处理单元执行不同的程序代码并处理不同的数据\",{\"1\":{\"186\":1}}],[\"模型中主要操作符的分区算法\",{\"1\":{\"429\":1}}],[\"模型中所有处理单元执行相同的程序\",{\"1\":{\"191\":1}}],[\"模型中\",{\"1\":{\"185\":2,\"186\":1,\"189\":1,\"190\":1}}],[\"模型\",{\"1\":{\"184\":1,\"190\":1,\"333\":1,\"445\":3}}],[\"模型训练等\",{\"1\":{\"90\":1}}],[\"模块时\",{\"1\":{\"173\":1}}],[\"模块能够以\",{\"1\":{\"171\":1}}],[\"模块的初始化函数\",{\"1\":{\"170\":1}}],[\"模块中的\",{\"1\":{\"162\":1}}],[\"模式下\",{\"1\":{\"51\":1}}],[\"模式\",{\"1\":{\"50\":1}}],[\"参训时的额外参数\",{\"1\":{\"365\":1}}],[\"参与任务的进程数量\",{\"1\":{\"204\":1}}],[\"参数和梯度的内存消耗\",{\"1\":{\"401\":1}}],[\"参数数量已经从百万级增长到数十亿级\",{\"1\":{\"394\":1}}],[\"参数确保只分割一次\",{\"1\":{\"168\":1}}],[\"参数转换\",{\"1\":{\"162\":1}}],[\"参数解析\",{\"0\":{\"158\":1},\"1\":{\"162\":1}}],[\"参数说明\",{\"0\":{\"152\":1,\"204\":1}}],[\"参数\",{\"0\":{\"150\":1},\"1\":{\"89\":1,\"90\":1,\"143\":1,\"162\":1}}],[\"参考资料\",{\"0\":{\"139\":1}}],[\"参考\",{\"1\":{\"1\":1,\"211\":1,\"212\":1}}],[\"输出字段解释\",{\"0\":{\"298\":1}}],[\"输出可能类似于\",{\"1\":{\"282\":1}}],[\"输出\",{\"1\":{\"169\":1}}],[\"输出归约后的结果\",{\"1\":{\"160\":1}}],[\"输出工件\",{\"1\":{\"95\":1}}],[\"输出工件和每个步骤的日志\",{\"1\":{\"95\":1}}],[\"输出规范\",{\"1\":{\"92\":1}}],[\"输出包括容器参数或数据工件uri\",{\"1\":{\"87\":1}}],[\"输入\",{\"1\":{\"87\":1,\"92\":1,\"257\":2,\"258\":3}}],[\"度量数据被聚合用于排序和过滤\",{\"1\":{\"86\":1}}],[\"实践经验\",{\"0\":{\"446\":1}}],[\"实际上\",{\"1\":{\"417\":1,\"429\":1}}],[\"实例\",{\"1\":{\"263\":1}}],[\"实时跟踪系统调用\",{\"1\":{\"254\":1}}],[\"实现高模型准确性是训练的最终目标\",{\"1\":{\"448\":1}}],[\"实现与经验\",{\"0\":{\"445\":1}}],[\"实现细节\",{\"0\":{\"408\":1}}],[\"实现自己的想法等\",{\"1\":{\"359\":2}}],[\"实现南北向和东西向流量的高效转发\",{\"1\":{\"346\":1}}],[\"实现全面的网络管理\",{\"1\":{\"332\":1}}],[\"实现百万级标记提示的可接受延迟\",{\"1\":{\"249\":1}}],[\"实现本地部署大模型以及相关应用\",{\"1\":{\"228\":1}}],[\"实现框架\",{\"1\":{\"223\":1}}],[\"实现基本的点对点通信\",{\"1\":{\"199\":1}}],[\"实现模型的并行训练和参数同步\",{\"1\":{\"198\":1}}],[\"实现包括\",{\"1\":{\"197\":1}}],[\"实现了增强的图转换器\",{\"1\":{\"445\":1}}],[\"实现了大多数深度神经网络\",{\"1\":{\"429\":1}}],[\"实现了大规模的数据中心和云环境中的网络虚拟化和扩展\",{\"1\":{\"293\":1}}],[\"实现了最高3\",{\"1\":{\"423\":1}}],[\"实现了42\",{\"1\":{\"416\":1}}],[\"实现了\",{\"1\":{\"161\":1,\"445\":1}}],[\"实现了集体通信和点对点发送\",{\"1\":{\"143\":1}}],[\"实现控制器\",{\"1\":{\"118\":1}}],[\"实现互操作\",{\"1\":{\"102\":1}}],[\"实现部分还描述了组件完成运行后如何获取输出值\",{\"1\":{\"92\":1}}],[\"实现\",{\"0\":{\"194\":1},\"1\":{\"92\":1,\"103\":1,\"163\":1}}],[\"实现资源的更高效利用\",{\"1\":{\"60\":1}}],[\"实验表明\",{\"1\":{\"423\":1}}],[\"实验设置\",{\"0\":{\"410\":1,\"454\":1}}],[\"实验结果表明\",{\"1\":{\"396\":1,\"419\":1}}],[\"实验使用了bert和gpt两种模型\",{\"1\":{\"396\":1}}],[\"实验方法\",{\"0\":{\"396\":1}}],[\"实验服务\",{\"1\":{\"108\":1,\"109\":1}}],[\"实验可以包含任意的运行\",{\"1\":{\"95\":1}}],[\"实验是一个工作空间\",{\"1\":{\"95\":1}}],[\"实验\",{\"1\":{\"86\":1}}],[\"调试\",{\"0\":{\"447\":1}}],[\"调试和排错\",{\"1\":{\"254\":1}}],[\"调用了\",{\"1\":{\"162\":1}}],[\"调用\",{\"1\":{\"162\":1,\"173\":1,\"253\":1}}],[\"调用底层\",{\"1\":{\"159\":1}}],[\"调用管道服务以从静态配置创建管道运行\",{\"1\":{\"83\":1}}],[\"调度在有约束和无约束情况下的时间排序搜索时间\",{\"1\":{\"459\":1}}],[\"调度和通信方案\",{\"1\":{\"427\":1}}],[\"调度和执行定时任务\",{\"1\":{\"97\":1}}],[\"调度到相同的节点\",{\"1\":{\"55\":1}}],[\"调度到特定节点上\",{\"1\":{\"36\":1}}],[\"调度到这个节点上\",{\"1\":{\"36\":1}}],[\"作为性能指标\",{\"1\":{\"454\":1}}],[\"作为一种策略\",{\"1\":{\"454\":1}}],[\"作为二进制协议\",{\"1\":{\"275\":1}}],[\"作为模块的实际初始化逻辑\",{\"1\":{\"174\":1}}],[\"作为\",{\"1\":{\"158\":1,\"218\":1}}],[\"作为工作流引擎\",{\"1\":{\"95\":1}}],[\"作为元数据依赖\",{\"1\":{\"95\":1}}],[\"作为在\",{\"1\":{\"79\":1}}],[\"作业管理\",{\"1\":{\"111\":1}}],[\"作业服务\",{\"1\":{\"108\":1}}],[\"作业的代码\",{\"1\":{\"91\":1}}],[\"作业\",{\"1\":{\"86\":1}}],[\"作用\",{\"0\":{\"19\":1,\"24\":1},\"1\":{\"345\":1,\"346\":1}}],[\"工人3则处理第三阶段的子批次\",{\"1\":{\"399\":1}}],[\"工人1处理第二个微批次\",{\"1\":{\"399\":1}}],[\"工人1从第一微批次开始前向传播\",{\"1\":{\"399\":1}}],[\"工人\",{\"1\":{\"399\":1}}],[\"工作原理\",{\"0\":{\"303\":1}}],[\"工作流控制器\",{\"1\":{\"97\":2}}],[\"工作流执行器\",{\"1\":{\"97\":1}}],[\"工作流执行器类型包括\",{\"0\":{\"96\":1}}],[\"工作流执行器是一个符合特定接口的进程\",{\"1\":{\"95\":1}}],[\"工作流\",{\"1\":{\"90\":1}}],[\"工作流的描述\",{\"1\":{\"89\":1}}],[\"工作流在\",{\"1\":{\"78\":1}}],[\"工具调用会用到\",{\"1\":{\"365\":2}}],[\"工具\",{\"0\":{\"465\":1},\"1\":{\"253\":1},\"2\":{\"243\":1}}],[\"工具包\",{\"1\":{\"79\":1}}],[\"工件的可用性\",{\"1\":{\"95\":1}}],[\"工件可以是简单的文本数据视图\",{\"1\":{\"95\":1}}],[\"工件还使得理解管道各个组件的工作方式成为可能\",{\"1\":{\"95\":1}}],[\"工程师和运营团队\",{\"1\":{\"78\":1}}],[\"管道并行会优先考虑分配设备以容纳\",{\"1\":{\"436\":1}}],[\"管道并行将一批样本划分为多个微批次\",{\"1\":{\"433\":1}}],[\"管道并行将模型g划分为子图gi\",{\"1\":{\"433\":1}}],[\"管道并行的约束总结在表4中\",{\"1\":{\"433\":1}}],[\"管道并行的约束\",{\"1\":{\"433\":1}}],[\"管道中的每个组件独立执行\",{\"1\":{\"93\":1}}],[\"管道\",{\"1\":{\"89\":1,\"90\":1}}],[\"管道配置包括运行管道所需的输入\",{\"1\":{\"89\":1}}],[\"管道是对机器学习\",{\"1\":{\"89\":1}}],[\"管道执行历史记录\",{\"1\":{\"88\":1}}],[\"管道web服务器从各种服务中收集数据以显示相关视图\",{\"1\":{\"88\":1}}],[\"管道持久性代理记录已执行的容器集合及其输入和输出\",{\"1\":{\"87\":1}}],[\"管道持久性代理监视管道服务创建的kubernetes资源\",{\"1\":{\"87\":1}}],[\"管道包\",{\"1\":{\"86\":1}}],[\"管道运行和单个标量指标\",{\"1\":{\"86\":1}}],[\"管道服务调用kubernetes\",{\"1\":{\"84\":1}}],[\"管道的执行过程如下\",{\"1\":{\"80\":1}}],[\"管道的数据科学家的平台\",{\"1\":{\"78\":1}}],[\"管理器直接使用pytorch中的原生gpu内存分配器\",{\"1\":{\"408\":1}}],[\"管理应用程序之间的会话\",{\"1\":{\"338\":1}}],[\"管理和终止会话\",{\"1\":{\"338\":1}}],[\"管理和协调工作流的各个部分\",{\"1\":{\"97\":1}}],[\"管理和调度超参数调优任务\",{\"1\":{\"97\":1}}],[\"管理工作流的持久化存储\",{\"1\":{\"97\":1}}],[\"管理存储\",{\"1\":{\"97\":1}}],[\"管理容器生命周期等\",{\"1\":{\"95\":1}}],[\"管理\",{\"1\":{\"31\":1,\"116\":1,\"121\":1}}],[\"管理员可以设置各种策略\",{\"1\":{\"310\":1}}],[\"管理员可以更好地管理和监控资源使用情况\",{\"1\":{\"19\":1}}],[\"管理员可以手动将\",{\"1\":{\"16\":1}}],[\"涵盖不同的模型配置和\",{\"1\":{\"453\":1}}],[\"涵盖\",{\"1\":{\"78\":1}}],[\"下的并行化计划是不同类型的手工流水线并行化\",{\"1\":{\"451\":1}}],[\"下的并行化计划是通过操作符转换实现的\",{\"1\":{\"451\":1}}],[\"下的\",{\"1\":{\"444\":1}}],[\"下有两个效果\",{\"1\":{\"204\":1}}],[\"下载\",{\"0\":{\"147\":1}}],[\"下载源码\",{\"0\":{\"144\":1}}],[\"下图展示了\",{\"1\":{\"79\":1}}],[\"下图展示了主要的\",{\"1\":{\"78\":1}}],[\"下面我们来介绍\",{\"1\":{\"344\":1}}],[\"下面我给你具体讲一下\",{\"1\":{\"255\":1}}],[\"下面是每个\",{\"1\":{\"97\":1}}],[\"下面是你使用kong和nginx创建服务和路由的步骤总结\",{\"1\":{\"65\":1}}],[\"下面是对该函数的逐行分析\",{\"1\":{\"167\":1}}],[\"下面是对代码的逐行分析\",{\"1\":{\"164\":1}}],[\"下面是对\",{\"1\":{\"37\":1}}],[\"下面最早创建的一个\",{\"1\":{\"5\":1}}],[\"只需重新配置预构建的并行化计划\",{\"1\":{\"447\":1}}],[\"只需要在交换机上配置相关的端口或接口即可\",{\"1\":{\"285\":1}}],[\"只需要传入一个单一的\",{\"1\":{\"158\":1}}],[\"只会拆分自身及其输出的\",{\"1\":{\"443\":1}}],[\"只在\",{\"1\":{\"436\":1}}],[\"只有\",{\"1\":{\"443\":1}}],[\"只有gpu\",{\"1\":{\"411\":1}}],[\"只有激活值在阶段之间传输\",{\"1\":{\"398\":1}}],[\"只有一个请求\",{\"1\":{\"270\":1}}],[\"只有rank为0的进程修改张量\",{\"1\":{\"183\":1}}],[\"只是数据不同\",{\"1\":{\"191\":1}}],[\"只要有足够的主机内存空间\",{\"1\":{\"411\":1}}],[\"只要不是调用系统调用\",{\"1\":{\"255\":1}}],[\"只要能够收集优化指标\",{\"1\":{\"106\":1}}],[\"只要您运行\",{\"1\":{\"78\":1}}],[\"只读权限\",{\"1\":{\"9\":1}}],[\"开放系统互连\",{\"1\":{\"333\":1}}],[\"开源技术\",{\"0\":{\"245\":1},\"2\":{\"250\":1}}],[\"开源课程的好朋友一起探讨研究\",{\"1\":{\"233\":1}}],[\"开源\",{\"1\":{\"220\":2}}],[\"开源系统部署到各种基础设施中\",{\"1\":{\"78\":1}}],[\"开始的最小大小\",{\"1\":{\"150\":1}}],[\"开发的专有高速互连技术\",{\"1\":{\"352\":1}}],[\"开发的一般流程\",{\"1\":{\"223\":1}}],[\"开发什么样的应用\",{\"1\":{\"223\":1}}],[\"开发更进阶的技巧\",{\"1\":{\"223\":1}}],[\"开发技巧\",{\"1\":{\"223\":1}}],[\"开发入门\",{\"1\":{\"223\":1}}],[\"开发\",{\"0\":{\"122\":1},\"1\":{\"223\":1,\"226\":1,\"359\":2}}],[\"开发者首先需要定义\",{\"1\":{\"118\":1}}],[\"开发者指南是希望为该项目做出贡献的开发者的良好起点\",{\"1\":{\"105\":1}}],[\"开发完成管道后\",{\"1\":{\"89\":1}}],[\"开发与测试环境\",{\"1\":{\"27\":1}}],[\"开发环境中的资源限制\",{\"1\":{\"28\":1}}],[\"开发环境\",{\"1\":{\"22\":1}}],[\"默认情况下\",{\"1\":{\"445\":1}}],[\"默认root密码\",{\"1\":{\"366\":1}}],[\"默认文本分割时候的\",{\"1\":{\"365\":1}}],[\"默认文件名\",{\"1\":{\"75\":1}}],[\"默认\",{\"1\":{\"203\":1}}],[\"默认为空\",{\"1\":{\"158\":1}}],[\"默认为\",{\"1\":{\"158\":1}}],[\"默认是\",{\"1\":{\"158\":1}}],[\"默认值为\",{\"1\":{\"204\":1}}],[\"默认值\",{\"1\":{\"150\":21}}],[\"默认值等\",{\"1\":{\"92\":1}}],[\"默认的\",{\"1\":{\"97\":1}}],[\"默认选择\",{\"1\":{\"97\":1}}],[\"默认builder只支持一种架构指定\",{\"1\":{\"2\":1}}],[\"服务端数据库版本\",{\"1\":{\"380\":1}}],[\"服务启动\",{\"0\":{\"376\":1}}],[\"服务器之间通过\",{\"1\":{\"454\":1}}],[\"服务器间通信\",{\"1\":{\"348\":1}}],[\"服务器到外部网络的流量\",{\"1\":{\"346\":1}}],[\"服务器到存储\",{\"1\":{\"346\":1}}],[\"服务器接收到数据后\",{\"1\":{\"342\":1}}],[\"服务器接受时才会正式请求\",{\"1\":{\"75\":1}}],[\"服务器可以主动推送相关的css和javascript文件\",{\"1\":{\"272\":1}}],[\"服务器可以在客户端请求之前主动发送资源\",{\"1\":{\"272\":1}}],[\"服务器只能响应客户端的请求\",{\"1\":{\"272\":1}}],[\"服务器推送\",{\"0\":{\"272\":1},\"1\":{\"277\":1}}],[\"服务一起用于\",{\"1\":{\"97\":1}}],[\"服务\",{\"1\":{\"97\":1}}],[\"服务自身健康检查\",{\"1\":{\"49\":1}}],[\"一些研究工作探索了在gpu内存不足时\",{\"1\":{\"418\":1}}],[\"一些大型企业的网络也采用spine\",{\"1\":{\"348\":1}}],[\"一是它无法减少优化器状态\",{\"1\":{\"401\":1}}],[\"一周的时间足够开发一个新产品\",{\"1\":{\"359\":2}}],[\"一周开发一个新产品\",{\"1\":{\"359\":4}}],[\"一旦这些操作符在时间维度上被精心编排\",{\"1\":{\"431\":1}}],[\"一旦会话建立\",{\"1\":{\"311\":1}}],[\"一旦仪表板设置完成\",{\"1\":{\"212\":1}}],[\"一次正向传播一次反向传播\",{\"1\":{\"452\":1}}],[\"一次性带你做个全面了解\",{\"1\":{\"255\":1}}],[\"一次运行\",{\"1\":{\"95\":1}}],[\"一般的评估方法有什么\",{\"1\":{\"223\":1}}],[\"一组编排控制器执行完成管道所需的容器\",{\"1\":{\"85\":1}}],[\"一定要有\",{\"1\":{\"75\":1}}],[\"一个针对深度学习模型的自动并行化系统\",{\"1\":{\"454\":1}}],[\"一个最先进的搜索策略来确定这些算子的执行顺序\",{\"1\":{\"441\":1}}],[\"一个设备\",{\"1\":{\"440\":1}}],[\"一个算子的不同划分选项会带来不同的通信成本\",{\"1\":{\"440\":1}}],[\"一个大型模型可能由大约\",{\"1\":{\"425\":1}}],[\"一个新的框架\",{\"1\":{\"424\":1}}],[\"一个由openai训练的大型语言模型\",{\"1\":{\"372\":1}}],[\"一个as是一组由同一管理实体管理的ip网络和路由器\",{\"1\":{\"310\":1}}],[\"一个是专门为\",{\"1\":{\"457\":1}}],[\"一个是连接到传统二层网络的接口\",{\"1\":{\"291\":1}}],[\"一个是\",{\"1\":{\"255\":1}}],[\"一个类似枚举的类\",{\"1\":{\"206\":1}}],[\"一个线程\",{\"1\":{\"143\":1}}],[\"一个流行的工具包\",{\"1\":{\"122\":1}}],[\"一个连接基础设施\",{\"1\":{\"101\":1}}],[\"一个示例控制器是argo\",{\"1\":{\"85\":1}}],[\"一个\",{\"1\":{\"16\":1,\"203\":1,\"359\":4,\"443\":1,\"455\":1}}],[\"一个写请求需要经过集群多数节点确认\",{\"1\":{\"5\":1}}],[\"添加规则\",{\"1\":{\"331\":1}}],[\"添加路由\",{\"1\":{\"328\":1}}],[\"添加新功能可以通过新帧类型和更复杂的协议操作来实现\",{\"1\":{\"275\":1}}],[\"添加\",{\"1\":{\"75\":1}}],[\"禁用\",{\"1\":{\"150\":2}}],[\"禁用定期运行\",{\"1\":{\"95\":1}}],[\"禁用缓存\",{\"1\":{\"75\":1}}],[\"禁用发夹模式\",{\"1\":{\"47\":1}}],[\"$\",{\"1\":{\"381\":11}}],[\"$$\",{\"1\":{\"366\":2}}],[\"$request\",{\"1\":{\"75\":1}}],[\"$remote\",{\"1\":{\"75\":1}}],[\"$upstream\",{\"1\":{\"75\":2}}],[\"$server\",{\"1\":{\"75\":1}}],[\"$scheme\",{\"1\":{\"75\":1}}],[\"$proxy\",{\"1\":{\"75\":1}}],[\"$host\",{\"1\":{\"75\":1}}],[\"$http\",{\"1\":{\"75\":1}}],[\"标记帧属于哪个vlan\",{\"1\":{\"285\":1}}],[\"标记帧\",{\"1\":{\"285\":1}}],[\"标准化管理流程\",{\"1\":{\"120\":1}}],[\"标准\",{\"1\":{\"75\":1}}],[\"标识符\",{\"1\":{\"287\":1}}],[\"标识\",{\"1\":{\"36\":3}}],[\"加密通信\",{\"1\":{\"307\":1}}],[\"加密是可选的\",{\"1\":{\"274\":1}}],[\"加密和安全\",{\"0\":{\"274\":1},\"1\":{\"277\":1}}],[\"加密算法\",{\"1\":{\"75\":1}}],[\"加载的模块名称为\",{\"1\":{\"171\":1}}],[\"加载模块时被调用\",{\"1\":{\"170\":1}}],[\"加速了模型数据的交换\",{\"1\":{\"414\":1}}],[\"加速长上下文\",{\"1\":{\"249\":1}}],[\"加速功能与\",{\"1\":{\"166\":1}}],[\"加速ai项目的落地与应用\",{\"1\":{\"129\":1}}],[\"加法\",{\"1\":{\"158\":1}}],[\"加我v\",{\"1\":{\"138\":1}}],[\"加锁\",{\"1\":{\"5\":1}}],[\"渐变背景\",{\"1\":{\"75\":1}}],[\"<loopback>\",{\"1\":{\"283\":2}}],[\"<broadcast\",{\"1\":{\"282\":2,\"283\":2}}],[\"<body>\",{\"1\":{\"75\":1}}],[\"<mpi\",{\"1\":{\"199\":1}}],[\"<module\",{\"1\":{\"171\":1}}],[\"<meta\",{\"1\":{\"75\":2}}],[\"<python\",{\"1\":{\"170\":1}}],[\"<p><a\",{\"1\":{\"75\":1}}],[\"<超时时间\",{\"1\":{\"150\":1}}],[\"<1\",{\"1\":{\"150\":1}}],[\"<cuda\",{\"1\":{\"150\":1}}],[\"<检查迭代次数>\",{\"1\":{\"150\":1}}],[\"<0=rank0\",{\"1\":{\"150\":1}}],[\"<0\",{\"1\":{\"150\":4}}],[\"<循环次数>\",{\"1\":{\"150\":1}}],[\"<聚合次数>\",{\"1\":{\"150\":1}}],[\"<预热迭代次数>\",{\"1\":{\"150\":1}}],[\"<迭代次数>\",{\"1\":{\"150\":1}}],[\"<root\",{\"1\":{\"150\":1}}],[\"<nccltype\",{\"1\":{\"150\":1}}],[\"<stdio\",{\"1\":{\"199\":1}}],[\"<style>\",{\"1\":{\"75\":1}}],[\"<sum\",{\"1\":{\"150\":1}}],[\"<递增因子>\",{\"1\":{\"150\":1}}],[\"<递增字节数>\",{\"1\":{\"150\":1}}],[\"<最大字节数>\",{\"1\":{\"150\":1}}],[\"<最小字节数>\",{\"1\":{\"150\":1}}],[\"<每个线程的\",{\"1\":{\"150\":1}}],[\"<线程数>\",{\"1\":{\"150\":1}}],[\"<footer>\",{\"1\":{\"75\":1}}],[\"<title>hello\",{\"1\":{\"75\":1}}],[\"<h1>hello\",{\"1\":{\"75\":1}}],[\"<head>\",{\"1\":{\"75\":1}}],[\"<html\",{\"1\":{\"75\":1}}],[\"<\",{\"1\":{\"75\":7,\"433\":3,\"435\":1}}],[\"将新模型整合到现有的分布式训练框架中通常会遇到复杂的工程挑战\",{\"1\":{\"446\":1}}],[\"将新分区添加到\",{\"0\":{\"259\":1}}],[\"将通过\",{\"1\":{\"444\":1}}],[\"将在\",{\"1\":{\"430\":1}}],[\"将操作符\",{\"1\":{\"429\":1}}],[\"将这些原语结合起来\",{\"1\":{\"428\":1}}],[\"将这些优化策略嵌入到合适的位置\",{\"1\":{\"405\":1}}],[\"将模型代码与搜索空间和搜索策略相关的代码分离\",{\"1\":{\"431\":1}}],[\"将模型分为\",{\"1\":{\"425\":1}}],[\"将模型训练任务并行化到多个gpu设备上已经成为常态\",{\"1\":{\"398\":1}}],[\"将张量交换到cpu内存的可能性\",{\"1\":{\"418\":1}}],[\"将张量沿某些维度进行分区\",{\"1\":{\"398\":1}}],[\"将优化器状态从gpu卸载到cpu\",{\"1\":{\"412\":1}}],[\"将gpu\",{\"1\":{\"407\":1}}],[\"将目标张量划分为若干子块\",{\"1\":{\"406\":1}}],[\"将现有解决方案分类为两种正交方向\",{\"1\":{\"398\":1}}],[\"将独立开发当作\",{\"1\":{\"359\":2}}],[\"将其分区为两个\",{\"1\":{\"429\":1}}],[\"将其mac地址伪装成另一个设备的mac地址\",{\"1\":{\"306\":1}}],[\"将其添加到\",{\"1\":{\"259\":1}}],[\"将二层以太网帧封装在三层ip包中\",{\"1\":{\"286\":1}}],[\"将原有的linux卸载\",{\"1\":{\"264\":1}}],[\"将原始数据转换为预处理数据的\",{\"1\":{\"91\":1}}],[\"将需要迁移的linux\",{\"1\":{\"264\":1}}],[\"将动态稀疏注意力分为三种模式并设计搜索算法\",{\"1\":{\"249\":1}}],[\"将检查\",{\"1\":{\"206\":1}}],[\"将创建\",{\"1\":{\"204\":1}}],[\"将rank\",{\"1\":{\"183\":1}}],[\"将数据包通过数据链路层和物理层传输到目标服务器\",{\"1\":{\"342\":1}}],[\"将数据先进行\",{\"1\":{\"165\":1}}],[\"将数据从一个进程传递到所有其他进程\",{\"1\":{\"165\":1}}],[\"将输入张量进行分片\",{\"1\":{\"398\":1}}],[\"将输入张量\",{\"1\":{\"162\":1}}],[\"将返回\",{\"1\":{\"162\":1,\"206\":1}}],[\"将接收所有\",{\"1\":{\"158\":1}}],[\"将使用\",{\"1\":{\"158\":1}}],[\"将迭代捕获为\",{\"1\":{\"150\":1}}],[\"将性能报告为所有节点的平均值\",{\"1\":{\"150\":1}}],[\"将\",{\"1\":{\"120\":1}}],[\"将最佳的\",{\"1\":{\"78\":1}}],[\"将特定的路径请求路由到相应的服务\",{\"1\":{\"75\":1}}],[\"将kong中的服务映射到nginx容器中的资源\",{\"1\":{\"75\":1}}],[\"将上述\",{\"1\":{\"32\":1}}],[\"页面\",{\"1\":{\"74\":1,\"359\":2}}],[\"9b\",{\"1\":{\"456\":1}}],[\"9bzwq\",{\"1\":{\"97\":2}}],[\"920\",{\"1\":{\"446\":1}}],[\"92\",{\"1\":{\"381\":6}}],[\"92g5h\",{\"1\":{\"97\":2}}],[\"90\",{\"1\":{\"381\":1,\"416\":1}}],[\"90s\",{\"1\":{\"366\":1}}],[\"9091\",{\"1\":{\"366\":1}}],[\"9000\",{\"1\":{\"366\":4}}],[\"9001\",{\"1\":{\"366\":3,\"381\":3}}],[\"97\",{\"1\":{\"149\":2}}],[\"94\",{\"1\":{\"149\":1}}],[\"98\",{\"1\":{\"149\":3}}],[\"999\",{\"1\":{\"366\":2}}],[\"9999\",{\"1\":{\"36\":1}}],[\"9956596d8\",{\"1\":{\"97\":2}}],[\"9\",{\"0\":{\"74\":1,\"276\":1},\"1\":{\"149\":2,\"359\":4,\"366\":2,\"416\":1,\"457\":1,\"458\":1}}],[\"xxxx\",{\"1\":{\"382\":1}}],[\"xfs\",{\"1\":{\"261\":2}}],[\"xgboost\",{\"1\":{\"105\":1}}],[\"x\",{\"1\":{\"68\":1,\"69\":1,\"70\":1,\"71\":1,\"72\":1,\"73\":1,\"74\":1,\"75\":6,\"267\":1,\"268\":1,\"269\":1,\"270\":1,\"271\":1,\"272\":1,\"273\":1,\"274\":1,\"275\":1,\"276\":1,\"277\":1}}],[\"指示该\",{\"1\":{\"443\":1}}],[\"指示其状态\",{\"1\":{\"94\":1}}],[\"指的是一类独立的\",{\"1\":{\"359\":2}}],[\"指从数据中心内部到外部网络的流量或从外部网络到数据中心的流量\",{\"1\":{\"347\":1}}],[\"指数据中心内服务器之间的通信\",{\"1\":{\"347\":1}}],[\"指导国内开发者如何学习\",{\"1\":{\"226\":1}}],[\"指标解释\",{\"0\":{\"211\":1}}],[\"指向nginx服务中的\",{\"1\":{\"68\":1}}],[\"指定进程id\",{\"1\":{\"253\":1}}],[\"指定如何初始化进程组的\",{\"1\":{\"204\":1}}],[\"指定使用的后端\",{\"1\":{\"204\":1}}],[\"指定使用哪个\",{\"1\":{\"150\":1}}],[\"指定使用哪种数据类型\",{\"1\":{\"150\":1}}],[\"指定哪个\",{\"1\":{\"162\":1}}],[\"指定归约操作\",{\"1\":{\"158\":1}}],[\"指定执行哪种规约操作\",{\"1\":{\"150\":1}}],[\"指定\",{\"1\":{\"58\":1,\"162\":1,\"171\":1,\"203\":1}}],[\"指定了操作类型\",{\"1\":{\"162\":1}}],[\"指定了哪块\",{\"1\":{\"162\":1}}],[\"指定了具有相同标签\",{\"1\":{\"54\":1}}],[\"指定了限制适用于\",{\"1\":{\"26\":1}}],[\"指定了\",{\"1\":{\"21\":1,\"433\":1}}],[\"项目将以斯坦福大学大规模语言模型课程和李宏毅生成式ai课程为基础\",{\"1\":{\"231\":1}}],[\"项目的主要内容就是教程\",{\"1\":{\"220\":1}}],[\"项目简介\",{\"0\":{\"217\":1,\"222\":1,\"226\":1,\"228\":1,\"231\":1}}],[\"项目经验\",{\"0\":{\"131\":1}}],[\"项目是开源的\",{\"1\":{\"105\":1}}],[\"项目\",{\"1\":{\"105\":1}}],[\"项目致力于让机器学习\",{\"1\":{\"78\":1}}],[\"项目目录和nginx配置文件\",{\"1\":{\"66\":1}}],[\"项目来说\",{\"1\":{\"61\":1}}],[\"挂载\",{\"1\":{\"66\":1}}],[\"该调度类似于执行嵌入层和\",{\"1\":{\"452\":1}}],[\"该转换器结合了\",{\"1\":{\"445\":1}}],[\"该分割沿某一维度进行\",{\"1\":{\"433\":1}}],[\"该算法从与\",{\"1\":{\"429\":1}}],[\"该算法会在后续配置相较于前一个配置的性能提升不明显时终止\",{\"1\":{\"407\":1}}],[\"该服务器具有与前面实验相同的gpu配置\",{\"1\":{\"412\":1}}],[\"该服务器配备了8个v100\",{\"1\":{\"400\":1}}],[\"该系统由2000行c++和python代码组成\",{\"1\":{\"408\":1}}],[\"该模型比较不同优化方法的时间成本\",{\"1\":{\"405\":1}}],[\"该计划确定在内存压力下应用内存优化的张量候选\",{\"1\":{\"405\":1}}],[\"该配置文件只是给快速启动\",{\"1\":{\"366\":1}}],[\"该响应帧包含设备b的mac地址\",{\"1\":{\"303\":1}}],[\"该arp请求包含设备b的ip地址\",{\"1\":{\"303\":1}}],[\"该帧首先被发送到本地的vtep\",{\"1\":{\"292\":1}}],[\"该命令会列出系统中所有的网络接口\",{\"1\":{\"279\":1}}],[\"该类的值是小写字符串\",{\"1\":{\"206\":1}}],[\"该函数将返回\",{\"1\":{\"165\":1}}],[\"该函数执行\",{\"1\":{\"157\":1}}],[\"该函数通过调用\",{\"1\":{\"157\":1}}],[\"该函数会抛出\",{\"1\":{\"150\":1}}],[\"该库经过优化\",{\"1\":{\"143\":1}}],[\"该容器暴露8088端口并挂载了配置文件和项目目录\",{\"1\":{\"66\":1}}],[\"该状态表示\",{\"1\":{\"12\":1,\"13\":1,\"14\":1,\"15\":1}}],[\"6的gpu内存\",{\"1\":{\"416\":1}}],[\"6倍\",{\"1\":{\"415\":1}}],[\"67b\",{\"1\":{\"416\":2}}],[\"67b时\",{\"1\":{\"411\":1}}],[\"67b和4b\",{\"1\":{\"410\":1}}],[\"63\",{\"1\":{\"149\":1}}],[\"66\",{\"1\":{\"149\":1}}],[\"66457c4745\",{\"1\":{\"97\":2}}],[\"68\",{\"1\":{\"149\":1}}],[\"64b时\",{\"1\":{\"411\":1}}],[\"64b是一个中等规模的模型\",{\"1\":{\"410\":1}}],[\"64b模型\",{\"1\":{\"398\":1}}],[\"64\",{\"1\":{\"149\":3,\"283\":1}}],[\"6bff\",{\"1\":{\"149\":1}}],[\"6c686b5b54\",{\"1\":{\"97\":2}}],[\"6553\",{\"1\":{\"149\":1}}],[\"65536\",{\"1\":{\"149\":2,\"283\":2}}],[\"65j6h\",{\"1\":{\"97\":2}}],[\"65\",{\"1\":{\"75\":1,\"149\":1,\"435\":1,\"454\":1}}],[\"6\",{\"0\":{\"71\":1,\"262\":1,\"273\":1,\"339\":1,\"442\":1},\"1\":{\"149\":2,\"175\":1,\"176\":1,\"366\":5,\"410\":1,\"412\":1,\"416\":3,\"436\":1,\"452\":2,\"455\":1,\"456\":1,\"458\":1}}],[\"61\",{\"1\":{\"97\":1,\"149\":3}}],[\"619995\",{\"1\":{\"62\":1}}],[\"619656\",{\"1\":{\"62\":1}}],[\"611818\",{\"1\":{\"62\":1}}],[\"60\",{\"1\":{\"149\":1,\"458\":1,\"459\":1}}],[\"608035\",{\"1\":{\"62\":1}}],[\"607274\",{\"1\":{\"62\":1}}],[\"605172\",{\"1\":{\"62\":1}}],[\"604995\",{\"1\":{\"62\":1}}],[\"overview\",{\"1\":{\"442\":1}}],[\"osdi24\",{\"1\":{\"422\":1}}],[\"osi模型通过将网络通信过程划分为七个独立的层次\",{\"1\":{\"343\":1}}],[\"o带宽的存储空间进行张量交换\",{\"1\":{\"412\":1}}],[\"ollama\",{\"1\":{\"228\":3}}],[\"old\",{\"1\":{\"156\":1}}],[\"other\",{\"1\":{\"205\":1,\"382\":1}}],[\"otherwise\",{\"1\":{\"150\":1}}],[\"obj\",{\"1\":{\"167\":4,\"168\":5,\"169\":1}}],[\"ooiioo\",{\"1\":{\"161\":1,\"162\":2}}],[\"o\",{\"1\":{\"150\":1,\"162\":4,\"196\":1,\"255\":4}}],[\"ok\",{\"1\":{\"149\":1,\"366\":1}}],[\"out任务分别管理两个额外的线程\",{\"1\":{\"408\":1}}],[\"out\",{\"1\":{\"149\":2}}],[\"output=output\",{\"1\":{\"160\":1}}],[\"output=none\",{\"1\":{\"156\":1}}],[\"outputs\",{\"1\":{\"156\":5,\"158\":2,\"159\":2}}],[\"output\",{\"1\":{\"95\":1,\"156\":21,\"158\":3,\"159\":3,\"160\":3,\"161\":6,\"162\":5}}],[\"ofst\",{\"1\":{\"433\":1,\"437\":2}}],[\"ofst=|d|\",{\"1\":{\"433\":1}}],[\"of\",{\"1\":{\"105\":1,\"149\":2,\"150\":3,\"154\":1,\"156\":5,\"205\":2,\"211\":1,\"212\":3,\"382\":1,\"442\":1}}],[\"offload将优化器状态卸载到cpu会在每个微批次中导致频繁的数据移动\",{\"1\":{\"412\":1}}],[\"offload的gpu计算效率高出20\",{\"1\":{\"412\":1}}],[\"offload\",{\"1\":{\"412\":3,\"454\":2,\"455\":1,\"456\":1,\"457\":1}}],[\"offload和zero\",{\"1\":{\"410\":1,\"418\":1}}],[\"off\",{\"1\":{\"75\":3,\"149\":2}}],[\"octet\",{\"1\":{\"75\":1}}],[\"order\",{\"0\":{\"431\":1},\"1\":{\"423\":1,\"424\":1,\"428\":1,\"431\":1,\"433\":4,\"439\":2}}],[\"org\",{\"1\":{\"78\":1,\"422\":1}}],[\"origin=http\",{\"1\":{\"381\":1}}],[\"origin\",{\"1\":{\"75\":2,\"381\":1}}],[\"or\",{\"1\":{\"62\":1,\"161\":1}}],[\"onyx\",{\"1\":{\"365\":3}}],[\"once\",{\"1\":{\"212\":1}}],[\"only\",{\"1\":{\"205\":1}}],[\"oneapimmysql\",{\"1\":{\"366\":2}}],[\"oneapi\",{\"0\":{\"369\":1},\"1\":{\"366\":7}}],[\"one\",{\"1\":{\"175\":1,\"359\":1,\"366\":2}}],[\"on\",{\"0\":{\"362\":1},\"1\":{\"62\":3,\"75\":2,\"98\":1,\"149\":1,\"150\":1,\"175\":4,\"366\":3,\"370\":1,\"372\":3,\"381\":2,\"393\":2,\"422\":1},\"2\":{\"378\":1}}],[\"opj\",{\"1\":{\"433\":1}}],[\"opi\",{\"1\":{\"433\":1}}],[\"ops\",{\"1\":{\"433\":1}}],[\"op2\",{\"1\":{\"431\":3}}],[\"op1\",{\"1\":{\"431\":2}}],[\"op=sum\",{\"1\":{\"156\":1}}],[\"op=exists\",{\"1\":{\"36\":2}}],[\"op\",{\"0\":{\"429\":1,\"430\":1,\"431\":1},\"1\":{\"150\":1,\"156\":2,\"158\":1,\"159\":1,\"161\":4,\"162\":4,\"423\":2,\"424\":3,\"428\":3,\"429\":4,\"430\":4,\"431\":6,\"433\":10,\"435\":3,\"439\":3,\"443\":1,\"444\":1}}],[\"opt\",{\"1\":{\"366\":1,\"372\":1}}],[\"optuna\",{\"1\":{\"106\":1}}],[\"optional<at\",{\"1\":{\"161\":1}}],[\"optional\",{\"1\":{\"156\":3,\"158\":3,\"202\":6}}],[\"options\",{\"1\":{\"75\":4,\"202\":1,\"204\":2}}],[\"optimization\",{\"1\":{\"105\":1}}],[\"operation\",{\"1\":{\"304\":1}}],[\"operate\",{\"1\":{\"263\":1}}],[\"operator\",{\"0\":{\"116\":1,\"117\":1,\"118\":1,\"119\":1,\"120\":1,\"121\":1,\"122\":1},\"1\":{\"36\":1,\"54\":1,\"56\":1,\"106\":1,\"116\":3,\"117\":1,\"118\":3,\"119\":5,\"120\":3,\"121\":3,\"122\":4,\"123\":4,\"393\":2,\"422\":1},\"2\":{\"125\":1}}],[\"openai\",{\"1\":{\"365\":12,\"366\":2,\"382\":4}}],[\"openapi\",{\"1\":{\"365\":1}}],[\"open消息以建立bgp会话\",{\"1\":{\"311\":1}}],[\"openmpi\",{\"1\":{\"197\":1}}],[\"open\",{\"1\":{\"149\":1,\"372\":2}}],[\"openssl\",{\"1\":{\"75\":1,\"366\":1}}],[\"jit\",{\"1\":{\"445\":1}}],[\"jpeg\",{\"1\":{\"339\":1}}],[\"jpg\",{\"1\":{\"242\":1}}],[\"j\",{\"1\":{\"145\":1,\"331\":2,\"429\":1,\"431\":1}}],[\"jeff\",{\"1\":{\"139\":1}}],[\"js\",{\"1\":{\"366\":2}}],[\"js进行动态\",{\"1\":{\"130\":1}}],[\"json5\",{\"1\":{\"365\":1}}],[\"json\",{\"0\":{\"383\":1},\"1\":{\"31\":1,\"60\":2,\"366\":2,\"381\":2,\"383\":1}}],[\"javascript\",{\"1\":{\"228\":1}}],[\"java\",{\"1\":{\"127\":1,\"228\":1,\"389\":1}}],[\"jobservice\",{\"1\":{\"108\":1,\"111\":1}}],[\"job\",{\"1\":{\"95\":1}}],[\"justify\",{\"1\":{\"75\":1}}],[\"jul\",{\"1\":{\"62\":8}}],[\"解密\",{\"1\":{\"339\":1}}],[\"解封装的以太网帧被发送到目标主机b所在的二层网络\",{\"1\":{\"292\":1}}],[\"解封装出原始的以太网帧\",{\"1\":{\"292\":1}}],[\"解释命令\",{\"0\":{\"253\":1}}],[\"解释为什么我们选择使用队列计算比率\",{\"1\":{\"212\":1}}],[\"解释器会调用\",{\"1\":{\"173\":1}}],[\"解决十亿规模模型训练中的gpu内存壁垒问题\",{\"1\":{\"419\":1}}],[\"解决ubantu\",{\"1\":{\"263\":1}}],[\"解决复杂的系统问题\",{\"1\":{\"127\":1}}],[\"解决了传统树形架构中容易出现的瓶颈问题\",{\"1\":{\"349\":1}}],[\"解决了\",{\"1\":{\"106\":1}}],[\"解决\",{\"1\":{\"62\":1}}],[\"解析这些应用范例的\",{\"1\":{\"223\":1}}],[\"解析\",{\"1\":{\"38\":1}}],[\"发布等环节\",{\"1\":{\"359\":2}}],[\"发布\",{\"1\":{\"359\":4}}],[\"发送设备的ip地址\",{\"1\":{\"304\":1}}],[\"发送设备的mac地址\",{\"1\":{\"304\":1}}],[\"发送方协议地址\",{\"1\":{\"304\":1}}],[\"发送方硬件地址\",{\"1\":{\"304\":1}}],[\"发生中断后的工作是必须要完成的\",{\"1\":{\"255\":1}}],[\"发出一个\",{\"1\":{\"255\":1}}],[\"发音为\",{\"1\":{\"143\":1}}],[\"发起真正的\",{\"1\":{\"61\":1}}],[\"发夹模式\",{\"1\":{\"45\":1}}],[\"所代表的\",{\"1\":{\"443\":1}}],[\"所示\",{\"1\":{\"433\":1,\"435\":1,\"443\":1,\"455\":1}}],[\"所有服务器均安装了\",{\"1\":{\"454\":1}}],[\"所有层组合成一个调度\",{\"1\":{\"452\":1}}],[\"所有这些并行策略在支持十亿规模的单服务器训练时都会遇到gpu内存瓶颈\",{\"1\":{\"398\":1}}],[\"所有的leaf交换机都会直接连接到上层的spine交换机\",{\"1\":{\"346\":1}}],[\"所有的nic流量都集中在同一个gpu上\",{\"1\":{\"176\":1}}],[\"所有请求被平等对待\",{\"1\":{\"273\":1}}],[\"所有方向都需要掌握的基础技能和概念\",{\"1\":{\"226\":1}}],[\"所有处理单元\",{\"1\":{\"185\":1}}],[\"所有测试支持相同的一组参数\",{\"1\":{\"150\":1}}],[\"所以这个硬中断的时间不能太长\",{\"1\":{\"255\":1}}],[\"所以这时候\",{\"1\":{\"61\":1}}],[\"所以应在必要时使用\",{\"1\":{\"255\":1}}],[\"所以在执行这些操作前释放\",{\"1\":{\"162\":1}}],[\"所管理的宿主机上不可压缩资源短缺时\",{\"1\":{\"51\":1}}],[\"给定一组设备d\",{\"1\":{\"433\":1}}],[\"给定一组设备\",{\"1\":{\"430\":1}}],[\"给定\",{\"1\":{\"425\":1}}],[\"给\",{\"1\":{\"61\":1}}],[\"uri=mongodb\",{\"1\":{\"366\":1}}],[\"url是oneapi中的令牌地址\",{\"1\":{\"366\":1}}],[\"urls\",{\"1\":{\"366\":1}}],[\"urls=http\",{\"1\":{\"366\":1}}],[\"url=postgresql\",{\"1\":{\"381\":1}}],[\"url=https\",{\"1\":{\"382\":1}}],[\"url=http\",{\"1\":{\"366\":2,\"381\":2}}],[\"url=\",{\"1\":{\"68\":1}}],[\"url\",{\"1\":{\"61\":3,\"203\":2,\"204\":1}}],[\"u\",{\"1\":{\"366\":2,\"381\":1}}],[\"udp\",{\"1\":{\"337\":1}}],[\"udp包的源ip和目的ip是vtep的ip地址\",{\"1\":{\"292\":1}}],[\"udp隧道封装\",{\"1\":{\"287\":1}}],[\"uds\",{\"1\":{\"149\":1}}],[\"umount\",{\"1\":{\"257\":1}}],[\"ubuntu22\",{\"1\":{\"264\":2}}],[\"ubuntu\",{\"0\":{\"238\":1},\"1\":{\"264\":5}}],[\"utilization\",{\"1\":{\"212\":1}}],[\"utf\",{\"1\":{\"75\":1}}],[\"update\",{\"1\":{\"311\":1,\"366\":2}}],[\"up>\",{\"1\":{\"282\":2,\"283\":2}}],[\"up\",{\"1\":{\"282\":2,\"283\":4,\"319\":1,\"325\":1}}],[\"uppercase\",{\"1\":{\"205\":1}}],[\"upgrade\",{\"1\":{\"75\":3}}],[\"ucc\",{\"1\":{\"204\":2,\"205\":1,\"206\":1,\"207\":3}}],[\"usage\",{\"1\":{\"255\":1}}],[\"usenix\",{\"1\":{\"422\":1}}],[\"use\",{\"1\":{\"164\":1,\"165\":2,\"205\":1,\"212\":1,\"372\":2,\"381\":1}}],[\"user=your\",{\"1\":{\"382\":1}}],[\"user=postgres\",{\"1\":{\"381\":1}}],[\"user=$\",{\"1\":{\"381\":1}}],[\"username=myusername\",{\"1\":{\"366\":1}}],[\"users\",{\"1\":{\"205\":1,\"242\":2}}],[\"user\",{\"1\":{\"156\":1,\"161\":2,\"162\":1,\"255\":1,\"381\":1,\"382\":1}}],[\"usedinqueryextension\",{\"1\":{\"365\":2}}],[\"usedintoolcall\",{\"1\":{\"365\":2}}],[\"usedinextractfields\",{\"1\":{\"365\":2}}],[\"usedinclassify\",{\"1\":{\"365\":2}}],[\"used\",{\"1\":{\"156\":1,\"205\":1,\"212\":1}}],[\"us\",{\"1\":{\"149\":2,\"211\":4,\"255\":4}}],[\"using\",{\"1\":{\"149\":6,\"387\":1}}],[\"ui库的使用\",{\"1\":{\"130\":1}}],[\"ui\",{\"1\":{\"89\":1,\"94\":1,\"95\":3,\"97\":6,\"103\":2,\"104\":1,\"130\":1}}],[\"until\",{\"1\":{\"366\":1}}],[\"untolerated\",{\"1\":{\"36\":1}}],[\"unconfined\",{\"1\":{\"366\":1,\"372\":1}}],[\"unknown\",{\"1\":{\"282\":2}}],[\"unregister\",{\"1\":{\"264\":1}}],[\"unreachable\",{\"1\":{\"36\":1}}],[\"undefined\",{\"1\":{\"207\":1}}],[\"undefined``\",{\"1\":{\"205\":1}}],[\"unpack\",{\"1\":{\"161\":2,\"162\":2}}],[\"unit\",{\"1\":{\"263\":1}}],[\"uninterruptible\",{\"1\":{\"255\":1}}],[\"universe\",{\"1\":{\"224\":1}}],[\"universal\",{\"1\":{\"122\":1}}],[\"unique\",{\"1\":{\"164\":2,\"165\":4}}],[\"union\",{\"1\":{\"156\":1,\"158\":1}}],[\"unix\",{\"1\":{\"62\":2}}],[\"unlock\",{\"1\":{\"5\":3,\"218\":1}}],[\"我的家人\",{\"1\":{\"372\":1}}],[\"我想给你做个补充\",{\"1\":{\"255\":1}}],[\"我拥有将技术与商业需求相结合的能力\",{\"1\":{\"131\":1}}],[\"我在java领域有着深厚的积累\",{\"1\":{\"127\":1}}],[\"我不仅关注性能优化和可扩展性\",{\"1\":{\"126\":1}}],[\"我始终追求技术创新\",{\"1\":{\"126\":1}}],[\"我是一名充满热情的全栈开发工程师\",{\"1\":{\"126\":1}}],[\"我们与两个基线进行了比较\",{\"1\":{\"457\":1}}],[\"我们与这些团队的合作也带来了许多启示\",{\"1\":{\"446\":1}}],[\"我们应用了逐层重计算\",{\"1\":{\"454\":1}}],[\"我们应该只将d2d交换应用于性能至关重要的情况\",{\"1\":{\"407\":1}}],[\"我们应该优先考虑对模型的后期层使用重计算来缓解内存限制\",{\"1\":{\"407\":1}}],[\"我们分别在\",{\"1\":{\"453\":1}}],[\"我们对实际模型的性能进行了评估\",{\"1\":{\"450\":1}}],[\"我们对共计\",{\"1\":{\"226\":1}}],[\"我们正在积极探索支持更多算子及其对应的转换算法的方法\",{\"1\":{\"445\":1}}],[\"我们基于\",{\"1\":{\"445\":1}}],[\"我们决定在不同微批次中交错前向和反向传播\",{\"1\":{\"437\":1}}],[\"我们决定使用固定内存作为交换空间\",{\"1\":{\"408\":1}}],[\"我们观察到\",{\"1\":{\"435\":1,\"448\":1}}],[\"我们把这些\",{\"1\":{\"431\":1}}],[\"我们相信\",{\"1\":{\"419\":1}}],[\"我们预计每个gpu的pcie带宽需要超过140gb\",{\"1\":{\"417\":1}}],[\"我们发现\",{\"1\":{\"417\":1}}],[\"我们得出结论\",{\"1\":{\"414\":1}}],[\"我们设计了一个编译过程\",{\"1\":{\"427\":1}}],[\"我们设计了一个极端案例\",{\"1\":{\"414\":1}}],[\"我们设计了一种设备\",{\"1\":{\"406\":1}}],[\"我们进行了简单的分析\",{\"1\":{\"417\":1}}],[\"我们进行了敏感性分析\",{\"1\":{\"413\":1}}],[\"我们进一步将正向子图表示为fgi\",{\"1\":{\"433\":1}}],[\"我们进一步构建了一个独立于pytorch运行时的主机固定内存池\",{\"1\":{\"408\":1}}],[\"我们进一步演进了数据分条技术\",{\"1\":{\"406\":1}}],[\"我们无法在上述amazon\",{\"1\":{\"412\":1}}],[\"我们测试了参数规模为6\",{\"1\":{\"411\":1}}],[\"我们测量了每秒处理的样本总数\",{\"1\":{\"410\":1}}],[\"我们首先分析了参数规模为0\",{\"1\":{\"411\":1}}],[\"我们首先执行生命周期变量分析来计算每个张量的生命周期\",{\"1\":{\"407\":1}}],[\"我们运行了两种mpress变体\",{\"1\":{\"410\":1}}],[\"我们通过分别遍历流水线并行\",{\"1\":{\"454\":1}}],[\"我们通过实现表\",{\"1\":{\"451\":1}}],[\"我们通过在pipedream和dapple系统中集成mpress\",{\"1\":{\"419\":1}}],[\"我们通过以下几个方面分析了结果\",{\"1\":{\"411\":1}}],[\"我们通过测量模型前向传播的flops\",{\"1\":{\"410\":1}}],[\"我们通过调整编码器层的数量和隐藏层的大小\",{\"1\":{\"410\":1}}],[\"我们通过将pipedream的原始pytorch版本从1\",{\"1\":{\"408\":1}}],[\"我们选择了两个广泛使用的dnn模型bert和gpt\",{\"1\":{\"410\":1}}],[\"我们选择操作间并行作为研究的出发点\",{\"1\":{\"398\":1}}],[\"我们在\",{\"1\":{\"454\":2,\"458\":1}}],[\"我们在一台高端gpu服务器上运行测试\",{\"1\":{\"412\":1}}],[\"我们在pipedream上运行mpress\",{\"1\":{\"410\":1}}],[\"我们在dgx\",{\"1\":{\"410\":1}}],[\"我们在执行交换操作之前记录子块数量\",{\"1\":{\"406\":1}}],[\"我们就接受它\",{\"1\":{\"407\":1}}],[\"我们就称之为\",{\"1\":{\"61\":1}}],[\"我们尽量使用d2d交换来减少它们的内存占用\",{\"1\":{\"407\":1}}],[\"我们引入了一个近似的搜索算法\",{\"1\":{\"407\":1}}],[\"我们引入了以下两项关键技术来优化d2d交换\",{\"1\":{\"406\":1}}],[\"我们还应用了数据并行性来扩展\",{\"1\":{\"457\":1}}],[\"我们还报告了每种优化方法对gpu内存减少的百分比贡献\",{\"1\":{\"416\":1}}],[\"我们还可以将其优化为多线程版本\",{\"1\":{\"414\":1}}],[\"我们还评估了运行设备映射算法的时间开销\",{\"1\":{\"414\":1}}],[\"我们还运行了两个最先进的训练系统\",{\"1\":{\"410\":1}}],[\"我们还部署了两种系统作为基线\",{\"1\":{\"410\":1}}],[\"我们还使用了另一台提供商的dgx\",{\"1\":{\"410\":1}}],[\"我们还管理了一个元数据表\",{\"1\":{\"406\":1}}],[\"我们还剩两个类型的\",{\"1\":{\"255\":1}}],[\"我们将搜索到的并行化计划应用于简化后的模型\",{\"1\":{\"448\":1}}],[\"我们将搜索空间表示为\",{\"1\":{\"439\":1}}],[\"我们将说明如何使用三个原语和约束\",{\"1\":{\"432\":1}}],[\"我们将\",{\"1\":{\"429\":1,\"454\":1}}],[\"我们将本文的相关工作分为以下几类进行讨论\",{\"1\":{\"418\":1}}],[\"我们将mpress与三个强大的基线系统进行了对比\",{\"1\":{\"412\":1}}],[\"我们将mpress集成到了pipedream和dapple这两个最近的操作间并行训练系统中\",{\"1\":{\"408\":1}}],[\"我们将原始dapple作为自然基线\",{\"1\":{\"410\":1}}],[\"我们将微批次大小设置为2\",{\"1\":{\"410\":1}}],[\"我们将微批次大小设置为12\",{\"1\":{\"410\":1}}],[\"我们将继续使mpress适用于这些系统\",{\"1\":{\"408\":1}}],[\"我们将上述设计原则集成到开源训练系统mpress中\",{\"1\":{\"408\":1}}],[\"我们将gpu\",{\"1\":{\"407\":1}}],[\"我们将子块划分为等大小\",{\"1\":{\"406\":1}}],[\"我们将持续根据社区贡献和反馈进行内容的更新和优化\",{\"1\":{\"231\":1}}],[\"我们必须综合考虑以下两个关键因素\",{\"1\":{\"406\":1}}],[\"我们使用了累计的有效\",{\"1\":{\"454\":1}}],[\"我们使用不同参数规模的gpt模型在dgx\",{\"1\":{\"412\":1}}],[\"我们使用bert和gpt模型推荐的计算平衡阶段分区策略\",{\"1\":{\"410\":1}}],[\"我们使用原始的pipedream作为没有内存优化的基线操作间并行训练系统\",{\"1\":{\"410\":1}}],[\"我们使用调整后的参数对gpt及其变体进行训练\",{\"1\":{\"410\":1}}],[\"我们使用squad\",{\"1\":{\"410\":1}}],[\"我们使用模拟器运行最新的配置\",{\"1\":{\"407\":1}}],[\"我们使用模拟器根据修改后的数据流图执行一次训练迭代\",{\"1\":{\"405\":1}}],[\"我们使用pipedream和dapple两个代表性系统训练了两个流行的dnn模型bert和gpt\",{\"1\":{\"400\":1}}],[\"我们可以将\",{\"1\":{\"436\":1}}],[\"我们可以积极满足每个gpu的内存交换带宽需求\",{\"1\":{\"404\":1}}],[\"我们可以用上面这张图\",{\"1\":{\"255\":1}}],[\"我们只对少量生命周期较短的模型数据应用d2d交换\",{\"1\":{\"404\":1}}],[\"我们提出了nnscaler\",{\"1\":{\"423\":1,\"424\":1}}],[\"我们提出了一个近似搜索算法\",{\"1\":{\"407\":1}}],[\"我们提出了一种新的gpu\",{\"1\":{\"402\":1}}],[\"我们提出了mpress\",{\"1\":{\"404\":1,\"419\":1}}],[\"我们专注于通过操作间并行实现十亿规模模型的高效训练\",{\"1\":{\"398\":1}}],[\"我们介绍了大部分的\",{\"1\":{\"255\":1}}],[\"我们期待通过这个项目\",{\"1\":{\"231\":1}}],[\"我们希望建立一个具有广泛参考价值的项目\",{\"1\":{\"231\":1}}],[\"我们的评估在配备\",{\"1\":{\"454\":1}}],[\"我们的评估旨在回答以下几个问题\",{\"1\":{\"409\":1}}],[\"我们的实验结果表明\",{\"1\":{\"424\":1}}],[\"我们的研究表明\",{\"1\":{\"423\":1,\"424\":1}}],[\"我们的搜索算法不会带来高额的开销\",{\"1\":{\"414\":1}}],[\"我们的配额申请多次失败\",{\"1\":{\"410\":1}}],[\"我们的内存管理器负责为张量分配和释放gpu\",{\"1\":{\"408\":1}}],[\"我们的算法会经历一些迭代步骤来逐步更新内存减少优化配置\",{\"1\":{\"407\":1}}],[\"我们的项目团队成员将分工负责各个章节的内容梳理和撰写\",{\"1\":{\"231\":1}}],[\"我们的教程提供清晰的步骤和实用的技巧\",{\"1\":{\"228\":1}}],[\"我们的目标不是重新创建其他服务\",{\"1\":{\"78\":1}}],[\"我们会根据课程内容将课程进行分级合并\",{\"1\":{\"226\":1}}],[\"我们欢迎每一位开发者参考我们已有课程的格式和写法来对课程进行复现并提交\",{\"1\":{\"226\":1}}],[\"我才能有机会\",{\"1\":{\"5\":1}}],[\"需要处理的搜索空间\",{\"1\":{\"459\":1}}],[\"需要注意的是\",{\"1\":{\"405\":1,\"408\":1,\"412\":1,\"429\":1}}],[\"需要保存多版本的模型数据\",{\"1\":{\"400\":1}}],[\"需要最新版的\",{\"1\":{\"365\":1}}],[\"需要有心理准备\",{\"1\":{\"359\":2}}],[\"需要重申审视是不是你的产品功能和特性不够\",{\"1\":{\"359\":2}}],[\"需要考虑产品适合使用哪种产品形态\",{\"1\":{\"359\":2}}],[\"需要大致正确即可\",{\"1\":{\"359\":2}}],[\"需要专业知识和经验\",{\"1\":{\"315\":1}}],[\"需要额外的配置和措施来防止路由劫持和攻击\",{\"1\":{\"314\":1}}],[\"需要深入的网络知识\",{\"1\":{\"314\":1}}],[\"需要配置隧道端点\",{\"1\":{\"287\":1}}],[\"需要等待当前请求完成后\",{\"1\":{\"270\":1}}],[\"需要使用\",{\"1\":{\"263\":1}}],[\"需要同时计算两个独立的物理过程\",{\"1\":{\"193\":1}}],[\"需要跟容器项目维护一个长连接来传输数据\",{\"1\":{\"61\":1}}],[\"需要手动编辑对应的\",{\"1\":{\"34\":1}}],[\"需要手工处理\",{\"1\":{\"10\":1}}],[\"问题背景\",{\"0\":{\"394\":1}}],[\"问题\",{\"1\":{\"60\":1,\"417\":1}}],[\"启用重计算的dapple能够成功训练最多10\",{\"1\":{\"412\":1}}],[\"启用了高性能重计算\",{\"1\":{\"412\":1}}],[\"启用或禁用接口\",{\"1\":{\"319\":1,\"325\":1}}],[\"启用systemd\",{\"0\":{\"263\":1}}],[\"启用\",{\"1\":{\"95\":1}}],[\"启用发夹模式\",{\"1\":{\"47\":1}}],[\"启动张量传输任务并与dnn计算同步检查其状态\",{\"1\":{\"408\":1}}],[\"启动聚合更新\",{\"1\":{\"366\":1}}],[\"启动mongodb服务\",{\"1\":{\"366\":1}}],[\"启动\",{\"1\":{\"255\":1}}],[\"启动时就一起启动\",{\"1\":{\"61\":1}}],[\"启动调度器时使用该策略文件\",{\"1\":{\"60\":1}}],[\"数值模拟\",{\"1\":{\"187\":1,\"198\":1}}],[\"数量足够多时\",{\"1\":{\"454\":1}}],[\"数量>\",{\"1\":{\"150\":1}}],[\"数量\",{\"1\":{\"150\":2,\"453\":1}}],[\"数量与其他节点上的最大偏差不超过1\",{\"1\":{\"58\":1}}],[\"数据依赖的物化\",{\"0\":{\"444\":1}}],[\"数据是在前面的d2d交换默认设置基础上进行的\",{\"1\":{\"414\":1}}],[\"数据并行性和灵活的张量并行性可以轻松支持\",{\"1\":{\"451\":1}}],[\"数据并行性是一种特殊的并行化计划\",{\"1\":{\"425\":1}}],[\"数据并行始终沿着批次维度进行分割\",{\"1\":{\"433\":1}}],[\"数据并行和张量并行\",{\"1\":{\"454\":1}}],[\"数据并行和张量并行的三维并行化方式\",{\"1\":{\"454\":1}}],[\"数据并行和张量并行的约束\",{\"1\":{\"433\":1}}],[\"数据并行和张量并行都将算子均匀地分成n个部分\",{\"1\":{\"433\":1}}],[\"数据并行训练带来了最重的内存负担和跨gpu通信开销\",{\"1\":{\"398\":1}}],[\"数据并行作为最简单的操作内并行\",{\"1\":{\"398\":1}}],[\"数据并行\",{\"1\":{\"398\":1}}],[\"数据中心\",{\"1\":{\"348\":1}}],[\"数据中心和云环境中的大规模虚拟化网络\",{\"1\":{\"286\":1}}],[\"数据分条使mpress性能比默认设置提高了11\",{\"1\":{\"414\":1}}],[\"数据分条\",{\"1\":{\"406\":1}}],[\"数据分段和重组\",{\"1\":{\"337\":1}}],[\"数据分析\",{\"1\":{\"198\":1}}],[\"数据分析和异构计算等领域\",{\"1\":{\"195\":1}}],[\"数据链路层\",{\"0\":{\"335\":1}}],[\"数据处理等需要处理大量计算的场景\",{\"1\":{\"197\":1}}],[\"数据的划分方式可以根据具体应用进行调整\",{\"1\":{\"190\":1}}],[\"数据的数据库\",{\"1\":{\"97\":1}}],[\"数据库最大连接数\",{\"1\":{\"366\":1}}],[\"数据库的默认账号和密码仅首次运行时设置有效\",{\"1\":{\"366\":1}}],[\"数据库的创建\",{\"1\":{\"121\":1}}],[\"数据库集群的创建\",{\"1\":{\"119\":1}}],[\"数据库管理器\",{\"1\":{\"97\":1}}],[\"数据可视化和认证功能\",{\"1\":{\"111\":1}}],[\"数据可能仍然存在于\",{\"1\":{\"14\":1}}],[\"数据转换\",{\"1\":{\"90\":1}}],[\"数据工件列表\",{\"1\":{\"88\":1}}],[\"应该在\",{\"1\":{\"433\":1}}],[\"应该均匀地分布在不同的节点上\",{\"1\":{\"58\":1}}],[\"应运而生\",{\"1\":{\"249\":1}}],[\"应为\",{\"1\":{\"204\":1}}],[\"应用约束后\",{\"1\":{\"440\":1,\"459\":1}}],[\"应用哪种优化以及何时执行相应的优化或恢复被节省的张量\",{\"1\":{\"405\":1}}],[\"应用示例\",{\"0\":{\"342\":1}}],[\"应用层的http协议将请求传递到传输层的tcp协议\",{\"1\":{\"342\":1}}],[\"应用层\",{\"0\":{\"340\":1}}],[\"应用实例\",{\"1\":{\"223\":1}}],[\"应用开发的门槛\",{\"1\":{\"218\":1}}],[\"应用场景\",{\"0\":{\"155\":1,\"187\":1,\"192\":1},\"1\":{\"191\":1,\"287\":1}}],[\"应用部署和管理\",{\"1\":{\"119\":1}}],[\"应用\",{\"0\":{\"223\":1},\"1\":{\"118\":1,\"223\":1,\"452\":1}}],[\"应用需要自定义的服务发现机制\",{\"1\":{\"39\":1}}],[\"应用程序中使用\",{\"1\":{\"143\":1}}],[\"应用程序的配置\",{\"1\":{\"116\":1}}],[\"应用程序的资源标准化和资源优化\",{\"1\":{\"28\":1}}],[\"应用程序使用通用的标签和注释\",{\"1\":{\"103\":1}}],[\"应用程序级别的健康检查\",{\"1\":{\"101\":1}}],[\"应用程序\",{\"0\":{\"100\":1}}],[\"应用程序标准化\",{\"1\":{\"27\":1}}],[\"应用类型\",{\"1\":{\"25\":1}}],[\"均匀地分布在集群的不同节点上\",{\"1\":{\"57\":1}}],[\"呢\",{\"0\":{\"52\":1}}],[\"堆叠\",{\"0\":{\"52\":1},\"1\":{\"52\":1,\"60\":1}}],[\"避免了gpu\",{\"1\":{\"418\":1}}],[\"避免\",{\"0\":{\"52\":1},\"1\":{\"52\":1,\"60\":1}}],[\"避免单点故障\",{\"1\":{\"5\":1}}],[\"操作会因不同的加法顺序导致浮点值漂移\",{\"1\":{\"448\":1}}],[\"操作符数量增加\",{\"1\":{\"459\":1}}],[\"操作符时间排序的成本\",{\"1\":{\"459\":1}}],[\"操作符转换和放置的成本\",{\"1\":{\"459\":1}}],[\"操作符表示为\",{\"1\":{\"431\":1}}],[\"操作符的计算与原始操作符的计算保持一致\",{\"1\":{\"429\":1}}],[\"操作符\",{\"1\":{\"429\":1}}],[\"操作内并行则通过将操作符拆分成更小的部分来工作\",{\"1\":{\"398\":1}}],[\"操作内并行依赖于一个操作符在具有多个维度的张量上工作\",{\"1\":{\"398\":1}}],[\"操作间并行\",{\"0\":{\"399\":1}}],[\"操作间并行已受到工业界和学术界的广泛关注\",{\"1\":{\"398\":1}}],[\"操作间并行训练引入的通信开销最少\",{\"1\":{\"398\":1}}],[\"操作间并行训练将目标dnn模型划分为不相交的阶段\",{\"1\":{\"398\":1}}],[\"操作间并行性\",{\"1\":{\"395\":1}}],[\"操作码\",{\"1\":{\"304\":1}}],[\"操作系统\",{\"0\":{\"252\":1},\"2\":{\"265\":1,\"266\":1}}],[\"操作在损坏的数据上运行\",{\"1\":{\"204\":1}}],[\"操作失败后进程将崩溃\",{\"1\":{\"204\":1}}],[\"操作并返回结果\",{\"1\":{\"163\":1}}],[\"操作是\",{\"1\":{\"162\":1}}],[\"操作类型\",{\"1\":{\"162\":1}}],[\"操作的接口\",{\"1\":{\"161\":1,\"163\":1}}],[\"操作阻塞\",{\"1\":{\"150\":1}}],[\"操作参数\",{\"1\":{\"150\":1}}],[\"操作\",{\"1\":{\"51\":1,\"143\":1,\"157\":1,\"160\":1,\"161\":1,\"165\":3}}],[\"才能开始下一个请求\",{\"1\":{\"270\":1}}],[\"才可能被选中进行\",{\"1\":{\"51\":1}}],[\"才会开始\",{\"1\":{\"51\":1}}],[\">0\",{\"1\":{\"149\":32}}],[\">请求workflow\",{\"1\":{\"113\":1}}],[\">8888888<\",{\"1\":{\"75\":1}}],[\">\",{\"1\":{\"51\":2,\"75\":3,\"145\":2,\"149\":32,\"150\":2,\"156\":1,\"202\":1,\"366\":3,\"381\":1}}],[\"监控和优化\",{\"1\":{\"97\":1}}],[\"监控和管理\",{\"0\":{\"34\":1}}],[\"监控到的数据\",{\"1\":{\"51\":1}}],[\"读取为单设备开发的\",{\"1\":{\"445\":1}}],[\"读取到的值\",{\"1\":{\"51\":1}}],[\"读写权限\",{\"1\":{\"9\":2}}],[\"阈值的数据来源\",{\"1\":{\"51\":1}}],[\"而在\",{\"1\":{\"457\":1}}],[\"而在其余三个设置中执行\",{\"1\":{\"455\":1}}],[\"而对于\",{\"1\":{\"456\":1}}],[\"而对于t5\",{\"1\":{\"415\":1}}],[\"而原本应在原地更新的操作变成了非就地操作\",{\"1\":{\"449\":1}}],[\"而其余部分保持现有的并行化计划不变\",{\"1\":{\"447\":1}}],[\"而其他系统因内存不足而失败\",{\"1\":{\"411\":1}}],[\"而其他四个系统成功执行了训练任务\",{\"1\":{\"411\":1}}],[\"而算子\",{\"1\":{\"443\":1}}],[\"而划分参数则需要在设备间复制输入激活张量\",{\"1\":{\"440\":1}}],[\"而内存使用率却很高\",{\"1\":{\"436\":1}}],[\"而内存优化操作则由执行器执行\",{\"1\":{\"405\":1}}],[\"而较晚的微批次的前向传播应该在较早微批次的反向传播之后紧接着执行\",{\"1\":{\"433\":1}}],[\"而速度较慢的层存储生命周期较长的数据\",{\"1\":{\"417\":1}}],[\"而重计算的贡献最大\",{\"1\":{\"416\":1}}],[\"而重计算引入了3毫秒的额外前向计算\",{\"1\":{\"415\":1}}],[\"而d2d交换则可以用于其他对性能更关键的任务\",{\"1\":{\"415\":1}}],[\"而后者则进一步最大化了数据传输带宽\",{\"1\":{\"414\":1}}],[\"而数据分条优化使性能进一步提高了33\",{\"1\":{\"414\":1}}],[\"而v100的内存为32gb\",{\"1\":{\"412\":1}}],[\"而vxlan适用于大规模数据中心和云环境中的网络虚拟化和扩展\",{\"1\":{\"288\":1}}],[\"而zero\",{\"1\":{\"412\":1}}],[\"而这些数据占用了大量gpu内存\",{\"1\":{\"401\":1}}],[\"而这些通信位于训练的关键路径上\",{\"1\":{\"398\":1}}],[\"而且供应量非常有限\",{\"1\":{\"417\":1}}],[\"而且这些激活值通常很小\",{\"1\":{\"398\":1}}],[\"而且在大模型领域最近持续演进如智能体等新技术\",{\"1\":{\"232\":1}}],[\"而无需再次发送arp请求\",{\"1\":{\"303\":1}}],[\"而整个系统是围绕着\",{\"1\":{\"233\":1}}],[\"而第二个进程在\",{\"1\":{\"193\":1}}],[\"而是通过三个原语\",{\"1\":{\"423\":1}}],[\"而是将d2d交换\",{\"1\":{\"418\":1}}],[\"而是一个专注于加速\",{\"1\":{\"143\":1}}],[\"而是提供一种简单的方法\",{\"1\":{\"78\":1}}],[\"而容器则会启动你的程序\",{\"1\":{\"89\":1}}],[\"而只会返回一个\",{\"1\":{\"61\":1}}],[\"而负责响应这个接口的\",{\"1\":{\"61\":1}}],[\"而\",{\"1\":{\"51\":1,\"61\":1,\"143\":1,\"162\":1,\"163\":1,\"168\":1,\"255\":1,\"354\":1,\"356\":2,\"443\":2,\"451\":1,\"454\":1,\"458\":1}}],[\"而不涉及远程服务器或网络通信\",{\"1\":{\"353\":1}}],[\"而不影响现有的功能\",{\"1\":{\"275\":1}}],[\"而不必等待接收方确认\",{\"1\":{\"196\":1}}],[\"而不是与gpu的直接通信有关\",{\"1\":{\"353\":1}}],[\"而不是动态学习到的\",{\"1\":{\"298\":1}}],[\"而不是通常的延迟调用\",{\"1\":{\"204\":1}}],[\"而不是通过负载均衡器来访问\",{\"1\":{\"38\":1}}],[\"而不是通过\",{\"1\":{\"30\":1}}],[\"而不是共享内存\",{\"1\":{\"196\":1}}],[\"而不是应用程序本身\",{\"1\":{\"100\":1}}],[\"而不是\",{\"1\":{\"39\":1,\"212\":1}}],[\"而不依赖于\",{\"1\":{\"33\":1}}],[\"分配到不同的设备组\",{\"1\":{\"452\":1}}],[\"分配和排序\",{\"1\":{\"443\":1}}],[\"分别对应\",{\"1\":{\"456\":1}}],[\"分别对四种配置应用了\",{\"1\":{\"455\":1}}],[\"分别在不同的gpu上运行\",{\"1\":{\"418\":1}}],[\"分别在现代gpu服务器\",{\"1\":{\"396\":1}}],[\"分别是启用gpu\",{\"1\":{\"410\":1}}],[\"分别是通过输入样本分区\",{\"1\":{\"398\":1}}],[\"分别用于发送和接收消息\",{\"1\":{\"196\":1}}],[\"分类\",{\"1\":{\"365\":2}}],[\"分发重启后\",{\"1\":{\"263\":1}}],[\"分发\",{\"1\":{\"263\":1}}],[\"分区空间\",{\"1\":{\"258\":1}}],[\"分区\",{\"0\":{\"257\":1},\"1\":{\"256\":1,\"257\":1,\"429\":1}}],[\"分析\",{\"1\":{\"242\":1}}],[\"分钟\",{\"1\":{\"204\":2}}],[\"分钟之后\",{\"1\":{\"51\":1}}],[\"分片\",{\"1\":{\"119\":1}}],[\"分布在数据中心的不同区域\",{\"1\":{\"346\":1}}],[\"分布在不同的节点上\",{\"1\":{\"52\":1}}],[\"分布在不同机器上\",{\"0\":{\"52\":1}}],[\"分布式系统\",{\"1\":{\"355\":1}}],[\"分布式架构\",{\"1\":{\"286\":1}}],[\"分布式\",{\"2\":{\"208\":1}}],[\"分布式计算和大规模数据处理任务中的主流选择\",{\"1\":{\"200\":1}}],[\"分布式深度学习\",{\"1\":{\"187\":1}}],[\"分布式训练通过将计算任务分配到多个设备\",{\"1\":{\"424\":1}}],[\"分布式训练成为了主流\",{\"1\":{\"424\":1}}],[\"分布式训练\",{\"1\":{\"182\":1}}],[\"分布式训练新篇章\",{\"1\":{\"139\":1}}],[\"分布式的进程组\",{\"1\":{\"152\":1}}],[\"分布式调度策略\",{\"0\":{\"57\":1}}],[\"分布式锁\",{\"2\":{\"7\":1}}],[\"分布式锁的三个主要核心要素\",{\"1\":{\"5\":1}}],[\"分布式锁最终是由写入此\",{\"1\":{\"5\":1}}],[\"就地操作符\",{\"0\":{\"449\":1}}],[\"就有可能最小化流水线\",{\"1\":{\"431\":1}}],[\"就有可能触发\",{\"1\":{\"51\":1}}],[\"就不会引入额外的时间延迟\",{\"1\":{\"407\":1}}],[\"就不会再犹豫\",{\"1\":{\"255\":1}}],[\"就都属于\",{\"1\":{\"255\":1}}],[\"就可以发布了\",{\"1\":{\"359\":2}}],[\"就可以查看这个图\",{\"1\":{\"94\":1}}],[\"就可以运行\",{\"1\":{\"78\":1}}],[\"就是全局\",{\"1\":{\"151\":1}}],[\"就是一个高级的控制器\",{\"1\":{\"117\":1}}],[\"就是直接调用\",{\"1\":{\"61\":1}}],[\"就是该\",{\"1\":{\"61\":1}}],[\"就会进入到第八个框\",{\"1\":{\"255\":1}}],[\"就会进入\",{\"1\":{\"255\":1}}],[\"就会进行一些文件系统层的操作\",{\"1\":{\"255\":1}}],[\"就会通过重定向来向\",{\"1\":{\"61\":1}}],[\"就会把它以\",{\"1\":{\"61\":1}}],[\"就会调用\",{\"1\":{\"61\":2}}],[\"就意味着当\",{\"1\":{\"51\":1}}],[\"两者的价格和容量差异主要是由不同的制造工艺导致的\",{\"1\":{\"417\":1}}],[\"两者结合使用\",{\"1\":{\"28\":1}}],[\"两台机器都运行了ubuntu\",{\"1\":{\"410\":1}}],[\"两种mpress变体表现最好且性能相同\",{\"1\":{\"411\":1}}],[\"两种交换方法的优势在于它们不消耗gpu的计算资源\",{\"1\":{\"407\":1}}],[\"两种模式\",{\"1\":{\"51\":1}}],[\"两个算子通过各自的\",{\"1\":{\"443\":1}}],[\"两个主机连续阶段的gpu之间仅交换每个微批次1\",{\"1\":{\"398\":1}}],[\"两个服务器之间的文件传输或数据库查询\",{\"1\":{\"347\":1}}],[\"两个bgp路由器\",{\"1\":{\"311\":1}}],[\"两个后端\",{\"1\":{\"204\":1}}],[\"两个进程之间直接进行消息传递\",{\"1\":{\"196\":1}}],[\"里对\",{\"1\":{\"61\":1}}],[\"里其实分为\",{\"1\":{\"51\":1}}],[\"里都是可配置的\",{\"1\":{\"51\":1}}],[\"等技术\",{\"1\":{\"454\":1}}],[\"等待docker\",{\"1\":{\"366\":1}}],[\"等待mongodb服务启动\",{\"1\":{\"366\":1}}],[\"等网络技术实现高效的远程内存访问\",{\"1\":{\"354\":1}}],[\"等价多路径路由\",{\"1\":{\"347\":1}}],[\"等调用方式\",{\"1\":{\"223\":1}}],[\"等并行计算框架为\",{\"1\":{\"195\":1}}],[\"等并行计算框架通常支持\",{\"1\":{\"190\":1}}],[\"等工具进行协调和通信\",{\"1\":{\"193\":1}}],[\"等工具创建和管理自定义资源\",{\"1\":{\"118\":1}}],[\"等规约操作有效\",{\"1\":{\"150\":1}}],[\"等\",{\"1\":{\"97\":1,\"105\":1,\"158\":1,\"161\":1,\"162\":1,\"197\":1,\"220\":2,\"294\":1,\"334\":1,\"335\":1,\"336\":1,\"340\":1,\"431\":1}}],[\"等接口\",{\"0\":{\"61\":1}}],[\"等等\",{\"1\":{\"51\":1,\"105\":1}}],[\"等信息\",{\"1\":{\"5\":1}}],[\"qq\",{\"1\":{\"422\":1}}],[\"qa\",{\"1\":{\"365\":1}}],[\"qamaxprocess\",{\"1\":{\"365\":1}}],[\"qlen\",{\"1\":{\"282\":2,\"283\":4}}],[\"qdisc\",{\"1\":{\"282\":2,\"283\":4}}],[\"qwen\",{\"1\":{\"224\":1}}],[\"quick\",{\"1\":{\"371\":1}}],[\"quay\",{\"1\":{\"366\":1}}],[\"qualified\",{\"1\":{\"167\":2,\"168\":4,\"169\":2}}],[\"quotemaxtoken\",{\"1\":{\"365\":2}}],[\"quota\",{\"1\":{\"20\":1,\"366\":1}}],[\"queue\",{\"1\":{\"211\":5,\"212\":2}}],[\"queryconfig\",{\"1\":{\"365\":1}}],[\"query\",{\"1\":{\"150\":1}}],[\"q9ddn\",{\"1\":{\"97\":2}}],[\"qos\",{\"1\":{\"51\":2,\"62\":1}}],[\"某些算子的时间顺序已由转换后的图中的数据依赖关系确定\",{\"1\":{\"441\":1}}],[\"某些科学计算或仿真任务可能需要不同的计算步骤\",{\"1\":{\"191\":1}}],[\"某些服务需要通过\",{\"1\":{\"49\":1}}],[\"某些pv可能支持多种访问模式\",{\"1\":{\"9\":1}}],[\"同样的规则也适用于反向传播中的\",{\"1\":{\"433\":1}}],[\"同样\",{\"1\":{\"280\":1,\"410\":1}}],[\"同样用于将通信器对象解包\",{\"1\":{\"162\":1}}],[\"同步通信要求发送方等待接收方确认消息接收\",{\"1\":{\"196\":1}}],[\"同步与异步通信\",{\"1\":{\"196\":1}}],[\"同步不同gpu上的模型参数\",{\"1\":{\"181\":1}}],[\"同一批次中的不同微批次上执行的同一算子的顺序未被指定\",{\"1\":{\"441\":1}}],[\"同一设备上的两个没有直接依赖关系的算子可以以任意顺序执行\",{\"1\":{\"441\":1}}],[\"同一\",{\"1\":{\"49\":1}}],[\"同一个\",{\"1\":{\"46\":1}}],[\"同时最小化通信成本\",{\"1\":{\"440\":1}}],[\"同时最小化额外的成本\",{\"1\":{\"395\":1}}],[\"同时保持时间顺序上的约束\",{\"1\":{\"437\":1}}],[\"同时保持较高的训练性能\",{\"1\":{\"419\":1}}],[\"同时复制张量\",{\"1\":{\"429\":1}}],[\"同时比基线方法提供更好的训练性能\",{\"1\":{\"409\":1}}],[\"同时将重计算分配给激活张量\",{\"1\":{\"407\":1}}],[\"同时将包括百度文心\",{\"1\":{\"223\":1}}],[\"同时进行大规模的点对点通信\",{\"1\":{\"352\":1}}],[\"同时\",{\"1\":{\"273\":1,\"399\":1,\"405\":1}}],[\"同时提供通信接口以在它们之间进行消息传递\",{\"1\":{\"194\":1}}],[\"同时要保证高可用\",{\"1\":{\"5\":1}}],[\"同时获得锁\",{\"1\":{\"5\":1}}],[\"访问\",{\"0\":{\"367\":1}}],[\"访问服务\",{\"0\":{\"74\":1}}],[\"访问自身或同一\",{\"1\":{\"47\":1}}],[\"访问自身以及同一\",{\"1\":{\"45\":1}}],[\"访问自己\",{\"1\":{\"46\":1}}],[\"访问同一\",{\"1\":{\"46\":1}}],[\"访问模式\",{\"0\":{\"9\":1}}],[\"示例输出\",{\"0\":{\"297\":1}}],[\"示例场景\",{\"0\":{\"193\":1}}],[\"示例代码\",{\"0\":{\"183\":1,\"199\":1}}],[\"示例解释\",{\"0\":{\"173\":1}}],[\"示例用法\",{\"0\":{\"169\":1}}],[\"示例\",{\"0\":{\"54\":1,\"56\":1,\"58\":1,\"60\":1,\"160\":1,\"188\":1,\"282\":1},\"1\":{\"41\":1}}],[\"名称\",{\"1\":{\"38\":1,\"43\":1,\"92\":2}}],[\"名称直接访问特定的\",{\"1\":{\"38\":1}}],[\"都不具备在其支持的并行化空间内自动搜索并行化计划的功能\",{\"1\":{\"454\":1}}],[\"都不会出现死锁\",{\"1\":{\"5\":1}}],[\"都是通过软中断来处理的\",{\"1\":{\"255\":1}}],[\"都可以从零开始学习\",{\"1\":{\"228\":1}}],[\"都可以帮助实现高效的运维管理\",{\"1\":{\"123\":1}}],[\"都能在此找到通往成功部署大型语言模型的关键路径\",{\"1\":{\"219\":1}}],[\"都集中在容器基础设施上\",{\"1\":{\"100\":1}}],[\"都有一个稳定的\",{\"1\":{\"38\":1,\"43\":1}}],[\"对每个\",{\"1\":{\"455\":1}}],[\"对重计算的支持依赖于操作符转换的自定义算法\",{\"1\":{\"451\":1}}],[\"对就地操作符进行划分可能会带来问题\",{\"1\":{\"449\":1}}],[\"对模型架构和并行训练具有深入了解\",{\"1\":{\"438\":1}}],[\"对一些流行的dnn模型\",{\"1\":{\"423\":1}}],[\"对著名dnn模型\",{\"1\":{\"423\":1}}],[\"对话默认携带的系统提示词\",{\"1\":{\"365\":1}}],[\"对比\",{\"0\":{\"287\":1}}],[\"对不同课程进行了分级和排序\",{\"1\":{\"226\":1}}],[\"对原课程内容进行筛选\",{\"1\":{\"226\":1}}],[\"对应oneapi中渠道的模型名\",{\"1\":{\"365\":1}}],[\"对应图中第五个框\",{\"1\":{\"255\":1}}],[\"对应图中的第三个框\",{\"1\":{\"255\":1}}],[\"对应于工作流\",{\"1\":{\"89\":1}}],[\"对应的反向传播子图应该在具有相对当前阶段的偏移量\",{\"1\":{\"437\":1}}],[\"对应的\",{\"1\":{\"61\":1}}],[\"对\",{\"1\":{\"51\":1,\"450\":2}}],[\"对自身进行健康检查\",{\"1\":{\"49\":1}}],[\"对于不同的模型配置\",{\"1\":{\"459\":1}}],[\"对于消费者\",{\"1\":{\"444\":1}}],[\"对于其他类型的原语\",{\"1\":{\"443\":1}}],[\"对于流水线并行\",{\"1\":{\"441\":1,\"454\":1}}],[\"对于一个流水线来说\",{\"1\":{\"435\":1}}],[\"对于一个中等水平的技术人员来说\",{\"1\":{\"359\":2}}],[\"对于任何两个微批次\",{\"1\":{\"433\":1}}],[\"对于足够大的\",{\"1\":{\"425\":1}}],[\"对于大型模型而言\",{\"1\":{\"425\":1}}],[\"对于大量\",{\"1\":{\"150\":1}}],[\"对于张量t4\",{\"1\":{\"415\":1}}],[\"对于张量t2\",{\"1\":{\"415\":1}}],[\"对于t3\",{\"1\":{\"415\":1}}],[\"对于dgx\",{\"1\":{\"414\":1}}],[\"对于d2d交换\",{\"1\":{\"408\":1}}],[\"对于基于dapple的mpress\",{\"1\":{\"410\":1}}],[\"对于基于pipedream的操作间并行训练\",{\"1\":{\"410\":1}}],[\"对于这些张量\",{\"1\":{\"407\":1}}],[\"对于每个张量\",{\"1\":{\"406\":1}}],[\"对于pipedream\",{\"1\":{\"400\":1}}],[\"对于bert\",{\"1\":{\"398\":1,\"416\":1}}],[\"对于需要大量并行计算的场景\",{\"1\":{\"348\":1}}],[\"对于名为\",{\"1\":{\"91\":1}}],[\"对于options方式的请求返回204\",{\"1\":{\"75\":1}}],[\"对于\",{\"1\":{\"38\":1,\"61\":1,\"433\":1,\"451\":1,\"456\":2,\"457\":6,\"458\":1,\"459\":4}}],[\"对象中解包成\",{\"1\":{\"162\":1}}],[\"对象中提取张量的自定义函数\",{\"1\":{\"162\":1}}],[\"对象和可视化\",{\"1\":{\"100\":1}}],[\"对象的通用类型\",{\"1\":{\"162\":1}}],[\"对象的\",{\"1\":{\"5\":2}}],[\"对象\",{\"1\":{\"5\":1,\"162\":5,\"172\":1}}],[\"对象后\",{\"1\":{\"5\":1}}],[\"例如为特定模型设计的自定义算子\",{\"1\":{\"445\":1}}],[\"例如由领域专家开发的算法\",{\"1\":{\"429\":1}}],[\"例如alphafold2\",{\"1\":{\"423\":1}}],[\"例如更好的计算和通信重叠技术\",{\"1\":{\"412\":1}}],[\"例如路由过滤\",{\"1\":{\"310\":1}}],[\"例如reachable\",{\"1\":{\"294\":1}}],[\"例如通过\",{\"1\":{\"255\":1}}],[\"例如256个gpu互联的场景\",{\"1\":{\"177\":1}}],[\"例如重新启动故障的组件\",{\"1\":{\"119\":1}}],[\"例如系统管理员\",{\"1\":{\"116\":1}}],[\"例如贝叶斯优化\",{\"1\":{\"105\":1}}],[\"例如在多卡训练中汇总各个设备上的张量\",{\"1\":{\"156\":1}}],[\"例如在\",{\"1\":{\"100\":1}}],[\"例如数据预处理\",{\"1\":{\"90\":1}}],[\"例如数据库集群或分布式文件系统\",{\"1\":{\"39\":1}}],[\"例如某些服务需要通过自身的外部\",{\"1\":{\"46\":1}}],[\"例如\",{\"1\":{\"38\":1,\"43\":1,\"48\":1,\"59\":1,\"91\":2,\"95\":1,\"101\":2,\"102\":1,\"105\":1,\"119\":1,\"143\":3,\"168\":1,\"181\":1,\"185\":1,\"191\":1,\"206\":4,\"207\":1,\"272\":1,\"294\":1,\"299\":1,\"341\":1,\"347\":1,\"365\":1,\"398\":1,\"399\":1,\"401\":1,\"417\":2,\"425\":3,\"426\":3,\"427\":1,\"429\":3,\"431\":2,\"435\":1,\"438\":1,\"440\":1,\"443\":1,\"444\":2,\"447\":1,\"448\":1,\"449\":1,\"452\":2,\"455\":1}}],[\"允许将由新约束生成的较少研究的子图替换为经过充分测试的约束\",{\"1\":{\"447\":1}}],[\"允许领域专家在应用这些原语时施加约束\",{\"1\":{\"431\":1}}],[\"允许在不限于批次维度的维度上进行分区\",{\"1\":{\"425\":1}}],[\"允许在同一个tcp连接上复用多个请求\",{\"1\":{\"269\":1}}],[\"允许服务器之间通过网络交换数据\",{\"1\":{\"353\":1}}],[\"允许更重要的请求先行处理\",{\"1\":{\"273\":1}}],[\"允许进行后端优化\",{\"1\":{\"204\":1}}],[\"允许多个\",{\"1\":{\"352\":2}}],[\"允许多个请求\",{\"1\":{\"270\":1}}],[\"允许多个进程同时读写大规模数据集\",{\"1\":{\"196\":1}}],[\"允许多个处理单元并行执行不同的程序\",{\"1\":{\"195\":1}}],[\"允许程序在多个处理单元上并行运行\",{\"1\":{\"197\":1}}],[\"允许程序在多个处理单元\",{\"1\":{\"195\":1}}],[\"允许不同的程序同时运行\",{\"1\":{\"191\":1}}],[\"允许并行处理不同区域或不同时间步的计算\",{\"1\":{\"187\":1}}],[\"允许并行执行\",{\"1\":{\"162\":1}}],[\"允许你在运行时根据字符串路径获取对象\",{\"1\":{\"170\":1}}],[\"允许你为\",{\"1\":{\"51\":1}}],[\"允许实现\",{\"1\":{\"143\":1}}],[\"允许优化任何规模的大模型的超参数\",{\"1\":{\"106\":1}}],[\"允许发送按段获取资源的请求\",{\"1\":{\"75\":1}}],[\"允许请求时携带的头部信息\",{\"1\":{\"75\":1}}],[\"允许跨域请求的方法\",{\"1\":{\"75\":1}}],[\"允许跨域的请求\",{\"1\":{\"75\":1}}],[\"允许携带cookie请求\",{\"1\":{\"75\":1}}],[\"允许使用自定义调度策略文件来自定义调度行为\",{\"1\":{\"59\":1}}],[\"允许用户交互和监控工作流\",{\"1\":{\"97\":1}}],[\"允许用户在同一个应用程序中启动多个不同的程序实例\",{\"1\":{\"194\":1}}],[\"允许用户在\",{\"1\":{\"97\":1,\"163\":1}}],[\"允许用户定义分布式调度策略\",{\"1\":{\"57\":1}}],[\"允许用户指定某些\",{\"1\":{\"53\":1}}],[\"允许调度器根据节点标签选择合适的节点\",{\"1\":{\"55\":1}}],[\"允许应用自行管理和发现服务实例\",{\"1\":{\"39\":1}}],[\"允许这些有状态应用中的各个\",{\"1\":{\"39\":1}}],[\"允许客户端直接访问服务后端的每个\",{\"1\":{\"38\":1}}],[\"允许被多个node挂载\",{\"1\":{\"9\":2}}],[\"这归因于表\",{\"1\":{\"459\":1}}],[\"这要求比单个\",{\"1\":{\"435\":1}}],[\"这两个术语互换使用\",{\"1\":{\"429\":1}}],[\"这两部分模拟数据可能会在某些阶段相互依赖\",{\"1\":{\"193\":1}}],[\"这促使我们设计一种更灵活的空间构建方法\",{\"1\":{\"426\":1}}],[\"这导致显著的\",{\"1\":{\"426\":1}}],[\"这导致了gpu内存的极大需求\",{\"1\":{\"394\":1}}],[\"这排除了将分割操作符放置在较少设备上的情况\",{\"1\":{\"426\":1}}],[\"这在决定如何组合这些方法时起到了关键作用\",{\"1\":{\"415\":1}}],[\"这在预期之中\",{\"1\":{\"414\":1}}],[\"这也影响了它们各自的mpress变体\",{\"1\":{\"412\":1}}],[\"这也将初始化分布式包\",{\"1\":{\"203\":1}}],[\"这得益于d2d交换技术的使用\",{\"1\":{\"412\":1}}],[\"这台dgx\",{\"1\":{\"410\":1}}],[\"这三种内存优化技术对gpu内存节省的贡献各自是多少\",{\"1\":{\"409\":1}}],[\"这三者是不同的技术\",{\"1\":{\"350\":1}}],[\"这篇论文的题目是\",{\"1\":{\"393\":1}}],[\"这就是我想要的\",{\"1\":{\"359\":2}}],[\"这类似于传统二层交换机的mac地址表\",{\"1\":{\"291\":1}}],[\"这表明了约束的重要性\",{\"1\":{\"459\":1}}],[\"这表明veth0和veth1是一对互相连接的虚拟以太网设备\",{\"1\":{\"282\":1}}],[\"这表明这个部分主要是为非\",{\"1\":{\"171\":1}}],[\"这有助于减少延迟和提升性能\",{\"1\":{\"272\":1}}],[\"这有助于了解程序在做什么\",{\"1\":{\"254\":1}}],[\"这包括删除\",{\"1\":{\"256\":1}}],[\"这意味着\",{\"1\":{\"212\":1,\"412\":1}}],[\"这意味着每个处理单元的代码路径是相同的\",{\"1\":{\"185\":1}}],[\"这通常通过划分数据集来实现\",{\"1\":{\"185\":1}}],[\"这与前面提到的nccl理论上支持256卡互联是一致的\",{\"1\":{\"176\":1}}],[\"这里默认填写了oneapi的快速默认key\",{\"1\":{\"366\":1}}],[\"这里默认填写了oneapi的访问地址\",{\"1\":{\"366\":1}}],[\"这里表示如果进程的\",{\"1\":{\"255\":1}}],[\"这里你要注意\",{\"1\":{\"255\":1}}],[\"这里\",{\"1\":{\"255\":1,\"412\":1}}],[\"这里我们假设一下\",{\"1\":{\"255\":1}}],[\"这里进程又回到用户态的\",{\"1\":{\"255\":1}}],[\"这里仍旧是内核态的\",{\"1\":{\"255\":1}}],[\"这里的\",{\"1\":{\"255\":1}}],[\"这里的节点可以是gpu或网络设备\",{\"1\":{\"176\":1}}],[\"这里就对应上面图里的第二个框\",{\"1\":{\"255\":1}}],[\"这里是\",{\"1\":{\"171\":1}}],[\"这里检查是否传入的\",{\"1\":{\"154\":1}}],[\"这段\",{\"1\":{\"170\":1}}],[\"这段代码展示了如何在非\",{\"1\":{\"174\":1}}],[\"这段代码的主要目的是将\",{\"1\":{\"170\":1}}],[\"这段代码的主要功能是将一个全局的\",{\"1\":{\"150\":1}}],[\"这段代码负责将\",{\"1\":{\"166\":1}}],[\"这段代码是\",{\"1\":{\"164\":1}}],[\"这段代码将各个\",{\"1\":{\"160\":1}}],[\"这段代码实现了\",{\"1\":{\"156\":1}}],[\"这段代码从\",{\"1\":{\"154\":1}}],[\"这段代码检查传入的\",{\"1\":{\"154\":1}}],[\"这一阶段的目标是将计算均匀分配到多个设备上\",{\"1\":{\"440\":1}}],[\"这一点已被zero\",{\"1\":{\"412\":1}}],[\"这一gpu内存需求可以通过我们测试的gpu服务器在没有内存优化的情况下满足\",{\"1\":{\"410\":1}}],[\"这一部分会通过\",{\"1\":{\"171\":1}}],[\"这一部分具体怎么实现\",{\"1\":{\"61\":1}}],[\"这一行注册了\",{\"1\":{\"165\":1}}],[\"这一行使用条件编译指令来检查是否启用了\",{\"1\":{\"165\":1}}],[\"这是\",{\"1\":{\"451\":1}}],[\"这是预期的行为\",{\"1\":{\"448\":1}}],[\"这是预期中的结果\",{\"1\":{\"411\":1}}],[\"这是将\",{\"1\":{\"445\":1}}],[\"这是一种新的单服务器多gpu系统\",{\"1\":{\"419\":1}}],[\"这是一个用于生成深度学习训练并行化计划的框架\",{\"1\":{\"423\":1}}],[\"这是一个高效的操作间并行深度神经网络\",{\"1\":{\"404\":1}}],[\"这是一个字符串\",{\"1\":{\"168\":1}}],[\"这是一个\",{\"1\":{\"162\":1}}],[\"这是一个过时参数\",{\"1\":{\"158\":1}}],[\"这是由于数据分条技术利用了多条nvlink的聚合带宽\",{\"1\":{\"414\":1}}],[\"这是因为在混合使用就地操作符和非就地操作符时\",{\"1\":{\"449\":1}}],[\"这是因为前者优化使交换操作能够通过可达的nvlink链路传输数据\",{\"1\":{\"414\":1}}],[\"这是因为我们租用的dgx\",{\"1\":{\"412\":1}}],[\"这是因为zero\",{\"1\":{\"412\":1}}],[\"这是因为普通的操作间并行训练已经能够满足该模型的gpu内存需求\",{\"1\":{\"411\":1}}],[\"这是因为本身它们在处理的时候就不属于任何一个进程\",{\"1\":{\"255\":1}}],[\"这是dapple文献中推荐的最小批次大小\",{\"1\":{\"410\":1}}],[\"这是文献中推荐的大小\",{\"1\":{\"410\":1}}],[\"这是通过一个硬件交换设备实现的\",{\"1\":{\"352\":1}}],[\"这是设备的mac地址\",{\"1\":{\"298\":1}}],[\"这是异步中止集合操作的时间限制\",{\"1\":{\"204\":1}}],[\"这是必需的\",{\"1\":{\"204\":2}}],[\"这是在分布式训练中非常常用的操作\",{\"1\":{\"181\":1}}],[\"这是常见的分布式通信操作\",{\"1\":{\"156\":1}}],[\"这是默认的执行器\",{\"1\":{\"96\":1}}],[\"这是默认模式\",{\"1\":{\"47\":1}}],[\"这可能需要进一步调整并行化计划以提高训练效率\",{\"1\":{\"446\":1}}],[\"这可能非常慢\",{\"1\":{\"150\":1}}],[\"这可以进一步减少除了第一层操作符的输入之外的内存消耗\",{\"1\":{\"407\":1}}],[\"这可以被以下用户使用\",{\"0\":{\"102\":1}}],[\"这可以用于避免将所有\",{\"1\":{\"55\":1}}],[\"这描述了自定义资源的结构和规范\",{\"1\":{\"118\":1}}],[\"这使得很难分辨是预期中的数值偏差\",{\"1\":{\"448\":1}}],[\"这使得\",{\"1\":{\"106\":1}}],[\"这对于网络故障排查和性能优化非常有用\",{\"1\":{\"301\":1}}],[\"这对于排查网络问题和管理网络连接非常有用\",{\"1\":{\"295\":1}}],[\"这对于将各种资源联系在一起甚至清理\",{\"1\":{\"101\":1}}],[\"这对于需要在容器之间共享数据的工作流特别有用\",{\"1\":{\"96\":1}}],[\"这对于需要直接与特定\",{\"1\":{\"38\":1}}],[\"这样包含大张量的模型\",{\"1\":{\"452\":1}}],[\"这样以后你解决相关问题时\",{\"1\":{\"255\":1}}],[\"这样得到的\",{\"1\":{\"168\":1}}],[\"这样用户在使用\",{\"1\":{\"166\":1}}],[\"这样可以实现快速同步\",{\"1\":{\"143\":1}}],[\"这样的就地操作符会在原地更新张量\",{\"1\":{\"449\":1}}],[\"这样的模型需要三次前向传播和一次反向传播\",{\"1\":{\"426\":1}}],[\"这样的工具\",{\"1\":{\"102\":1}}],[\"这样的应用程序\",{\"1\":{\"101\":1}}],[\"这样客户端可以通过\",{\"1\":{\"38\":1}}],[\"这会很有帮助\",{\"1\":{\"95\":1}}],[\"这将通过kong访问到nginx提供的\",{\"1\":{\"74\":1}}],[\"这时在这个\",{\"1\":{\"255\":1}}],[\"这时候\",{\"1\":{\"255\":1}}],[\"这时候这个用户进程就会从用户态切换到内核态\",{\"1\":{\"255\":1}}],[\"这时\",{\"1\":{\"61\":1,\"255\":1}}],[\"这个过程通常需要两名有经验的工程师大约两个月的时间才能完成\",{\"1\":{\"446\":1}}],[\"这个优化问题可以被看作是一个\",{\"1\":{\"440\":1}}],[\"这个层次结构使得可以使用动态规划等高效搜索技术\",{\"1\":{\"425\":1}}],[\"这个算法首先枚举所有可能的设备映射方案\",{\"1\":{\"406\":1}}],[\"这个命令将显示根文件系统的更新后的容量\",{\"1\":{\"262\":1}}],[\"这个步骤\",{\"1\":{\"255\":1}}],[\"这个用户进程在读取数据之后\",{\"1\":{\"255\":1}}],[\"这个进程一般会被置为\",{\"1\":{\"255\":1}}],[\"这个表达式用于监控推理请求在队列中等待的时间相对于实际计算时间的比例\",{\"1\":{\"211\":1}}],[\"这个结果被记录为\",{\"1\":{\"211\":1}}],[\"这个字典可以用于在代码中根据所选择的后端来决定可以在哪些设备上运行操作\",{\"1\":{\"207\":1}}],[\"这个宏定义了nccl拓扑结构支持的最大节点数为256\",{\"1\":{\"176\":1}}],[\"这个模块对象包含了所有需要导出的\",{\"1\":{\"173\":1}}],[\"这个对象是通过调用\",{\"1\":{\"171\":1}}],[\"这个函数用于初始化nccl拓扑搜索过程\",{\"1\":{\"176\":1}}],[\"这个函数又调用了\",{\"1\":{\"173\":1}}],[\"这个函数返回一个\",{\"1\":{\"171\":1}}],[\"这个函数可能在别的地方定义\",{\"1\":{\"171\":1}}],[\"这个函数可以在\",{\"1\":{\"161\":1}}],[\"这个函数的主要作用是实现动态加载模块中的对象\",{\"1\":{\"170\":1}}],[\"这个配置实现了通过kong网关将请求转发到nginx容器中的具体路径\",{\"1\":{\"75\":1}}],[\"这个\",{\"1\":{\"61\":2,\"167\":1,\"207\":1,\"255\":1}}],[\"这个请求首先交给\",{\"1\":{\"61\":1}}],[\"这个示例展示了如何使用节点标签\",{\"1\":{\"56\":1}}],[\"这个示例定义了一个名为\",{\"1\":{\"40\":1}}],[\"这种安排会导致硬件利用率不平衡\",{\"1\":{\"436\":1}}],[\"这种非常规的训练方法使得现有的流水线并行性无法适用\",{\"1\":{\"426\":1}}],[\"这种并行化的效果依赖于如何将模型的计算操作有效地分配给多个设备\",{\"1\":{\"424\":1}}],[\"这种并行性可以大幅提高计算效率\",{\"1\":{\"185\":1}}],[\"这种设计允许执行器在不阻塞主线程的情况下\",{\"1\":{\"408\":1}}],[\"这种设计使得\",{\"1\":{\"166\":1,\"196\":1}}],[\"这种架构通过提供多个冗余路径和均衡流量的能力\",{\"1\":{\"349\":1}}],[\"这种分层模型有助于不同网络设备和协议的互操作性和标准化\",{\"1\":{\"343\":1}}],[\"这种过程称为封装和解封装\",{\"1\":{\"341\":1}}],[\"这种方式被称为张量并行\",{\"1\":{\"418\":1}}],[\"这种方式允许二层流量跨越不同的三层网络\",{\"1\":{\"290\":1}}],[\"这种方法有助于定位问题模块\",{\"1\":{\"447\":1}}],[\"这种方法由于流水线气泡和中间结果的积累效率低下\",{\"1\":{\"437\":1}}],[\"这种方法以参数化的方式结合了数据\",{\"1\":{\"425\":1}}],[\"这种方法允许将分区后的操作符分布在不同的设备上\",{\"1\":{\"425\":1}}],[\"这种方法在需要根据配置文件或用户输入来加载类或函数时非常有用\",{\"1\":{\"170\":1}}],[\"这种方法依赖于\",{\"1\":{\"96\":1}}],[\"这种灵活性允许处理单元根据任务需求执行不同的操作或算法\",{\"1\":{\"190\":1}}],[\"这种模型更改可以很容易实现\",{\"1\":{\"448\":1}}],[\"这种模型适用于更复杂的并行计算任务\",{\"1\":{\"189\":1}}],[\"这种模型广泛应用于高性能计算和分布式计算领域\",{\"1\":{\"184\":1}}],[\"这种模块初始化机制在\",{\"1\":{\"172\":1}}],[\"这种模式在深度学习框架中非常常见\",{\"1\":{\"163\":1}}],[\"这种模式在性能上可能有一些开销\",{\"1\":{\"47\":1}}],[\"这种模式下\",{\"1\":{\"47\":1}}],[\"这种模式主要用于以下情况\",{\"1\":{\"46\":1}}],[\"这种连接可视化称为谱系图\",{\"1\":{\"95\":1}}],[\"这种\",{\"1\":{\"61\":1}}],[\"这种访问模式被称为\",{\"1\":{\"45\":1}}],[\"这种服务类型主要用于暴露\",{\"1\":{\"37\":1}}],[\"这种机制有助于确保工作负载在集群中得到更好地分布和隔离\",{\"1\":{\"36\":1}}],[\"这些计划可以分解为操作符转换\",{\"1\":{\"451\":1}}],[\"这些约束在表\",{\"1\":{\"436\":1}}],[\"这些约束如表\",{\"1\":{\"435\":1}}],[\"这些约束可以显著减少搜索空间\",{\"1\":{\"431\":1}}],[\"这些代码不一定与特定的\",{\"1\":{\"431\":1}}],[\"这些代码的指令消耗的\",{\"1\":{\"255\":1}}],[\"这些操作符\",{\"1\":{\"431\":1}}],[\"这些操作涉及多个进程之间的通信\",{\"1\":{\"196\":1}}],[\"这些方案支持在已知的并行化空间内的并行化计划\",{\"1\":{\"427\":1}}],[\"这些简化可能会排除一些有前景的计划\",{\"1\":{\"426\":1}}],[\"这些分区后的操作符随后在多个设备\",{\"1\":{\"425\":1}}],[\"这些原语可以捕捉模型转换以及任何并行化计划中对模型的时空调度\",{\"1\":{\"424\":1}}],[\"这些原语能够捕捉模型的转换以及任何并行化计划中转化模型的时空调度\",{\"1\":{\"423\":1}}],[\"这些遗漏的配置在某些情况下对训练性能有很大的影响\",{\"1\":{\"424\":1}}],[\"这些搜索空间通常不够全面\",{\"1\":{\"424\":1}}],[\"这些搜索空间定义了并行化的各种配置\",{\"1\":{\"424\":1}}],[\"这些配置在某些设置下\",{\"1\":{\"423\":1}}],[\"这些配置文件不会因为\",{\"1\":{\"31\":1}}],[\"这些硬件需要定制的软件支持\",{\"1\":{\"418\":1}}],[\"这些系统的性能往往受限于pcie带宽\",{\"1\":{\"418\":1}}],[\"这些系统应用了最先进的内存节省技术\",{\"1\":{\"412\":1}}],[\"这些内存或许能更好地用于其他张量\",{\"1\":{\"415\":1}}],[\"这些数据占用了更多的内存资源\",{\"1\":{\"411\":1}}],[\"这些数据的生命周期过短\",{\"1\":{\"404\":1}}],[\"这些线程使用系统启动时通过调用cudastreamcreate创建的不同cuda流\",{\"1\":{\"408\":1}}],[\"这些张量的优化引入了最大的额外开销\",{\"1\":{\"407\":1}}],[\"这些命令一起使用可以全面管理和配置网络\",{\"1\":{\"332\":1}}],[\"这些规则包括\",{\"1\":{\"310\":1}}],[\"这些会话通常是静态配置的\",{\"1\":{\"310\":1}}],[\"这些值到底影不影响\",{\"1\":{\"255\":1}}],[\"这些模型包括\",{\"1\":{\"446\":1}}],[\"这些模型通常需要大量的计算资源和内存\",{\"1\":{\"217\":1}}],[\"这些模式定义了不同情况下网络流量如何在gpu之间分布\",{\"1\":{\"176\":1}}],[\"这些可视化可以提供洞察\",{\"1\":{\"212\":1}}],[\"这些任务通常需要处理非常大的数据集和复杂的计算过程\",{\"1\":{\"198\":1}}],[\"这些场的计算方法不同\",{\"1\":{\"192\":1}}],[\"这些步骤可以由不同的程序在不同的处理单元上并行执行\",{\"1\":{\"191\":1}}],[\"这些不同的拓扑模式允许nccl根据具体的硬件拓扑和通信需求\",{\"1\":{\"177\":1}}],[\"这些定义用于描述不同的通信模式以及节点间的互联方式\",{\"1\":{\"175\":1}}],[\"这些服务涵盖了实验管理\",{\"1\":{\"111\":1}}],[\"这些框架实现了大多数最先进的优化算法\",{\"1\":{\"106\":1}}],[\"这些组件通过存储系统\",{\"1\":{\"97\":1}}],[\"这些组件通过元数据存储和\",{\"1\":{\"97\":1}}],[\"这些组件必须在集群启动时运行\",{\"1\":{\"33\":1}}],[\"这些\",{\"1\":{\"89\":2,\"97\":3}}],[\"这些容器在虚拟机上的kubernetes\",{\"1\":{\"85\":1}}],[\"具备可扩展gpu计算能力和存储容量的高端gpu服务器几乎不可能\",{\"1\":{\"412\":1}}],[\"具备创新能力的全栈开发工程师\",{\"1\":{\"131\":1}}],[\"具备良好的网页结构设计能力\",{\"1\":{\"130\":1}}],[\"具备大规模数据存储与查询优化的经验\",{\"1\":{\"128\":1}}],[\"具备处理硬件交互及操作系统底层模块的经验\",{\"1\":{\"127\":1}}],[\"具备广泛的编程语言知识和丰富的实际项目经验\",{\"1\":{\"126\":1}}],[\"具备更高的安全性\",{\"1\":{\"5\":1}}],[\"具有组合搜索复杂性\",{\"1\":{\"431\":1}}],[\"具有名称\",{\"1\":{\"90\":1}}],[\"具有相应的\",{\"1\":{\"36\":1}}],[\"具体说明如下\",{\"1\":{\"434\":1}}],[\"具体而言\",{\"1\":{\"407\":1}}],[\"具体工作原理\",{\"0\":{\"151\":1}}],[\"具体地说\",{\"1\":{\"51\":1}}],[\"具体来说\",{\"1\":{\"45\":1,\"439\":1}}],[\"则应用了交错流水线\",{\"1\":{\"456\":1}}],[\"则将权重卸载到\",{\"1\":{\"454\":1}}],[\"则将每个集体操作实现为一个处理通信和计算操作的单一核函数\",{\"1\":{\"143\":1}}],[\"则表示应用原语后产生的结果张量\",{\"1\":{\"443\":1}}],[\"则使用提示词模式\",{\"1\":{\"365\":1}}],[\"则使用\",{\"1\":{\"365\":1}}],[\"则用于同一台服务器内部的多gpu通信\",{\"1\":{\"356\":1}}],[\"则是用于同一服务器内部多个\",{\"1\":{\"353\":1}}],[\"则会编译接下来的代码\",{\"1\":{\"171\":1}}],[\"则会报错\",{\"1\":{\"158\":1}}],[\"则编译器会包含以下代码块\",{\"1\":{\"165\":1}}],[\"则抛出\",{\"1\":{\"154\":1}}],[\"则抛出异常\",{\"1\":{\"151\":1,\"154\":1}}],[\"则直接返回\",{\"1\":{\"151\":1}}],[\"则无法进行部署\",{\"1\":{\"36\":1}}],[\"则进入等待模式\",{\"1\":{\"5\":1}}],[\"移除\",{\"1\":{\"36\":1}}],[\"也在\",{\"1\":{\"457\":1}}],[\"也对所有模型配置使用了纯张量并行性\",{\"1\":{\"455\":1}}],[\"也称为osi\",{\"1\":{\"333\":1}}],[\"也称\",{\"0\":{\"320\":1}}],[\"也就是说\",{\"1\":{\"433\":1}}],[\"也就是当目标张量的生命周期\",{\"1\":{\"407\":1}}],[\"也就是服务器到服务器\",{\"1\":{\"346\":1}}],[\"也就是第七个框\",{\"1\":{\"255\":1}}],[\"也就是第六个框\",{\"1\":{\"255\":1}}],[\"也就是图中的第四个框\",{\"1\":{\"255\":1}}],[\"也可以玩转大模型推理部署\",{\"1\":{\"228\":1}}],[\"也可以使用该参数\",{\"1\":{\"204\":1}}],[\"也可以用于分布式机器学习\",{\"1\":{\"198\":1}}],[\"也可以是丰富的交互式可视化\",{\"1\":{\"95\":1}}],[\"也可能会调度\",{\"1\":{\"36\":1}}],[\"也不应假设它的存在\",{\"1\":{\"207\":1}}],[\"也不包含进程启动器和管理器\",{\"1\":{\"143\":1}}],[\"也不能直接共享内存数据\",{\"1\":{\"93\":1}}],[\"也不会被调度到这个节点上\",{\"1\":{\"36\":1}}],[\"新分区创建并标记为\",{\"1\":{\"259\":1}}],[\"新\",{\"1\":{\"36\":1}}],[\"新的约束\",{\"0\":{\"434\":1}}],[\"新的空间可能会揭示操作符分区的新方法\",{\"1\":{\"427\":1}}],[\"新的d2d交换技术\",{\"1\":{\"395\":1}}],[\"新的\",{\"1\":{\"36\":1,\"158\":1}}],[\"常见用途\",{\"1\":{\"285\":1,\"286\":1}}],[\"常见的\",{\"1\":{\"197\":1}}],[\"常见的选择是默认的\",{\"1\":{\"50\":1}}],[\"常见的效果有三种\",{\"1\":{\"36\":1}}],[\"常用于升级时候的初始化请求\",{\"1\":{\"366\":1}}],[\"常用于网络通信\",{\"1\":{\"351\":1}}],[\"常用于实现复杂的数值模拟\",{\"1\":{\"198\":1}}],[\"常用选项\",{\"0\":{\"299\":1}}],[\"常用工具总结\",{\"0\":{\"237\":1}}],[\"常用的解决方案是超时和自动过期机制\",{\"1\":{\"5\":1}}],[\"效果\",{\"1\":{\"36\":1}}],[\"值得注意的是\",{\"1\":{\"412\":1,\"451\":1}}],[\"值是正值\",{\"1\":{\"255\":1}}],[\"值\",{\"1\":{\"36\":1,\"152\":1}}],[\"键\",{\"1\":{\"36\":1}}],[\"提高了\",{\"1\":{\"457\":2}}],[\"提高网络性能\",{\"1\":{\"285\":1}}],[\"提高网络安全性\",{\"1\":{\"285\":1}}],[\"提出了三个原语\",{\"1\":{\"428\":1}}],[\"提出最佳推理代码库\",{\"1\":{\"249\":1}}],[\"提示用户迁移到新的\",{\"1\":{\"159\":1}}],[\"提醒用户该功能将被弃用\",{\"1\":{\"159\":1}}],[\"提升了训练大规模模型的效率\",{\"1\":{\"418\":1}}],[\"提升了用户体验和网络性能\",{\"1\":{\"277\":1}}],[\"提升了整体性能\",{\"1\":{\"276\":1,\"411\":1}}],[\"提升项目的开发效率与用户体验\",{\"1\":{\"130\":1}}],[\"提升系统响应速度\",{\"1\":{\"128\":1}}],[\"提升资源管理能力\",{\"1\":{\"19\":1}}],[\"提前停止和神经架构搜索\",{\"1\":{\"105\":1}}],[\"提供高达160gb\",{\"1\":{\"402\":1}}],[\"提供比传统\",{\"1\":{\"352\":1}}],[\"提供网络服务和应用程序接口\",{\"1\":{\"340\":1}}],[\"提供端到端的通信服务\",{\"1\":{\"337\":1}}],[\"提供节点之间的可靠数据传输\",{\"1\":{\"335\":1}}],[\"提供灵活的网络管理和用户分组\",{\"1\":{\"285\":1}}],[\"提供流量控制机制\",{\"1\":{\"273\":1}}],[\"提供用于高性能应用的\",{\"1\":{\"143\":1}}],[\"提供以下集体通信原语\",{\"1\":{\"143\":1}}],[\"提供拓扑感知的\",{\"1\":{\"143\":1}}],[\"提供标准的\",{\"1\":{\"143\":1}}],[\"提供一种方式\",{\"1\":{\"104\":1}}],[\"提供一种明确的机制\",{\"1\":{\"103\":1}}],[\"提供一种标准方式\",{\"1\":{\"103\":1}}],[\"提供一个用于在\",{\"1\":{\"103\":1}}],[\"提供应用程序的安装状态和垃圾回收\",{\"1\":{\"103\":1}}],[\"提供通过\",{\"1\":{\"103\":1}}],[\"提供工作流执行状态和结果的可视化\",{\"1\":{\"97\":1}}],[\"提供了替代传统gpu的硬件选择\",{\"1\":{\"418\":1}}],[\"提供了极高的带宽\",{\"1\":{\"417\":1}}],[\"提供了强大的防火墙配置能力\",{\"1\":{\"332\":1}}],[\"提供了更丰富和更强大的功能\",{\"1\":{\"321\":1}}],[\"提供了更大的灵活性\",{\"1\":{\"186\":1,\"191\":1}}],[\"提供了海量的预训练模型和众多强大易用的函数库\",{\"1\":{\"218\":1}}],[\"提供了灵活且高效的消息传递机制\",{\"1\":{\"200\":1}}],[\"提供了多种集体通信操作\",{\"1\":{\"196\":1}}],[\"提供了一种高效的解决方案\",{\"1\":{\"418\":1}}],[\"提供了一种声明性的方式来定义和管理\",{\"1\":{\"122\":1}}],[\"提供了一组标准的\",{\"1\":{\"195\":1}}],[\"提供了对数据进行广播和同步的接口\",{\"1\":{\"181\":1}}],[\"提供了分布式数据并行\",{\"1\":{\"180\":1}}],[\"提供了面向\",{\"1\":{\"122\":1}}],[\"提供了从生成基础代码到测试和部署的全流程支持\",{\"1\":{\"122\":1}}],[\"提供了从超参数调优到机器学习工作流管理的完整功能\",{\"1\":{\"97\":1}}],[\"提供了定义自定义对象的能力\",{\"1\":{\"117\":1}}],[\"提供了机器学习工作流的定义\",{\"1\":{\"97\":1}}],[\"提供了几个选项来配置\",{\"1\":{\"47\":1}}],[\"提供\",{\"1\":{\"97\":7,\"158\":1}}],[\"提供稳定的\",{\"1\":{\"44\":1}}],[\"提供的三个原语和约束\",{\"1\":{\"436\":1}}],[\"提供的arp检测功能\",{\"1\":{\"307\":1}}],[\"提供的多\",{\"1\":{\"143\":1}}],[\"提供的负载均衡\",{\"1\":{\"39\":1}}],[\"提供的一种灵活机制\",{\"1\":{\"34\":1}}],[\"要将\",{\"1\":{\"256\":1}}],[\"要配置\",{\"1\":{\"48\":1}}],[\"要更新\",{\"1\":{\"34\":1}}],[\"要创建一个\",{\"1\":{\"32\":1}}],[\"命令一起使用\",{\"1\":{\"332\":1}}],[\"命令套件\",{\"1\":{\"332\":1}}],[\"命令套件的一部分\",{\"1\":{\"321\":1,\"324\":1}}],[\"命令是查看和管理网络设备的主要工具\",{\"1\":{\"279\":1}}],[\"命令\",{\"0\":{\"279\":1,\"280\":1}}],[\"命令行后\",{\"1\":{\"257\":1,\"258\":1}}],[\"命令查询\",{\"1\":{\"75\":1}}],[\"命令查看\",{\"1\":{\"34\":2}}],[\"命令的时候\",{\"1\":{\"61\":1}}],[\"命名空间\",{\"1\":{\"22\":1}}],[\"略有不同的是\",{\"1\":{\"143\":1}}],[\"略有不同\",{\"1\":{\"34\":1}}],[\"来优化内存使用\",{\"1\":{\"455\":1}}],[\"来优化非ml任务\",{\"1\":{\"106\":1}}],[\"来推导出有效的约束\",{\"1\":{\"438\":1}}],[\"来表达像数据\",{\"1\":{\"432\":1}}],[\"来节省内存\",{\"1\":{\"418\":1}}],[\"来过滤出一组减少的张量\",{\"1\":{\"407\":1}}],[\"来返回1024维度的向量\",{\"1\":{\"365\":1}}],[\"来检查根文件系统的大小\",{\"1\":{\"262\":1}}],[\"来扩展文件系统\",{\"1\":{\"261\":1}}],[\"来使用\",{\"1\":{\"255\":1}}],[\"来进行常见机器学习代码的实战\",{\"1\":{\"229\":1}}],[\"来进行处理\",{\"1\":{\"61\":1}}],[\"来自不同的\",{\"1\":{\"158\":1}}],[\"来创建新分区\",{\"1\":{\"258\":1}}],[\"来创建该组\",{\"1\":{\"154\":1}}],[\"来创建和管理\",{\"1\":{\"30\":1}}],[\"来说\",{\"1\":{\"150\":1,\"459\":1}}],[\"来说是不合适的\",{\"1\":{\"36\":1}}],[\"来作为实现的\",{\"1\":{\"61\":1}}],[\"来实现\",{\"1\":{\"351\":1,\"444\":1}}],[\"来实现具体的\",{\"1\":{\"157\":1}}],[\"来实现均匀调度\",{\"1\":{\"59\":1}}],[\"来实现这一点\",{\"1\":{\"38\":1,\"44\":1}}],[\"来运行节点级别的服务或代理\",{\"1\":{\"33\":1}}],[\"简单邮件传输协议\",{\"1\":{\"340\":1}}],[\"简单\",{\"1\":{\"287\":1}}],[\"简单清除文件的操作\",{\"1\":{\"10\":1}}],[\"简便的编程体验也是\",{\"1\":{\"143\":1}}],[\"简介\",{\"0\":{\"78\":1},\"1\":{\"78\":2}}],[\"简化开源大模型的部署\",{\"1\":{\"220\":1}}],[\"简化了\",{\"1\":{\"122\":1}}],[\"简化数据库集群的管理\",{\"1\":{\"121\":1}}],[\"简化运维操作\",{\"1\":{\"120\":1}}],[\"简化网络配置\",{\"1\":{\"49\":1}}],[\"简化的节点管理\",{\"1\":{\"33\":1}}],[\"82\",{\"1\":{\"458\":2}}],[\"84\",{\"1\":{\"445\":1}}],[\"849479cf5f\",{\"1\":{\"97\":2}}],[\"8倍的训练性能提升\",{\"1\":{\"411\":1}}],[\"8gb\",{\"1\":{\"410\":1}}],[\"8gi\",{\"1\":{\"20\":1}}],[\"8个nvidia\",{\"1\":{\"410\":2}}],[\"8800\",{\"1\":{\"381\":2}}],[\"8e\",{\"1\":{\"258\":1}}],[\"83\",{\"1\":{\"149\":1}}],[\"8388608\",{\"1\":{\"149\":2}}],[\"8192\",{\"1\":{\"149\":2}}],[\"81\",{\"1\":{\"149\":1}}],[\"871\",{\"1\":{\"253\":3,\"254\":1}}],[\"87\",{\"1\":{\"149\":1}}],[\"8m\",{\"1\":{\"149\":2}}],[\"86868f775c\",{\"1\":{\"97\":2}}],[\"8\",{\"0\":{\"73\":1,\"275\":1,\"450\":1,\"451\":1,\"452\":1,\"453\":1,\"454\":1,\"455\":1,\"456\":1,\"457\":1,\"458\":1,\"459\":1},\"1\":{\"75\":2,\"96\":1,\"149\":7,\"366\":3,\"410\":1,\"412\":3,\"450\":3,\"451\":1,\"452\":2,\"454\":1,\"455\":3,\"456\":7,\"457\":4}}],[\"895\",{\"1\":{\"62\":1}}],[\"802\",{\"1\":{\"285\":1,\"287\":1,\"335\":1}}],[\"80万元+\",{\"1\":{\"131\":1}}],[\"8000\",{\"1\":{\"74\":1,\"381\":1}}],[\"8001\",{\"1\":{\"68\":1,\"69\":1,\"70\":1,\"71\":1,\"72\":1,\"73\":1}}],[\"8088\",{\"1\":{\"66\":4,\"68\":1,\"75\":1}}],[\"8080\",{\"1\":{\"40\":2,\"42\":1,\"43\":1}}],[\"80\",{\"1\":{\"32\":1,\"36\":1,\"40\":2,\"42\":1,\"149\":1}}],[\"你旨在回答并解决人们的任何问题\",{\"1\":{\"372\":1}}],[\"你是chatgpt\",{\"1\":{\"372\":1}}],[\"你会哪个就用哪个\",{\"1\":{\"359\":2}}],[\"你会看到进程871的系统调用输出\",{\"1\":{\"255\":1}}],[\"你很快就会知道你的想法是不是可以赚到钱\",{\"1\":{\"359\":2}}],[\"你需要重新创建一个新的分区\",{\"1\":{\"258\":1}}],[\"你需要确保\",{\"1\":{\"257\":1}}],[\"你需要执行以下步骤\",{\"1\":{\"256\":1}}],[\"你需要在节点的特定目录中\",{\"1\":{\"32\":1}}],[\"你还可以指定最大并发运行数\",{\"1\":{\"95\":1}}],[\"你必须将传递给组件之间的数据序列化\",{\"1\":{\"93\":1}}],[\"你必须将组件打包为\",{\"1\":{\"93\":1}}],[\"你可以将新的空间分配给逻辑卷\",{\"1\":{\"260\":1}}],[\"你可以这样理解这个软中断\",{\"1\":{\"255\":1}}],[\"你可以看到进程\",{\"1\":{\"254\":1}}],[\"你可以查看跨管道运行的工件和执行之间的连接\",{\"1\":{\"95\":1}}],[\"你可以从\",{\"1\":{\"95\":1}}],[\"你可以在任何实验中启动定期运行\",{\"1\":{\"95\":1}}],[\"你可以在其中尝试管道的不同配置\",{\"1\":{\"95\":1}}],[\"你可以通过以下方式加载\",{\"1\":{\"169\":1}}],[\"你可以通过以下命令访问kong代理的服务\",{\"1\":{\"74\":1}}],[\"你可以通过查看\",{\"1\":{\"95\":1}}],[\"你可以使用实验将你的运行组织成逻辑组\",{\"1\":{\"95\":1}}],[\"你可以使用\",{\"1\":{\"89\":1}}],[\"你通过以下命令启动了一个nginx容器\",{\"1\":{\"66\":1}}],[\"你仍然可以使用\",{\"1\":{\"34\":1}}],[\"你都需要确保任意故障场景下\",{\"1\":{\"5\":1}}],[\"创建新的分区并标记为\",{\"0\":{\"258\":1}}],[\"创建runs\",{\"0\":{\"113\":1}}],[\"创建流水线只是把相关参数信息写入数据库\",{\"1\":{\"112\":1}}],[\"创建组件或指定管道\",{\"1\":{\"81\":1}}],[\"创建路由\",{\"0\":{\"71\":1}}],[\"创建服务\",{\"0\":{\"68\":1}}],[\"创建一个新的分区\",{\"1\":{\"258\":1}}],[\"创建一个张量\",{\"1\":{\"183\":1}}],[\"创建一个所有工具必须实现的标准\",{\"1\":{\"104\":1}}],[\"创建一个\",{\"1\":{\"38\":1}}],[\"创建一个包含\",{\"1\":{\"32\":1}}],[\"创建\",{\"0\":{\"32\":1},\"1\":{\"152\":1}}],[\"创建了一个路由\",{\"1\":{\"71\":1}}],[\"创建了一个\",{\"1\":{\"5\":1}}],[\"保持动力等\",{\"1\":{\"359\":2}}],[\"保持不变\",{\"1\":{\"151\":1,\"443\":1}}],[\"保存了\",{\"1\":{\"151\":1}}],[\"保障系统的弹性伸缩和高可用性\",{\"1\":{\"128\":1}}],[\"保障系统的稳定性与可扩展性\",{\"1\":{\"127\":1}}],[\"保证这些关键组件的高可用性\",{\"1\":{\"31\":1}}],[\"保留数据\",{\"1\":{\"10\":1}}],[\"崩溃或被删除\",{\"1\":{\"31\":1}}],[\"自主运营并开发自己的在线业务以获得收入的人\",{\"1\":{\"359\":2}}],[\"自治系统\",{\"1\":{\"310\":1}}],[\"自由的大模型更快融入到普通学习者的生活中\",{\"1\":{\"220\":1}}],[\"自然语言处理任务中的\",{\"1\":{\"445\":1}}],[\"自然语言处理\",{\"1\":{\"218\":1}}],[\"自然就是具体的\",{\"1\":{\"61\":1}}],[\"自愈能力\",{\"1\":{\"119\":1}}],[\"自动使用链式法则的\",{\"1\":{\"445\":1}}],[\"自动缩放器行为的指标\",{\"1\":{\"212\":1}}],[\"自动同步各个设备计算出的梯度\",{\"1\":{\"181\":1}}],[\"自动处理\",{\"1\":{\"121\":1}}],[\"自动化\",{\"1\":{\"121\":1}}],[\"自动化了许多日常的运维任务\",{\"1\":{\"120\":1}}],[\"自动化升级\",{\"1\":{\"119\":1}}],[\"自动修复出现的问题\",{\"1\":{\"119\":1}}],[\"自动执行\",{\"1\":{\"119\":1}}],[\"自动重启\",{\"1\":{\"31\":1}}],[\"自\",{\"1\":{\"96\":1}}],[\"自定义额外参数\",{\"1\":{\"365\":1}}],[\"自定义内容提取提示词\",{\"1\":{\"365\":1}}],[\"自定义文本分类提示词\",{\"1\":{\"365\":1}}],[\"自定义资源\",{\"1\":{\"117\":1}}],[\"自定义资源定义\",{\"1\":{\"100\":1,\"117\":1}}],[\"自定义调度策略文件\",{\"1\":{\"60\":1}}],[\"自定义调度器策略\",{\"0\":{\"59\":1}}],[\"自定义服务发现\",{\"1\":{\"39\":1}}],[\"自访问\",{\"1\":{\"46\":1}}],[\"自身来管理\",{\"1\":{\"33\":1}}],[\"自身的管理中\",{\"1\":{\"30\":1}}],[\"存在\",{\"1\":{\"207\":1}}],[\"存储时的额外参数\",{\"1\":{\"365\":1}}],[\"存储系统\",{\"1\":{\"355\":1}}],[\"存储系统等场景中\",{\"1\":{\"351\":1}}],[\"存储等终端设备\",{\"1\":{\"347\":1}}],[\"存储设备等连接到网络\",{\"1\":{\"346\":1}}],[\"存储设备和其他网络终端\",{\"1\":{\"346\":1}}],[\"存储了所有创建的进程组及其对应的\",{\"1\":{\"151\":1}}],[\"存储工作流定义和执行状态\",{\"1\":{\"97\":1}}],[\"存储超参数调优任务的状态和结果\",{\"1\":{\"97\":1}}],[\"存储和对象数量等\",{\"1\":{\"21\":1}}],[\"存放在节点的文件系统中\",{\"1\":{\"31\":1}}],[\"格式化字符串\",{\"1\":{\"162\":1}}],[\"格式的组件规范描述\",{\"1\":{\"92\":1}}],[\"格式\",{\"1\":{\"31\":1}}],[\"静态部分的任务是生成内存节省计划\",{\"1\":{\"405\":1}}],[\"静态arp表\",{\"1\":{\"307\":1}}],[\"静态配置\",{\"1\":{\"31\":1}}],[\"静态pod\",{\"0\":{\"30\":1}}],[\"滚动更新等高级特性\",{\"1\":{\"31\":1}}],[\"会违反静态单一赋值\",{\"1\":{\"449\":1}}],[\"会识别出依赖的生产者\",{\"1\":{\"444\":1}}],[\"会被实例化为实际的\",{\"1\":{\"443\":1}}],[\"会被驱逐\",{\"1\":{\"36\":1}}],[\"会将模型和生成的并行化计划编译为可执行代码\",{\"1\":{\"442\":1}}],[\"会将设备b的ip地址和mac地址映射关系存储在本地的arp缓存中\",{\"1\":{\"303\":1}}],[\"会优先使用\",{\"1\":{\"365\":1}}],[\"会自动去掉注释\",{\"1\":{\"365\":1}}],[\"会自动检测到文件的变化并重新创建\",{\"1\":{\"34\":1}}],[\"会自动检测到该文件并创建对应的\",{\"1\":{\"32\":1}}],[\"会话层\",{\"0\":{\"338\":1}}],[\"会话\",{\"1\":{\"310\":1}}],[\"会响应中断\",{\"1\":{\"255\":1}}],[\"会把这段时间标示成\",{\"1\":{\"255\":1}}],[\"会对被跟踪的进程产生一定的性能开销\",{\"1\":{\"255\":1}}],[\"会附加到这个进程\",{\"1\":{\"253\":1}}],[\"会抛出警告\",{\"1\":{\"159\":1}}],[\"会启动\",{\"1\":{\"89\":1}}],[\"会以options方式发送预检请求\",{\"1\":{\"75\":1}}],[\"会在物化过程中插入点对点的发送\",{\"1\":{\"444\":1}}],[\"会在\",{\"1\":{\"61\":1}}],[\"会在创建容器网络接口时启用发夹规则\",{\"1\":{\"47\":1}}],[\"会保证只有当\",{\"1\":{\"51\":1}}],[\"会为每个\",{\"1\":{\"38\":1}}],[\"会根据配置文件自动重新创建它们\",{\"1\":{\"31\":1}}],[\"会定期扫描特定的目录\",{\"1\":{\"31\":1}}],[\"会使用我们上面的介绍的\",{\"1\":{\"5\":1}}],[\"由algo描述\",{\"1\":{\"433\":1}}],[\"由网络管理员手动设置\",{\"1\":{\"310\":1}}],[\"由三个部分组成\",{\"1\":{\"36\":1}}],[\"由于内存消耗较大\",{\"1\":{\"456\":1}}],[\"由于激活张量的体积巨大\",{\"1\":{\"455\":1}}],[\"由于调度搜索\",{\"1\":{\"452\":1}}],[\"由于峰值内存的减少\",{\"1\":{\"452\":1}}],[\"由于模型代码与训练代码之间的清晰分离\",{\"1\":{\"448\":1}}],[\"由于原语的灵活性和大型\",{\"1\":{\"431\":1}}],[\"由于灵活性带来的新挑战\",{\"0\":{\"427\":1}}],[\"由于其更大的搜索空间\",{\"1\":{\"425\":1}}],[\"由于大型深度神经网络\",{\"1\":{\"425\":1}}],[\"由于gpu的空闲内存资源有限\",{\"1\":{\"407\":1}}],[\"由于gpu资源有限\",{\"1\":{\"404\":1}}],[\"由于pcie带宽有限\",{\"1\":{\"401\":1}}],[\"由于深度神经网络\",{\"1\":{\"398\":1}}],[\"由于每个leaf交换机连接到多个spine交换机\",{\"1\":{\"347\":1}}],[\"由于是文本协议\",{\"1\":{\"275\":1}}],[\"由于我们的中断服务处理需要关闭中断\",{\"1\":{\"255\":1}}],[\"由于\",{\"1\":{\"34\":1,\"191\":1,\"204\":1,\"444\":1,\"457\":1}}],[\"由于某种原因无法使用\",{\"1\":{\"15\":1}}],[\"由运行在节点上的\",{\"1\":{\"31\":1}}],[\"由\",{\"1\":{\"31\":1,\"34\":1,\"143\":1}}],[\"直到我们拿出自己的产品\",{\"1\":{\"359\":2}}],[\"直到你停止\",{\"1\":{\"255\":1}}],[\"直到被释放\",{\"1\":{\"13\":1}}],[\"直接将损失和梯度值与经过充分测试的训练计划\",{\"1\":{\"448\":1}}],[\"直接修改这个环境变量\",{\"1\":{\"366\":1}}],[\"直接返回\",{\"1\":{\"154\":1}}],[\"直接与\",{\"1\":{\"96\":1}}],[\"直接与集群交互\",{\"1\":{\"96\":1}}],[\"直接相互访问\",{\"1\":{\"39\":1}}],[\"直接访问\",{\"1\":{\"38\":1}}],[\"直接管理\",{\"1\":{\"30\":1,\"31\":1,\"34\":1}}],[\"目标客户更愿意使用哪种产品\",{\"1\":{\"359\":2}}],[\"目标客户会经常出现在那里\",{\"1\":{\"359\":2}}],[\"目标设备的ip地址\",{\"1\":{\"304\":1}}],[\"目标设备的mac地址\",{\"1\":{\"304\":1}}],[\"目标协议地址\",{\"1\":{\"304\":1}}],[\"目标硬件地址\",{\"1\":{\"304\":1}}],[\"目标vtep解封装udp包\",{\"1\":{\"291\":1}}],[\"目标发现和告警管理\",{\"1\":{\"121\":1}}],[\"目标\",{\"0\":{\"103\":1}}],[\"目录结构说明\",{\"1\":{\"228\":1}}],[\"目录包含所有运行时代码\",{\"1\":{\"91\":1}}],[\"目录中后\",{\"1\":{\"32\":1}}],[\"目前缺乏访问张量中具体值的能力\",{\"1\":{\"451\":1}}],[\"目前必须小于1536维度\",{\"1\":{\"365\":1}}],[\"目前只有gpt支持\",{\"1\":{\"365\":1}}],[\"目前只有nfs和hostpath两种类型的pv支持recycle策略\",{\"1\":{\"10\":1}}],[\"目前有能力提供哪种产品形态\",{\"1\":{\"359\":2}}],[\"目前在\",{\"1\":{\"204\":1}}],[\"目前支持的选项是\",{\"1\":{\"204\":1}}],[\"目前\",{\"1\":{\"51\":1}}],[\"目的vtep接收到vxlan包后\",{\"1\":{\"292\":1}}],[\"目的\",{\"1\":{\"28\":2}}],[\"范围是1到4094\",{\"1\":{\"285\":1}}],[\"范围\",{\"1\":{\"28\":2}}],[\"比现有的系统支持更大规模的模型训练\",{\"1\":{\"419\":1}}],[\"比在dgx\",{\"1\":{\"412\":1}}],[\"比如说\",{\"1\":{\"255\":1}}],[\"比如挂起\",{\"1\":{\"254\":1}}],[\"比如上面例子里的\",{\"1\":{\"51\":1}}],[\"比如\",{\"1\":{\"51\":1,\"61\":2,\"255\":1,\"365\":1}}],[\"比较与总结\",{\"0\":{\"28\":1}}],[\"比自己小的\",{\"1\":{\"5\":2}}],[\"鼓励开发人员在部署\",{\"1\":{\"24\":1}}],[\"鼓励合理的资源分配\",{\"1\":{\"24\":1}}],[\"与三个流行的分布式训练系统进行了比较\",{\"1\":{\"454\":1}}],[\"与表\",{\"1\":{\"451\":1}}],[\"与相关通信时间\",{\"1\":{\"440\":1}}],[\"与deepspeed\",{\"1\":{\"423\":1}}],[\"与这些系统不同\",{\"1\":{\"418\":1}}],[\"与mpress相同\",{\"1\":{\"412\":1}}],[\"与最先进的重计算系统相比\",{\"1\":{\"411\":1}}],[\"与gpu\",{\"1\":{\"411\":1}}],[\"与gpu内存之间的数据传输速度快于普通可分页内存\",{\"1\":{\"408\":1}}],[\"与重计算相比\",{\"1\":{\"407\":1}}],[\"与实际训练可能需要运行数百万次迭代以实现模型收敛不同\",{\"1\":{\"405\":1}}],[\"与此相反\",{\"1\":{\"399\":1}}],[\"与此不同\",{\"1\":{\"398\":1,\"412\":1}}],[\"与其他两种方法相比\",{\"1\":{\"398\":1}}],[\"与其他并行模型的比较\",{\"0\":{\"186\":1}}],[\"与oneapi对应\",{\"1\":{\"365\":1}}],[\"与物理内存和网络适配器\",{\"1\":{\"351\":1}}],[\"与vxlan\",{\"0\":{\"284\":1}}],[\"与多个程序相对应\",{\"1\":{\"190\":1}}],[\"与许多优化框架\",{\"1\":{\"106\":1}}],[\"与应用程序\",{\"1\":{\"103\":1}}],[\"与元数据\",{\"1\":{\"97\":1}}],[\"与执行或工件关联的自定义属性等\",{\"1\":{\"95\":1}}],[\"与端点通信以提交作业的代码\",{\"1\":{\"91\":1}}],[\"与它建立长连接\",{\"1\":{\"61\":1}}],[\"与普通的\",{\"1\":{\"38\":1}}],[\"与\",{\"0\":{\"41\":1,\"191\":1,\"353\":1},\"1\":{\"23\":1,\"91\":1,\"97\":1,\"106\":2,\"143\":3,\"172\":1,\"186\":2,\"189\":1,\"190\":1,\"204\":2,\"352\":1,\"353\":1,\"354\":1,\"444\":1,\"454\":1}}],[\"与pv相连的后端存储完成volume的删除操作\",{\"1\":{\"10\":1}}],[\"成为可能\",{\"1\":{\"431\":1}}],[\"成为一名独立开发者可以提供很多传统工作所无法提供的优点\",{\"1\":{\"359\":2}}],[\"成长与学习\",{\"1\":{\"359\":2}}],[\"成功支持了\",{\"1\":{\"451\":1}}],[\"成功\",{\"1\":{\"94\":1}}],[\"成功后\",{\"1\":{\"5\":1}}],[\"成本管理\",{\"1\":{\"22\":1}}],[\"之和\",{\"1\":{\"440\":1}}],[\"之前执行\",{\"1\":{\"431\":1,\"433\":1}}],[\"之前方法难以低成本在单个\",{\"1\":{\"249\":1}}],[\"之前\",{\"1\":{\"176\":1}}],[\"之前已经绑定的\",{\"1\":{\"14\":1}}],[\"之间快速交换数据\",{\"1\":{\"352\":1}}],[\"之间交换路由信息\",{\"1\":{\"309\":1}}],[\"之间进行消息传递和协调\",{\"1\":{\"195\":1}}],[\"之间提供快速的集体通信\",{\"1\":{\"143\":1}}],[\"之间的某些通信模式可以通过集体通信原语\",{\"1\":{\"444\":1}}],[\"之间的高速互连技术\",{\"1\":{\"356\":1}}],[\"之间的高速通信\",{\"1\":{\"354\":1,\"355\":1}}],[\"之间的高速数据传输密切相关\",{\"1\":{\"351\":1}}],[\"之间的数据传输\",{\"1\":{\"353\":1}}],[\"之间的数据交换\",{\"1\":{\"352\":1}}],[\"之间的数字\",{\"1\":{\"204\":1}}],[\"之间的通信可以通过更高效的\",{\"1\":{\"444\":1}}],[\"之间的通信效率\",{\"1\":{\"354\":1}}],[\"之间的通信\",{\"1\":{\"352\":1}}],[\"之间的安全网络通信\",{\"1\":{\"143\":1}}],[\"之间的互操作性\",{\"1\":{\"103\":1}}],[\"之间的资源使用\",{\"1\":{\"22\":1}}],[\"之间有一定的关联关系\",{\"1\":{\"97\":1}}],[\"之上安排\",{\"1\":{\"79\":1}}],[\"之上\",{\"1\":{\"78\":1}}],[\"之后\",{\"1\":{\"61\":1,\"311\":1}}],[\"控制数据包的流入\",{\"1\":{\"332\":1}}],[\"控制\",{\"1\":{\"143\":1}}],[\"控制平面来实现和基准测试他们自己的优化算法\",{\"1\":{\"106\":1}}],[\"控制平面组件\",{\"1\":{\"30\":1,\"33\":2}}],[\"控制器的核心任务是不断将资源的实际状态调整为期望状态\",{\"1\":{\"118\":1}}],[\"控制器监控自定义资源的状态\",{\"1\":{\"118\":1}}],[\"控制器是\",{\"1\":{\"117\":1}}],[\"控制器管理器\",{\"1\":{\"97\":2}}],[\"控制器\",{\"1\":{\"33\":1,\"97\":1,\"117\":1}}],[\"控制命名空间内的资源使用上限\",{\"1\":{\"28\":1}}],[\"控制资源使用来管理和控制成本\",{\"1\":{\"22\":1}}],[\"控制资源分配\",{\"1\":{\"19\":1}}],[\"控制不同租户\",{\"1\":{\"22\":1}}],[\"多程序多数据\",{\"1\":{\"451\":1}}],[\"多语言模型如\",{\"1\":{\"436\":1}}],[\"多语言大型语言模型\",{\"1\":{\"426\":1}}],[\"多租户支持\",{\"1\":{\"290\":1}}],[\"多租户环境\",{\"1\":{\"22\":1,\"28\":1}}],[\"多路复用\",{\"0\":{\"270\":1},\"1\":{\"277\":2}}],[\"多类型源数据的处理\",{\"1\":{\"223\":1}}],[\"多物理场仿真\",{\"1\":{\"192\":1}}],[\"多个小的请求可能会因为串行化处理导致较高的延迟和低效的带宽利用\",{\"1\":{\"276\":1}}],[\"多个程序\",{\"1\":{\"190\":1}}],[\"多个处理单元\",{\"1\":{\"189\":1}}],[\"多个处理单元同时执行相同的程序代码\",{\"1\":{\"184\":1}}],[\"多数据流\",{\"1\":{\"185\":1,\"190\":1}}],[\"多gpu训练\",{\"1\":{\"182\":1}}],[\"多节点的分布式训练任务\",{\"1\":{\"177\":1}}],[\"多节点和多gpu分布式训练\",{\"1\":{\"106\":1}}],[\"多进程\",{\"1\":{\"143\":1}}],[\"多线程\",{\"1\":{\"143\":1}}],[\"多种访问模式不能同时生效\",{\"1\":{\"9\":1}}],[\"内容提取\",{\"1\":{\"365\":2}}],[\"内容如下\",{\"1\":{\"169\":1}}],[\"内核防火墙实现\",{\"1\":{\"330\":1}}],[\"内核态\",{\"1\":{\"255\":1}}],[\"内核中的延迟细分和稀疏模式\",{\"1\":{\"249\":1}}],[\"内核执行高效计算\",{\"1\":{\"249\":1}}],[\"内部原理\",{\"0\":{\"403\":1}}],[\"内部bgp\",{\"1\":{\"310\":1}}],[\"内部的不同容器通过\",{\"1\":{\"49\":1}}],[\"内部通信\",{\"1\":{\"46\":1}}],[\"内的容器通信\",{\"1\":{\"49\":1}}],[\"内的容器是否能够通过\",{\"1\":{\"45\":1}}],[\"内的多个容器之间的通信\",{\"1\":{\"46\":1}}],[\"内的其他容器\",{\"1\":{\"46\":1,\"47\":1}}],[\"内存使用\",{\"1\":{\"438\":1,\"454\":1}}],[\"内存消耗\",{\"1\":{\"426\":1}}],[\"内存优化\",{\"1\":{\"418\":2}}],[\"内存优化及其局限性\",{\"0\":{\"401\":1}}],[\"内存不足\",{\"1\":{\"417\":1}}],[\"内存交换\",{\"1\":{\"408\":1}}],[\"内存交换需求与目标操作间并行训练任务中空闲gpu内存资源的多样性\",{\"1\":{\"406\":1}}],[\"内存管理\",{\"1\":{\"408\":1}}],[\"内存管理器和压缩库三个关键系统组件\",{\"1\":{\"405\":1}}],[\"内存压缩规划\",{\"0\":{\"407\":1}}],[\"内存平衡的分区策略能够解决gpu内存不平衡的问题\",{\"1\":{\"401\":1}}],[\"内存缓存\",{\"1\":{\"366\":1}}],[\"内存拷贝操作和\",{\"1\":{\"143\":1}}],[\"内存\",{\"1\":{\"21\":1,\"454\":1}}],[\"内资源总量的机制\",{\"1\":{\"18\":1}}],[\"包括现有的手工设计的计划\",{\"1\":{\"450\":1}}],[\"包括新模块的并行化\",{\"1\":{\"446\":1}}],[\"包括不要熬夜做产品\",{\"1\":{\"359\":2}}],[\"包括产品有什么核心功能和特点\",{\"1\":{\"359\":2}}],[\"包括想法\",{\"1\":{\"359\":2}}],[\"包括美工问题\",{\"1\":{\"359\":2}}],[\"包括人身自由\",{\"1\":{\"359\":2}}],[\"包括什么是独立开发者\",{\"1\":{\"359\":2}}],[\"包括数据加密\",{\"1\":{\"339\":1}}],[\"包括定义硬件设备的电气\",{\"1\":{\"334\":1}}],[\"包括定期运行\",{\"1\":{\"95\":1}}],[\"包括其ip地址和mac地址\",{\"1\":{\"294\":1}}],[\"包括veth设备对\",{\"1\":{\"279\":1}}],[\"包括大模型本身\",{\"1\":{\"224\":1}}],[\"包括但不限于\",{\"1\":{\"223\":1}}],[\"包括将\",{\"1\":{\"223\":1}}],[\"包括调用原生\",{\"1\":{\"223\":1}}],[\"包括分布式全量微调\",{\"1\":{\"220\":1}}],[\"包括命令行调用\",{\"1\":{\"220\":1}}],[\"包括工件在内的管道组件非常有用\",{\"1\":{\"95\":1}}],[\"包括工作流中的所有组件及其相互关系\",{\"1\":{\"89\":1}}],[\"包括\",{\"1\":{\"21\":1,\"143\":1,\"220\":1,\"318\":1,\"332\":1,\"395\":1}}],[\"包含了所有进程\",{\"1\":{\"196\":1}}],[\"包含模块路径和对象名称\",{\"1\":{\"168\":1}}],[\"包含\",{\"1\":{\"5\":1,\"436\":1,\"445\":1}}],[\"主打\",{\"1\":{\"226\":1}}],[\"主页\",{\"1\":{\"100\":1}}],[\"主要通过在数据并行模式下只保留优化器状态的单份拷贝来减少内存占用\",{\"1\":{\"454\":1}}],[\"主要包括执行器\",{\"1\":{\"405\":1}}],[\"主要有三种并行训练方法\",{\"1\":{\"398\":1}}],[\"主要负责流量控制\",{\"1\":{\"337\":1}}],[\"主要是指ai系统遇到大模型\",{\"1\":{\"232\":1}}],[\"主要特色为力求数码结合\",{\"1\":{\"229\":1}}],[\"主要内容包括\",{\"1\":{\"222\":1}}],[\"主要功能\",{\"0\":{\"181\":1}}],[\"主要用于\",{\"1\":{\"352\":1}}],[\"主要用于注册与\",{\"1\":{\"164\":1}}],[\"主要用于以下几种场景\",{\"1\":{\"39\":1}}],[\"主要集中在容器化应用程序上\",{\"1\":{\"100\":1}}],[\"主要的\",{\"0\":{\"96\":1}}],[\"主要依赖于从\",{\"1\":{\"51\":1}}],[\"主要控制单个\",{\"1\":{\"23\":1}}],[\"主要字段\",{\"0\":{\"21\":1,\"26\":1}}],[\"主备异步复制可能导致丢数据的问题\",{\"1\":{\"5\":1}}],[\"5×\",{\"1\":{\"450\":2}}],[\"5倍\",{\"1\":{\"424\":1}}],[\"5倍的加速\",{\"1\":{\"423\":1}}],[\"5b的模型\",{\"1\":{\"412\":1}}],[\"5bbh9\",{\"1\":{\"97\":2}}],[\"5mb的数据\",{\"1\":{\"398\":1}}],[\"5s\",{\"1\":{\"381\":2}}],[\"5e\",{\"1\":{\"297\":1}}],[\"58\",{\"1\":{\"294\":4}}],[\"58248\",{\"1\":{\"149\":1}}],[\"58247\",{\"1\":{\"149\":1}}],[\"58246\",{\"1\":{\"149\":1}}],[\"58245\",{\"1\":{\"149\":47}}],[\"58239\",{\"1\":{\"149\":59}}],[\"52\",{\"1\":{\"283\":2}}],[\"524288\",{\"1\":{\"149\":2}}],[\"59918\",{\"1\":{\"149\":1}}],[\"50\",{\"1\":{\"455\":1,\"459\":1}}],[\"507e\",{\"1\":{\"283\":1}}],[\"504\",{\"1\":{\"149\":1}}],[\"50000\",{\"1\":{\"375\":2,\"376\":1}}],[\"5000+\",{\"1\":{\"131\":1}}],[\"5000\",{\"1\":{\"36\":1,\"97\":1}}],[\"500m\",{\"1\":{\"25\":1,\"36\":1}}],[\"5432\",{\"1\":{\"381\":3}}],[\"54\",{\"1\":{\"149\":2,\"431\":1}}],[\"5499555669\",{\"1\":{\"97\":2}}],[\"53\",{\"1\":{\"149\":1}}],[\"512gb\",{\"1\":{\"417\":1}}],[\"512\",{\"1\":{\"149\":2,\"365\":2}}],[\"512mi\",{\"1\":{\"25\":1}}],[\"57dbbdfd77\",{\"1\":{\"97\":2}}],[\"5\",{\"0\":{\"70\":1,\"261\":1,\"272\":1,\"338\":1,\"439\":1,\"440\":1,\"441\":1,\"458\":1},\"1\":{\"20\":1,\"149\":3,\"150\":1,\"175\":1,\"176\":1,\"242\":1,\"365\":3,\"366\":4,\"372\":1,\"381\":1,\"410\":1,\"411\":1,\"416\":1,\"426\":1,\"431\":1,\"435\":2,\"452\":1,\"455\":2,\"456\":2,\"457\":1,\"458\":1,\"459\":2}}],[\"限制了其在某些场景下的应用\",{\"1\":{\"217\":1}}],[\"限制资源以确保测试环境不会占用过多的生产资源\",{\"1\":{\"22\":1}}],[\"限制内存使用总量\",{\"1\":{\"20\":1}}],[\"限制内存请求总量\",{\"1\":{\"20\":1}}],[\"限制\",{\"1\":{\"20\":4}}],[\"限制命名空间资源使用\",{\"1\":{\"19\":1}}],[\"和计算与通信的重叠\",{\"1\":{\"451\":1}}],[\"和本文中介绍的创新计划\",{\"1\":{\"450\":1}}],[\"和图神经网络\",{\"1\":{\"446\":1}}],[\"和用户指定的搜索空间作为输入\",{\"1\":{\"439\":1}}],[\"和用户界面进行紧密集成\",{\"1\":{\"97\":1}}],[\"和前馈\",{\"1\":{\"435\":1}}],[\"和一个操作符\",{\"1\":{\"430\":1}}],[\"和流水线并行性的结合\",{\"1\":{\"425\":1}}],[\"和23\",{\"1\":{\"412\":1}}],[\"和通过层级分区\",{\"1\":{\"398\":1}}],[\"和网络交换机有关\",{\"1\":{\"353\":1}}],[\"和vxlan\",{\"1\":{\"284\":1}}],[\"和聚集\",{\"1\":{\"196\":1}}],[\"和sharp\",{\"1\":{\"176\":1}}],[\"和其他可选参数\",{\"1\":{\"159\":1}}],[\"和其他为性能优化的库类似\",{\"1\":{\"143\":1}}],[\"和相对\",{\"1\":{\"154\":1}}],[\"和多节点通信\",{\"1\":{\"143\":1}}],[\"和控制器的实现\",{\"1\":{\"118\":1}}],[\"和控制器旨在改变这种状况\",{\"1\":{\"100\":1}}],[\"和行为方式\",{\"1\":{\"118\":1}}],[\"和工具来自动管理复杂应用的生命周期\",{\"1\":{\"116\":1}}],[\"和服务正常运行\",{\"1\":{\"97\":1}}],[\"和内存的默认值和最大\",{\"1\":{\"25\":1}}],[\"和内存总量\",{\"1\":{\"20\":1}}],[\"和\",{\"0\":{\"292\":1,\"316\":1,\"352\":1,\"443\":1},\"1\":{\"17\":1,\"20\":1,\"30\":1,\"33\":2,\"51\":1,\"97\":1,\"106\":2,\"111\":3,\"139\":1,\"143\":1,\"158\":1,\"159\":1,\"162\":2,\"171\":1,\"192\":1,\"196\":1,\"203\":2,\"204\":2,\"207\":6,\"228\":1,\"332\":2,\"352\":1,\"353\":1,\"354\":3,\"356\":1,\"359\":2,\"366\":1,\"427\":1,\"428\":1,\"429\":1,\"431\":1,\"433\":4,\"435\":2,\"437\":1,\"439\":3,\"442\":1,\"443\":1,\"444\":3,\"446\":1,\"450\":3,\"451\":1,\"453\":1,\"454\":4,\"455\":3,\"456\":6,\"457\":5,\"458\":5,\"459\":1}}],[\"或全归约\",{\"1\":{\"448\":1}}],[\"或撤销\",{\"1\":{\"311\":1}}],[\"或在解析管道代码中的\",{\"1\":{\"95\":1}}],[\"或在\",{\"1\":{\"95\":1,\"203\":1}}],[\"或跳过\",{\"1\":{\"94\":1}}],[\"或者私有化的laf环境\",{\"1\":{\"365\":1}}],[\"或者通过增加leaf交换机来连接更多设备\",{\"1\":{\"347\":1}}],[\"或者宿主机本身正处于\",{\"1\":{\"51\":1}}],[\"或者在启动\",{\"1\":{\"48\":1}}],[\"或者\",{\"1\":{\"46\":1}}],[\"或其他控制器管理的\",{\"1\":{\"31\":1}}],[\"或容器的资源使用\",{\"1\":{\"28\":1}}],[\"或容器的资源使用范围\",{\"1\":{\"23\":1}}],[\"或容器没有指定资源请求和限制\",{\"1\":{\"24\":1}}],[\"或容器资源使用的机制\",{\"1\":{\"23\":1}}],[\"或\",{\"1\":{\"17\":1,\"31\":3,\"89\":1,\"105\":1,\"143\":2,\"150\":1,\"162\":1,\"204\":1,\"350\":1,\"353\":1,\"354\":4,\"356\":1,\"429\":2,\"444\":2}}],[\"删除规则\",{\"1\":{\"331\":1}}],[\"删除和查看路由规则\",{\"1\":{\"327\":1,\"332\":1}}],[\"删除路由\",{\"0\":{\"73\":1},\"1\":{\"328\":1}}],[\"删除服务和路由\",{\"1\":{\"75\":1}}],[\"删除服务\",{\"0\":{\"70\":1}}],[\"删除或再利用\",{\"1\":{\"17\":1}}],[\"删除\",{\"1\":{\"17\":1,\"257\":2}}],[\"|di|\",{\"1\":{\"435\":1}}],[\"|d|\",{\"1\":{\"433\":2}}],[\"|mi|\",{\"1\":{\"435\":2}}],[\"|\",{\"1\":{\"17\":6,\"279\":1,\"280\":1,\"282\":1,\"366\":1,\"433\":1}}],[\"使某些并行化计划容易出错\",{\"1\":{\"447\":1}}],[\"使并行化计划的生成比以前的方法更加简单\",{\"1\":{\"438\":1}}],[\"使领域专家能够为他们的模型找到更有效的训练计划\",{\"1\":{\"426\":1}}],[\"使bert模型变得更深\",{\"1\":{\"410\":1}}],[\"使设备能够通过ip地址找到目标设备的mac地址\",{\"1\":{\"308\":1}}],[\"使得数据转发路径较短\",{\"1\":{\"347\":1}}],[\"使得网络设计和实现更加模块化和清晰\",{\"1\":{\"343\":1}}],[\"使得网络应用能够更高效地传输数据\",{\"1\":{\"277\":1}}],[\"使得设备能够通过ip地址找到目标设备的物理地址\",{\"1\":{\"302\":1}}],[\"使得跨越不同物理位置的虚拟机能够像在同一个二层网络中一样进行通信\",{\"1\":{\"293\":1}}],[\"使得虚拟机可以在不同的物理位置之间自由迁移\",{\"1\":{\"290\":1}}],[\"使得虚拟机和容器之间的通信更加灵活和高效\",{\"1\":{\"286\":1}}],[\"使得不同vlan之间的通信受到限制\",{\"1\":{\"285\":1}}],[\"使得程序能够在多处理单元环境中高效运行\",{\"1\":{\"200\":1}}],[\"使得这些函数能够被\",{\"1\":{\"173\":1}}],[\"使得创建复杂的应用管理变得更简单\",{\"1\":{\"122\":1}}],[\"使得\",{\"1\":{\"120\":1}}],[\"使得复杂应用的管理变得更一致和可靠\",{\"1\":{\"120\":1}}],[\"使得用户可以在\",{\"1\":{\"117\":1}}],[\"使得流量可以从容器发出后\",{\"1\":{\"45\":1}}],[\"使应用程序能够声明对另一个应用程序的依赖关系\",{\"1\":{\"103\":1}}],[\"使应用程序能够向\",{\"1\":{\"103\":1}}],[\"使其适应单个设备的训练\",{\"1\":{\"448\":1}}],[\"使其利用新增的空间\",{\"1\":{\"261\":1}}],[\"使其能够直接与\",{\"1\":{\"143\":1}}],[\"使其能够在众多支持工具之间实现互操作\",{\"1\":{\"100\":1}}],[\"使其可以绑定到新的\",{\"1\":{\"16\":1}}],[\"使主容器可以访问子容器的文件系统和进程\",{\"1\":{\"96\":1}}],[\"使\",{\"1\":{\"95\":1,\"104\":1,\"150\":1}}],[\"使用张量并行性处理大嵌入层\",{\"1\":{\"456\":1}}],[\"使用了纯数据并行性结合\",{\"1\":{\"457\":1}}],[\"使用了纯数据并行性\",{\"1\":{\"457\":1}}],[\"使用了\",{\"1\":{\"456\":2,\"457\":2}}],[\"使用三维并行化空间\",{\"1\":{\"454\":1}}],[\"使用三个原语构建搜索空间就变得直观了\",{\"1\":{\"438\":1}}],[\"使用更大的图像会在训练过程中生成更大的中间张量\",{\"1\":{\"435\":1}}],[\"使用上述提到的三个原语\",{\"1\":{\"431\":1}}],[\"使用不同规模的bert变体进行操作间并行训练时的性能\",{\"1\":{\"411\":1}}],[\"使用维基百科数据集训练gpt\",{\"1\":{\"410\":1}}],[\"使用异构内存优化技术来应对著名的gpu内存墙问题\",{\"1\":{\"404\":1}}],[\"使用fastgpt\",{\"1\":{\"372\":1}}],[\"使用什么样的编程语言\",{\"1\":{\"359\":4}}],[\"使用ecmp\",{\"1\":{\"347\":1}}],[\"使用网络设备\",{\"1\":{\"307\":1}}],[\"使用示例\",{\"0\":{\"300\":1}}],[\"使用hpack算法进行压缩\",{\"1\":{\"277\":1}}],[\"使用流的概念\",{\"1\":{\"269\":1}}],[\"使用二进制帧传输数据\",{\"1\":{\"268\":1}}],[\"使用新行符分隔的文本消息进行通信\",{\"1\":{\"268\":1}}],[\"使用默认的开始和结束扇区\",{\"1\":{\"258\":1}}],[\"使用类型\",{\"1\":{\"255\":1}}],[\"使用没讲到\",{\"1\":{\"255\":1}}],[\"使用中的\",{\"1\":{\"255\":1}}],[\"使用优化的\",{\"1\":{\"249\":1}}],[\"使用和应用流程\",{\"1\":{\"220\":1}}],[\"使用给定的\",{\"1\":{\"159\":1}}],[\"使用线程并行初始化\",{\"1\":{\"150\":1}}],[\"使用简单的模式匹配来识别每个\",{\"1\":{\"444\":1}}],[\"使用简单的\",{\"1\":{\"143\":1}}],[\"使用大规模指标来调试管道运行或调查单个运行的性能\",{\"1\":{\"86\":1}}],[\"使用kubeflow\",{\"1\":{\"81\":1}}],[\"使用混杂模式的网桥\",{\"1\":{\"47\":1}}],[\"使用量\",{\"1\":{\"25\":2}}],[\"使用场景\",{\"0\":{\"22\":1,\"27\":1,\"33\":1,\"39\":1,\"49\":1,\"182\":1,\"198\":1,\"254\":1}}],[\"使用总量\",{\"1\":{\"20\":1}}],[\"使用\",{\"0\":{\"121\":1,\"279\":1,\"280\":1},\"1\":{\"11\":1,\"12\":1,\"13\":1,\"33\":1,\"95\":2,\"116\":1,\"168\":3,\"174\":1,\"188\":1,\"193\":1,\"211\":1,\"223\":1,\"255\":3,\"257\":1,\"261\":1,\"262\":1,\"271\":1,\"274\":1,\"332\":3,\"354\":1,\"380\":1,\"454\":1}}],[\"如重计算\",{\"1\":{\"451\":1}}],[\"如数据并行性\",{\"1\":{\"448\":1}}],[\"如算法1所示\",{\"1\":{\"439\":1}}],[\"如图右侧所示\",{\"1\":{\"452\":1}}],[\"如图\",{\"1\":{\"433\":1,\"443\":1,\"444\":1,\"455\":1}}],[\"如表3所示\",{\"1\":{\"433\":1}}],[\"如表ii所示\",{\"1\":{\"410\":1}}],[\"如deepspeed\",{\"1\":{\"424\":1}}],[\"如dgx\",{\"1\":{\"396\":1,\"406\":1}}],[\"如alphafold2\",{\"1\":{\"424\":1}}],[\"如swin\",{\"1\":{\"423\":1,\"424\":1}}],[\"如处理大型嵌入表时\",{\"1\":{\"423\":1}}],[\"如参数和梯度\",{\"1\":{\"411\":1}}],[\"如gpipe\",{\"1\":{\"408\":1}}],[\"如pipedream\",{\"1\":{\"398\":1}}],[\"如深度学习训练和大规模并行计算\",{\"1\":{\"355\":1}}],[\"如科学计算和模拟仿真\",{\"1\":{\"348\":1}}],[\"如双绞线\",{\"1\":{\"334\":1}}],[\"如交换机\",{\"1\":{\"307\":1}}],[\"如mac地址\",{\"1\":{\"302\":1}}],[\"如ens3或docker0\",{\"1\":{\"298\":1}}],[\"如33\",{\"1\":{\"298\":1}}],[\"如flannel\",{\"1\":{\"295\":1}}],[\"如广播\",{\"1\":{\"196\":1}}],[\"如广播或规约\",{\"1\":{\"150\":1}}],[\"如计算集群\",{\"1\":{\"196\":1}}],[\"如在大规模数据处理或分析任务中\",{\"1\":{\"192\":1}}],[\"如流体动力学和热传导\",{\"1\":{\"192\":1}}],[\"如多个gpu或多台机器\",{\"1\":{\"180\":1}}],[\"如nic\",{\"1\":{\"176\":1}}],[\"如初始化\",{\"1\":{\"164\":1}}],[\"如求和\",{\"1\":{\"156\":1,\"157\":1}}],[\"如何无法访问\",{\"1\":{\"366\":1}}],[\"如何面对压力\",{\"1\":{\"359\":2}}],[\"如何面对压力等\",{\"1\":{\"359\":2}}],[\"如何保持积极的心态\",{\"1\":{\"359\":4}}],[\"如何解决用户的问题\",{\"1\":{\"359\":4}}],[\"如何判断想法的是不是可以赚钱\",{\"1\":{\"359\":4}}],[\"如何评估你的大模型\",{\"1\":{\"224\":1}}],[\"如何调用大模型\",{\"1\":{\"223\":1}}],[\"如何开发一个\",{\"0\":{\"223\":1}}],[\"如何发现同伴\",{\"1\":{\"203\":1}}],[\"如何选择适合的执行器\",{\"0\":{\"97\":1}}],[\"如何能够让\",{\"0\":{\"52\":1}}],[\"如监控\",{\"1\":{\"95\":1}}],[\"如下图所示\",{\"1\":{\"106\":1}}],[\"如下所示\",{\"1\":{\"36\":1}}],[\"如下代码所示\",{\"1\":{\"5\":1}}],[\"如仅应用于某些特定的资源类型\",{\"1\":{\"21\":1}}],[\"如\",{\"1\":{\"20\":1,\"30\":2,\"33\":1,\"97\":1,\"106\":3,\"117\":1,\"143\":1,\"161\":1,\"162\":2,\"181\":1,\"187\":1,\"189\":1,\"192\":1,\"195\":1,\"204\":1,\"351\":2,\"352\":1,\"427\":1,\"444\":2,\"459\":1}}],[\"如果就地操作符的划分导致张量被克隆\",{\"1\":{\"449\":1}}],[\"如果新的配置比之前的配置性能更好\",{\"1\":{\"407\":1}}],[\"如果需要修改\",{\"1\":{\"366\":1}}],[\"如果需要删除路由\",{\"1\":{\"73\":1}}],[\"如果需要删除服务\",{\"1\":{\"70\":1}}],[\"如果修改了账号密码\",{\"1\":{\"366\":1}}],[\"如果希望使用\",{\"1\":{\"365\":1}}],[\"如果仍为\",{\"1\":{\"365\":1}}],[\"如果为false\",{\"1\":{\"365\":1}}],[\"如果使用\",{\"1\":{\"365\":1}}],[\"如果使用多个进程并且使用\",{\"1\":{\"204\":1}}],[\"如果设备b的ip地址与请求中的ip地址匹配\",{\"1\":{\"303\":1}}],[\"如果在arp缓存中找不到设备b的mac地址\",{\"1\":{\"303\":1}}],[\"如果在函数执行过程中发生异常\",{\"1\":{\"162\":1}}],[\"如果将veth设备移动到不同的命名空间\",{\"1\":{\"283\":1}}],[\"如果已经挂载\",{\"1\":{\"257\":1}}],[\"如果这些工作比较耗时那怎么办呢\",{\"1\":{\"255\":1}}],[\"如果这时这台机器在网络收到一个网络数据包\",{\"1\":{\"255\":1}}],[\"如果目标进程由另一个用户\",{\"1\":{\"255\":1}}],[\"如果某个进程表现异常\",{\"1\":{\"254\":1}}],[\"如果有必要\",{\"1\":{\"414\":1}}],[\"如果有你非常喜欢但我们还没有进行复现的吴恩达老师大模型课程\",{\"1\":{\"226\":1}}],[\"如果有效\",{\"1\":{\"206\":1}}],[\"如果想提前知道\",{\"1\":{\"204\":1}}],[\"如果指定了\",{\"1\":{\"204\":2}}],[\"如果未指定\",{\"1\":{\"204\":1}}],[\"如果未提供后端\",{\"1\":{\"204\":1}}],[\"如果两者都未指定\",{\"1\":{\"203\":1}}],[\"如果是在\",{\"1\":{\"171\":1}}],[\"如果是的话\",{\"1\":{\"154\":1}}],[\"如果不是\",{\"1\":{\"171\":1}}],[\"如果编译时定义了\",{\"1\":{\"165\":1}}],[\"如果参数无法解析\",{\"1\":{\"162\":1}}],[\"如果用户使用了旧版\",{\"1\":{\"159\":1}}],[\"如果同时传入\",{\"1\":{\"158\":1}}],[\"如果没有提供\",{\"1\":{\"158\":1}}],[\"如果没有注册\",{\"1\":{\"154\":1}}],[\"如果你正在寻找一位能够推动项目成功\",{\"1\":{\"131\":1}}],[\"如果你对开发\",{\"1\":{\"123\":1}}],[\"如果你更熟悉\",{\"1\":{\"97\":1}}],[\"如果你的工作流需要高效处理大量文件操作\",{\"1\":{\"97\":1}}],[\"如果你的工作流步骤之间需要共享文件或进程命名空间\",{\"1\":{\"97\":1}}],[\"如果你的工作流不需要特别的资源共享或文件处理\",{\"1\":{\"97\":1}}],[\"如果一个工件被多个不同运行中的执行使用\",{\"1\":{\"95\":1}}],[\"如果管道预计运行时间较长且触发频繁运行\",{\"1\":{\"95\":1}}],[\"如果pod不设置亲和性tolerations\",{\"1\":{\"36\":1}}],[\"如果\",{\"1\":{\"16\":1,\"24\":1,\"31\":1,\"150\":1,\"151\":3,\"154\":1,\"159\":1}}],[\"如果允许再利用\",{\"1\":{\"16\":1}}],[\"再往上则会出现gpu内存不足的错误\",{\"1\":{\"400\":1}}],[\"再从spine交换机到另一台leaf交换机\",{\"1\":{\"347\":1}}],[\"再选择性地学习我们的选修类课程\",{\"1\":{\"226\":1}}],[\"再利用或删除\",{\"1\":{\"16\":1}}],[\"再次使用\",{\"1\":{\"14\":1}}],[\"释放\",{\"1\":{\"16\":1,\"162\":1}}],[\"释放锁的过程性能开销要尽量低\",{\"1\":{\"5\":1}}],[\"释放锁\",{\"1\":{\"5\":1}}],[\"后来的手工搜索空间\",{\"1\":{\"426\":1}}],[\"后面跟随的是设备名\",{\"1\":{\"298\":1}}],[\"后续请求只需发送差异部分\",{\"1\":{\"271\":1}}],[\"后端都支持\",{\"1\":{\"207\":1}}],[\"后端只支持\",{\"1\":{\"207\":2}}],[\"后端支持\",{\"1\":{\"207\":4}}],[\"后端使用高优先级的\",{\"1\":{\"204\":1}}],[\"后端的默认值为\",{\"1\":{\"204\":1}}],[\"后端为实验性特性\",{\"1\":{\"204\":1}}],[\"后端时\",{\"1\":{\"156\":1}}],[\"后端将管道运行的运行时信息存储在元数据存储中\",{\"1\":{\"95\":1}}],[\"后端\",{\"1\":{\"95\":1,\"204\":1}}],[\"后\",{\"1\":{\"16\":1,\"118\":1,\"259\":1}}],[\"被分割成两部分\",{\"1\":{\"452\":1}}],[\"被分配给第\",{\"1\":{\"435\":1}}],[\"被分配到同一设备时\",{\"1\":{\"431\":1}}],[\"被引入以追踪应用三个原语时数据依赖关系的变化\",{\"1\":{\"443\":1}}],[\"被证明能够产生更优的并行化计划\",{\"1\":{\"425\":1}}],[\"被广泛应用于isp\",{\"1\":{\"309\":1}}],[\"被广泛应用于分布式深度学习训练中\",{\"1\":{\"182\":1}}],[\"被设置时\",{\"1\":{\"204\":1}}],[\"被调度到带有特定标签的节点上\",{\"1\":{\"56\":1}}],[\"被认为不再需要\",{\"1\":{\"16\":1}}],[\"被删除后\",{\"1\":{\"16\":1}}],[\"被绑定到\",{\"1\":{\"16\":1}}],[\"被创建后\",{\"1\":{\"16\":1}}],[\"状态是stale\",{\"1\":{\"294\":1}}],[\"状态是reachable\",{\"1\":{\"294\":1}}],[\"状态检查\",{\"1\":{\"34\":1}}],[\"状态图示\",{\"0\":{\"17\":1}}],[\"状态重置为\",{\"1\":{\"16\":1}}],[\"状态变为\",{\"1\":{\"16\":2}}],[\"状态\",{\"1\":{\"16\":1,\"294\":1}}],[\"状态转换\",{\"0\":{\"16\":1}}],[\"状态时\",{\"1\":{\"12\":1,\"51\":1}}],[\"无需实现新的执行引擎\",{\"1\":{\"451\":1}}],[\"无需手动去除\",{\"1\":{\"365\":1}}],[\"无直接依赖关系\",{\"1\":{\"354\":1}}],[\"无法处理剩余的模型数据\",{\"1\":{\"411\":1}}],[\"无法承受重新计算或gpu\",{\"1\":{\"404\":1}}],[\"无法在服务器之间通过网络进行通信\",{\"1\":{\"354\":1}}],[\"无法安全继续执行用户代码\",{\"1\":{\"204\":1}}],[\"无法正常使用\",{\"1\":{\"15\":1}}],[\"无头服务\",{\"0\":{\"37\":1}}],[\"无论你是初涉此领域的新人\",{\"1\":{\"219\":1}}],[\"无论是\",{\"1\":{\"255\":1}}],[\"无论是刚刚接触大模型部署的小白\",{\"1\":{\"228\":1}}],[\"无论是在自启动阶段\",{\"1\":{\"143\":1}}],[\"无论是在单个节点内还是跨节点\",{\"1\":{\"143\":1}}],[\"无论是安装在单节点还是跨多个节点的系统中\",{\"1\":{\"143\":1}}],[\"无论是管理数据库\",{\"1\":{\"123\":1}}],[\"无论\",{\"1\":{\"5\":1}}],[\"通信不平衡\",{\"1\":{\"438\":1}}],[\"通信器立即初始化\",{\"1\":{\"204\":1}}],[\"通信机制\",{\"1\":{\"196\":1}}],[\"通信与同步\",{\"1\":{\"185\":1,\"190\":1}}],[\"通信后端\",{\"1\":{\"181\":1}}],[\"通信库是用于分布式计算的核心组件\",{\"1\":{\"180\":1}}],[\"通信\",{\"1\":{\"165\":1}}],[\"通信操作聚合成\",{\"1\":{\"162\":1}}],[\"通信操作\",{\"1\":{\"162\":1}}],[\"通信对象\",{\"1\":{\"162\":1}}],[\"通信处理器之间的紧密同步是关键\",{\"1\":{\"143\":1}}],[\"通信例程\",{\"1\":{\"143\":1}}],[\"通信以提交\",{\"1\":{\"91\":1}}],[\"通常使用一个大型嵌入表\",{\"1\":{\"436\":1}}],[\"通常在模型的早期计算阶段使用一个大型嵌入表\",{\"1\":{\"426\":1}}],[\"通常在集群中运行\",{\"1\":{\"91\":1}}],[\"通常应用于同一个物理节点内的多个\",{\"1\":{\"354\":1}}],[\"通常连接服务器\",{\"1\":{\"346\":1}}],[\"通常为4\",{\"1\":{\"304\":1}}],[\"通常为6\",{\"1\":{\"304\":1}}],[\"通常为0x0800\",{\"1\":{\"304\":1}}],[\"通常为1\",{\"1\":{\"304\":1}}],[\"通常通过\",{\"1\":{\"255\":1}}],[\"通常需要同步操作来协调各个处理单元的执行\",{\"1\":{\"185\":1}}],[\"通常会调用一系列的\",{\"1\":{\"172\":1}}],[\"通常定义为\",{\"1\":{\"171\":1}}],[\"通常指模块对象\",{\"1\":{\"162\":1}}],[\"通常由\",{\"1\":{\"152\":1}}],[\"通常用于优化大规模集群中的点对点通信\",{\"1\":{\"176\":1}}],[\"通常用于有状态应用和自定义服务发现场景\",{\"1\":{\"44\":1}}],[\"通常用于部署有状态应用\",{\"1\":{\"39\":1}}],[\"通常用于以下场景\",{\"1\":{\"33\":1}}],[\"通常用于集群管理工具\",{\"1\":{\"30\":1}}],[\"通常是领域专家\",{\"1\":{\"438\":1}}],[\"通常是gpu\",{\"1\":{\"424\":1}}],[\"通常是通过leaf交换机到外部的防火墙\",{\"1\":{\"347\":1}}],[\"通常是不同的cpu或gpu\",{\"1\":{\"185\":1}}],[\"通常是模块路径和对象名称的组合\",{\"1\":{\"167\":1}}],[\"通常是指分布式训练中全局进程的编号\",{\"1\":{\"152\":1}}],[\"通常是最合适的选择\",{\"1\":{\"97\":1}}],[\"通常是\",{\"1\":{\"31\":2,\"32\":1}}],[\"通常是因为与\",{\"1\":{\"15\":1}}],[\"通过操作符转换轻松实现了这种解耦\",{\"1\":{\"451\":1}}],[\"通过在输入张量和其操作符之间插入一个恒等操作符\",{\"1\":{\"451\":1}}],[\"通过在构建空间时引入约束条件\",{\"1\":{\"424\":1}}],[\"通过迭代地更改计划中疑似有问题的模块\",{\"1\":{\"447\":1}}],[\"通过原语和相关约束定义搜索空间\",{\"1\":{\"442\":1}}],[\"通过将划分和放置选项表示为整数\",{\"1\":{\"440\":1}}],[\"通过对约束的细化\",{\"1\":{\"438\":1}}],[\"通过对模型构建\",{\"1\":{\"231\":1}}],[\"通过综合运用这些技术\",{\"1\":{\"419\":1}}],[\"通过gpu\",{\"1\":{\"412\":1}}],[\"通过grep过滤出veth设备\",{\"1\":{\"279\":1}}],[\"通过优先使用更快的d2d交换和尽可能使用重计算\",{\"1\":{\"411\":1}}],[\"通过启用pipedream中的内存交换和重计算优化实现内存压缩\",{\"1\":{\"410\":1}}],[\"通过精心映射流水线阶段到gpu设备\",{\"1\":{\"404\":1}}],[\"通过nvlink将张量从高内存压力的gpu卸载到有空闲内存的gpu\",{\"1\":{\"402\":1}}],[\"通过智能调度优化性能和内存使用\",{\"1\":{\"395\":1}}],[\"通过节省内存的操作间并行化民主化十亿规模模型训练\",{\"1\":{\"393\":1}}],[\"通过存储保存算子间并行性在多gpu服务器上实现十亿规模级模型训练的民主化\",{\"0\":{\"393\":1}}],[\"通过网络结构分区\",{\"1\":{\"398\":1}}],[\"通过网络直接读取和写入远程内存\",{\"1\":{\"351\":1}}],[\"通过网络技术\",{\"1\":{\"351\":1}}],[\"通过增加spine交换机来提高网络容量\",{\"1\":{\"347\":1}}],[\"通过维护到达每个目标网络的路径信息来选择最佳路径\",{\"1\":{\"310\":1}}],[\"通过建立bgp会话来交换路由信息\",{\"1\":{\"310\":1}}],[\"通过虚拟专用网络\",{\"1\":{\"307\":1}}],[\"通过ip网络传输\",{\"1\":{\"292\":1}}],[\"通过减少广播流量和冲突域\",{\"1\":{\"285\":1}}],[\"通过分割网络减少广播域\",{\"1\":{\"285\":1}}],[\"通过vlan\",{\"1\":{\"285\":1}}],[\"通过多路复用\",{\"1\":{\"276\":1}}],[\"通过https\",{\"1\":{\"274\":1}}],[\"通过http或https\",{\"1\":{\"274\":1}}],[\"通过这个命令\",{\"1\":{\"296\":1}}],[\"通过这个场景假设\",{\"1\":{\"255\":1}}],[\"通过这些原语和约束\",{\"1\":{\"423\":1}}],[\"通过这些命令\",{\"1\":{\"283\":1}}],[\"通过这些函数\",{\"1\":{\"164\":1}}],[\"通过四个基准测试评估\",{\"1\":{\"249\":1}}],[\"通过动态稀疏注意力加速长上下文\",{\"1\":{\"245\":1}}],[\"通过最小的每一块\",{\"1\":{\"232\":1}}],[\"通过一个课程完成大模型开发的重点入门\",{\"1\":{\"222\":1}}],[\"通过观察队列与计算的比率\",{\"1\":{\"212\":1}}],[\"通过消息传递机制实现进程间的通信与同步\",{\"1\":{\"190\":1}}],[\"通过让多个处理单元执行相同的程序代码并处理不同的数据\",{\"1\":{\"189\":1}}],[\"通过提供灵活的通信后端和强大的同步机制\",{\"1\":{\"184\":1}}],[\"通过全局\",{\"1\":{\"150\":1}}],[\"通过丰富的教学资源和优质的用户体验\",{\"1\":{\"131\":1}}],[\"通过定义自定义资源和控制器\",{\"1\":{\"123\":1}}],[\"通过创建工具可以实现的标准\",{\"1\":{\"103\":1}}],[\"通过共享的进程命名空间\",{\"1\":{\"96\":1}}],[\"通过kong路由访问\",{\"1\":{\"75\":1}}],[\"通过以下命令查询了路由是否成功创建\",{\"1\":{\"72\":1}}],[\"通过以下命令查询了服务是否成功创建\",{\"1\":{\"69\":1}}],[\"通过以下命令在kong中创建了一个名为\",{\"1\":{\"68\":1}}],[\"通过配置这些策略\",{\"1\":{\"60\":1}}],[\"通过标记节点来影响\",{\"1\":{\"36\":1}}],[\"通过限制单个容器或\",{\"1\":{\"24\":1}}],[\"通过设置资源限额\",{\"1\":{\"19\":1}}],[\"通过\",{\"1\":{\"5\":2,\"46\":1,\"75\":1,\"96\":1,\"97\":1,\"117\":1,\"120\":1,\"143\":1,\"162\":1,\"182\":1,\"198\":1,\"254\":1,\"436\":1,\"442\":1,\"443\":2}}],[\"上分别提高到\",{\"1\":{\"458\":1}}],[\"上分别比\",{\"1\":{\"458\":1}}],[\"上比\",{\"1\":{\"457\":2}}],[\"上使用了纯数据并行性\",{\"1\":{\"457\":1}}],[\"上使用纯张量并行性\",{\"1\":{\"456\":1}}],[\"上可以使用数据并行性结合\",{\"1\":{\"456\":1}}],[\"上应用了\",{\"1\":{\"455\":1,\"457\":1}}],[\"上对三种新并行化计划进行了评估\",{\"1\":{\"453\":1}}],[\"上复制\",{\"1\":{\"425\":1}}],[\"上取得了显著的性能提升\",{\"1\":{\"424\":1}}],[\"上来加速训练过程\",{\"1\":{\"424\":1}}],[\"上进行训练\",{\"1\":{\"396\":1}}],[\"上没有重要数据\",{\"1\":{\"257\":1}}],[\"上也没有其他需要运行的进程了\",{\"1\":{\"255\":1}}],[\"上运行\",{\"1\":{\"196\":1}}],[\"上运行海洋模拟程序\",{\"1\":{\"193\":1}}],[\"上运行大气模拟程序\",{\"1\":{\"193\":1}}],[\"上的结果\",{\"1\":{\"458\":1}}],[\"上的表现分别比\",{\"1\":{\"456\":1}}],[\"上的速度分别比\",{\"1\":{\"455\":1}}],[\"上的下一代\",{\"1\":{\"446\":1}}],[\"上的执行时间为其分配的算子的计算时间\",{\"1\":{\"440\":1}}],[\"上的文件前\",{\"1\":{\"255\":1}}],[\"上的输出张量\",{\"1\":{\"160\":1}}],[\"上的张量相加\",{\"1\":{\"160\":1}}],[\"上的张量\",{\"1\":{\"160\":1}}],[\"上的运行详情页面来跟踪运行的进度\",{\"1\":{\"95\":1}}],[\"上的部署变得简单\",{\"1\":{\"78\":1}}],[\"上传你的管道\",{\"1\":{\"89\":1}}],[\"上述并行化方案可以组合成一种新的方案\",{\"1\":{\"425\":1}}],[\"上述fastgpt\",{\"1\":{\"366\":1}}],[\"上述代码是\",{\"1\":{\"161\":1}}],[\"上述描述来自\",{\"1\":{\"100\":1}}],[\"上述各个触发条件在\",{\"1\":{\"51\":1}}],[\"上述配置说明pod能够容忍节点设置taint的level=high\",{\"1\":{\"36\":1}}],[\"上\",{\"1\":{\"14\":1,\"436\":1,\"456\":1}}],[\"已被\",{\"1\":{\"446\":1}}],[\"已被删除\",{\"1\":{\"14\":1}}],[\"已成功转换了\",{\"1\":{\"445\":1}}],[\"已超过单个gpu的容量\",{\"1\":{\"410\":1}}],[\"已使用\",{\"1\":{\"365\":1}}],[\"已弃用\",{\"1\":{\"204\":1}}],[\"已从使用\",{\"1\":{\"95\":1}}],[\"已经集成了该技术\",{\"1\":{\"398\":1}}],[\"已经运行在这个节点上的\",{\"1\":{\"36\":1}}],[\"已经被注册到\",{\"1\":{\"154\":1}}],[\"已经被删除\",{\"1\":{\"14\":1}}],[\"已经被绑定到一个\",{\"1\":{\"13\":1}}],[\"已经与一个\",{\"1\":{\"13\":1}}],[\"本文参考了最近的alpa工作\",{\"1\":{\"398\":1}}],[\"本文主要介绍了独立开发者的相关内容\",{\"1\":{\"359\":2}}],[\"本开源课程主要是跟大家一起探讨和学习人工智能\",{\"1\":{\"233\":1}}],[\"本教程涵盖从基础入门到进阶使用的全方位内容\",{\"1\":{\"228\":1}}],[\"本教程主要侧重于模型\",{\"1\":{\"219\":1}}],[\"本节介绍了国内外知名大模型产品\",{\"1\":{\"223\":1}}],[\"本地部署\",{\"1\":{\"220\":1}}],[\"本项目旨在作为一个大规模预训练语言模型的教程\",{\"1\":{\"231\":1}}],[\"本项目旨在为广大学习者搭建一个清晰的\",{\"1\":{\"224\":1}}],[\"本项目旨在为学习者提供深入学习\",{\"1\":{\"218\":1}}],[\"本项目以西瓜书以及南瓜书为主要参考\",{\"1\":{\"229\":1}}],[\"本项目基于吴恩达老师大模型系列课程内容\",{\"1\":{\"226\":1}}],[\"本项目将从基础原理出发\",{\"1\":{\"224\":1}}],[\"本项目主要包括三部分内容\",{\"1\":{\"223\":1}}],[\"本项目是一个面向开发者的大模型手册\",{\"1\":{\"226\":1}}],[\"本项目是一个面向小白开发者的大模型应用开发教程\",{\"1\":{\"222\":1}}],[\"本项目是一个从原理出发\",{\"1\":{\"224\":1}}],[\"本项目是一个围绕开源大模型\",{\"1\":{\"220\":1}}],[\"本项目的主要内容包括\",{\"1\":{\"220\":1,\"224\":1}}],[\"本项目使用通俗易懂的语言介绍模型的剪枝\",{\"1\":{\"217\":1}}],[\"本项目中的应用程序\",{\"1\":{\"100\":1}}],[\"本质上是一个\",{\"1\":{\"118\":1}}],[\"本质是创建了一个\",{\"1\":{\"5\":1}}],[\"本身\",{\"1\":{\"30\":1,\"61\":1}}],[\"本身还没有被集群中的任何新\",{\"1\":{\"14\":1}}],[\"但经过数千步的训练后\",{\"1\":{\"448\":1}}],[\"但新的原语和约束也增加了系统的复杂性\",{\"1\":{\"447\":1}}],[\"但减少设备间的通信可以降低成本并加快整体过程\",{\"1\":{\"435\":1}}],[\"但计算利用率却很低\",{\"1\":{\"426\":1}}],[\"但要满足未来不断增长的模型需求仍然是一个挑战\",{\"1\":{\"417\":1}}],[\"但要注意其兼容性问题\",{\"1\":{\"97\":1}}],[\"但重计算不会消耗有限的gpu空闲内存\",{\"1\":{\"415\":1}}],[\"但其训练性能分别比mpress降低了30\",{\"1\":{\"412\":1}}],[\"但其性能比mpress低19\",{\"1\":{\"412\":1}}],[\"但需要牺牲训练速度\",{\"1\":{\"412\":1}}],[\"但拥有更大的cpu内存和额外的nvme\",{\"1\":{\"412\":1}}],[\"但mpress通过设备映射优化和三种优化策略的组合\",{\"1\":{\"411\":1}}],[\"但比mpress慢19\",{\"1\":{\"411\":1}}],[\"但也引入了不可忽视的跨gpu通信开销\",{\"1\":{\"401\":1}}],[\"但会带来额外的计算或通信开销\",{\"1\":{\"394\":1}}],[\"但一起使用时可以全面管理和配置网络接口\",{\"0\":{\"316\":1}}],[\"但通过适当的防御措施可以有效防止arp欺骗攻击\",{\"1\":{\"308\":1}}],[\"但通常也更复杂\",{\"1\":{\"186\":1}}],[\"但不知道设备b的mac地址\",{\"1\":{\"303\":1}}],[\"但非强制\",{\"1\":{\"277\":1}}],[\"但非加密的http请求仍然普遍存在\",{\"1\":{\"274\":1}}],[\"但仅作为某些字段的初始值\",{\"1\":{\"207\":1}}],[\"但它消耗了大量内存\",{\"1\":{\"436\":1}}],[\"但它依赖于简化搜索和构建并行化计划的假设\",{\"1\":{\"426\":1}}],[\"但它需要大量通信来收集和汇总部分结果\",{\"1\":{\"398\":1}}],[\"但它主要是用于同一台服务器内部的通信\",{\"1\":{\"352\":1}}],[\"但它们的作用和使用场景不同\",{\"1\":{\"350\":1}}],[\"但它们仍可能需要在某些阶段进行通信和数据交换\",{\"1\":{\"190\":1}}],[\"但它还未被新的\",{\"1\":{\"14\":1}}],[\"但每个处理单元处理的输入数据是不同的\",{\"1\":{\"185\":1}}],[\"但每个处理单元处理不同的数据\",{\"1\":{\"184\":1}}],[\"但可以根据处理单元的id或索引来执行不同的操作\",{\"1\":{\"185\":1}}],[\"但\",{\"1\":{\"97\":1}}],[\"但在避免gpu\",{\"1\":{\"416\":1}}],[\"但在某些系统上仍然可用\",{\"1\":{\"332\":1}}],[\"但在某些网络插件或环境下可能是必要的\",{\"1\":{\"47\":1}}],[\"但在同一时刻只能处理一个请求\",{\"1\":{\"269\":1}}],[\"但在这一步\",{\"1\":{\"61\":1}}],[\"但如果没有其他合适的节点\",{\"1\":{\"36\":1}}],[\"但是速度越慢\",{\"1\":{\"365\":1}}],[\"但是同样会抛出警告\",{\"1\":{\"159\":1}}],[\"但是\",{\"1\":{\"14\":1,\"255\":1}}],[\"但pv在挂载时只能使用一种访问模式\",{\"1\":{\"9\":1}}],[\"还进一步应用了数据并行性扩展到所有可用\",{\"1\":{\"456\":1}}],[\"还进一步应用了数据并行性\",{\"1\":{\"455\":1}}],[\"还支持内存优化技术\",{\"1\":{\"451\":1}}],[\"还可以使用\",{\"1\":{\"454\":1}}],[\"还可以集成自定义转换算法\",{\"1\":{\"429\":1}}],[\"还可以采用\",{\"1\":{\"425\":1}}],[\"还可以创建新的搜索空间\",{\"1\":{\"424\":1}}],[\"还可以创建新的空间\",{\"1\":{\"423\":1}}],[\"还通过进一步减少内存消耗来训练更大规模的模型\",{\"1\":{\"418\":1}}],[\"还展示了\",{\"1\":{\"249\":1}}],[\"还注重代码的可维护性和团队协作\",{\"1\":{\"126\":1}}],[\"还适用于想要将\",{\"1\":{\"78\":1}}],[\"还是语义错误\",{\"1\":{\"448\":1}}],[\"还是\",{\"1\":{\"255\":1}}],[\"还是有一定经验的开发者\",{\"1\":{\"228\":1}}],[\"还是寻求深化专业技能的资深人士\",{\"1\":{\"219\":1}}],[\"还是在高速通信过程中\",{\"1\":{\"143\":1}}],[\"还是大数据处理集群\",{\"1\":{\"123\":1}}],[\"还是容器\",{\"1\":{\"26\":1}}],[\"还是遭遇网络分区\",{\"1\":{\"5\":1}}],[\"还未与任何\",{\"1\":{\"12\":1}}],[\"绑定\",{\"1\":{\"12\":3,\"13\":2,\"16\":1,\"17\":1,\"204\":1}}],[\"可扩展\",{\"1\":{\"349\":1}}],[\"可扩展性\",{\"1\":{\"313\":1,\"347\":1}}],[\"可扩展性和可移植性\",{\"1\":{\"106\":1}}],[\"可达\",{\"1\":{\"294\":1}}],[\"可复现的大模型世界\",{\"1\":{\"224\":1}}],[\"可指定\",{\"1\":{\"204\":1}}],[\"可供所有工作者访问的键值存储\",{\"1\":{\"204\":1}}],[\"可选\",{\"1\":{\"204\":9,\"277\":1}}],[\"可选的通信器对象\",{\"1\":{\"158\":1}}],[\"可选参数\",{\"1\":{\"158\":1}}],[\"可选字段\",{\"1\":{\"21\":1}}],[\"可视化服务\",{\"1\":{\"108\":1}}],[\"可视化服务器\",{\"1\":{\"97\":1}}],[\"可微分架构搜索\",{\"1\":{\"105\":1}}],[\"可移植且可扩展\",{\"1\":{\"78\":1}}],[\"可用的\",{\"1\":{\"224\":1}}],[\"可用的大模型系统\",{\"1\":{\"224\":1}}],[\"可用的后端包括\",{\"1\":{\"206\":1}}],[\"可用的运行触发器类型包括\",{\"1\":{\"95\":1}}],[\"可用的宿主机磁盘空间\",{\"1\":{\"51\":1}}],[\"可用内存\",{\"1\":{\"51\":1}}],[\"可能导致训练时间延长33\",{\"1\":{\"401\":1}}],[\"可能导致后续的\",{\"1\":{\"204\":1}}],[\"可能需要相应的权限\",{\"1\":{\"255\":1}}],[\"可能需要管理员干预以修复问题\",{\"1\":{\"15\":1}}],[\"可能涉及多个物理场\",{\"1\":{\"192\":1}}],[\"可能耗时较长\",{\"1\":{\"162\":1}}],[\"可能无法满足所有应用的需求\",{\"1\":{\"117\":1}}],[\"可能会使用\",{\"1\":{\"33\":1}}],[\"可能会被删除\",{\"1\":{\"16\":1}}],[\"可以代表一个子图\",{\"1\":{\"431\":1}}],[\"可以沿着张量\",{\"1\":{\"429\":1}}],[\"可以为任意模型和加速器设备构建任何并行化计划的搜索空间\",{\"1\":{\"428\":1}}],[\"可以为每个\",{\"1\":{\"158\":1}}],[\"可以应用于其他操作间并行训练系统\",{\"1\":{\"408\":1}}],[\"可以应用于节点\",{\"1\":{\"35\":1}}],[\"可以用阿里云\",{\"1\":{\"366\":1}}],[\"可以传入\",{\"1\":{\"365\":1}}],[\"可以轻松扩展\",{\"1\":{\"347\":1}}],[\"可以轻松通过多种编程语言访问\",{\"1\":{\"143\":1}}],[\"可以与多个算子相关联\",{\"1\":{\"443\":1}}],[\"可以与\",{\"1\":{\"332\":1}}],[\"可以与任何\",{\"1\":{\"106\":1}}],[\"可以添加\",{\"1\":{\"332\":1}}],[\"可以查看和配置网络接口的状态和地址\",{\"1\":{\"332\":1}}],[\"可以查看桥接设备当前的mac地址表\",{\"1\":{\"296\":1}}],[\"可以查看它在调用哪些系统调用\",{\"1\":{\"254\":1}}],[\"可以方便地查看和管理系统中的veth设备对\",{\"1\":{\"283\":1}}],[\"可以方便地调用这些\",{\"1\":{\"166\":1}}],[\"可以搭建出一个简单的\",{\"1\":{\"223\":1}}],[\"可以有效地解决各种问题\",{\"1\":{\"217\":1}}],[\"可以更好地理解集群的性能和负载情况\",{\"1\":{\"212\":1}}],[\"可以执行不同的程序\",{\"1\":{\"189\":1}}],[\"可以通过深度学习模型的检测工具来实现\",{\"1\":{\"451\":1}}],[\"可以通过计算生产者和消费者\",{\"1\":{\"443\":1}}],[\"可以通过识别训练中的性能瓶颈\",{\"1\":{\"438\":1}}],[\"可以通过增加一个额外的重新计算操作符或内存交换操作符来增强操作符\",{\"1\":{\"429\":1}}],[\"可以通过属性访问\",{\"1\":{\"206\":1}}],[\"可以通过\",{\"1\":{\"187\":1}}],[\"可以通过以下几种方式配置调度策略\",{\"1\":{\"52\":1}}],[\"可以实现神经网络训练的高效扩展\",{\"1\":{\"143\":1}}],[\"可以先从简单的示例开始\",{\"1\":{\"123\":1}}],[\"可以管理更复杂的工作负载\",{\"1\":{\"120\":1}}],[\"可以将一个物理网络分割成多个逻辑网络\",{\"1\":{\"285\":1}}],[\"可以将计算任务分布到多个节点\",{\"1\":{\"198\":1}}],[\"可以将多个进程组织成一个组\",{\"1\":{\"181\":1}}],[\"可以将最佳实践和操作流程编码成标准化的流程\",{\"1\":{\"120\":1}}],[\"可以将人类操作员\",{\"1\":{\"116\":1}}],[\"可以监控应用的健康状态\",{\"1\":{\"119\":1}}],[\"可以监控应用的新版本\",{\"1\":{\"119\":1}}],[\"可以定期备份应用的数据\",{\"1\":{\"119\":1}}],[\"可以自由对话\",{\"1\":{\"372\":1}}],[\"可以自动化和简化复杂应用的管理\",{\"1\":{\"123\":1}}],[\"可以自动化复杂应用的部署和管理过程\",{\"1\":{\"119\":1}}],[\"可以自定义变量$http\",{\"1\":{\"75\":1}}],[\"可以协调更高级的优化工作流\",{\"1\":{\"106\":1}}],[\"可以协调多节点和多gpu的分布式训练工作负载\",{\"1\":{\"106\":1}}],[\"可以考虑\",{\"1\":{\"97\":1}}],[\"可以选择性地将数据并行性应用于模型的一部分\",{\"1\":{\"447\":1}}],[\"可以选择性地指定\",{\"1\":{\"203\":1}}],[\"可以选择\",{\"1\":{\"97\":1}}],[\"可以选择适当的发夹模式配置\",{\"1\":{\"50\":1}}],[\"可以看到\",{\"1\":{\"61\":1}}],[\"可以显著改善\",{\"1\":{\"60\":1}}],[\"可以设置防火墙规则\",{\"1\":{\"332\":1}}],[\"可以设置\",{\"1\":{\"59\":1}}],[\"可以防止某些\",{\"1\":{\"36\":1}}],[\"可以使用grep过滤出veth设备\",{\"1\":{\"280\":1}}],[\"可以使用以下几种方法\",{\"0\":{\"278\":1}}],[\"可以使用以下命令查看特定命名空间中的网络接口\",{\"1\":{\"283\":1}}],[\"可以使用以下命令查看\",{\"1\":{\"282\":1}}],[\"可以使用以下命令查看某个veth设备对的详细信息\",{\"1\":{\"281\":1}}],[\"可以使用以下命令进行确认\",{\"1\":{\"263\":1}}],[\"可以使用以下命令\",{\"1\":{\"70\":1,\"73\":1}}],[\"可以使用\",{\"1\":{\"34\":1}}],[\"可以在任意顺序下相对于\",{\"1\":{\"431\":1}}],[\"可以在ns1命名空间中看到它\",{\"1\":{\"283\":1}}],[\"可以在不同的处理单元上并行运行各自的程序\",{\"1\":{\"192\":1}}],[\"可以在不同的进程组之间进行广播\",{\"1\":{\"181\":1}}],[\"可以在\",{\"1\":{\"28\":1,\"48\":1}}],[\"可以提供默认值\",{\"1\":{\"24\":1}}],[\"可以供新的\",{\"1\":{\"12\":1}}],[\"可以被绑定到\",{\"1\":{\"12\":1}}],[\"可通过\",{\"1\":{\"5\":1}}],[\"描述应用程序元数据的能力\",{\"1\":{\"101\":1}}],[\"描述在给定组件输入参数值的情况下如何运行组件的规范\",{\"1\":{\"92\":1}}],[\"描述等\",{\"1\":{\"92\":1}}],[\"描述\",{\"1\":{\"12\":1,\"13\":1,\"14\":1,\"15\":1,\"92\":1}}],[\"以减少激活张量的内存消耗\",{\"1\":{\"454\":1}}],[\"以减少激活张量的峰值内存\",{\"1\":{\"452\":1}}],[\"以优化\",{\"1\":{\"454\":1}}],[\"以优化内存使用\",{\"1\":{\"451\":1}}],[\"以优化管道的执行效率和资源管理\",{\"1\":{\"97\":1}}],[\"以展示整个系统在实现新模型和设置的高效并行化方面的有效性\",{\"1\":{\"450\":1}}],[\"以提取相应的张量片段\",{\"1\":{\"444\":1}}],[\"以下\",{\"1\":{\"432\":1}}],[\"以下是七层网络模型的详细介绍\",{\"1\":{\"333\":1}}],[\"以下是这些命令的功能及其关系的详细介绍\",{\"0\":{\"316\":1}}],[\"以下是对它们的解析\",{\"1\":{\"284\":1}}],[\"以下是对这两者的详细介绍\",{\"1\":{\"17\":1}}],[\"以下是函数\",{\"1\":{\"202\":1}}],[\"以下是它们之间的一些主要关联关系\",{\"1\":{\"97\":1}}],[\"以下是一个简单的\",{\"1\":{\"199\":1}}],[\"以下是一个简单的使用\",{\"1\":{\"183\":1}}],[\"以下是一个使用\",{\"1\":{\"41\":1}}],[\"以下是一个示例\",{\"1\":{\"32\":1}}],[\"以下是一个\",{\"1\":{\"20\":1,\"25\":1,\"40\":1}}],[\"以下是状态转换的示意图\",{\"1\":{\"17\":1}}],[\"以下是\",{\"1\":{\"11\":1,\"267\":1}}],[\"以节省内存\",{\"1\":{\"429\":1}}],[\"以捕捉并行化计划的三个方面\",{\"1\":{\"428\":1}}],[\"以检测和防止并行化计划中的潜在错误\",{\"1\":{\"427\":1}}],[\"以同时减少内存消耗和设备间通信成本\",{\"1\":{\"426\":1}}],[\"以进一步提高训练性能\",{\"1\":{\"425\":1}}],[\"以进一步提高训练效率\",{\"1\":{\"425\":1}}],[\"以进一步降低成本\",{\"1\":{\"417\":1}}],[\"以适应无法在单个设备上容纳的模型\",{\"1\":{\"425\":1}}],[\"以实现并发模型训练\",{\"1\":{\"425\":1}}],[\"以实现负载均衡和计算资源的优化利用\",{\"1\":{\"190\":1}}],[\"以支持类似\",{\"1\":{\"425\":1}}],[\"以支持更大的模型\",{\"1\":{\"418\":1}}],[\"以支持的设备类型列表作为值\",{\"1\":{\"207\":1}}],[\"以智能地将不同模型张量分配到合适的内存层\",{\"1\":{\"417\":1}}],[\"以此来测试我们的搜索算法\",{\"1\":{\"414\":1}}],[\"以探讨设备映射\",{\"1\":{\"413\":1}}],[\"以满足目标内存节省需求\",{\"1\":{\"407\":1}}],[\"以满足特定的网络需求\",{\"1\":{\"310\":1}}],[\"以最大限度地减少gpu\",{\"1\":{\"407\":1}}],[\"以最大化gpu内存节省的同时最小化训练过程中引入的额外延迟是一个非常具有挑战性的问题\",{\"1\":{\"407\":1}}],[\"以最大化这些gpu的交换带宽\",{\"1\":{\"406\":1}}],[\"以最大化带宽利用率\",{\"1\":{\"177\":1}}],[\"以释放已使用的gpu内存\",{\"1\":{\"405\":1}}],[\"以确定当前的配置是否接近最佳配置\",{\"1\":{\"405\":1}}],[\"以确保高可用性和扩展性\",{\"1\":{\"348\":1}}],[\"以确保项目的持续发展和知识的时效性\",{\"1\":{\"231\":1}}],[\"以确保\",{\"1\":{\"56\":1}}],[\"以符合操作的依赖关系\",{\"1\":{\"405\":1}}],[\"以选择对性能影响最小的优化方法\",{\"1\":{\"405\":1}}],[\"以启动第二阶段\",{\"1\":{\"399\":1}}],[\"以触发后续的计算\",{\"1\":{\"398\":1}}],[\"以充分利用闲置的gpu内存\",{\"1\":{\"395\":1}}],[\"以充分利用各自的计算优势\",{\"1\":{\"192\":1}}],[\"以太网\",{\"1\":{\"335\":1}}],[\"以通知其他对等体\",{\"1\":{\"311\":1}}],[\"以保证arp缓存的最新性\",{\"1\":{\"305\":1}}],[\"以细致讲解和代码注释帮助读者独立复现大模型核心部分\",{\"1\":{\"224\":1}}],[\"以\",{\"1\":{\"224\":1}}],[\"以避免环路\",{\"1\":{\"310\":1}}],[\"以避免除以零的情况\",{\"1\":{\"211\":1}}],[\"以避免不必要的组创建开销\",{\"1\":{\"204\":1}}],[\"以高效地在多\",{\"1\":{\"163\":1}}],[\"以限制并行启动的运行数量\",{\"1\":{\"95\":1}}],[\"以便为各种模型搜索新的\",{\"1\":{\"434\":1}}],[\"以便后续通信时可以直接使用\",{\"1\":{\"303\":1}}],[\"以便分析问题的根本原因\",{\"1\":{\"254\":1}}],[\"以便更灵活地管理和组织进程\",{\"1\":{\"196\":1}}],[\"以便它们之间进行通信\",{\"1\":{\"181\":1}}],[\"以便于重现\",{\"1\":{\"95\":1}}],[\"以便数据可以在分布式网络上传输\",{\"1\":{\"93\":1}}],[\"以图的形式呈现\",{\"1\":{\"89\":1}}],[\"以尽可能地将\",{\"1\":{\"52\":1}}],[\"以及时间顺序搜索\",{\"1\":{\"439\":1}}],[\"以及具有非常规通信模式的新操作符调度\",{\"1\":{\"427\":1}}],[\"以及张量并行性\",{\"1\":{\"426\":1}}],[\"以及内存压缩计划的选择\",{\"1\":{\"413\":1}}],[\"以及多种内存压缩优化技术的结合\",{\"1\":{\"412\":1}}],[\"以及三种方法各自的内存减少情况\",{\"1\":{\"410\":1}}],[\"以及948gb的cpu内存和6tb的nvme\",{\"1\":{\"410\":1}}],[\"以及768gb的cpu内存\",{\"1\":{\"410\":1}}],[\"以及调整合适的知识库参数\",{\"1\":{\"366\":1}}],[\"以及\",{\"1\":{\"352\":1,\"459\":1}}],[\"以及它们的组网架构\",{\"1\":{\"344\":1}}],[\"以及它是否能够被持久卷声明\",{\"1\":{\"11\":1}}],[\"以及组网架构\",{\"0\":{\"344\":1}}],[\"以及代码的实战\",{\"1\":{\"231\":1}}],[\"以及对前沿大模型知识的及时更新\",{\"1\":{\"231\":1}}],[\"以及对象数量\",{\"1\":{\"20\":1}}],[\"以及模型在安全\",{\"1\":{\"231\":1}}],[\"以及其他已注册的后端\",{\"1\":{\"206\":1}}],[\"以及基于\",{\"1\":{\"143\":1}}],[\"以及任意基于发送\",{\"1\":{\"143\":1}}],[\"以及每个组件的输入和输出\",{\"1\":{\"89\":1}}],[\"以及使用\",{\"1\":{\"51\":1}}],[\"以及容器运行时镜像存储空间\",{\"1\":{\"51\":1}}],[\"中并行化计划的搜索成本包括\",{\"1\":{\"459\":1}}],[\"中实现了\",{\"1\":{\"454\":1}}],[\"中实现高效分布式计算的关键组件\",{\"1\":{\"184\":1}}],[\"中概述的约束定义了正向和反向传递如何在流水线的稳定状态中交错执行\",{\"1\":{\"452\":1}}],[\"中指定约束下搜索到的流水线调度\",{\"1\":{\"452\":1}}],[\"中列出的流行手工并行化计划\",{\"1\":{\"451\":1}}],[\"中列出了\",{\"1\":{\"437\":1}}],[\"中展示的端到端流程\",{\"1\":{\"442\":1}}],[\"中有突出体现\",{\"1\":{\"436\":1}}],[\"中有一个软中断的概念\",{\"1\":{\"255\":1}}],[\"中剩余的资源\",{\"1\":{\"436\":1}}],[\"中定义的搜索空间\",{\"1\":{\"435\":1}}],[\"中原语的参数化参数\",{\"1\":{\"432\":1}}],[\"中文解读\",{\"1\":{\"422\":1}}],[\"中等规模模型\",{\"1\":{\"411\":1}}],[\"中间加个具有号召性的按钮\",{\"1\":{\"359\":2}}],[\"中编码所有必需参数并省略它们\",{\"1\":{\"203\":1}}],[\"中编译\",{\"1\":{\"171\":1}}],[\"中解析出输入的值\",{\"1\":{\"162\":1}}],[\"中调用\",{\"1\":{\"161\":1,\"163\":1,\"164\":1}}],[\"中一个\",{\"1\":{\"161\":1}}],[\"中一个不断循环检查资源实际状态并使其符合预期状态的逻辑组件\",{\"1\":{\"117\":1}}],[\"中找到\",{\"1\":{\"151\":1}}],[\"中引入新的资源类型\",{\"1\":{\"117\":1}}],[\"中创建\",{\"1\":{\"103\":1}}],[\"中创建和管理元数据\",{\"1\":{\"97\":1}}],[\"中称为作业\",{\"1\":{\"95\":1}}],[\"中的时间排序约束\",{\"1\":{\"459\":1}}],[\"中的数据\",{\"1\":{\"458\":1}}],[\"中的数据库分片或有状态应用\",{\"1\":{\"38\":1}}],[\"中的三种原语紧密对齐\",{\"1\":{\"451\":1}}],[\"中的并行化原语可以构建各种并行化计划\",{\"1\":{\"450\":1}}],[\"中的任意\",{\"1\":{\"435\":1}}],[\"中的算子被分割并分配到\",{\"1\":{\"435\":1}}],[\"中的约束\",{\"1\":{\"433\":2,\"437\":1}}],[\"中的第\",{\"1\":{\"430\":1,\"459\":1}}],[\"中的不相交设备分配\",{\"1\":{\"426\":1}}],[\"中的限制了\",{\"1\":{\"255\":1}}],[\"中的稀疏索引\",{\"1\":{\"249\":1}}],[\"中的进程可以组织成进程组\",{\"1\":{\"196\":1}}],[\"中的进程组是通信的基本单元\",{\"1\":{\"181\":1}}],[\"中的相对\",{\"1\":{\"151\":1,\"154\":1}}],[\"中的全局\",{\"1\":{\"151\":1}}],[\"中的元数据管理\",{\"1\":{\"97\":1}}],[\"中的各个核心组件\",{\"1\":{\"97\":1}}],[\"中的各个步骤\",{\"1\":{\"89\":1}}],[\"中的自定义资源定义\",{\"1\":{\"97\":1}}],[\"中的定时任务\",{\"1\":{\"97\":1}}],[\"中的图形表示\",{\"1\":{\"94\":1}}],[\"中的某一步骤\",{\"1\":{\"90\":1}}],[\"中的其他容器的服务\",{\"1\":{\"45\":1}}],[\"中的一种特殊服务类型\",{\"1\":{\"44\":1}}],[\"中的一种特殊类型的\",{\"1\":{\"30\":1}}],[\"中的一种机制\",{\"1\":{\"35\":1}}],[\"中的\",{\"1\":{\"31\":1,\"153\":1,\"444\":1}}],[\"中用于限制命名空间内单个\",{\"1\":{\"23\":1}}],[\"中用来限制命名空间\",{\"1\":{\"18\":1}}],[\"中\",{\"1\":{\"11\":2,\"36\":1,\"37\":1,\"44\":1,\"52\":1,\"89\":1,\"90\":1,\"94\":1,\"100\":1,\"150\":1,\"154\":1,\"170\":1,\"171\":1,\"432\":1,\"433\":1,\"435\":1,\"437\":1,\"442\":1,\"443\":1,\"444\":1}}],[\"在四个系统上的端到端训练吞吐量\",{\"1\":{\"455\":1}}],[\"在接下来的所有实验中\",{\"1\":{\"454\":1}}],[\"在排序搜索过程中\",{\"1\":{\"452\":1}}],[\"在每个构建的空间内进行搜索\",{\"1\":{\"452\":1}}],[\"在每个步骤中\",{\"1\":{\"407\":1}}],[\"在更复杂的计划中\",{\"1\":{\"448\":1}}],[\"在训练早期阶段\",{\"1\":{\"448\":1}}],[\"在模型训练中提供了很大的灵活性\",{\"1\":{\"447\":1}}],[\"在进行转换\",{\"1\":{\"445\":1}}],[\"在进程组上执行操作的超时时间\",{\"1\":{\"204\":1}}],[\"在应用了原语和约束后\",{\"1\":{\"444\":1}}],[\"在图转换过程中遵循\",{\"1\":{\"449\":1}}],[\"在图\",{\"1\":{\"443\":2}}],[\"在此步骤中\",{\"1\":{\"442\":1}}],[\"在算子变换与分配完成后\",{\"1\":{\"441\":1}}],[\"在最后执行的前向传播完成后\",{\"1\":{\"437\":1}}],[\"在阶段\",{\"1\":{\"433\":1,\"435\":1}}],[\"在搜索空间中应用约束\",{\"0\":{\"432\":1}}],[\"在流水线中越早的阶段\",{\"1\":{\"433\":1}}],[\"在流水线并行性中\",{\"1\":{\"431\":1}}],[\"在流体力学\",{\"1\":{\"198\":1}}],[\"在本文中\",{\"1\":{\"429\":1}}],[\"在张量并行性中\",{\"1\":{\"426\":1}}],[\"在三种方法中\",{\"1\":{\"416\":1}}],[\"在bert模型中\",{\"1\":{\"415\":1}}],[\"在我们的所有评估案例中\",{\"1\":{\"414\":1}}],[\"在dgx\",{\"1\":{\"414\":1}}],[\"在大模型上\",{\"1\":{\"412\":1}}],[\"在大规模数据分析任务中\",{\"1\":{\"198\":1}}],[\"在主机内存请求方面\",{\"1\":{\"408\":1}}],[\"在不对称的拓扑结构中\",{\"1\":{\"406\":1}}],[\"在不同as之间的路由器之间运行\",{\"1\":{\"310\":1}}],[\"在不同模型和方法对比中性能良好\",{\"1\":{\"249\":1}}],[\"在不同环境中设置不同的限制\",{\"1\":{\"27\":1}}],[\"在对称nvlink拓扑结构中\",{\"1\":{\"406\":1}}],[\"在设计d2d交换技术时\",{\"1\":{\"406\":1}}],[\"在mpress的静态部分\",{\"1\":{\"405\":1}}],[\"在pipedream中对39\",{\"1\":{\"401\":1}}],[\"在相同的硬件配置下\",{\"1\":{\"400\":1}}],[\"在相邻的微批次之间有两种调度执行方式\",{\"1\":{\"399\":1}}],[\"在实践的过程中\",{\"1\":{\"359\":2}}],[\"在实际使用中\",{\"1\":{\"177\":1}}],[\"在单一服务器中多个\",{\"1\":{\"355\":1}}],[\"在spine\",{\"1\":{\"345\":1,\"346\":1}}],[\"在现代数据中心和高性能网络中\",{\"1\":{\"344\":1}}],[\"在同一as内的路由器之间运行\",{\"1\":{\"310\":1}}],[\"在同一时间内\",{\"1\":{\"5\":1}}],[\"在使用flannel的kubernetes集群中\",{\"1\":{\"294\":1}}],[\"在以太网帧中添加一个4字节的标签\",{\"1\":{\"285\":1}}],[\"在一台aws\",{\"1\":{\"400\":1}}],[\"在一个连接上\",{\"1\":{\"270\":1}}],[\"在一些复杂的物理仿真中\",{\"1\":{\"192\":1}}],[\"在一些简化的集群管理方案中\",{\"1\":{\"33\":1}}],[\"在释放\",{\"1\":{\"258\":1}}],[\"在用户态得到文件数据\",{\"1\":{\"255\":1}}],[\"在问答\",{\"1\":{\"249\":1}}],[\"在成本效率和系统延迟方面表现出色\",{\"1\":{\"249\":1}}],[\"在推理中动态近似动态稀疏索引\",{\"1\":{\"249\":1}}],[\"在工作当中所积累\",{\"1\":{\"233\":1}}],[\"在自己感兴趣的方向上不断探索和学习\",{\"1\":{\"226\":1}}],[\"在线阅读\",{\"1\":{\"226\":1,\"228\":1}}],[\"在线阅读地址\",{\"1\":{\"217\":1,\"226\":1}}],[\"在线\",{\"1\":{\"220\":1}}],[\"在涉及多种计算架构\",{\"1\":{\"192\":1}}],[\"在需要并行处理不同任务的工作流中\",{\"1\":{\"192\":1}}],[\"在分布式训练中\",{\"1\":{\"188\":1}}],[\"在分布式数据并行训练中\",{\"1\":{\"181\":1}}],[\"在深度学习中\",{\"1\":{\"187\":1}}],[\"在深度学习框架中有着广泛的应用\",{\"1\":{\"143\":1}}],[\"在这种情况下\",{\"1\":{\"411\":2,\"417\":1}}],[\"在这种模型中\",{\"1\":{\"184\":1}}],[\"在这里是flannel\",{\"1\":{\"294\":1}}],[\"在这个实验中\",{\"1\":{\"457\":1}}],[\"在这个子空间中可以应用现有的搜索策略\",{\"1\":{\"439\":1}}],[\"在这个\",{\"1\":{\"111\":1}}],[\"在这个示例中\",{\"1\":{\"54\":1,\"58\":1}}],[\"在这个例子中\",{\"1\":{\"43\":1,\"294\":1}}],[\"在多gpu训练中\",{\"1\":{\"181\":1}}],[\"在多个gpu之间分配模型参数\",{\"1\":{\"418\":1}}],[\"在多个\",{\"1\":{\"143\":1}}],[\"在调用\",{\"1\":{\"176\":1}}],[\"在特定组内的\",{\"1\":{\"155\":1}}],[\"在指定\",{\"1\":{\"153\":1}}],[\"在指定秒数后对每个测试进行超时\",{\"1\":{\"150\":1}}],[\"在安全的网络上运行\",{\"1\":{\"143\":1}}],[\"在集体通信中\",{\"1\":{\"143\":1}}],[\"在集群中的分布情况\",{\"1\":{\"60\":1}}],[\"在集群启动或恢复过程中\",{\"1\":{\"33\":1}}],[\"在开发过程中\",{\"1\":{\"126\":1}}],[\"在配置\",{\"1\":{\"97\":1}}],[\"在某些\",{\"1\":{\"96\":1}}],[\"在某些情况下\",{\"1\":{\"39\":1}}],[\"在复杂的管道中\",{\"1\":{\"95\":1}}],[\"在那里你可以看到运行时的图表\",{\"1\":{\"95\":1}}],[\"在高层次上\",{\"1\":{\"80\":1}}],[\"在发送\",{\"1\":{\"150\":1}}],[\"在发送post跨域请求前\",{\"1\":{\"75\":1}}],[\"在发夹模式下\",{\"1\":{\"46\":1}}],[\"在拿到这个\",{\"1\":{\"61\":1}}],[\"在节点上运行的条件\",{\"1\":{\"35\":2}}],[\"在命名空间内强制执行资源使用标准\",{\"1\":{\"27\":1}}],[\"在共享集群中\",{\"1\":{\"22\":1}}],[\"在操作过程中遇到错误\",{\"1\":{\"15\":1}}],[\"在生命周期中的位置\",{\"1\":{\"11\":1}}],[\"在\",{\"1\":{\"11\":1,\"17\":1,\"36\":1,\"37\":1,\"48\":1,\"51\":1,\"52\":1,\"89\":1,\"90\":1,\"94\":1,\"151\":1,\"154\":1,\"170\":1,\"171\":1,\"185\":2,\"186\":1,\"189\":1,\"190\":1,\"226\":1,\"330\":1,\"432\":1,\"437\":1,\"451\":1,\"455\":3,\"456\":3,\"457\":2,\"458\":2}}],[\"gnn\",{\"1\":{\"446\":1}}],[\"gj\",{\"1\":{\"433\":1}}],[\"gv\",{\"1\":{\"422\":1}}],[\"gshard等系统通过将每个层的矩阵乘法分块\",{\"1\":{\"418\":1}}],[\"guide\",{\"1\":{\"389\":1}}],[\"guaranteed\",{\"1\":{\"51\":3}}],[\"ghcr\",{\"1\":{\"366\":3}}],[\"ghemawat联合出品\",{\"1\":{\"139\":1}}],[\"glm4\",{\"1\":{\"365\":1}}],[\"gloo\",{\"1\":{\"181\":1,\"183\":1,\"204\":2,\"205\":4,\"206\":4,\"207\":3}}],[\"global\",{\"1\":{\"150\":10,\"151\":3,\"152\":1,\"153\":1,\"154\":8,\"283\":1,\"372\":1}}],[\"gpipe首先引入了这种技术\",{\"1\":{\"418\":1}}],[\"gpipe和dapple等系统采用了流水线并行\",{\"1\":{\"418\":1}}],[\"gpipe和dapple中使用的同步模式则要求不同微批次的计算是串行的\",{\"1\":{\"399\":1}}],[\"gpipe\",{\"1\":{\"398\":1}}],[\"gpt模型中的情况与bert类似\",{\"1\":{\"415\":1}}],[\"gpt\",{\"1\":{\"365\":2,\"372\":1,\"410\":1,\"416\":3,\"425\":1}}],[\"gpu的内存为40gb\",{\"1\":{\"412\":1}}],[\"gpu的计算密度高于dgx\",{\"1\":{\"412\":1}}],[\"gpu服务器上的类似趋势\",{\"1\":{\"412\":1}}],[\"gpu服务器上的性能对比情况\",{\"1\":{\"412\":1}}],[\"gpu服务器上对mpress进行了测试\",{\"1\":{\"412\":1}}],[\"gpu服务器上进行实验以评估mpress和基线方法\",{\"1\":{\"410\":1}}],[\"gpu服务器上进行实验\",{\"1\":{\"400\":1}}],[\"gpu之间的数据移动可以与dnn计算异步进行\",{\"1\":{\"408\":1}}],[\"gpu对之间的带宽可能会有所不同\",{\"1\":{\"406\":1}}],[\"gpu间完全通过同质的链路连接\",{\"1\":{\"406\":1}}],[\"gpu引入了第一代nvlink\",{\"1\":{\"402\":1}}],[\"gpu内存消耗的问题\",{\"0\":{\"400\":1}}],[\"gpus\",{\"1\":{\"175\":2,\"375\":1}}],[\"gpu\",{\"1\":{\"143\":11,\"149\":1,\"150\":4,\"156\":1,\"157\":1,\"158\":5,\"160\":6,\"161\":1,\"162\":3,\"163\":1,\"175\":5,\"187\":1,\"188\":2,\"192\":1,\"193\":1,\"198\":1,\"204\":1,\"212\":2,\"249\":2,\"352\":6,\"353\":2,\"354\":4,\"355\":2,\"356\":1,\"393\":2,\"395\":1,\"400\":1,\"401\":2,\"407\":1,\"410\":3,\"411\":3,\"415\":1,\"416\":1,\"418\":3,\"419\":1,\"422\":1,\"425\":3,\"426\":1,\"435\":1,\"436\":1,\"438\":1,\"443\":1,\"446\":1,\"453\":1,\"454\":4,\"455\":5,\"456\":9,\"457\":10,\"458\":3},\"2\":{\"421\":1,\"461\":1}}],[\"gpu与国产计算卡芯片异构通信\",{\"1\":{\"139\":1}}],[\"gateway\",{\"1\":{\"309\":1}}],[\"gather\",{\"1\":{\"143\":2,\"164\":2,\"165\":3,\"196\":1}}],[\"gi\",{\"1\":{\"433\":3}}],[\"gif\",{\"1\":{\"339\":1}}],[\"gil\",{\"1\":{\"161\":2,\"162\":6}}],[\"git地址\",{\"1\":{\"373\":1}}],[\"git\",{\"1\":{\"144\":2,\"147\":2,\"366\":3,\"374\":2}}],[\"github\",{\"1\":{\"1\":1,\"98\":1,\"99\":1,\"144\":1,\"147\":1,\"217\":1,\"228\":1,\"246\":1,\"363\":1,\"370\":1}}],[\"gbps\",{\"1\":{\"454\":1}}],[\"gb\",{\"1\":{\"149\":4}}],[\"gtx\",{\"1\":{\"149\":1}}],[\"g\",{\"1\":{\"149\":2,\"150\":2,\"205\":4,\"433\":1,\"439\":1}}],[\"gen3x16带宽的近5倍\",{\"1\":{\"402\":1}}],[\"generate\",{\"1\":{\"145\":1}}],[\"geforce\",{\"1\":{\"149\":1}}],[\"getobject\",{\"1\":{\"383\":1}}],[\"getbucketlocation\",{\"1\":{\"383\":1}}],[\"getattr\",{\"1\":{\"167\":1,\"168\":2}}],[\"getstringconfig\",{\"1\":{\"108\":2}}],[\"get\",{\"1\":{\"34\":1,\"69\":1,\"72\":1,\"74\":1,\"75\":2,\"97\":1,\"150\":1,\"183\":1}}],[\"gcr\",{\"1\":{\"98\":1}}],[\"gcepersistentdisk\",{\"1\":{\"10\":1}}],[\"going\",{\"1\":{\"175\":1}}],[\"google\",{\"1\":{\"91\":1,\"95\":1,\"105\":1,\"418\":1}}],[\"gov\",{\"1\":{\"75\":1,\"393\":1}}],[\"gotraceback=\",{\"1\":{\"62\":1}}],[\"gomaxprocs=\",{\"1\":{\"62\":1}}],[\"gogc=\",{\"1\":{\"62\":1}}],[\"golang\",{\"1\":{\"62\":1}}],[\"go\",{\"1\":{\"62\":7,\"122\":1,\"127\":1}}],[\"grep\",{\"1\":{\"279\":1,\"280\":1,\"282\":1}}],[\"greet\",{\"1\":{\"169\":2}}],[\"growfs\",{\"1\":{\"261\":2}}],[\"groupmember\",{\"1\":{\"150\":1,\"151\":1,\"154\":1}}],[\"group\",{\"0\":{\"202\":1},\"1\":{\"149\":1,\"150\":21,\"151\":9,\"152\":2,\"153\":1,\"154\":21,\"181\":1,\"183\":1,\"202\":3,\"204\":1,\"282\":2,\"283\":4,\"372\":2}}],[\"graphs\",{\"1\":{\"149\":1}}],[\"graph\",{\"0\":{\"94\":1},\"1\":{\"94\":1,\"95\":1,\"149\":1,\"442\":3}}],[\"gradient\",{\"1\":{\"75\":1}}],[\"grace\",{\"1\":{\"51\":2,\"417\":1}}],[\"grpc\",{\"1\":{\"61\":1,\"97\":8}}],[\"回收策略\",{\"0\":{\"10\":1}}],[\"载\",{\"1\":{\"9\":1}}],[\"并了解不同硬件对训练性能的影响\",{\"1\":{\"458\":1}}],[\"并分别结合了\",{\"1\":{\"455\":1}}],[\"并顺序执行\",{\"1\":{\"452\":1}}],[\"并发现了三种在训练性能上表现优越的并行化计划\",{\"1\":{\"452\":1}}],[\"并维护一个掩码\",{\"1\":{\"443\":1}}],[\"并带有与约束相关的增强\",{\"1\":{\"439\":1}}],[\"并为发现的并行化计划生成具有高效通信操作的运行时代码\",{\"1\":{\"427\":1}}],[\"并为每个映射方案确定合适的内存分配策略\",{\"1\":{\"406\":1}}],[\"并为每个\",{\"1\":{\"44\":1}}],[\"并禁止任何两个阶段通过时间复用共享相同的设备集\",{\"1\":{\"426\":1}}],[\"并以流线化的方式计算\",{\"1\":{\"426\":1}}],[\"并按照精心设计的时间顺序执行\",{\"1\":{\"425\":1}}],[\"并共享相同的模型参数\",{\"1\":{\"425\":1}}],[\"并被用于将早期阶段的张量\",{\"1\":{\"416\":1}}],[\"并优先选择重计算而不是d2d交换\",{\"1\":{\"415\":1}}],[\"并优化多gpu\",{\"1\":{\"177\":1}}],[\"并会延迟操作间并行训练\",{\"1\":{\"415\":1}}],[\"并估算相应的反向传播的flops为前向传播的两倍\",{\"1\":{\"410\":1}}],[\"并启用了高性能重计算的dapple+recomp\",{\"1\":{\"410\":1}}],[\"并启用其nccl库以使用nvlink在阶段之间传输数据\",{\"1\":{\"408\":1}}],[\"并监控每个设备的内存使用情况\",{\"1\":{\"408\":1}}],[\"并基于以下几个关键观察来进行简化\",{\"1\":{\"407\":1}}],[\"并让其总数量与目标接收gpu的数量一致\",{\"1\":{\"406\":1}}],[\"并触发启用了内存压缩的操作间并行训练\",{\"1\":{\"405\":1}}],[\"并与之前的运行结果进行比较\",{\"1\":{\"405\":1}}],[\"并收集gpu内存节省量及引入的开销\",{\"1\":{\"405\":1}}],[\"并引入额外的延迟\",{\"1\":{\"401\":1}}],[\"并已被许多主流系统采用\",{\"1\":{\"401\":1}}],[\"并设置了最大可持续的模型规模\",{\"1\":{\"400\":1}}],[\"并从工人3回流至工人1\",{\"1\":{\"399\":1}}],[\"并定期交换与模型参数等大小的梯度\",{\"1\":{\"398\":1}}],[\"并映射到单独的gpu上进行计算\",{\"1\":{\"398\":1}}],[\"并重启即可\",{\"1\":{\"366\":1}}],[\"并不依赖\",{\"1\":{\"350\":1}}],[\"并不会直接去调用后端的容器项目\",{\"1\":{\"61\":1}}],[\"并具有高带宽和低延迟的特点\",{\"1\":{\"348\":1}}],[\"并单播发送给设备a\",{\"1\":{\"303\":1}}],[\"并询问\",{\"1\":{\"303\":1}}],[\"并附加上对应的vni\",{\"1\":{\"292\":1}}],[\"并跟踪它的系统调用\",{\"1\":{\"253\":1}}],[\"并实时显示它的系统调用\",{\"1\":{\"252\":1}}],[\"并预计在三个月内完成初始版本内容\",{\"1\":{\"231\":1}}],[\"并结合了\",{\"1\":{\"456\":1}}],[\"并结合国内学习者的实际情况\",{\"1\":{\"226\":1}}],[\"并结合硬件架构和通信需求\",{\"1\":{\"177\":1}}],[\"并展现出非凡的能力\",{\"1\":{\"217\":1}}],[\"并确保其最小值为1\",{\"1\":{\"211\":1}}],[\"并确保kong服务已正确启动\",{\"1\":{\"67\":1}}],[\"并处理不同的数据集\",{\"1\":{\"189\":1,\"195\":1}}],[\"并在其余三种设置中应用\",{\"1\":{\"455\":1}}],[\"并在需要时将其取回\",{\"1\":{\"454\":1}}],[\"并在后期优化阶段将某些非就地操作符替换为原始的就地版本\",{\"1\":{\"449\":1}}],[\"并在物化过程中插入张量操作\",{\"1\":{\"444\":1}}],[\"并在多个流行的dnn模型\",{\"1\":{\"424\":1}}],[\"并在dapple上运行mpress\",{\"1\":{\"410\":1}}],[\"并在复现中实现对大模型的深入理解与掌握\",{\"1\":{\"224\":1}}],[\"并在训练过程中共享模型参数\",{\"1\":{\"187\":1}}],[\"并在出现故障时自动进行恢复\",{\"1\":{\"119\":1}}],[\"并行执行以进行分布式训练\",{\"1\":{\"445\":1}}],[\"并行化搜索空间构建\",{\"0\":{\"428\":1}}],[\"并行化计划优化了通信成本\",{\"1\":{\"458\":1}}],[\"并行化计划的编译\",{\"0\":{\"442\":1}}],[\"并行化计划的搜索空间\",{\"1\":{\"425\":1}}],[\"并行化计划可以自然地通过模型分区和分区模型的时空调度来表达\",{\"1\":{\"428\":1}}],[\"并行化计划是指一种训练执行计划\",{\"1\":{\"425\":1}}],[\"并行化模型\",{\"1\":{\"143\":1}}],[\"并行计算\",{\"1\":{\"197\":1}}],[\"并行i\",{\"1\":{\"196\":1}}],[\"并行性和\",{\"1\":{\"451\":1}}],[\"并行性代表了在大型搜索空间内几类经过充分研究的并行化计划\",{\"1\":{\"425\":1}}],[\"并行性\",{\"1\":{\"185\":1,\"190\":1,\"425\":2}}],[\"并通过比较损失曲线和梯度归一化曲线来评估其与数据并行训练的重叠情况\",{\"1\":{\"448\":1}}],[\"并通过高带宽\",{\"1\":{\"417\":1}}],[\"并通过不同链路并行传输\",{\"1\":{\"406\":1}}],[\"并通过多种实验和测试展示了其效果\",{\"1\":{\"248\":1}}],[\"并通过实际应用案例深入理解和掌握大模型部署以及应用技术\",{\"1\":{\"228\":1}}],[\"并通过完成生动有趣的具体项目提升学习者实践水平\",{\"1\":{\"218\":1}}],[\"并通过\",{\"1\":{\"174\":1,\"193\":1,\"445\":1}}],[\"并通过兼容不同平台的方式导出\",{\"1\":{\"170\":1}}],[\"并负责创建和初始化模块对象\",{\"1\":{\"171\":1}}],[\"并抛出错误\",{\"1\":{\"162\":1}}],[\"并提示用户需要通过\",{\"1\":{\"154\":1}}],[\"并最大限度地减少达到峰值带宽所需的资源\",{\"1\":{\"143\":1}}],[\"并自动执行无中断的滚动升级\",{\"1\":{\"119\":1}}],[\"并根据需要恢复状态\",{\"1\":{\"405\":1}}],[\"并根据策略决定是否将这些路由信息传播给其他对等体\",{\"1\":{\"311\":1}}],[\"并根据用户定义的逻辑执行相应的操作\",{\"1\":{\"118\":1}}],[\"并根据这些文件创建和管理\",{\"1\":{\"31\":1}}],[\"并进行相应的标注\",{\"1\":{\"94\":1}}],[\"并将分割后的张量分配给不相交的设备\",{\"1\":{\"426\":1}}],[\"并将计算传递给工人2\",{\"1\":{\"399\":1}}],[\"并将数据片段分配给gpu设备来训练共享的复制模型\",{\"1\":{\"398\":1}}],[\"并将结果分配给多个设备\",{\"1\":{\"398\":1}}],[\"并将结果存储在\",{\"1\":{\"160\":1}}],[\"并将结果存储在某个\",{\"1\":{\"157\":1}}],[\"并将流量转发给spine交换机\",{\"1\":{\"349\":1}}],[\"并将流量从服务的\",{\"1\":{\"40\":1}}],[\"并将它们之间的通信转发到spine交换机\",{\"1\":{\"346\":1}}],[\"并将它们绑定到模块的命名空间中\",{\"1\":{\"172\":1}}],[\"并将以太网帧发送到其二层网络接口\",{\"1\":{\"291\":1}}],[\"并将以下行添加到\",{\"1\":{\"263\":1}}],[\"并将其转换为中间图表示\",{\"1\":{\"445\":1}}],[\"并将其余设备留给其他算子\",{\"1\":{\"436\":1}}],[\"并将其类型设置为\",{\"1\":{\"258\":1}}],[\"并将其添加到现有的\",{\"1\":{\"256\":1}}],[\"并将这些资源的状态持久化到ml元数据服务中\",{\"1\":{\"87\":1}}],[\"并且分区后的\",{\"1\":{\"429\":1}}],[\"并且无需对硬件进行额外的修改或优化\",{\"1\":{\"418\":1}}],[\"并且只在必要时使用gpu\",{\"1\":{\"418\":1}}],[\"并且只能被单个node挂\",{\"1\":{\"9\":1}}],[\"并且吸收了来自深度学习社区的各种优化\",{\"1\":{\"412\":1}}],[\"并且需要额外的具有高i\",{\"1\":{\"412\":1}}],[\"并且比重计算更快\",{\"1\":{\"411\":1}}],[\"并且能够与gpu上的前向和后向计算并行运行\",{\"1\":{\"407\":1}}],[\"并且能够训练比基线更大的模型\",{\"1\":{\"396\":1}}],[\"并且允许d2d交换更好地与dnn计算重叠\",{\"1\":{\"404\":1}}],[\"并且允许直接访问每个\",{\"1\":{\"37\":1}}],[\"并且可以使用多种语言与人交流\",{\"1\":{\"372\":1}}],[\"并且可以在单进程或多进程\",{\"1\":{\"143\":1}}],[\"并且它未被挂载\",{\"1\":{\"257\":1}}],[\"并且我们可以进一步假设\",{\"1\":{\"255\":1}}],[\"并且每个处理单元处理不同的数据\",{\"1\":{\"186\":1}}],[\"并且支持不同版本的api\",{\"1\":{\"111\":1}}],[\"并且本身支持许多\",{\"1\":{\"105\":1}}],[\"并且希望与其他工具\",{\"1\":{\"102\":1}}],[\"并且你的集群配置支持\",{\"1\":{\"97\":1}}],[\"并且\",{\"1\":{\"61\":1}}],[\"并指定一个键值对\",{\"1\":{\"35\":1}}],[\"并获取到\",{\"1\":{\"5\":1}}],[\"k\",{\"1\":{\"425\":3,\"429\":2}}],[\"kv\",{\"1\":{\"249\":1}}],[\"komorebitimothy\",{\"1\":{\"138\":1}}],[\"kong路由\",{\"1\":{\"75\":1}}],[\"kong服务\",{\"1\":{\"75\":1}}],[\"kong\",{\"1\":{\"66\":1},\"2\":{\"76\":1,\"77\":1}}],[\"kong和nginx创建服务和路由\",{\"1\":{\"65\":1}}],[\"kong和nginx部署服务\",{\"0\":{\"65\":1}}],[\"kudo\",{\"1\":{\"122\":1}}],[\"kubebuilder\",{\"1\":{\"122\":1}}],[\"kubeflow\",{\"0\":{\"78\":1},\"1\":{\"78\":7,\"79\":2,\"86\":2,\"89\":3,\"90\":1,\"92\":1,\"94\":2,\"95\":9,\"96\":2,\"97\":18,\"106\":2,\"129\":1},\"2\":{\"115\":1}}],[\"kubeadm\",{\"1\":{\"62\":2}}],[\"kubectl\",{\"1\":{\"34\":2,\"36\":2,\"61\":1,\"97\":1,\"103\":1,\"118\":1}}],[\"kube\",{\"1\":{\"30\":3,\"32\":1,\"33\":3,\"34\":1,\"60\":1,\"98\":1}}],[\"kubelet如何实现\",{\"0\":{\"61\":1}}],[\"kubeletconfiguration\",{\"1\":{\"48\":1}}],[\"kubelet的\",{\"0\":{\"45\":1}}],[\"kubelet\",{\"1\":{\"30\":1,\"31\":4,\"32\":1,\"34\":2,\"45\":1,\"47\":2,\"48\":5,\"50\":1,\"51\":4,\"61\":5,\"62\":12}}],[\"kubernetes\",{\"0\":{\"52\":1,\"100\":1},\"1\":{\"11\":2,\"17\":1,\"18\":1,\"23\":1,\"28\":1,\"30\":4,\"31\":1,\"32\":3,\"33\":5,\"34\":1,\"35\":1,\"36\":3,\"37\":2,\"38\":1,\"39\":1,\"44\":1,\"51\":5,\"52\":1,\"54\":2,\"57\":1,\"58\":1,\"59\":1,\"62\":1,\"78\":3,\"79\":2,\"89\":1,\"96\":2,\"97\":4,\"98\":1,\"99\":1,\"100\":3,\"103\":2,\"105\":1,\"106\":1,\"116\":4,\"117\":4,\"118\":1,\"120\":3,\"122\":2,\"123\":3,\"128\":1}}],[\"kubernetes支持的回收策略如下\",{\"1\":{\"10\":1}}],[\"kubernetes支持的访问模式如下\",{\"1\":{\"9\":1}}],[\"k8r6z\",{\"1\":{\"97\":2}}],[\"k8sapiexecutor\",{\"1\":{\"96\":1,\"97\":2}}],[\"k8s技能图谱\",{\"0\":{\"29\":1}}],[\"k8s\",{\"0\":{\"116\":1},\"1\":{\"8\":1,\"17\":1,\"48\":1,\"78\":1,\"98\":3,\"128\":1},\"2\":{\"63\":1}}],[\"k8s知识点\",{\"0\":{\"8\":1}}],[\"katib\",{\"0\":{\"105\":1,\"106\":1},\"1\":{\"97\":19,\"105\":5,\"106\":10}}],[\"keep\",{\"1\":{\"269\":1}}],[\"keepalive\",{\"1\":{\"75\":1}}],[\"kernel\",{\"1\":{\"249\":1}}],[\"kernels\",{\"1\":{\"149\":1}}],[\"keycloak\",{\"0\":{\"387\":1},\"1\":{\"387\":2}}],[\"key=zpuzvy34umfcfxvwksv0p00vczvmb6ymgjs5j9eo\",{\"1\":{\"382\":1}}],[\"key=filetoken\",{\"1\":{\"366\":1}}],[\"key=root\",{\"1\":{\"366\":1}}],[\"key=any\",{\"1\":{\"366\":1}}],[\"key=sk\",{\"1\":{\"366\":1,\"382\":1}}],[\"keyfile\",{\"1\":{\"366\":1}}],[\"key\",{\"1\":{\"5\":8,\"36\":2,\"54\":1,\"56\":1,\"62\":1,\"366\":9,\"372\":2,\"381\":1,\"382\":1}}],[\"kind\",{\"1\":{\"20\":1,\"25\":1,\"32\":1,\"36\":1,\"40\":1,\"42\":1,\"43\":1,\"48\":1,\"54\":1,\"56\":1,\"58\":1,\"60\":1,\"98\":1}}],[\"高带宽内存\",{\"1\":{\"417\":1}}],[\"高带宽\",{\"1\":{\"347\":1}}],[\"高扩展性\",{\"1\":{\"287\":1}}],[\"高效微调方法\",{\"1\":{\"220\":1}}],[\"高效微调等技能在内的全流程指导\",{\"1\":{\"220\":1}}],[\"高效的消息传递\",{\"1\":{\"197\":1}}],[\"高效神经架构搜索\",{\"1\":{\"105\":1}}],[\"高性能计算\",{\"1\":{\"348\":1}}],[\"高性能的后端服务\",{\"1\":{\"127\":1}}],[\"高性能\",{\"1\":{\"5\":1}}],[\"高可用\",{\"1\":{\"5\":1}}],[\"活性\",{\"1\":{\"5\":1}}],[\"不理想\",{\"1\":{\"446\":1}}],[\"不受影响\",{\"1\":{\"443\":1}}],[\"不到\",{\"1\":{\"426\":1}}],[\"不可避免的额外重计算延迟会扩大早期层的生命周期\",{\"1\":{\"407\":1}}],[\"不幸的是\",{\"1\":{\"398\":1}}],[\"不积极才是常态\",{\"1\":{\"359\":2}}],[\"不做完美的产品\",{\"1\":{\"359\":2}}],[\"不做免费的产品\",{\"1\":{\"359\":2}}],[\"不依赖\",{\"1\":{\"354\":1,\"356\":1}}],[\"不依赖于cpu进行数据传输\",{\"1\":{\"351\":1}}],[\"不用于网络通信\",{\"1\":{\"352\":1}}],[\"不支持工具和函数调用的模型\",{\"1\":{\"365\":1}}],[\"不支持\",{\"1\":{\"277\":4,\"354\":1,\"451\":1}}],[\"不过\",{\"1\":{\"255\":1}}],[\"不包括缓存命中\",{\"1\":{\"211\":1}}],[\"不在该组中\",{\"1\":{\"154\":1}}],[\"不在\",{\"1\":{\"151\":1}}],[\"不在给定的进程组\",{\"1\":{\"150\":1}}],[\"不计时\",{\"1\":{\"150\":1}}],[\"不提供\",{\"1\":{\"143\":1}}],[\"不提供并行环境\",{\"1\":{\"143\":1}}],[\"不仅仅是基础设施视图\",{\"1\":{\"102\":1}}],[\"不应该被调度到相同的节点上\",{\"1\":{\"54\":1}}],[\"不应该与其他特定\",{\"1\":{\"53\":1}}],[\"不足的阈值达到\",{\"1\":{\"51\":1}}],[\"不同团队的多个项目使用\",{\"1\":{\"446\":1}}],[\"不同gpu之间的带宽和连接链路数量可能存在硬件异构性\",{\"1\":{\"406\":1}}],[\"不同的流可以独立处理\",{\"1\":{\"270\":1}}],[\"不同的处理单元可以负责不同的任务或数据集\",{\"1\":{\"192\":1}}],[\"不同类型知识库文档的加载\",{\"1\":{\"223\":1}}],[\"不同\",{\"1\":{\"38\":1,\"143\":1,\"186\":1}}],[\"不会相互阻塞\",{\"1\":{\"270\":1}}],[\"不会为服务分配一个\",{\"1\":{\"38\":1}}],[\"不会分配集群\",{\"1\":{\"37\":1}}],[\"不会被调度到这个节点上\",{\"1\":{\"36\":1}}],[\"不会出现\",{\"1\":{\"5\":1}}],[\"不能依赖于\",{\"1\":{\"33\":1}}],[\"不是通过\",{\"1\":{\"31\":1}}],[\"不需要使用\",{\"1\":{\"457\":1}}],[\"不需要\",{\"1\":{\"31\":1}}],[\"不允许多个\",{\"1\":{\"5\":1}}],[\"安徵省高性能计算实验室和美国休斯顿大学\",{\"1\":{\"393\":1}}],[\"安全套接层\",{\"1\":{\"339\":1}}],[\"安全链接可选的加密协议\",{\"1\":{\"75\":1}}],[\"安全性和管理灵活性\",{\"1\":{\"288\":1}}],[\"安全性\",{\"1\":{\"5\":1,\"314\":1}}],[\"安装\",{\"0\":{\"239\":1}}],[\"安装kong\",{\"0\":{\"67\":1}}],[\"安装架构\",{\"0\":{\"1\":1}}],[\"它使用了\",{\"1\":{\"457\":2}}],[\"它采用了\",{\"1\":{\"456\":1}}],[\"它只使用了纯张量并行性\",{\"1\":{\"456\":1}}],[\"它允许开发者从新的搜索空间中\",{\"1\":{\"439\":1}}],[\"它打破了不同流水线阶段中的算子不能共享同一设备集的常规假设\",{\"1\":{\"436\":1}}],[\"它沿着与其相关的张量的批次维度对操作符进行分区\",{\"1\":{\"425\":1}}],[\"它指定了在给定的\",{\"1\":{\"425\":1}}],[\"它结合了多种内存优化技术\",{\"1\":{\"395\":1}}],[\"它为\",{\"1\":{\"352\":1}}],[\"它为容器设置了\",{\"1\":{\"25\":1}}],[\"它能够支持训练参数最多为6亿的bert模型\",{\"1\":{\"400\":1}}],[\"它能够在大多数场景下提供良好的性能和功能支持\",{\"1\":{\"50\":1}}],[\"它能有效处理大规模集群中的东西向流量\",{\"1\":{\"348\":1}}],[\"它位于组网架构的核心层或骨干层\",{\"1\":{\"345\":1}}],[\"它解决了传统树形网络架构中的瓶颈问题\",{\"1\":{\"344\":1}}],[\"它用于管理入站\",{\"1\":{\"330\":1}}],[\"它用于标识\",{\"1\":{\"171\":1}}],[\"它知道设备b的ip地址\",{\"1\":{\"303\":1}}],[\"它在以太网等局域网环境中起着关键作用\",{\"1\":{\"302\":1}}],[\"它可以与张量并行共存\",{\"1\":{\"452\":1}}],[\"它可以添加\",{\"1\":{\"327\":1}}],[\"它可以查看和修改接口配置\",{\"1\":{\"318\":1}}],[\"它可以完成这些耗时比较长的工作\",{\"1\":{\"255\":1}}],[\"它可以帮助你诊断程序的行为或调试程序\",{\"1\":{\"252\":1}}],[\"它可以调优用任何用户选择的语言编写的应用程序的超参数\",{\"1\":{\"105\":1}}],[\"它以后端名称作为键\",{\"1\":{\"207\":1}}],[\"它还提供同步和对话控制\",{\"1\":{\"338\":1}}],[\"它还接受大写字符串\",{\"1\":{\"206\":1}}],[\"它还支持点对点发送\",{\"1\":{\"143\":1}}],[\"它的搜索算法和训练系统目前基于\",{\"1\":{\"454\":1}}],[\"它的路径向量机制\",{\"1\":{\"315\":1}}],[\"它的主要特点和用途如下\",{\"1\":{\"285\":1,\"286\":1}}],[\"它的灵活性使其非常适合处理复杂的并行任务\",{\"1\":{\"195\":1}}],[\"它的简洁性和高效性使其成为许多并行和分布式计算任务的首选模型\",{\"1\":{\"189\":1}}],[\"它将模型层均匀划分为多个阶段\",{\"1\":{\"454\":1}}],[\"它将模型的不同层分配给不同的设备\",{\"1\":{\"418\":1}}],[\"它将网络通信过程划分为七个层次\",{\"1\":{\"333\":1}}],[\"它将帧封装在udp包中\",{\"1\":{\"291\":1}}],[\"它将\",{\"1\":{\"174\":1}}],[\"它保证了\",{\"1\":{\"171\":1}}],[\"它返回一个\",{\"1\":{\"171\":1}}],[\"它实现了在分布式训练中\",{\"1\":{\"150\":1}}],[\"它支持多种互连技术\",{\"1\":{\"143\":1}}],[\"它不仅能够利用现有的流水线并行\",{\"1\":{\"418\":1}}],[\"它不是一个完整的并行编程框架\",{\"1\":{\"143\":1}}],[\"它不能再被其他\",{\"1\":{\"13\":1}}],[\"它包括了\",{\"1\":{\"118\":1}}],[\"它提供了\",{\"0\":{\"101\":1}}],[\"它会检查其中的ip地址\",{\"1\":{\"303\":1}}],[\"它会在\",{\"1\":{\"170\":1}}],[\"它会定期启动运行配置的新副本\",{\"1\":{\"95\":1}}],[\"它会创建一个\",{\"1\":{\"5\":1}}],[\"它执行机器学习\",{\"1\":{\"90\":1}}],[\"它编排基于任务的工作流\",{\"1\":{\"85\":1}}],[\"它决定了\",{\"1\":{\"45\":1}}],[\"它通过结合多种内存优化技术\",{\"1\":{\"418\":1}}],[\"它通过丢弃中间激活值并在反向传播中重新计算它们\",{\"1\":{\"418\":1}}],[\"它通过\",{\"1\":{\"161\":1}}],[\"它通过不分配\",{\"1\":{\"44\":1}}],[\"它通过将模型的层分成多个阶段\",{\"1\":{\"418\":1}}],[\"它通过将\",{\"1\":{\"38\":1}}],[\"它与\",{\"1\":{\"43\":1,\"353\":1}}],[\"它选择了带有标签\",{\"1\":{\"40\":1}}],[\"它由\",{\"1\":{\"30\":1}}],[\"它限制了某个命名空间内的\",{\"1\":{\"20\":1}}],[\"它们可以使用操作符排序来支持\",{\"1\":{\"451\":1}}],[\"它们可以通过数据并行进行大规模模型训练\",{\"1\":{\"410\":1}}],[\"它们解耦了操作符及其输入张量的划分\",{\"1\":{\"451\":1}}],[\"它们分别对应三个原语\",{\"1\":{\"439\":1}}],[\"它们定义了\",{\"1\":{\"433\":1}}],[\"它们通过自定义的内存架构和高效的并行计算\",{\"1\":{\"418\":1}}],[\"它们都来自自然语言处理领域\",{\"1\":{\"410\":1}}],[\"它们各自用于不同的通信场景\",{\"1\":{\"356\":1}}],[\"它们各自有不同的功能\",{\"0\":{\"316\":1}}],[\"它们各自有不同的优缺点和应用场景\",{\"1\":{\"288\":1}}],[\"它们各自有不同的应用场景和特点\",{\"1\":{\"284\":1}}],[\"它们仅用于同一台服务器中的\",{\"1\":{\"354\":1}}],[\"它们只连接到leaf交换机\",{\"1\":{\"345\":1}}],[\"它们的\",{\"1\":{\"255\":1}}],[\"它们在不同的计算环境中均能有效运行\",{\"1\":{\"197\":1}}],[\"它们将自动捕捉并将错误报告给\",{\"1\":{\"162\":1}}],[\"它们将其软件包发布集中在应用程序安装上\",{\"1\":{\"102\":1}}],[\"它们共同组成了\",{\"1\":{\"97\":1}}],[\"它们帮助管理员公平分配集群资源\",{\"1\":{\"19\":1}}],[\"它们帮助管理员确保资源的公平分配和高效利用\",{\"1\":{\"17\":1}}],[\"它们用于防止某个命名空间消耗过多的集群资源\",{\"1\":{\"18\":1}}],[\"它未被任何\",{\"1\":{\"12\":1}}],[\"它反映了存储卷的当前状态\",{\"1\":{\"11\":1}}],[\"它一定是持久化到了集群多数节点上\",{\"1\":{\"5\":1}}],[\"因为模型较小\",{\"1\":{\"457\":1}}],[\"因为这些层由于激活张量占用了大量内存\",{\"1\":{\"455\":1}}],[\"因为hbm成本昂贵\",{\"1\":{\"417\":1}}],[\"因为在三种方法中\",{\"1\":{\"415\":1}}],[\"因为在高内存压力下\",{\"1\":{\"411\":1}}],[\"因为其时间成本过高\",{\"1\":{\"416\":1}}],[\"因为其生命周期较长\",{\"1\":{\"415\":1}}],[\"因为其最大每gpu内存需求超过了32gb\",{\"1\":{\"412\":1}}],[\"因为前者的时间成本超过了t2的生命周期\",{\"1\":{\"415\":1}}],[\"因为对称的全互联nvlink连接使得每个gpu拥有相同数量的nvlink连接\",{\"1\":{\"414\":1}}],[\"因为对于大规模的自然语言处理模型\",{\"1\":{\"398\":1}}],[\"因为dapple默认启用了fp16低精度训练功能\",{\"1\":{\"412\":1}}],[\"因为a100\",{\"1\":{\"412\":1}}],[\"因为aws\",{\"1\":{\"410\":1}}],[\"因为zero\",{\"1\":{\"412\":1}}],[\"因为它使用的\",{\"1\":{\"458\":1}}],[\"因为它采用的是异步训练方法\",{\"1\":{\"451\":1}}],[\"因为它过于缓慢\",{\"1\":{\"415\":1}}],[\"因为它的性能比gpu\",{\"1\":{\"415\":1}}],[\"因为它的时间成本只有3毫秒\",{\"1\":{\"415\":1}}],[\"因为它的成本可以被隐藏起来\",{\"1\":{\"415\":1}}],[\"因为它可以应用于所有类型的模型数据\",{\"1\":{\"411\":1}}],[\"因为它们是集中处理流量的设备\",{\"1\":{\"345\":1}}],[\"因为它们可以用于性能评估\",{\"1\":{\"95\":1}}],[\"因为重计算只能减少前向传播生成的激活值的内存消耗\",{\"1\":{\"411\":1}}],[\"因为重新计算丢弃激活值的前向传播引入的延迟通常远低于gpu\",{\"1\":{\"411\":1}}],[\"因为pcie带宽的限制导致交换操作非常慢\",{\"1\":{\"411\":1}}],[\"因为第一层操作符的输出是前一层的输入\",{\"1\":{\"407\":1}}],[\"因为每个gpu都会复制相同数量的模型数据\",{\"1\":{\"398\":1}}],[\"因为每个处理单元可以执行不同的程序\",{\"1\":{\"191\":1}}],[\"因为\",{\"1\":{\"162\":1,\"456\":1,\"459\":1}}],[\"因为默认进程组中的\",{\"1\":{\"151\":1}}],[\"因为只有\",{\"1\":{\"5\":1}}],[\"因此它能够在\",{\"1\":{\"455\":1}}],[\"因此它们的一些管理和监控操作与普通\",{\"1\":{\"34\":1}}],[\"因此它们没有自动伸缩\",{\"1\":{\"31\":1}}],[\"因此无法在令牌级别确定数据依赖关系\",{\"1\":{\"451\":1}}],[\"因此每个设备只持有一个分割后的算子\",{\"1\":{\"435\":1}}],[\"因此algo的选择比张量并行更为受限\",{\"1\":{\"433\":1}}],[\"因此可能容易出错\",{\"1\":{\"427\":1}}],[\"因此也遭受了相同的局限性\",{\"1\":{\"426\":1}}],[\"因此也可以将模型分为多个阶段\",{\"1\":{\"425\":1}}],[\"因此称为流水线并行性\",{\"1\":{\"425\":1}}],[\"因此mpress没有使用其他两种优化\",{\"1\":{\"411\":1}}],[\"因此我们引入了数据分条技术\",{\"1\":{\"406\":1}}],[\"因此不需要触发任何内存压缩优化\",{\"1\":{\"411\":1}}],[\"因此不会带来运行时开销\",{\"1\":{\"405\":1}}],[\"因此不支持\",{\"1\":{\"354\":1}}],[\"因此降低了cpu负载\",{\"1\":{\"351\":1}}],[\"因此容易受到arp欺骗\",{\"1\":{\"306\":1}}],[\"因此需要通过通信机制进行数据交换\",{\"1\":{\"193\":1}}],[\"因此任务协调和进程管理可能更加复杂\",{\"1\":{\"191\":1}}],[\"因此熟悉\",{\"1\":{\"143\":1}}],[\"因此\",{\"1\":{\"95\":1,\"143\":2,\"177\":1,\"398\":2,\"408\":1,\"414\":1,\"415\":2,\"417\":3,\"428\":1,\"431\":1,\"433\":1,\"437\":1,\"440\":1,\"443\":1,\"454\":1}}],[\"因此非常适合用于管理集群的核心组件\",{\"1\":{\"31\":1}}],[\"因此一旦分布式锁申请返回给\",{\"1\":{\"5\":1}}],[\"是特殊的张量并行性\",{\"1\":{\"451\":1}}],[\"是为\",{\"1\":{\"451\":1}}],[\"是设备集\",{\"1\":{\"435\":1}}],[\"是最常见的技术\",{\"1\":{\"418\":1}}],[\"是最常用的实现\",{\"1\":{\"194\":1}}],[\"是grace\",{\"1\":{\"417\":1}}],[\"是这四个训练任务中d2d交换节省内存最多的一次\",{\"1\":{\"416\":1}}],[\"是pcie\",{\"1\":{\"402\":1}}],[\"是用户与网络交互的界面\",{\"1\":{\"340\":1}}],[\"是用于捕获和处理\",{\"1\":{\"162\":1}}],[\"是用于节点管理的机制\",{\"1\":{\"36\":1}}],[\"是由国际标准化组织\",{\"1\":{\"333\":1}}],[\"是由管道组件发出的输出\",{\"1\":{\"95\":1}}],[\"是现代的\",{\"1\":{\"332\":1}}],[\"是网络管理中常用的命令\",{\"0\":{\"316\":1}}],[\"是互联网核心路由协议\",{\"1\":{\"309\":1}}],[\"是另一个邻居节点的ip地址\",{\"1\":{\"294\":1}}],[\"是其mac地址\",{\"1\":{\"294\":2}}],[\"是两种用于网络分段和虚拟化的技术\",{\"1\":{\"284\":1}}],[\"是两种用于资源管理和控制的机制\",{\"1\":{\"17\":1}}],[\"是对\",{\"1\":{\"267\":1}}],[\"是对管道的单次执行\",{\"1\":{\"95\":1}}],[\"是在虚拟机里用的一个\",{\"1\":{\"255\":1}}],[\"是在所有处理单元上执行相同的指令\",{\"1\":{\"186\":1}}],[\"是指\",{\"1\":{\"255\":1}}],[\"是什么\",{\"0\":{\"223\":1}}],[\"是并行计算领域的重要工具\",{\"1\":{\"200\":1}}],[\"是所有\",{\"1\":{\"196\":1}}],[\"是模块中的对象名称\",{\"1\":{\"168\":1}}],[\"是模块路径\",{\"1\":{\"168\":1}}],[\"是主节点\",{\"1\":{\"162\":1}}],[\"是必要的\",{\"1\":{\"162\":1}}],[\"是将\",{\"1\":{\"162\":1}}],[\"是从\",{\"1\":{\"162\":2}}],[\"是否支持函数调用\",{\"1\":{\"365\":1}}],[\"是否支持工具选择\",{\"1\":{\"365\":1}}],[\"是否支持图片输入\",{\"1\":{\"365\":1}}],[\"是否用于问题优化\",{\"1\":{\"365\":1}}],[\"是否用于问题分类\",{\"1\":{\"365\":1}}],[\"是否用于工具调用\",{\"1\":{\"365\":1}}],[\"是否用于内容提取\",{\"1\":{\"365\":1}}],[\"是否设置为知识库处理模型\",{\"1\":{\"365\":1}}],[\"是否开启敏感校验\",{\"1\":{\"365\":1}}],[\"是否有效\",{\"1\":{\"206\":1}}],[\"是否是默认的全局进程组\",{\"1\":{\"154\":1}}],[\"是否在该组中\",{\"1\":{\"151\":1}}],[\"是默认的进程组\",{\"1\":{\"151\":1}}],[\"是可扩展和可移植的\",{\"1\":{\"106\":1}}],[\"是管道中某个组件的执行\",{\"1\":{\"95\":1}}],[\"是管道的可重复运行\",{\"1\":{\"95\":1}}],[\"是管道运行时在\",{\"1\":{\"94\":1}}],[\"是需要通过使用\",{\"1\":{\"61\":1}}],[\"是当宿主机资源紧张的时候\",{\"1\":{\"51\":1}}],[\"是应用在节点上的属性\",{\"1\":{\"36\":1}}],[\"是集群稳定运行的关键保障之一\",{\"1\":{\"34\":1}}],[\"是\",{\"1\":{\"30\":1,\"34\":1,\"35\":1,\"44\":1,\"50\":1,\"79\":1,\"97\":3,\"117\":1,\"162\":2,\"184\":1,\"196\":1,\"255\":8,\"321\":1,\"324\":1,\"352\":2,\"356\":1}}],[\"是一致的\",{\"1\":{\"154\":1}}],[\"是一款专注于在线教育的产品\",{\"1\":{\"131\":1}}],[\"是一个超参数\",{\"1\":{\"435\":1}}],[\"是一个较老的工具\",{\"1\":{\"332\":1}}],[\"是一个用户空间实用程序\",{\"1\":{\"330\":1}}],[\"是一个用于跟踪系统调用和信号的工具\",{\"1\":{\"252\":1}}],[\"是一个传统的工具\",{\"1\":{\"318\":1}}],[\"是一个邻居节点的ip地址\",{\"1\":{\"294\":1}}],[\"是一个宏\",{\"1\":{\"171\":1}}],[\"是一个张量序列而不是单个张量\",{\"1\":{\"159\":1}}],[\"是一个通信库\",{\"1\":{\"143\":1}}],[\"是一个库\",{\"1\":{\"143\":1}}],[\"是一个与机器学习\",{\"1\":{\"105\":1}}],[\"是一个原生于\",{\"1\":{\"105\":1}}],[\"是一个开源系统\",{\"1\":{\"100\":1}}],[\"是一个好的选择\",{\"1\":{\"97\":1}}],[\"是一个面向想要构建和试验\",{\"1\":{\"78\":1}}],[\"是一个配置选项\",{\"1\":{\"45\":1}}],[\"是一个\",{\"1\":{\"43\":1}}],[\"是一个集群级别的资源\",{\"1\":{\"11\":1}}],[\"是一种网络通信技术\",{\"1\":{\"353\":1}}],[\"是一种高带宽\",{\"1\":{\"352\":1}}],[\"是一种允许计算机之间直接访问彼此内存的技术\",{\"1\":{\"351\":1}}],[\"是一种标准接口\",{\"1\":{\"197\":1}}],[\"是一种用于跨服务器网络通信的技术\",{\"1\":{\"356\":1}}],[\"是一种用于在ipv4网络中将ip地址解析为物理地址\",{\"1\":{\"302\":1}}],[\"是一种用于并行计算的标准接口\",{\"1\":{\"195\":1}}],[\"是一种用于多\",{\"1\":{\"161\":1}}],[\"是一种并行计算模型\",{\"1\":{\"189\":1}}],[\"是一种强大的工具\",{\"1\":{\"123\":1}}],[\"是一种软件扩展\",{\"1\":{\"116\":1}}],[\"是一种特殊类型的\",{\"1\":{\"37\":1}}],[\"是一种在\",{\"1\":{\"18\":1,\"23\":1}}],[\"是基于\",{\"1\":{\"5\":1}}],[\"是如何等待的呢\",{\"1\":{\"5\":1}}],[\"基线系统\",{\"1\":{\"454\":1}}],[\"基线方案分别加速了\",{\"1\":{\"450\":1}}],[\"基线和系统配置\",{\"1\":{\"410\":1}}],[\"基于这一观察\",{\"1\":{\"429\":1}}],[\"基于以上观察和权衡\",{\"1\":{\"407\":1}}],[\"基于隧道\",{\"1\":{\"286\":1}}],[\"基于二进制\",{\"1\":{\"277\":1}}],[\"基于二进制的协议\",{\"1\":{\"268\":1}}],[\"基于纯文本\",{\"1\":{\"277\":1}}],[\"基于纯文本的协议\",{\"1\":{\"268\":1}}],[\"基于检索等一系列任务中测试\",{\"1\":{\"249\":1}}],[\"基于message\",{\"1\":{\"181\":1}}],[\"基于\",{\"1\":{\"96\":1,\"143\":1,\"220\":2,\"445\":1,\"454\":1}}],[\"基于时间间隔调度运行\",{\"1\":{\"95\":1}}],[\"基于主备异步复制导致锁的安全性问题\",{\"1\":{\"5\":1}}],[\"基础镜像\",{\"1\":{\"2\":1}}],[\"相反\",{\"1\":{\"416\":1}}],[\"相对于\",{\"1\":{\"267\":1,\"458\":1}}],[\"相应地\",{\"1\":{\"255\":1}}],[\"相关工作\",{\"0\":{\"418\":1}}],[\"相关项目\",{\"1\":{\"226\":1}}],[\"相关的\",{\"1\":{\"164\":1}}],[\"相关的存储设备出现了错误或问题\",{\"1\":{\"15\":1}}],[\"相比于图\",{\"1\":{\"458\":1}}],[\"相比于无约束的搜索\",{\"1\":{\"450\":1}}],[\"相比之下\",{\"1\":{\"191\":1,\"398\":1,\"411\":1,\"412\":1,\"414\":1,\"417\":1,\"418\":1}}],[\"相比\",{\"1\":{\"5\":1,\"186\":1,\"321\":1}}],[\"相同\",{\"1\":{\"5\":1}}],[\"hbm\",{\"1\":{\"417\":1}}],[\"hub\",{\"1\":{\"334\":1,\"372\":1,\"373\":1}}],[\"huggingface😊\",{\"1\":{\"218\":1}}],[\"huggingface\",{\"1\":{\"218\":1,\"445\":1}}],[\"hqjiang\",{\"1\":{\"247\":1}}],[\"hf在线阅读链接\",{\"1\":{\"218\":1}}],[\"hopper目前64gb\",{\"1\":{\"417\":1}}],[\"hopper架构已经为每个gpu支持专用的cpu侧内存\",{\"1\":{\"417\":1}}],[\"home\",{\"1\":{\"375\":1,\"381\":1,\"382\":1,\"383\":1}}],[\"hot\",{\"1\":{\"372\":1}}],[\"horizontal\",{\"1\":{\"212\":1}}],[\"host=postgresql\",{\"1\":{\"381\":1}}],[\"host\",{\"1\":{\"75\":1,\"366\":1}}],[\"hostname\",{\"1\":{\"54\":2,\"58\":1}}],[\"hpack\",{\"1\":{\"271\":1}}],[\"hpa\",{\"0\":{\"212\":1}}],[\"hpc\",{\"1\":{\"195\":1,\"348\":1,\"351\":1}}],[\"hi\",{\"1\":{\"255\":3}}],[\"hits\",{\"1\":{\"211\":1}}],[\"hierarchical\",{\"1\":{\"176\":1}}],[\"high\",{\"1\":{\"36\":2,\"204\":1}}],[\"h>\",{\"1\":{\"170\":1,\"199\":2}}],[\"h\",{\"1\":{\"145\":2,\"262\":2}}],[\"hyperopt\",{\"1\":{\"106\":1}}],[\"hyperband\",{\"1\":{\"105\":1}}],[\"href=\",{\"1\":{\"75\":1}}],[\"h1>\",{\"1\":{\"75\":1}}],[\"h1\",{\"1\":{\"75\":1}}],[\"html>\",{\"1\":{\"75\":2}}],[\"html\",{\"1\":{\"68\":2,\"74\":1,\"75\":2,\"130\":1,\"247\":1},\"2\":{\"77\":1}}],[\"http头部是以纯文本格式传输的\",{\"1\":{\"271\":1}}],[\"http2与http1区别\",{\"1\":{\"267\":1}}],[\"http\",{\"1\":{\"36\":2,\"40\":1,\"42\":1,\"68\":2,\"69\":1,\"70\":1,\"71\":1,\"72\":1,\"73\":1,\"74\":1,\"75\":2,\"267\":4,\"268\":2,\"269\":4,\"270\":2,\"271\":2,\"272\":2,\"273\":3,\"274\":3,\"275\":3,\"276\":3,\"277\":3,\"340\":1,\"366\":4,\"368\":1,\"369\":1,\"372\":1,\"381\":1,\"382\":1},\"2\":{\"358\":1}}],[\"https\",{\"1\":{\"1\":1,\"75\":1,\"78\":1,\"98\":1,\"99\":1,\"144\":1,\"147\":1,\"217\":1,\"228\":1,\"246\":1,\"247\":1,\"277\":1,\"359\":1,\"363\":1,\"364\":1,\"365\":2,\"366\":1,\"370\":1,\"371\":1,\"374\":1,\"382\":1,\"393\":1,\"422\":2}}],[\"healthy\",{\"1\":{\"381\":2}}],[\"healthz\",{\"1\":{\"366\":1}}],[\"health\",{\"1\":{\"366\":2}}],[\"healthcheck\",{\"1\":{\"366\":3,\"381\":1}}],[\"headers\",{\"1\":{\"75\":2}}],[\"header\",{\"1\":{\"75\":19}}],[\"head>\",{\"1\":{\"75\":1}}],[\"headless\",{\"0\":{\"37\":1,\"38\":1,\"40\":1,\"41\":1,\"42\":1},\"1\":{\"37\":2,\"38\":3,\"39\":3,\"40\":3,\"41\":1,\"43\":1,\"44\":2}}],[\"height\",{\"1\":{\"75\":1}}],[\"help\",{\"1\":{\"372\":1}}],[\"helpful\",{\"1\":{\"36\":1}}],[\"helm\",{\"1\":{\"102\":1}}],[\"hello\",{\"1\":{\"68\":1,\"69\":1,\"70\":1,\"71\":5,\"72\":2,\"73\":1,\"74\":1,\"169\":2}}],[\"hangzhou\",{\"1\":{\"366\":4,\"372\":1,\"373\":1}}],[\"handy\",{\"1\":{\"228\":1}}],[\"handle\",{\"1\":{\"161\":2,\"162\":2}}],[\"has\",{\"1\":{\"183\":1,\"212\":1,\"263\":1}}],[\"have\",{\"1\":{\"156\":1,\"382\":1}}],[\"hairpinmode\",{\"1\":{\"48\":1}}],[\"hairpin\",{\"0\":{\"46\":1},\"1\":{\"45\":3,\"47\":2,\"48\":3,\"50\":2}}],[\"had\",{\"1\":{\"36\":1}}],[\"hardware\",{\"1\":{\"255\":1,\"304\":4}}],[\"hard=imagefs\",{\"1\":{\"51\":1}}],[\"hard\",{\"1\":{\"20\":1,\"21\":1,\"51\":2}}],[\"hdr\",{\"1\":{\"5\":3}}],[\"wx\",{\"1\":{\"372\":1}}],[\"wsl2迁移至其他目录\",{\"0\":{\"264\":1}}],[\"wsl\",{\"0\":{\"263\":1},\"1\":{\"263\":4,\"264\":4}}],[\"w\",{\"1\":{\"150\":1,\"257\":1,\"258\":1}}],[\"wrong\",{\"1\":{\"149\":2}}],[\"writer\",{\"1\":{\"97\":4}}],[\"www\",{\"1\":{\"78\":1,\"374\":1,\"422\":1}}],[\"wordpress\",{\"1\":{\"101\":1}}],[\"workfifobytes\",{\"1\":{\"149\":1}}],[\"workflow\",{\"1\":{\"97\":3}}],[\"workflows\",{\"1\":{\"95\":1,\"97\":1,\"106\":1}}],[\"workflow控制器\",{\"1\":{\"85\":1}}],[\"worker\",{\"1\":{\"75\":2}}],[\"world\",{\"1\":{\"75\":1,\"150\":3,\"151\":3,\"154\":5,\"169\":2,\"196\":1,\"199\":10,\"202\":1,\"203\":2,\"204\":2}}],[\"world<\",{\"1\":{\"75\":1}}],[\"which\",{\"1\":{\"382\":1}}],[\"whisper1\",{\"1\":{\"365\":1}}],[\"whisper\",{\"1\":{\"365\":1}}],[\"whispermodel\",{\"1\":{\"365\":1}}],[\"white\",{\"1\":{\"75\":2,\"372\":1}}],[\"why\",{\"1\":{\"212\":1}}],[\"whenunsatisfiable\",{\"1\":{\"58\":1}}],[\"w0729\",{\"1\":{\"62\":1}}],[\"wi\",{\"1\":{\"335\":1}}],[\"windows\",{\"1\":{\"171\":2,\"174\":1}}],[\"win32\",{\"1\":{\"170\":1,\"171\":1}}],[\"width\",{\"1\":{\"75\":2}}],[\"width=device\",{\"1\":{\"75\":1}}],[\"withdraw\",{\"1\":{\"311\":1}}],[\"with\",{\"1\":{\"62\":2,\"150\":1,\"154\":1,\"156\":4,\"263\":1}}],[\"withttl\",{\"1\":{\"5\":1}}],[\"will\",{\"1\":{\"62\":1,\"205\":1,\"212\":1}}],[\"weixin\",{\"1\":{\"422\":1}}],[\"weight\",{\"1\":{\"60\":1,\"365\":3}}],[\"wechat\",{\"1\":{\"370\":1,\"372\":3}}],[\"we\",{\"1\":{\"156\":1,\"212\":1}}],[\"webui\",{\"1\":{\"376\":1}}],[\"web\",{\"0\":{\"362\":1},\"1\":{\"97\":4},\"2\":{\"378\":1}}],[\"werr\",{\"1\":{\"5\":2}}],[\"wa\",{\"1\":{\"255\":2}}],[\"warn\",{\"1\":{\"156\":2,\"366\":1}}],[\"warnings\",{\"1\":{\"156\":2}}],[\"warning\",{\"1\":{\"36\":1}}],[\"warmup\",{\"1\":{\"149\":1,\"150\":1}}],[\"was\",{\"1\":{\"62\":1}}],[\"wangshi\",{\"1\":{\"36\":1}}],[\"watch\",{\"1\":{\"5\":2}}],[\"waiting\",{\"1\":{\"366\":1}}],[\"waited\",{\"1\":{\"366\":1}}],[\"waitdelete\",{\"1\":{\"5\":1}}],[\"waitdeletes\",{\"1\":{\"5\":1}}],[\"wait\",{\"1\":{\"5\":2,\"204\":1,\"366\":1}}],[\"4×\",{\"1\":{\"450\":1}}],[\"4毫秒\",{\"1\":{\"415\":1}}],[\"4b的表现则有所不同\",{\"1\":{\"416\":1}}],[\"4b\",{\"1\":{\"412\":1,\"416\":1}}],[\"4b不等规模的所有训练任务\",{\"1\":{\"412\":1}}],[\"4b及以上模型中失败了\",{\"1\":{\"411\":1}}],[\"42\",{\"1\":{\"297\":2,\"416\":1}}],[\"47d2\",{\"1\":{\"283\":1}}],[\"47\",{\"1\":{\"283\":2}}],[\"49\",{\"1\":{\"149\":1}}],[\"46\",{\"1\":{\"149\":2}}],[\"469\",{\"1\":{\"62\":1}}],[\"48\",{\"1\":{\"149\":1}}],[\"48px\",{\"1\":{\"75\":1}}],[\"45\",{\"1\":{\"149\":2}}],[\"404\",{\"1\":{\"462\":1}}],[\"400\",{\"1\":{\"366\":1}}],[\"4000\",{\"1\":{\"365\":1}}],[\"40\",{\"1\":{\"149\":1,\"412\":1,\"426\":1}}],[\"4096\",{\"1\":{\"149\":2}}],[\"4194304\",{\"1\":{\"149\":1}}],[\"41\",{\"1\":{\"149\":1}}],[\"44\",{\"1\":{\"149\":1,\"412\":1}}],[\"4+cuda12\",{\"1\":{\"149\":1}}],[\"4\",{\"0\":{\"15\":1,\"59\":1,\"69\":1,\"260\":1,\"271\":1,\"337\":1,\"348\":1,\"432\":1,\"433\":1,\"434\":1,\"435\":1,\"436\":1,\"437\":1,\"438\":1,\"457\":1,\"459\":1},\"1\":{\"5\":1,\"20\":1,\"145\":2,\"149\":3,\"160\":2,\"175\":1,\"176\":1,\"264\":1,\"366\":1,\"410\":2,\"411\":2,\"412\":1,\"414\":1,\"416\":2,\"431\":1,\"432\":2,\"433\":6,\"443\":3,\"444\":2,\"452\":3,\"455\":7,\"456\":7,\"457\":7,\"458\":1,\"459\":4}}],[\"其值可以通过策略搜索确定\",{\"1\":{\"435\":1}}],[\"其复杂性远高于图7和图8中的所有实验\",{\"1\":{\"414\":1}}],[\"其总内存需求是服务器gpu内存供应量的5倍\",{\"1\":{\"410\":1}}],[\"其总gpu内存需求为108\",{\"1\":{\"410\":1}}],[\"其最大和最小阶段内存需求分别高于和低于每个gpu的内存容量\",{\"1\":{\"410\":1}}],[\"其后端引擎是pytorch\",{\"1\":{\"408\":1}}],[\"其次\",{\"1\":{\"407\":1,\"408\":1,\"415\":1,\"416\":1,\"446\":1}}],[\"其次得到\",{\"1\":{\"5\":1}}],[\"其报文格式如下\",{\"1\":{\"304\":1}}],[\"其主要功能包括\",{\"1\":{\"291\":1}}],[\"其主要特性包括\",{\"1\":{\"290\":1}}],[\"其它可能的操作有\",{\"1\":{\"158\":1}}],[\"其中i表示第i个管道阶段\",{\"1\":{\"433\":1}}],[\"其中原语适用于子图中的每个操作符\",{\"1\":{\"431\":1}}],[\"其中包含来自多种语言的词汇嵌入\",{\"1\":{\"436\":1}}],[\"其中包含处理具有数万维度大小的张量的多个操作符\",{\"1\":{\"425\":1}}],[\"其中包括我们提出的d2d交换\",{\"1\":{\"405\":1}}],[\"其中阶段按dapple的建议映射到设备\",{\"1\":{\"414\":1}}],[\"其中一种仅使用d2d交换\",{\"1\":{\"410\":1}}],[\"其中\",{\"1\":{\"5\":1,\"51\":1,\"431\":1,\"433\":1,\"435\":1,\"437\":1}}],[\"其他层则通过\",{\"1\":{\"456\":1}}],[\"其他算子可以共享\",{\"1\":{\"436\":1}}],[\"其他算子可以通过现有的搜索空间来描述\",{\"1\":{\"435\":1}}],[\"其他四个gpt配置的每阶段最大gpu内存需求为56\",{\"1\":{\"410\":1}}],[\"其他资料为辅助\",{\"1\":{\"229\":1}}],[\"其他配置选项请参考\",{\"1\":{\"204\":1}}],[\"其他后端为\",{\"1\":{\"204\":1}}],[\"其他服务注册在\",{\"1\":{\"107\":1}}],[\"其他\",{\"0\":{\"110\":1},\"1\":{\"5\":1}}],[\"最高加速达到3\",{\"1\":{\"424\":1}}],[\"最快的内存层存储的是计算立即需要的数据\",{\"1\":{\"417\":1}}],[\"最新的gpu只有80gb的hbm\",{\"1\":{\"417\":1}}],[\"最好有以下几方面准备\",{\"1\":{\"359\":2}}],[\"最好先拉取镜像对应\",{\"1\":{\"2\":1}}],[\"最稳定的路径\",{\"1\":{\"310\":1}}],[\"最短的as路径\",{\"1\":{\"310\":1}}],[\"最多1600万个\",{\"1\":{\"287\":1}}],[\"最多4094个vlan\",{\"1\":{\"287\":1}}],[\"最多4094个\",{\"1\":{\"287\":1}}],[\"最便捷地入门\",{\"1\":{\"223\":1}}],[\"最大\",{\"1\":{\"365\":1}}],[\"最大温度\",{\"1\":{\"365\":1}}],[\"最大引用内容\",{\"1\":{\"365\":1}}],[\"最大回复\",{\"1\":{\"365\":1}}],[\"最大上下文\",{\"1\":{\"365\":1}}],[\"最大化了计算资源的利用率\",{\"1\":{\"190\":1}}],[\"最大值\",{\"1\":{\"158\":1}}],[\"最后做数据分析\",{\"1\":{\"359\":2}}],[\"最后\",{\"1\":{\"143\":1,\"159\":1,\"261\":1,\"407\":1,\"410\":2,\"411\":1,\"415\":2,\"416\":1,\"417\":1}}],[\"最后使用结束\",{\"1\":{\"5\":1}}],[\"最终出现发散\",{\"1\":{\"448\":1}}],[\"最终这些内容会被物化为并行执行的可执行代码\",{\"1\":{\"442\":1}}],[\"最终将其减少到唯一的并行化计划\",{\"1\":{\"439\":1}}],[\"最终将网页内容展示给用户\",{\"1\":{\"342\":1}}],[\"最终选择时间成本最小的映射方案\",{\"1\":{\"406\":1}}],[\"最终到达目标服务器\",{\"1\":{\"347\":1}}],[\"最终返回\",{\"1\":{\"154\":1}}],[\"最终根据\",{\"1\":{\"151\":1}}],[\"最终\",{\"1\":{\"74\":1,\"405\":1}}],[\"最小的路由器id\",{\"1\":{\"310\":1}}],[\"最小的多出口判别器\",{\"1\":{\"310\":1}}],[\"最小限制\",{\"1\":{\"28\":1}}],[\"最小值\",{\"1\":{\"25\":1,\"158\":1}}],[\"最小\",{\"1\":{\"5\":1}}],[\"+精度\",{\"1\":{\"365\":1}}],[\"+100\",{\"1\":{\"260\":1}}],[\"+=\",{\"1\":{\"183\":1}}],[\"+\",{\"0\":{\"387\":1,\"388\":1,\"389\":1,\"390\":1},\"1\":{\"5\":1,\"175\":1,\"417\":1,\"440\":1,\"455\":1}}],[\"时的典型障碍\",{\"1\":{\"445\":1}}],[\"时空调度以及插入通信和张量操作后\",{\"1\":{\"445\":1}}],[\"时间顺序搜索\",{\"0\":{\"441\":1}}],[\"时间\",{\"1\":{\"255\":1}}],[\"时间都不会计入进程的\",{\"1\":{\"255\":1}}],[\"时间而非延迟\",{\"1\":{\"150\":1}}],[\"时间序列\",{\"1\":{\"86\":1}}],[\"时需要用到的\",{\"1\":{\"51\":1}}],[\"时通过命令行参数\",{\"1\":{\"48\":1}}],[\"时合理设置资源请求和限制\",{\"1\":{\"24\":1}}],[\"时\",{\"1\":{\"5\":1,\"97\":1,\"166\":1,\"424\":1,\"443\":1}}],[\"当生产者和消费者位于不同设备上时\",{\"1\":{\"444\":1}}],[\"当应用\",{\"1\":{\"443\":1}}],[\"当所有参数都变为具体值时\",{\"1\":{\"432\":1}}],[\"当非依赖操作符\",{\"1\":{\"431\":1}}],[\"当模型规模超过单个设备的内存容量时\",{\"1\":{\"418\":1}}],[\"当模型扩大到1\",{\"1\":{\"411\":1}}],[\"当模型从bert\",{\"1\":{\"411\":1}}],[\"当被适当地应用时\",{\"1\":{\"407\":1}}],[\"当微批次大小缩小到2时\",{\"1\":{\"400\":1}}],[\"当工人3完成第一个微批次的前向传播计算后\",{\"1\":{\"399\":1}}],[\"当你的产品完成了最小\",{\"1\":{\"359\":2}}],[\"当你运行一个管道时\",{\"1\":{\"89\":1}}],[\"当数据从发送端传输到接收端时\",{\"1\":{\"341\":1}}],[\"当网络拓扑发生变化时\",{\"1\":{\"311\":1}}],[\"当设备b接收到这个arp请求时\",{\"1\":{\"303\":1}}],[\"当设备a需要向设备b发送数据时\",{\"1\":{\"303\":1}}],[\"当主机a发送一个以太网帧给主机b时\",{\"1\":{\"292\":1}}],[\"当vtep接收到来自二层网络的以太网帧时\",{\"1\":{\"291\":1}}],[\"当客户端请求html页面时\",{\"1\":{\"272\":1}}],[\"当磁盘返回数据时\",{\"1\":{\"255\":1}}],[\"当这个用户程序代码中调用了系统调用\",{\"1\":{\"255\":1}}],[\"当可能时\",{\"1\":{\"204\":1}}],[\"当前进程的特定设备\",{\"1\":{\"204\":1}}],[\"当前进程的编号\",{\"1\":{\"204\":1}}],[\"当前运行的管道列表\",{\"1\":{\"88\":1}}],[\"当节点的父节点包含条件语句时\",{\"1\":{\"94\":1}}],[\"当然\",{\"1\":{\"61\":1}}],[\"当我们对一个容器执行\",{\"1\":{\"61\":1}}],[\"当\",{\"1\":{\"5\":1,\"51\":1,\"173\":1,\"204\":1,\"454\":1}}],[\"3f1b\",{\"1\":{\"437\":2,\"452\":2,\"457\":1,\"459\":1}}],[\"3d\",{\"1\":{\"425\":3}}],[\"3d6d\",{\"1\":{\"149\":1}}],[\"3模型依然会遇到oom\",{\"1\":{\"417\":1}}],[\"3b\",{\"1\":{\"416\":1}}],[\"3b到20\",{\"1\":{\"412\":1}}],[\"3b参数的模型\",{\"1\":{\"412\":1}}],[\"3b参数规模的模型\",{\"1\":{\"412\":1}}],[\"3b是最小的模型\",{\"1\":{\"410\":1}}],[\"35b扩大到bert\",{\"1\":{\"411\":1}}],[\"35b的最小bert模型\",{\"1\":{\"411\":1}}],[\"35b表示最小的bert模型\",{\"1\":{\"410\":1}}],[\"3306\",{\"1\":{\"366\":2}}],[\"3307\",{\"1\":{\"366\":1}}],[\"33\",{\"1\":{\"297\":2,\"298\":1}}],[\"3=最大>\",{\"1\":{\"150\":1}}],[\"3>\",{\"1\":{\"150\":1}}],[\"37\",{\"1\":{\"149\":1}}],[\"3600\",{\"1\":{\"372\":1}}],[\"3600s\",{\"1\":{\"75\":1}}],[\"36\",{\"1\":{\"366\":1}}],[\"3615\",{\"1\":{\"149\":1}}],[\"32gb\",{\"1\":{\"454\":1}}],[\"3210\",{\"1\":{\"381\":2}}],[\"32m\",{\"1\":{\"150\":2}}],[\"32768\",{\"1\":{\"149\":2}}],[\"32\",{\"1\":{\"149\":39,\"454\":1,\"455\":1,\"456\":5,\"457\":4,\"458\":3}}],[\"30s\",{\"1\":{\"366\":3}}],[\"300m\",{\"1\":{\"374\":2,\"376\":1}}],[\"3001\",{\"1\":{\"366\":1,\"369\":1}}],[\"3000\",{\"1\":{\"365\":3,\"366\":5,\"368\":1,\"372\":1}}],[\"300s\",{\"1\":{\"36\":2}}],[\"30\",{\"1\":{\"149\":2,\"204\":1,\"446\":1}}],[\"30mi\",{\"1\":{\"98\":1}}],[\"30m\",{\"1\":{\"75\":1}}],[\"3437386\",{\"1\":{\"62\":14}}],[\"31\",{\"1\":{\"62\":16,\"149\":2,\"381\":7}}],[\"3m57s\",{\"1\":{\"36\":1}}],[\"3\",{\"0\":{\"14\":1,\"57\":1,\"68\":1,\"259\":1,\"270\":1,\"336\":1,\"347\":1,\"428\":1,\"437\":1,\"438\":1,\"449\":1,\"453\":1,\"454\":1,\"455\":1,\"456\":2,\"457\":1,\"458\":1},\"1\":{\"5\":1,\"36\":1,\"43\":1,\"75\":1,\"149\":3,\"171\":1,\"175\":1,\"176\":1,\"264\":1,\"365\":6,\"366\":6,\"372\":1,\"414\":1,\"416\":1,\"433\":5,\"437\":1,\"442\":2,\"446\":1,\"450\":2,\"451\":1,\"455\":1,\"456\":4,\"457\":1,\"458\":1}}],[\"386\",{\"1\":{\"1\":1}}],[\"2上a100\",{\"1\":{\"412\":1}}],[\"2b\",{\"1\":{\"416\":1}}],[\"2b的bert模型\",{\"1\":{\"411\":1}}],[\"2b是一个超大模型\",{\"1\":{\"410\":1}}],[\"2服务器上\",{\"1\":{\"414\":1}}],[\"2服务器的ssd存储带宽显著低于dgx\",{\"1\":{\"412\":1}}],[\"2服务器有164个虚拟cpu\",{\"1\":{\"410\":1}}],[\"2服务器\",{\"1\":{\"410\":1}}],[\"2>\",{\"1\":{\"366\":1}}],[\"2表示arp响应\",{\"1\":{\"304\":1}}],[\"2=最小\",{\"1\":{\"150\":1}}],[\"28\",{\"1\":{\"149\":3,\"283\":2}}],[\"27017\",{\"1\":{\"366\":4}}],[\"27962\",{\"1\":{\"149\":1}}],[\"27\",{\"1\":{\"149\":3}}],[\"243\",{\"1\":{\"445\":1}}],[\"24xlarge实例\",{\"1\":{\"410\":1}}],[\"24xlarge\",{\"1\":{\"400\":1}}],[\"244\",{\"1\":{\"294\":4}}],[\"24位vni\",{\"1\":{\"287\":1}}],[\"24\",{\"1\":{\"149\":3,\"283\":1,\"328\":2,\"431\":1,\"433\":1,\"445\":1}}],[\"22\",{\"1\":{\"149\":4,\"331\":2}}],[\"21gb\",{\"1\":{\"455\":1}}],[\"218\",{\"1\":{\"149\":1}}],[\"21\",{\"1\":{\"149\":2}}],[\"262144\",{\"1\":{\"149\":2}}],[\"26\",{\"1\":{\"149\":6}}],[\"2379\",{\"1\":{\"366\":3}}],[\"23ff\",{\"1\":{\"149\":1}}],[\"235<0>\",{\"1\":{\"149\":2}}],[\"23\",{\"1\":{\"145\":2,\"149\":6,\"412\":1,\"416\":1}}],[\"2gb\",{\"1\":{\"66\":1}}],[\"2016年\",{\"1\":{\"402\":1}}],[\"2012\",{\"1\":{\"383\":1}}],[\"20s\",{\"1\":{\"366\":3}}],[\"20t20\",{\"1\":{\"366\":1}}],[\"2097152\",{\"1\":{\"149\":2}}],[\"20\",{\"1\":{\"149\":5,\"150\":1,\"264\":3,\"416\":2}}],[\"20mi\",{\"1\":{\"98\":1}}],[\"2023\",{\"1\":{\"366\":1}}],[\"20231101\",{\"1\":{\"98\":1}}],[\"20230525183624\",{\"1\":{\"1\":1}}],[\"2022\",{\"1\":{\"96\":1}}],[\"2048\",{\"1\":{\"149\":2}}],[\"204\",{\"1\":{\"75\":1}}],[\"203\",{\"1\":{\"62\":1}}],[\"29\",{\"1\":{\"62\":9,\"149\":5,\"454\":1}}],[\"255\",{\"1\":{\"319\":3}}],[\"256\",{\"1\":{\"149\":2,\"175\":1,\"176\":1}}],[\"256mi\",{\"1\":{\"25\":1,\"36\":1}}],[\"25\",{\"1\":{\"149\":5}}],[\"250m\",{\"1\":{\"25\":1}}],[\"2\",{\"0\":{\"13\":1,\"55\":1,\"67\":1,\"258\":1,\"269\":1,\"335\":1,\"346\":1,\"425\":1,\"426\":1,\"427\":2,\"434\":1,\"435\":1,\"436\":2,\"437\":1,\"441\":1,\"448\":1,\"452\":1,\"455\":1},\"1\":{\"5\":1,\"51\":1,\"62\":1,\"75\":1,\"96\":1,\"145\":4,\"149\":8,\"150\":1,\"175\":1,\"176\":1,\"204\":1,\"264\":2,\"267\":2,\"268\":1,\"269\":1,\"270\":1,\"271\":1,\"272\":1,\"273\":2,\"274\":2,\"275\":2,\"276\":2,\"277\":2,\"283\":1,\"294\":6,\"328\":2,\"365\":3,\"366\":1,\"372\":1,\"396\":1,\"406\":1,\"408\":1,\"410\":3,\"412\":4,\"416\":4,\"417\":1,\"432\":1,\"433\":6,\"437\":2,\"445\":1,\"450\":2,\"452\":4,\"454\":2,\"455\":5,\"456\":5,\"457\":3,\"459\":2}}],[\"的排序约束逐个应用时的搜索时间\",{\"1\":{\"459\":1}}],[\"的排序搜索时间约为\",{\"1\":{\"459\":1}}],[\"的搜索时间小于\",{\"1\":{\"459\":1}}],[\"的搜索时间细分\",{\"1\":{\"459\":1}}],[\"的搜索算法\",{\"1\":{\"454\":1}}],[\"的相对性能增益在\",{\"1\":{\"458\":1}}],[\"的相关操作函数注册到\",{\"1\":{\"166\":1}}],[\"的端到端训练吞吐量\",{\"1\":{\"456\":1,\"457\":1}}],[\"的前四层\",{\"1\":{\"455\":1}}],[\"的结果\",{\"0\":{\"455\":1,\"456\":1,\"457\":1}}],[\"的结合\",{\"0\":{\"41\":1}}],[\"的四种不同模型配置下进行实验\",{\"1\":{\"454\":1}}],[\"的情况下达到稳定状态\",{\"1\":{\"452\":1}}],[\"的峰值激活大小减少了一半\",{\"1\":{\"452\":1}}],[\"的重计算后\",{\"1\":{\"452\":1}}],[\"的三个新并行化计划进行的端到端评估\",{\"1\":{\"450\":1}}],[\"的评估涵盖了并行化原语的表达能力以及带有约束的并行化计划搜索效率\",{\"1\":{\"450\":1}}],[\"的决定主要基于两个关键因素\",{\"1\":{\"446\":1}}],[\"的值跟踪来处理控制流\",{\"1\":{\"445\":1}}],[\"的符号执行和\",{\"1\":{\"445\":1}}],[\"的适当集体通信原语\",{\"1\":{\"444\":1}}],[\"的掩码交集来检测它们之间是否存在数据依赖关系\",{\"1\":{\"443\":1}}],[\"的掩码保持不变\",{\"1\":{\"443\":1}}],[\"的输入\",{\"1\":{\"443\":1}}],[\"的输出作为算子\",{\"1\":{\"443\":1}}],[\"的顶部\",{\"1\":{\"443\":1}}],[\"的设备\",{\"1\":{\"436\":1}}],[\"的设备内存\",{\"1\":{\"417\":1}}],[\"的第一个和最后一个层中使用\",{\"1\":{\"436\":1}}],[\"的约束条件\",{\"1\":{\"437\":1}}],[\"的约束\",{\"0\":{\"435\":1,\"436\":1,\"437\":1}}],[\"的微批次id上执行\",{\"1\":{\"437\":1}}],[\"的微妙调度顺序\",{\"1\":{\"433\":1}}],[\"的微基准测试结果\",{\"1\":{\"249\":1}}],[\"的维度\",{\"1\":{\"429\":1}}],[\"的维护者自行决定\",{\"1\":{\"61\":1}}],[\"的模型尺寸比\",{\"1\":{\"457\":1}}],[\"的模型设计\",{\"1\":{\"454\":1}}],[\"的模型\",{\"1\":{\"425\":1}}],[\"的训练性能有显著影响\",{\"1\":{\"423\":1}}],[\"的训练时间延长\",{\"1\":{\"417\":1}}],[\"的训练操作\",{\"1\":{\"106\":1}}],[\"的资源\",{\"1\":{\"417\":1}}],[\"的资源使用量超过了其\",{\"1\":{\"51\":1}}],[\"的资源使用\",{\"1\":{\"24\":1}}],[\"的速度\",{\"1\":{\"416\":1}}],[\"的内存压力\",{\"1\":{\"454\":1}}],[\"的内存节省\",{\"1\":{\"416\":1}}],[\"的内存\",{\"1\":{\"416\":1}}],[\"的内置资源\",{\"1\":{\"117\":1}}],[\"的gpu内存占用\",{\"1\":{\"416\":1}}],[\"的gpu内存\",{\"1\":{\"416\":1}}],[\"的开销比较\",{\"1\":{\"413\":1}}],[\"的开发过程\",{\"1\":{\"122\":1}}],[\"的性能下降较小\",{\"1\":{\"458\":1}}],[\"的性能下降了\",{\"1\":{\"458\":1}}],[\"的性能分别下降了\",{\"1\":{\"458\":1}}],[\"的性能\",{\"1\":{\"411\":1}}],[\"的bert数据应用gpu\",{\"1\":{\"401\":1}}],[\"的话\",{\"1\":{\"365\":1}}],[\"的时候\",{\"1\":{\"359\":2}}],[\"的时间共享模式\",{\"1\":{\"452\":1}}],[\"的时间\",{\"1\":{\"255\":1}}],[\"的区别\",{\"0\":{\"353\":1}}],[\"的扩展版\",{\"1\":{\"352\":1}}],[\"的网络协议\",{\"1\":{\"302\":1}}],[\"的网络接口实现内循环\",{\"1\":{\"46\":1}}],[\"的邻居节点信息\",{\"1\":{\"295\":1}}],[\"的邻居表项\",{\"1\":{\"294\":1}}],[\"的一些关键区别和改进\",{\"1\":{\"267\":1}}],[\"的一个要求\",{\"1\":{\"451\":1}}],[\"的一个子集\",{\"1\":{\"196\":1}}],[\"的一个重要配置选项\",{\"1\":{\"50\":1}}],[\"的物理卷中\",{\"1\":{\"259\":1}}],[\"的空间中没有约束条件\",{\"1\":{\"459\":1}}],[\"的空间已经成功分配给\",{\"1\":{\"262\":1}}],[\"的空间后\",{\"1\":{\"258\":1}}],[\"的空间扩展到\",{\"1\":{\"256\":1}}],[\"的用户态\",{\"1\":{\"255\":1}}],[\"的用户会发现\",{\"1\":{\"143\":1}}],[\"的缩写\",{\"1\":{\"255\":8}}],[\"的进程\",{\"1\":{\"253\":1}}],[\"的主要特性和工作原理\",{\"0\":{\"310\":1}}],[\"的主要贡献\",{\"1\":{\"249\":1}}],[\"的主要功能\",{\"0\":{\"197\":1}}],[\"的提出背景\",{\"1\":{\"249\":1}}],[\"的动态稀疏注意力方法\",{\"1\":{\"248\":1}}],[\"的预填充阶段多达\",{\"1\":{\"249\":1}}],[\"的预填充\",{\"1\":{\"245\":1}}],[\"的多种调用方式\",{\"1\":{\"223\":1}}],[\"的全量微调\",{\"1\":{\"220\":1}}],[\"的全局解释器锁\",{\"1\":{\"162\":1}}],[\"的部署应用指导\",{\"1\":{\"220\":1}}],[\"的部署使用教程\",{\"1\":{\"220\":1}}],[\"的部署和管理\",{\"1\":{\"30\":1}}],[\"的异步执行\",{\"1\":{\"204\":1}}],[\"的翻译\",{\"1\":{\"202\":1}}],[\"的标准化设计和广泛支持使其成为高性能计算\",{\"1\":{\"200\":1}}],[\"的核心概念\",{\"0\":{\"196\":1}}],[\"的核心组件之一\",{\"1\":{\"97\":1}}],[\"的框架\",{\"0\":{\"194\":1}}],[\"的应用中\",{\"1\":{\"192\":1}}],[\"的应用场景\",{\"0\":{\"119\":1}}],[\"的计算\",{\"1\":{\"192\":1}}],[\"的比较\",{\"0\":{\"191\":1}}],[\"的梯度进行合并并同步模型参数\",{\"1\":{\"188\":1}}],[\"的数据\",{\"1\":{\"188\":1}}],[\"的数据库\",{\"1\":{\"97\":1}}],[\"的底层实现\",{\"1\":{\"180\":1}}],[\"的唯一标识符\",{\"1\":{\"165\":1}}],[\"的版本信息\",{\"1\":{\"165\":1}}],[\"的功能\",{\"1\":{\"164\":1}}],[\"的功能简介\",{\"1\":{\"97\":1}}],[\"的函数\",{\"1\":{\"162\":1,\"168\":1}}],[\"的兼容性\",{\"1\":{\"159\":1}}],[\"的类型是否正确\",{\"1\":{\"159\":1}}],[\"的归约结果\",{\"1\":{\"158\":1}}],[\"的张量根据某种操作\",{\"1\":{\"156\":1}}],[\"的所有全局\",{\"1\":{\"154\":1}}],[\"的操作来进行高效的多gpu并行计算\",{\"1\":{\"166\":1}}],[\"的操作\",{\"1\":{\"150\":1}}],[\"的操作自动化\",{\"1\":{\"116\":1}}],[\"的集体操作带有一个\",{\"1\":{\"143\":1}}],[\"的集体操作通常通过\",{\"1\":{\"143\":1}}],[\"的管理能力\",{\"1\":{\"123\":1}}],[\"的管理能力扩展到了自定义应用领域\",{\"1\":{\"120\":1}}],[\"的工作重点是提升\",{\"1\":{\"354\":1}}],[\"的工作重点是通过网络快速访问远程服务器内存\",{\"1\":{\"354\":1}}],[\"的工作过程\",{\"0\":{\"311\":1}}],[\"的工作流程\",{\"0\":{\"292\":1}}],[\"的工作原理\",{\"0\":{\"46\":1,\"118\":1},\"1\":{\"249\":1}}],[\"的工具\",{\"0\":{\"122\":1}}],[\"的示例\",{\"0\":{\"121\":1}}],[\"的能力\",{\"1\":{\"120\":1}}],[\"的优势和挑战\",{\"0\":{\"312\":1}}],[\"的优势\",{\"0\":{\"120\":1}}],[\"的基本概念\",{\"0\":{\"117\":1}}],[\"的自动化机器学习\",{\"1\":{\"105\":1}}],[\"的根对象\",{\"1\":{\"101\":1}}],[\"的元数据\",{\"1\":{\"100\":1}}],[\"的各个组件通过数据库和控制器进行通信和协调\",{\"1\":{\"97\":1}}],[\"的可视化服务\",{\"1\":{\"97\":1}}],[\"的展示\",{\"1\":{\"97\":1}}],[\"的持久化存储\",{\"1\":{\"97\":1}}],[\"的控制器组件之一\",{\"1\":{\"97\":1}}],[\"的控制器组件\",{\"1\":{\"97\":1}}],[\"的默认执行器\",{\"1\":{\"96\":1}}],[\"的默认阈值如下所示\",{\"1\":{\"51\":1}}],[\"的任务\",{\"1\":{\"91\":1}}],[\"的定义\",{\"1\":{\"89\":1}}],[\"的定义示例\",{\"0\":{\"40\":1}}],[\"的方式返回给\",{\"1\":{\"61\":1}}],[\"的地址和端口\",{\"1\":{\"61\":1}}],[\"的实现\",{\"1\":{\"61\":1}}],[\"的限制\",{\"1\":{\"51\":1}}],[\"的过程\",{\"1\":{\"51\":1}}],[\"的启动参数中设置\",{\"1\":{\"48\":1}}],[\"的作用\",{\"1\":{\"444\":1}}],[\"的作用是在容器网络接口上设置发夹规则\",{\"1\":{\"45\":1}}],[\"的作用方式\",{\"1\":{\"36\":1}}],[\"的场景\",{\"1\":{\"44\":1}}],[\"的服务\",{\"1\":{\"40\":1,\"68\":1}}],[\"的详细介绍\",{\"1\":{\"37\":1}}],[\"的每个\",{\"1\":{\"37\":1}}],[\"的调度器尽可能地将\",{\"0\":{\"52\":1}}],[\"的调度\",{\"1\":{\"36\":1}}],[\"的具体值\",{\"1\":{\"36\":1}}],[\"的名称\",{\"1\":{\"36\":1}}],[\"的日志\",{\"1\":{\"34\":1}}],[\"的故障而丢失\",{\"1\":{\"31\":1}}],[\"的配置是静态文件\",{\"1\":{\"31\":1}}],[\"的参与\",{\"1\":{\"31\":1}}],[\"的特点\",{\"0\":{\"31\":1,\"38\":1}}],[\"的整体限制不同\",{\"1\":{\"23\":1}}],[\"的总数量\",{\"1\":{\"20\":2}}],[\"的状态\",{\"1\":{\"34\":1}}],[\"的状态转换通常遵循以下过程\",{\"1\":{\"16\":1}}],[\"的状态由其\",{\"1\":{\"11\":1}}],[\"的几种可能的状态\",{\"1\":{\"11\":1}}],[\"的\",{\"1\":{\"5\":3,\"20\":1,\"25\":1,\"40\":3,\"41\":1,\"45\":2,\"51\":2,\"54\":1,\"61\":3,\"79\":1,\"97\":3,\"102\":1,\"143\":1,\"156\":1,\"160\":1,\"161\":2,\"164\":1,\"165\":1,\"166\":2,\"180\":1,\"255\":1,\"365\":1,\"429\":1,\"443\":2,\"444\":2,\"445\":1,\"454\":2}}],[\"为操作间并行训练和gpu内存优化提供了新的方向\",{\"1\":{\"419\":1}}],[\"为四个操作间并行训练任务\",{\"1\":{\"416\":1}}],[\"为此\",{\"1\":{\"406\":1}}],[\"为终端设备提供网络接入\",{\"1\":{\"346\":1}}],[\"为了验证新并行化计划的有效性\",{\"1\":{\"458\":1}}],[\"为了扩展到所有可用的\",{\"1\":{\"455\":1}}],[\"为了进行直接比较\",{\"1\":{\"454\":1}}],[\"为了支持各种\",{\"1\":{\"445\":1}}],[\"为了设计有效的约束\",{\"1\":{\"438\":1}}],[\"为了提升视觉任务的能力\",{\"1\":{\"435\":1}}],[\"为了提高训练性能\",{\"1\":{\"449\":1}}],[\"为了提高通信效率\",{\"1\":{\"444\":1}}],[\"为了提高流水线效率\",{\"1\":{\"425\":1}}],[\"为了提高效率\",{\"1\":{\"305\":1}}],[\"为了最小化\",{\"1\":{\"433\":1}}],[\"为了简化编程工作\",{\"1\":{\"431\":1}}],[\"为了解决上述挑战\",{\"1\":{\"427\":1}}],[\"为了解决这个问题\",{\"1\":{\"423\":1,\"431\":1,\"447\":1,\"448\":1}}],[\"为了解决这一问题\",{\"1\":{\"407\":1}}],[\"为了训练具有高保真图像的视觉模型\",{\"1\":{\"426\":1}}],[\"为了填补这一空白\",{\"1\":{\"424\":1}}],[\"为了满足这一需求\",{\"1\":{\"424\":1}}],[\"为了避免这个问题\",{\"1\":{\"449\":1}}],[\"为了避免搜索空间爆炸\",{\"1\":{\"423\":1}}],[\"为了避免频繁分配和释放固定内存的高成本\",{\"1\":{\"408\":1}}],[\"为了应对gpu内存的限制\",{\"1\":{\"418\":1}}],[\"为了完全隐藏gpu\",{\"1\":{\"417\":1}}],[\"为了理解mpress在这种新架构下的优势\",{\"1\":{\"417\":1}}],[\"为了更好地理解mpress相较于基线系统的优势\",{\"1\":{\"413\":1}}],[\"为了展示其在操作间并行训练中优化gpu内存使用的通用性\",{\"1\":{\"408\":1}}],[\"为了发挥其全部潜力\",{\"1\":{\"407\":1}}],[\"为了反映这种差异\",{\"1\":{\"406\":1}}],[\"为了克服gpu总体交换空间有限的局限\",{\"1\":{\"404\":1}}],[\"为了探索操作间并行训练中gpu内存的利用情况\",{\"1\":{\"400\":1}}],[\"为了便于理解模型并行和流水线并行的区别\",{\"1\":{\"398\":1}}],[\"为了确保数据的一致性\",{\"1\":{\"185\":1}}],[\"为大型语言模型研究领域贡献一份宝贵的资源\",{\"1\":{\"231\":1}}],[\"为读者提供较为全面而深入的理论知识和实践方法\",{\"1\":{\"231\":1}}],[\"为导向\",{\"1\":{\"224\":1}}],[\"为并行计算中的数据管理提供了高效的解决方案\",{\"1\":{\"196\":1}}],[\"为什么要做独立开发者\",{\"1\":{\"359\":4}}],[\"为什么选择\",{\"0\":{\"106\":1}}],[\"为什么使用etcd分布式锁比redis分布式锁更好\",{\"1\":{\"5\":1}}],[\"为支持应用程序提供信息\",{\"1\":{\"101\":1}}],[\"为你维护的\",{\"1\":{\"61\":1}}],[\"为你设置的\",{\"1\":{\"51\":1}}],[\"为\",{\"1\":{\"5\":3,\"54\":1,\"71\":1,\"203\":1,\"253\":1,\"435\":1,\"437\":1}}],[\"1f1b\",{\"1\":{\"433\":2,\"437\":1,\"452\":1}}],[\"1上支持的规模更大\",{\"1\":{\"412\":1}}],[\"1上的v100\",{\"1\":{\"412\":1}}],[\"1服务器\",{\"1\":{\"414\":1}}],[\"1服务器翻了一倍多\",{\"1\":{\"412\":1}}],[\"1服务器是aws\",{\"1\":{\"410\":1}}],[\"1倍\",{\"1\":{\"411\":1}}],[\"1数据集训练bert\",{\"1\":{\"410\":1}}],[\"1升级到1\",{\"1\":{\"408\":1}}],[\"1架构\",{\"1\":{\"406\":1}}],[\"1和dgx\",{\"1\":{\"396\":1,\"410\":1,\"412\":1}}],[\"1k\",{\"1\":{\"365\":2}}],[\"1表示arp请求\",{\"1\":{\"304\":1}}],[\"1命令用于查看指定设备\",{\"1\":{\"295\":1}}],[\"1命令用于显示指定网络设备\",{\"1\":{\"294\":1}}],[\"1可能得到以下输出\",{\"1\":{\"294\":1}}],[\"1通常是用于overlay网络的设备接口\",{\"1\":{\"294\":1}}],[\"1q\",{\"1\":{\"287\":1}}],[\"1q标准\",{\"1\":{\"285\":1}}],[\"1>\",{\"1\":{\"150\":3}}],[\"1=平均\",{\"1\":{\"150\":1}}],[\"140\",{\"1\":{\"410\":1}}],[\"14\",{\"1\":{\"149\":9,\"451\":1,\"454\":1}}],[\"14px\",{\"1\":{\"75\":1}}],[\"1<0>\",{\"1\":{\"149\":1}}],[\"19530\",{\"1\":{\"366\":1}}],[\"192\",{\"1\":{\"283\":1,\"319\":1,\"328\":3,\"366\":2}}],[\"19\",{\"1\":{\"149\":4,\"255\":1}}],[\"190\",{\"1\":{\"149\":2}}],[\"12345678\",{\"1\":{\"369\":1}}],[\"1234\",{\"1\":{\"368\":1}}],[\"127\",{\"1\":{\"366\":1}}],[\"120000\",{\"1\":{\"365\":2}}],[\"12050\",{\"1\":{\"149\":1}}],[\"12位vlan\",{\"1\":{\"287\":1}}],[\"125000\",{\"1\":{\"365\":2}}],[\"125\",{\"1\":{\"149\":1}}],[\"128\",{\"1\":{\"149\":2,\"366\":1}}],[\"128mi\",{\"1\":{\"25\":1,\"36\":1}}],[\"12\",{\"1\":{\"149\":6,\"459\":1}}],[\"16000\",{\"1\":{\"365\":1}}],[\"168\",{\"1\":{\"283\":1,\"319\":1,\"328\":3,\"366\":2}}],[\"16384\",{\"1\":{\"149\":2}}],[\"16\",{\"1\":{\"149\":6,\"366\":2,\"454\":1,\"455\":1,\"456\":5,\"457\":6,\"458\":2}}],[\"1660\",{\"1\":{\"149\":1}}],[\"16gi\",{\"1\":{\"20\":1}}],[\"1gb\",{\"1\":{\"410\":1}}],[\"1gb+\",{\"1\":{\"131\":1}}],[\"1gi\",{\"1\":{\"25\":1}}],[\"13530\",{\"1\":{\"149\":1}}],[\"131072\",{\"1\":{\"149\":3}}],[\"13\",{\"1\":{\"111\":1,\"149\":9}}],[\"130\",{\"1\":{\"62\":1}}],[\"17\",{\"1\":{\"149\":3,\"383\":1,\"451\":1}}],[\"172\",{\"1\":{\"149\":3}}],[\"1728000\",{\"1\":{\"75\":1}}],[\"17h\",{\"1\":{\"97\":14}}],[\"1m\",{\"1\":{\"75\":1,\"150\":1,\"211\":4}}],[\"150\",{\"1\":{\"459\":2}}],[\"1500\",{\"1\":{\"282\":2,\"283\":2}}],[\"157\",{\"1\":{\"62\":1}}],[\"15\",{\"1\":{\"62\":16,\"149\":18,\"365\":2}}],[\"182\",{\"1\":{\"381\":7}}],[\"18z\",{\"1\":{\"366\":1}}],[\"1872\",{\"1\":{\"149\":1}}],[\"18\",{\"1\":{\"57\":1,\"149\":2,\"366\":1,\"410\":1}}],[\"1\",{\"0\":{\"12\":1,\"53\":1,\"66\":1,\"257\":1,\"268\":1,\"334\":1,\"345\":1,\"424\":1,\"426\":1,\"433\":1,\"435\":1,\"440\":1,\"446\":1,\"447\":2,\"448\":1,\"449\":1,\"451\":1,\"454\":1},\"1\":{\"5\":2,\"25\":1,\"36\":5,\"57\":1,\"58\":1,\"60\":1,\"62\":2,\"75\":4,\"96\":1,\"97\":27,\"98\":3,\"149\":169,\"150\":7,\"160\":1,\"161\":1,\"175\":1,\"176\":1,\"183\":2,\"199\":6,\"202\":2,\"204\":2,\"211\":2,\"255\":1,\"257\":1,\"263\":1,\"264\":1,\"267\":2,\"268\":1,\"269\":4,\"270\":1,\"271\":1,\"272\":1,\"273\":1,\"274\":1,\"275\":1,\"276\":1,\"277\":1,\"283\":3,\"294\":5,\"295\":1,\"297\":2,\"319\":1,\"328\":2,\"365\":4,\"366\":3,\"406\":1,\"410\":1,\"412\":2,\"416\":2,\"428\":1,\"432\":2,\"433\":6,\"437\":1,\"445\":1,\"450\":2,\"451\":1,\"454\":1,\"455\":3,\"456\":3,\"457\":3,\"458\":6,\"459\":4}}],[\"10b\",{\"1\":{\"458\":1}}],[\"10a\",{\"1\":{\"458\":1}}],[\"10410479\",{\"1\":{\"393\":1}}],[\"1048576\",{\"1\":{\"149\":3}}],[\"109\",{\"1\":{\"149\":1}}],[\"101\",{\"1\":{\"97\":1}}],[\"1024\",{\"1\":{\"75\":1,\"149\":2,\"365\":2}}],[\"10px\",{\"1\":{\"75\":1}}],[\"1008\",{\"1\":{\"149\":1}}],[\"1000\",{\"1\":{\"149\":3,\"282\":2,\"283\":4,\"372\":1}}],[\"100\",{\"1\":{\"75\":1,\"199\":1,\"319\":1,\"365\":4,\"425\":1,\"454\":1,\"459\":1}}],[\"100vh\",{\"1\":{\"75\":1}}],[\"100m\",{\"1\":{\"25\":1,\"36\":1,\"98\":2}}],[\"10\",{\"1\":{\"5\":2,\"20\":2,\"36\":1,\"149\":3,\"204\":1,\"249\":1,\"282\":1,\"294\":4,\"366\":2,\"383\":1,\"416\":1}}],[\"116\",{\"1\":{\"381\":7}}],[\"110\",{\"1\":{\"149\":1}}],[\"11\",{\"1\":{\"1\":1,\"149\":7,\"226\":1,\"282\":1,\"297\":2,\"335\":1,\"410\":1,\"450\":1,\"454\":1,\"459\":2}}],[\"fpgi\",{\"1\":{\"437\":1}}],[\"fgn\",{\"1\":{\"433\":1}}],[\"fgm\",{\"1\":{\"433\":1}}],[\"fgi\",{\"1\":{\"433\":4}}],[\"ftp\",{\"1\":{\"340\":1}}],[\"fdb记录了mac地址与网络接口的映射关系\",{\"1\":{\"296\":1}}],[\"fdb\",{\"0\":{\"296\":1},\"1\":{\"296\":2,\"297\":1,\"299\":3,\"300\":3,\"301\":1}}],[\"fdisk\",{\"1\":{\"257\":4,\"258\":4}}],[\"f4\",{\"1\":{\"294\":4}}],[\"func\",{\"1\":{\"170\":1,\"171\":2,\"173\":1}}],[\"functioncall\",{\"1\":{\"365\":3}}],[\"function\",{\"1\":{\"150\":1}}],[\"fully\",{\"1\":{\"167\":2,\"168\":4,\"169\":2}}],[\"futurewarning\",{\"1\":{\"156\":2}}],[\"feconfigs\",{\"1\":{\"365\":1}}],[\"feb6\",{\"1\":{\"283\":1}}],[\"feb47b\",{\"1\":{\"75\":1}}],[\"fe0a\",{\"1\":{\"149\":1}}],[\"fea5\",{\"1\":{\"149\":1}}],[\"fe80\",{\"1\":{\"149\":2,\"283\":1}}],[\"f\",{\"1\":{\"149\":2,\"150\":3,\"154\":2,\"183\":1,\"242\":1,\"366\":2,\"381\":1}}],[\"fsdp\",{\"1\":{\"139\":1}}],[\"fsgks\",{\"1\":{\"97\":2}}],[\"figure\",{\"1\":{\"442\":1}}],[\"fi\",{\"1\":{\"335\":1}}],[\"finalize\",{\"1\":{\"199\":1}}],[\"find\",{\"1\":{\"149\":3,\"150\":1}}],[\"first\",{\"1\":{\"175\":2}}],[\"fields\",{\"1\":{\"205\":1}}],[\"fieldpath\",{\"1\":{\"98\":1}}],[\"fieldref\",{\"1\":{\"98\":1}}],[\"file\",{\"1\":{\"366\":1,\"381\":1}}],[\"files\",{\"1\":{\"263\":1,\"383\":2,\"422\":1}}],[\"filename\",{\"1\":{\"62\":1}}],[\"file=scheduler\",{\"1\":{\"60\":1}}],[\"free\",{\"1\":{\"260\":1}}],[\"framework\",{\"2\":{\"213\":1}}],[\"frame\",{\"1\":{\"75\":1}}],[\"from\",{\"1\":{\"36\":1,\"62\":1,\"98\":1,\"167\":2,\"168\":2,\"169\":1,\"175\":1,\"199\":1}}],[\"ff\",{\"1\":{\"283\":12,\"435\":3}}],[\"ffmpeg\",{\"0\":{\"241\":1},\"1\":{\"242\":1}}],[\"ffffff\",{\"1\":{\"75\":1}}],[\"ff7e5f\",{\"1\":{\"75\":1}}],[\"found\",{\"1\":{\"462\":1}}],[\"foundation\",{\"1\":{\"232\":1}}],[\"footer>\",{\"1\":{\"75\":1}}],[\"footer\",{\"1\":{\"75\":1}}],[\"font\",{\"1\":{\"75\":3}}],[\"forwarding\",{\"1\":{\"296\":1}}],[\"forwarded\",{\"1\":{\"75\":4}}],[\"forever\",{\"1\":{\"283\":4}}],[\"for\",{\"1\":{\"5\":5,\"36\":3,\"75\":2,\"139\":1,\"156\":1,\"160\":1,\"205\":1,\"366\":2,\"382\":2,\"433\":3}}],[\"flops\",{\"1\":{\"410\":1,\"446\":1}}],[\"float\",{\"1\":{\"149\":21,\"150\":1}}],[\"flannel\",{\"1\":{\"294\":5,\"295\":1}}],[\"flashattention\",{\"1\":{\"249\":1}}],[\"flag\",{\"1\":{\"62\":1}}],[\"flex\",{\"1\":{\"75\":1}}],[\"fatgpt\",{\"1\":{\"372\":1}}],[\"fatal\",{\"1\":{\"5\":4}}],[\"fable\",{\"1\":{\"365\":3}}],[\"favor\",{\"1\":{\"156\":1}}],[\"factor\",{\"1\":{\"149\":1}}],[\"fastgpt\",{\"0\":{\"368\":1},\"1\":{\"362\":1,\"363\":1,\"366\":21,\"372\":5},\"2\":{\"378\":1}}],[\"fastgpt+chatgpt\",{\"0\":{\"362\":1}}],[\"fastapi\",{\"1\":{\"223\":1}}],[\"fast\",{\"1\":{\"105\":1}}],[\"family\",{\"1\":{\"75\":1}}],[\"false\",{\"1\":{\"62\":1,\"365\":6,\"372\":3}}],[\"failure\",{\"1\":{\"62\":1}}],[\"fail\",{\"1\":{\"62\":1}}],[\"failedscheduling\",{\"1\":{\"36\":1}}],[\"failed\",{\"1\":{\"5\":1,\"17\":1,\"62\":3,\"94\":1,\"149\":1}}],[\"fmt\",{\"1\":{\"5\":2}}],[\"ir\",{\"1\":{\"442\":3,\"445\":2}}],[\"irq\",{\"1\":{\"255\":1}}],[\"iv\",{\"0\":{\"409\":1}}],[\"iii\",{\"0\":{\"403\":1}}],[\"ii\",{\"0\":{\"398\":1}}],[\"iic\",{\"1\":{\"374\":1}}],[\"iz2zei23h3vwykyqq9th6oz\",{\"1\":{\"381\":1,\"382\":1,\"383\":1}}],[\"iwarp\",{\"1\":{\"351\":1,\"354\":1}}],[\"icmp\",{\"1\":{\"336\":1}}],[\"ibgp\",{\"1\":{\"310\":1}}],[\"ieee\",{\"1\":{\"287\":1}}],[\"ignore\",{\"1\":{\"199\":1}}],[\"imgs\",{\"1\":{\"365\":5}}],[\"import\",{\"1\":{\"167\":1,\"168\":2,\"183\":2,\"264\":1}}],[\"importlib\",{\"1\":{\"167\":1,\"168\":2}}],[\"image2\",{\"1\":{\"242\":1}}],[\"images\",{\"1\":{\"228\":1}}],[\"imagefs\",{\"1\":{\"51\":4}}],[\"imagepullpolicy\",{\"1\":{\"36\":1,\"98\":1}}],[\"image\",{\"1\":{\"32\":1,\"36\":1,\"43\":2,\"58\":2,\"98\":2,\"242\":1,\"366\":12,\"372\":2,\"381\":6}}],[\"id=soaucnp8bip0tddujxng\",{\"1\":{\"382\":1}}],[\"id=a387a4892ee19b1a2249\",{\"1\":{\"382\":1}}],[\"id映射到vxlan的vni\",{\"1\":{\"291\":1}}],[\"idle\",{\"1\":{\"255\":1}}],[\"identifier\",{\"1\":{\"286\":1,\"290\":1}}],[\"identity\",{\"1\":{\"150\":1}}],[\"idea\",{\"1\":{\"223\":1}}],[\"id\",{\"1\":{\"164\":2,\"165\":4,\"202\":1,\"204\":1,\"255\":2,\"285\":2,\"287\":1,\"298\":1,\"366\":2,\"431\":1}}],[\"its\",{\"1\":{\"205\":1}}],[\"it\",{\"1\":{\"205\":2,\"382\":1}}],[\"iters\",{\"1\":{\"149\":3,\"150\":3}}],[\"items\",{\"1\":{\"75\":1}}],[\"itd\",{\"1\":{\"66\":1,\"375\":1}}],[\"i\",{\"1\":{\"68\":1,\"70\":1,\"71\":1,\"73\":1,\"150\":1,\"160\":2,\"162\":2,\"242\":1,\"255\":4,\"429\":2,\"431\":1,\"433\":2,\"435\":3,\"437\":2}}],[\"i0729\",{\"1\":{\"62\":5}}],[\"in和swap\",{\"1\":{\"408\":1}}],[\"indiehacker\",{\"1\":{\"359\":1}}],[\"index\",{\"1\":{\"68\":2,\"74\":1,\"75\":3}}],[\"input\",{\"1\":{\"331\":2}}],[\"inputs\",{\"1\":{\"156\":5,\"158\":1,\"159\":2,\"160\":2,\"161\":8,\"162\":7}}],[\"inet6\",{\"1\":{\"283\":1}}],[\"inet\",{\"1\":{\"283\":1}}],[\"insight\",{\"1\":{\"212\":1}}],[\"instruction\",{\"1\":{\"186\":2}}],[\"instance\",{\"1\":{\"169\":2}}],[\"install\",{\"1\":{\"1\":1,\"145\":1,\"239\":1}}],[\"instead\",{\"1\":{\"156\":2,\"212\":1}}],[\"including\",{\"1\":{\"211\":1}}],[\"include\",{\"1\":{\"75\":1,\"145\":1,\"170\":1,\"199\":2}}],[\"invalidarguments\",{\"1\":{\"161\":1}}],[\"integration\",{\"1\":{\"389\":1}}],[\"inter\",{\"1\":{\"393\":2,\"422\":1}}],[\"interval=10\",{\"1\":{\"366\":1}}],[\"interval\",{\"1\":{\"366\":3,\"381\":1}}],[\"interrupt\",{\"1\":{\"255\":1}}],[\"internet\",{\"1\":{\"336\":1}}],[\"internlm\",{\"1\":{\"220\":1}}],[\"internal\",{\"1\":{\"149\":2}}],[\"interface\",{\"1\":{\"181\":1,\"190\":1,\"195\":1}}],[\"into\",{\"1\":{\"150\":1,\"212\":1,\"433\":1}}],[\"int\",{\"1\":{\"150\":3,\"152\":1,\"156\":2,\"158\":2,\"161\":3,\"199\":8,\"202\":2}}],[\"introduction\",{\"1\":{\"78\":1}}],[\"infinity利用cpu内存和nvme存储来扩展模型规模\",{\"1\":{\"418\":1}}],[\"infinity也不应显著优于zero\",{\"1\":{\"412\":1}}],[\"infinity的原始论文和图8a中的结果验证\",{\"1\":{\"412\":1}}],[\"infinity的表现不如zero\",{\"1\":{\"412\":1}}],[\"infinity的性能提升了37\",{\"1\":{\"412\":1}}],[\"infinity通过gpu\",{\"1\":{\"412\":1}}],[\"infinity比zero\",{\"1\":{\"412\":1}}],[\"infinity需要大量的cpu内存来进行初始化\",{\"1\":{\"412\":1}}],[\"infinity\",{\"1\":{\"410\":1,\"412\":1}}],[\"infiniband\",{\"1\":{\"143\":2,\"351\":1,\"354\":1,\"454\":1}}],[\"infer\",{\"1\":{\"211\":2}}],[\"inference\",{\"0\":{\"210\":1},\"1\":{\"210\":1,\"211\":5}}],[\"information\",{\"1\":{\"382\":1}}],[\"info\",{\"1\":{\"149\":54,\"366\":1}}],[\"ingress\",{\"1\":{\"96\":1}}],[\"initreplicaset\",{\"1\":{\"366\":2}}],[\"initiate\",{\"1\":{\"366\":1}}],[\"initial\",{\"1\":{\"75\":1,\"205\":1,\"366\":1}}],[\"initdb\",{\"1\":{\"366\":2}}],[\"initmodule\",{\"1\":{\"170\":3,\"171\":3,\"172\":1,\"173\":2,\"174\":1}}],[\"init\",{\"0\":{\"202\":1},\"1\":{\"62\":1,\"149\":3,\"150\":1,\"164\":2,\"165\":3,\"169\":1,\"175\":1,\"183\":1,\"199\":1,\"202\":3,\"203\":2,\"204\":3,\"263\":1,\"381\":2}}],[\"in\",{\"1\":{\"54\":1,\"56\":1,\"62\":1,\"98\":1,\"149\":1,\"150\":2,\"154\":2,\"156\":3,\"160\":1,\"211\":1,\"372\":1,\"381\":1}}],[\"inodesfree<5\",{\"1\":{\"51\":2}}],[\"ipu等专用加速器的兴起\",{\"1\":{\"418\":1}}],[\"iputils\",{\"1\":{\"239\":1}}],[\"ip协议进行路由选择\",{\"1\":{\"342\":1}}],[\"iptables\",{\"1\":{\"330\":1,\"331\":3,\"332\":2}}],[\"ipv4地址长度\",{\"1\":{\"304\":1}}],[\"ip地址\",{\"1\":{\"294\":1}}],[\"ipinfo\",{\"1\":{\"240\":1}}],[\"ip\",{\"0\":{\"294\":1},\"1\":{\"37\":1,\"38\":2,\"44\":1,\"45\":1,\"46\":4,\"47\":1,\"49\":2,\"50\":1,\"75\":1,\"143\":2,\"240\":1,\"279\":3,\"281\":1,\"282\":2,\"283\":6,\"294\":1,\"295\":1,\"318\":1,\"319\":1,\"321\":3,\"322\":1,\"324\":2,\"325\":3,\"327\":1,\"328\":3,\"332\":8,\"336\":1}}],[\"issuer=http\",{\"1\":{\"381\":1}}],[\"isready\",{\"1\":{\"381\":1}}],[\"isinited\",{\"1\":{\"366\":2}}],[\"isinstance\",{\"1\":{\"156\":2}}],[\"iso\",{\"1\":{\"333\":1}}],[\"is\",{\"1\":{\"36\":1,\"62\":3,\"150\":3,\"154\":3,\"156\":7,\"204\":1,\"205\":2}}],[\"iowait\",{\"1\":{\"255\":1}}],[\"io\",{\"1\":{\"36\":2,\"48\":1,\"54\":2,\"58\":1,\"98\":4,\"196\":2,\"217\":1,\"228\":1,\"240\":1,\"366\":4}}],[\"if29\",{\"1\":{\"283\":2}}],[\"ifconfig\",{\"1\":{\"280\":2,\"318\":1,\"319\":4,\"321\":1,\"332\":2}}],[\"ifconfig命令也可以用于查看网络接口\",{\"1\":{\"280\":1}}],[\"ifdef\",{\"1\":{\"164\":1,\"165\":1,\"170\":1,\"171\":1}}],[\"ifndef\",{\"1\":{\"170\":1,\"171\":1}}],[\"ifname\",{\"1\":{\"143\":1}}],[\"ifnotpresent\",{\"1\":{\"36\":1,\"98\":1}}],[\"if\",{\"1\":{\"5\":6,\"75\":1,\"95\":1,\"150\":3,\"154\":3,\"156\":3,\"161\":1,\"162\":1,\"183\":1,\"199\":2,\"205\":2,\"366\":1,\"382\":2}}],[\"=|\",{\"1\":{\"433\":1}}],[\"======\",{\"1\":{\"382\":2}}],[\"===========================\",{\"1\":{\"382\":2}}],[\"===\",{\"1\":{\"366\":1}}],[\"==\",{\"1\":{\"183\":1,\"199\":2}}],[\"=\",{\"1\":{\"5\":12,\"71\":1,\"75\":1,\"150\":1,\"154\":1,\"156\":8,\"160\":2,\"161\":10,\"167\":1,\"168\":1,\"169\":3,\"183\":2,\"199\":1,\"202\":9,\"207\":1,\"366\":1,\"433\":1}}],[\"cfinal\",{\"1\":{\"439\":3}}],[\"cf9fppxspbnbesvhs5g\",{\"1\":{\"422\":1}}],[\"c2c\",{\"1\":{\"417\":1}}],[\"ctrans\",{\"1\":{\"439\":1}}],[\"ctrl+c\",{\"1\":{\"255\":1}}],[\"ctx\",{\"1\":{\"5\":2}}],[\"c10d\",{\"1\":{\"180\":3,\"181\":5,\"182\":2,\"183\":1,\"184\":1,\"202\":1},\"2\":{\"209\":1}}],[\"cplusplus\",{\"1\":{\"170\":1,\"171\":1}}],[\"cpp\",{\"0\":{\"161\":1,\"164\":1}}],[\"cpu内存\",{\"1\":{\"417\":1}}],[\"cpu内存更便宜\",{\"1\":{\"417\":1}}],[\"cpu内存空间\",{\"1\":{\"408\":1}}],[\"cpu交换对内存节省的贡献为0\",{\"1\":{\"416\":1}}],[\"cpu交换快了7\",{\"1\":{\"415\":1}}],[\"cpu交换快了143\",{\"1\":{\"411\":1}}],[\"cpu交换取而代之\",{\"1\":{\"412\":1}}],[\"cpu交换并进一步扩展到nvme设备\",{\"1\":{\"412\":1}}],[\"cpu交换可以支持相同的超大模型\",{\"1\":{\"411\":1}}],[\"cpu交换实现了1\",{\"1\":{\"411\":1}}],[\"cpu交换依然可行\",{\"1\":{\"411\":1}}],[\"cpu交换相比\",{\"1\":{\"411\":1}}],[\"cpu交换分配给剩余的张量\",{\"1\":{\"407\":1}}],[\"cpu交换分配给生命周期特别长的张量\",{\"1\":{\"407\":1}}],[\"cpu交换的高延迟\",{\"1\":{\"418\":1}}],[\"cpu交换的方案可能可以支持非常大规模的模型训练\",{\"1\":{\"412\":1}}],[\"cpu交换的性能最差\",{\"1\":{\"411\":1}}],[\"cpu交换的系统和启用重计算的系统\",{\"1\":{\"410\":1}}],[\"cpu交换的成本\",{\"1\":{\"407\":1,\"417\":1}}],[\"cpu交换的延迟\",{\"1\":{\"404\":1}}],[\"cpu交换要快得多\",{\"1\":{\"407\":1}}],[\"cpu交换腾出更多空间\",{\"1\":{\"407\":1}}],[\"cpu交换和我们新提出的d2d交换\",{\"1\":{\"419\":1}}],[\"cpu交换和深度学习加速器\",{\"1\":{\"418\":1}}],[\"cpu交换和d2d交换的时间成本\",{\"1\":{\"415\":1}}],[\"cpu交换和d2d交换的优势\",{\"1\":{\"395\":1}}],[\"cpu交换和mpress能够成功执行训练任务\",{\"1\":{\"411\":1}}],[\"cpu交换和重计算相结合\",{\"1\":{\"418\":1}}],[\"cpu交换和重计算带来的额外开销或gpu资源争用方面起到了关键作用\",{\"1\":{\"416\":1}}],[\"cpu交换和重计算带来的额外延迟\",{\"1\":{\"407\":1}}],[\"cpu交换和重计算都会带来额外开销\",{\"1\":{\"415\":1}}],[\"cpu交换和重计算为d2d交换腾出了更多空间\",{\"1\":{\"411\":1}}],[\"cpu交换和重计算的时间成本\",{\"1\":{\"410\":1}}],[\"cpu交换和重计算替换为d2d交换来优化配置\",{\"1\":{\"407\":1}}],[\"cpu交换和重计算优化\",{\"1\":{\"407\":1}}],[\"cpu交换和重计算结合起来的最佳配置\",{\"1\":{\"407\":1}}],[\"cpu交换技术来进一步减少gpu内存消耗\",{\"1\":{\"404\":1}}],[\"cpu交换所带来的高额性能损失至关重要\",{\"1\":{\"404\":1}}],[\"cpu交换后\",{\"1\":{\"401\":1}}],[\"cpu交换会大幅降低训练吞吐量\",{\"1\":{\"401\":1}}],[\"cpu交换利用了cpu内存的大容量来扩展gpu内存空间\",{\"1\":{\"401\":1}}],[\"cpu交换\",{\"1\":{\"394\":1,\"411\":1,\"413\":1,\"415\":3,\"416\":3,\"418\":3}}],[\"cputime\",{\"1\":{\"150\":1}}],[\"cpu\",{\"1\":{\"20\":5,\"21\":1,\"25\":9,\"36\":2,\"62\":1,\"98\":2,\"143\":1,\"149\":3,\"150\":2,\"189\":1,\"192\":1,\"193\":1,\"195\":1,\"207\":8,\"228\":1,\"255\":18,\"352\":1,\"353\":1,\"354\":1,\"454\":1}}],[\"csrc\",{\"0\":{\"161\":1,\"164\":1}}],[\"cycles\",{\"1\":{\"150\":1}}],[\"cc\",{\"1\":{\"149\":2}}],[\"chunk\",{\"1\":{\"444\":1}}],[\"chunksize\",{\"1\":{\"149\":1}}],[\"chown\",{\"1\":{\"366\":1}}],[\"chosen\",{\"1\":{\"212\":1}}],[\"chmod\",{\"1\":{\"366\":1}}],[\"children\",{\"1\":{\"175\":1}}],[\"child\",{\"1\":{\"175\":2}}],[\"check\",{\"1\":{\"150\":1,\"156\":1,\"205\":1}}],[\"change\",{\"1\":{\"382\":1}}],[\"channels\",{\"1\":{\"149\":5}}],[\"channel\",{\"1\":{\"149\":32,\"372\":1}}],[\"chatgpt测试群2\",{\"1\":{\"372\":1}}],[\"chatgpt测试群\",{\"1\":{\"372\":1}}],[\"chatgpt\",{\"1\":{\"370\":1,\"372\":3},\"2\":{\"378\":1}}],[\"chatglm\",{\"1\":{\"220\":1}}],[\"chat\",{\"1\":{\"366\":1,\"372\":3,\"381\":4,\"382\":1,\"383\":1}}],[\"character\",{\"1\":{\"372\":1}}],[\"charspointsprice\",{\"1\":{\"365\":7}}],[\"charset=utf\",{\"1\":{\"75\":1}}],[\"charset=\",{\"1\":{\"75\":1}}],[\"char\",{\"1\":{\"199\":1}}],[\"c821\",{\"1\":{\"149\":1}}],[\"cd\",{\"1\":{\"148\":1}}],[\"c\",{\"0\":{\"406\":1,\"412\":1},\"1\":{\"127\":1,\"143\":1,\"150\":2,\"156\":1,\"157\":1,\"159\":1,\"161\":1,\"162\":1,\"170\":5,\"171\":10,\"172\":3,\"173\":4,\"174\":2,\"242\":2,\"366\":1,\"381\":1,\"435\":2}}],[\"c++参考示例\",{\"1\":{\"170\":1}}],[\"c++\",{\"1\":{\"127\":1,\"161\":1,\"162\":1,\"163\":2,\"164\":1,\"170\":1,\"171\":1,\"172\":1}}],[\"cmd\",{\"1\":{\"366\":3,\"381\":1}}],[\"cm\",{\"1\":{\"108\":2}}],[\"ciphers\",{\"1\":{\"75\":2}}],[\"cn\",{\"1\":{\"75\":1,\"366\":4,\"372\":1,\"373\":1,\"374\":1}}],[\"cnbita\",{\"1\":{\"36\":1,\"97\":1}}],[\"censor\",{\"1\":{\"365\":2}}],[\"centos\",{\"1\":{\"256\":1,\"259\":1,\"260\":2,\"261\":1,\"262\":1}}],[\"center\",{\"1\":{\"75\":3}}],[\"cert\",{\"1\":{\"62\":1}}],[\"certificate\",{\"1\":{\"62\":1}}],[\"cgroup\",{\"1\":{\"62\":1,\"255\":1}}],[\"cgroups\",{\"1\":{\"51\":1,\"62\":1}}],[\"cassign\",{\"1\":{\"439\":1}}],[\"casbin\",{\"1\":{\"381\":1}}],[\"casdoor\",{\"0\":{\"388\":1},\"1\":{\"381\":8,\"382\":4,\"388\":1}}],[\"cat\",{\"1\":{\"381\":1,\"382\":1,\"383\":1}}],[\"capability\",{\"1\":{\"207\":2}}],[\"call\",{\"1\":{\"255\":1}}],[\"called\",{\"1\":{\"156\":1,\"205\":1}}],[\"calling\",{\"1\":{\"150\":1,\"175\":1}}],[\"can\",{\"1\":{\"156\":1,\"205\":2,\"212\":1,\"263\":1,\"382\":1}}],[\"cache\",{\"1\":{\"75\":5,\"211\":1,\"366\":1}}],[\"ca\",{\"1\":{\"62\":2}}],[\"cafile\",{\"1\":{\"62\":1}}],[\"cadvisor\",{\"1\":{\"51\":1}}],[\"cudastream\",{\"1\":{\"162\":1}}],[\"cudastream>>\",{\"1\":{\"161\":1}}],[\"cudagraph\",{\"1\":{\"150\":1}}],[\"cudadev\",{\"1\":{\"149\":3}}],[\"cudadriverversion\",{\"1\":{\"149\":1}}],[\"cuda\",{\"0\":{\"156\":1,\"161\":1,\"164\":1},\"1\":{\"143\":4,\"150\":1,\"156\":1,\"158\":3,\"160\":2,\"161\":3,\"162\":2,\"166\":1,\"204\":3,\"207\":11,\"410\":1}}],[\"curl\",{\"1\":{\"68\":1,\"69\":1,\"70\":1,\"71\":1,\"72\":1,\"73\":1,\"74\":1,\"75\":1,\"240\":2,\"366\":2}}],[\"current\",{\"1\":{\"62\":1,\"212\":1}}],[\"customextractprompt\",{\"1\":{\"365\":2}}],[\"customcqprompt\",{\"1\":{\"365\":2}}],[\"custom\",{\"0\":{\"59\":1},\"1\":{\"117\":2}}],[\"cr\",{\"1\":{\"117\":3}}],[\"cron\",{\"1\":{\"95\":2}}],[\"crd\",{\"1\":{\"84\":1,\"97\":6,\"98\":1,\"100\":1,\"117\":3,\"118\":4}}],[\"credentials\",{\"1\":{\"75\":1}}],[\"createdatabase=true\",{\"1\":{\"381\":1}}],[\"createrevision\",{\"1\":{\"5\":1}}],[\"create\",{\"1\":{\"5\":1,\"149\":1,\"150\":1,\"154\":1,\"372\":1}}],[\"crt\",{\"1\":{\"62\":1}}],[\"crit\",{\"1\":{\"75\":1}}],[\"cri\",{\"1\":{\"61\":7,\"62\":4}}],[\"crash\",{\"1\":{\"5\":1}}],[\"clamp\",{\"1\":{\"211\":2}}],[\"class\",{\"1\":{\"169\":1,\"205\":4}}],[\"classname\",{\"1\":{\"168\":1}}],[\"clash\",{\"2\":{\"137\":1}}],[\"clash节点转为v2ray\",{\"0\":{\"135\":1}}],[\"clone\",{\"1\":{\"144\":1,\"147\":1,\"374\":1}}],[\"cloud\",{\"1\":{\"105\":1}}],[\"close\",{\"1\":{\"5\":2}}],[\"cluster\",{\"1\":{\"38\":2,\"43\":1,\"44\":1,\"212\":1}}],[\"clusterip\",{\"1\":{\"37\":1,\"38\":1,\"40\":2,\"42\":1}}],[\"client\",{\"1\":{\"5\":8,\"62\":3,\"366\":2,\"382\":1,\"387\":1}}],[\"clientv3\",{\"1\":{\"5\":2}}],[\"cli\",{\"1\":{\"5\":3,\"103\":1}}],[\"corder\",{\"1\":{\"439\":1}}],[\"cors\",{\"1\":{\"381\":1}}],[\"coreos\",{\"1\":{\"366\":1}}],[\"core\",{\"1\":{\"149\":3}}],[\"coshard\",{\"1\":{\"452\":2,\"455\":2,\"458\":1}}],[\"cosyvoice\",{\"0\":{\"373\":1},\"1\":{\"373\":1,\"374\":2,\"375\":3,\"376\":1}}],[\"cost\",{\"1\":{\"347\":1}}],[\"cow\",{\"1\":{\"371\":1}}],[\"cookbook\",{\"1\":{\"225\":1}}],[\"count=50000\",{\"1\":{\"366\":1}}],[\"count\",{\"1\":{\"149\":1}}],[\"could\",{\"1\":{\"149\":3}}],[\"collective\",{\"1\":{\"161\":1,\"164\":1,\"175\":1}}],[\"collections\",{\"1\":{\"156\":1}}],[\"collnet直接通信模式\",{\"1\":{\"176\":1}}],[\"collnet\",{\"1\":{\"149\":1,\"175\":2,\"176\":1}}],[\"coll\",{\"1\":{\"149\":1}}],[\"color\",{\"1\":{\"75\":3}}],[\"covariance\",{\"1\":{\"105\":1}}],[\"code\",{\"1\":{\"62\":1,\"149\":1,\"304\":1,\"382\":1}}],[\"code=exited\",{\"1\":{\"62\":1}}],[\"condition\",{\"1\":{\"381\":5,\"383\":1}}],[\"conversation\",{\"1\":{\"372\":1}}],[\"const\",{\"1\":{\"366\":1}}],[\"constraints\",{\"0\":{\"57\":1},\"1\":{\"433\":6}}],[\"console\",{\"1\":{\"366\":1,\"381\":2}}],[\"connection\",{\"1\":{\"75\":1,\"366\":1}}],[\"connections\",{\"1\":{\"75\":1,\"149\":1}}],[\"conf\",{\"1\":{\"66\":3,\"75\":1,\"263\":2}}],[\"configure\",{\"1\":{\"382\":1}}],[\"configuration\",{\"1\":{\"382\":2}}],[\"config\",{\"0\":{\"383\":1},\"1\":{\"5\":1,\"48\":1,\"60\":3,\"366\":2,\"372\":1,\"382\":1,\"383\":1}}],[\"control\",{\"1\":{\"75\":8,\"98\":3,\"212\":1,\"336\":1}}],[\"controller\",{\"0\":{\"98\":1},\"1\":{\"30\":1,\"33\":1,\"62\":1,\"97\":9,\"98\":8,\"117\":1}}],[\"contained\",{\"1\":{\"62\":1}}],[\"containerport\",{\"1\":{\"32\":1,\"36\":1,\"43\":1}}],[\"containers\",{\"1\":{\"32\":1,\"36\":1,\"43\":1,\"58\":1,\"98\":1}}],[\"container\",{\"1\":{\"25\":1,\"43\":1,\"58\":1,\"366\":8,\"372\":1,\"381\":5}}],[\"content=\",{\"1\":{\"75\":1}}],[\"content\",{\"1\":{\"62\":1,\"75\":5}}],[\"context\",{\"1\":{\"5\":2}}],[\"concurrency\",{\"1\":{\"5\":5}}],[\"commd\",{\"1\":{\"440\":2}}],[\"communicator\",{\"1\":{\"196\":1}}],[\"communications\",{\"1\":{\"161\":1,\"164\":1,\"175\":1}}],[\"comms\",{\"1\":{\"156\":1,\"158\":1,\"161\":6,\"162\":5}}],[\"comms=none\",{\"1\":{\"156\":2}}],[\"commid\",{\"1\":{\"149\":2}}],[\"comm\",{\"1\":{\"149\":4,\"196\":1,\"199\":6}}],[\"common\",{\"1\":{\"108\":2}}],[\"command\",{\"1\":{\"36\":1,\"62\":1,\"98\":1,\"366\":5,\"381\":2}}],[\"compd\",{\"1\":{\"440\":2}}],[\"compaction\",{\"1\":{\"366\":2}}],[\"compose\",{\"0\":{\"366\":1,\"372\":1,\"381\":1},\"1\":{\"380\":1,\"381\":2,\"382\":1,\"383\":1}}],[\"component\",{\"0\":{\"90\":1}}],[\"compression\",{\"1\":{\"217\":1}}],[\"compute\",{\"1\":{\"211\":4,\"212\":2}}],[\"complete\",{\"1\":{\"149\":2}}],[\"competition\",{\"1\":{\"5\":1}}],[\"com\",{\"1\":{\"1\":1,\"36\":1,\"97\":1,\"98\":1,\"99\":1,\"144\":1,\"147\":1,\"246\":1,\"247\":1,\"363\":1,\"366\":4,\"370\":1,\"372\":1,\"373\":1,\"382\":1,\"422\":1}}],[\"ec2上最新的gpu实例仍然使用dgx\",{\"1\":{\"417\":1}}],[\"ec2上这种高端gpu服务器的配额非常有限\",{\"1\":{\"410\":1}}],[\"ec2实例上进行这组实验\",{\"1\":{\"412\":1}}],[\"ec2\",{\"1\":{\"400\":1,\"410\":1}}],[\"echo\",{\"1\":{\"365\":3,\"366\":2}}],[\"embedding3\",{\"1\":{\"365\":1}}],[\"embedding\",{\"1\":{\"365\":6}}],[\"emissary\",{\"1\":{\"96\":2,\"97\":1}}],[\"emissaryexecutor\",{\"1\":{\"96\":1,\"97\":2}}],[\"ebgp\",{\"1\":{\"310\":1}}],[\"e0ff\",{\"1\":{\"283\":1}}],[\"e0\",{\"1\":{\"283\":2}}],[\"e0729\",{\"1\":{\"62\":1}}],[\"eaee979aadb0\",{\"1\":{\"149\":1}}],[\"ethernet\",{\"1\":{\"335\":1}}],[\"ether\",{\"1\":{\"283\":2}}],[\"eth0\",{\"1\":{\"149\":2,\"319\":3,\"325\":2,\"328\":1}}],[\"etc\",{\"1\":{\"31\":1,\"32\":3,\"62\":1,\"66\":1,\"263\":1,\"381\":2}}],[\"etcdctl\",{\"1\":{\"366\":1}}],[\"etcd获取分布式锁\",{\"1\":{\"5\":1}}],[\"etcd\",{\"0\":{\"5\":1},\"1\":{\"5\":1,\"30\":1,\"31\":1,\"33\":2,\"366\":10},\"2\":{\"6\":1}}],[\"e\",{\"0\":{\"408\":1},\"1\":{\"149\":2,\"150\":1,\"205\":4,\"436\":5}}],[\"elif\",{\"1\":{\"156\":1}}],[\"elements\",{\"1\":{\"149\":1}}],[\"element\",{\"1\":{\"130\":1}}],[\"elasticsearch\",{\"1\":{\"121\":2}}],[\"else\",{\"1\":{\"5\":1,\"95\":1,\"156\":3,\"199\":1}}],[\"efficient\",{\"1\":{\"105\":1}}],[\"effect\",{\"1\":{\"36\":2,\"383\":3}}],[\"estimators\",{\"1\":{\"105\":1}}],[\"eecdh+3des\",{\"1\":{\"75\":1}}],[\"eecdh+aes256\",{\"1\":{\"75\":1}}],[\"eecdh+aes128\",{\"1\":{\"75\":1}}],[\"eecdh+chacha20\",{\"1\":{\"75\":2}}],[\"enable\",{\"1\":{\"381\":1}}],[\"enabled=true\",{\"1\":{\"366\":2}}],[\"enabled\",{\"1\":{\"62\":1}}],[\"ens3\",{\"1\":{\"297\":2}}],[\"engineering\",{\"1\":{\"223\":1,\"226\":1}}],[\"entrypoint\",{\"1\":{\"366\":3,\"381\":1}}],[\"entry\",{\"1\":{\"205\":1}}],[\"enum\",{\"1\":{\"205\":1}}],[\"endif\",{\"1\":{\"164\":1,\"170\":2}}],[\"end\",{\"1\":{\"161\":1,\"162\":1}}],[\"endpoint=http\",{\"1\":{\"381\":1}}],[\"endpoints\",{\"1\":{\"5\":2,\"366\":1}}],[\"endpoint\",{\"0\":{\"291\":1},\"1\":{\"1\":1,\"366\":1}}],[\"environment\",{\"1\":{\"366\":7,\"372\":1,\"381\":4,\"382\":3}}],[\"env\",{\"0\":{\"382\":1},\"1\":{\"98\":1,\"203\":1,\"204\":1,\"381\":2,\"382\":1}}],[\"en\",{\"1\":{\"75\":1}}],[\"exe\",{\"1\":{\"242\":1,\"263\":1}}],[\"exec\",{\"0\":{\"61\":1},\"1\":{\"61\":5,\"283\":3,\"366\":1}}],[\"existence\",{\"1\":{\"205\":1}}],[\"exit\",{\"1\":{\"62\":1,\"310\":1}}],[\"exited\",{\"1\":{\"62\":1}}],[\"exception\",{\"1\":{\"202\":1}}],[\"extensible\",{\"0\":{\"286\":1,\"290\":1},\"1\":{\"284\":1}}],[\"external\",{\"1\":{\"372\":1}}],[\"extern\",{\"1\":{\"170\":2,\"171\":4}}],[\"extract\",{\"1\":{\"161\":2,\"162\":2}}],[\"expires\",{\"1\":{\"372\":1}}],[\"expr\",{\"1\":{\"211\":2}}],[\"export\",{\"1\":{\"149\":1,\"264\":1}}],[\"expose\",{\"1\":{\"75\":1}}],[\"experimentservice\",{\"1\":{\"108\":1,\"109\":1,\"111\":1}}],[\"experiment\",{\"0\":{\"95\":1}}],[\"example\",{\"1\":{\"20\":2,\"25\":2,\"32\":2,\"54\":1,\"56\":1,\"58\":1}}],[\"eval\",{\"1\":{\"224\":1,\"366\":1}}],[\"evolution\",{\"1\":{\"105\":1}}],[\"evenpodsspreadpriority\",{\"1\":{\"59\":1,\"60\":1}}],[\"events\",{\"1\":{\"36\":1,\"75\":1}}],[\"eviction\",{\"1\":{\"51\":15}}],[\"equal\",{\"1\":{\"36\":1,\"347\":1}}],[\"errors\",{\"1\":{\"161\":2,\"162\":2}}],[\"error\",{\"1\":{\"75\":1,\"366\":1}}],[\"err=\",{\"1\":{\"62\":1}}],[\"err\",{\"1\":{\"5\":12}}],[\"笔记\",{\"2\":{\"4\":1,\"64\":1}}],[\"笔记总结\",{\"1\":{\"0\":1,\"8\":1}}],[\"tflops\",{\"1\":{\"454\":1}}],[\"t5\",{\"0\":{\"436\":1,\"456\":1},\"1\":{\"436\":1,\"450\":1,\"453\":1,\"454\":1,\"456\":2,\"457\":1,\"459\":2}}],[\"tpu和graphcore\",{\"1\":{\"418\":1}}],[\"tpriority\",{\"1\":{\"62\":1}}],[\"tls\",{\"1\":{\"274\":1,\"339\":1}}],[\"tlsv1\",{\"1\":{\"75\":3}}],[\"turbo\",{\"1\":{\"365\":2,\"372\":1}}],[\"tunnel\",{\"0\":{\"291\":1}}],[\"tuner\",{\"1\":{\"149\":3}}],[\"tused\",{\"1\":{\"62\":1}}],[\"ts\",{\"1\":{\"130\":1}}],[\"tsize\",{\"1\":{\"62\":1}}],[\"trigger\",{\"1\":{\"372\":1}}],[\"triton\",{\"0\":{\"210\":1},\"1\":{\"210\":1,\"211\":2},\"2\":{\"214\":1}}],[\"tryfastgpt\",{\"1\":{\"364\":1}}],[\"trans\",{\"0\":{\"429\":1},\"1\":{\"423\":1,\"424\":1,\"428\":1,\"429\":1,\"433\":1,\"439\":2,\"443\":1}}],[\"transport\",{\"0\":{\"337\":1}}],[\"transformer和alphafold2\",{\"1\":{\"423\":1,\"424\":1}}],[\"transformer\",{\"0\":{\"435\":1},\"1\":{\"218\":1,\"224\":1,\"435\":1,\"446\":1,\"451\":2,\"454\":1,\"455\":1}}],[\"translate\",{\"1\":{\"150\":1}}],[\"traffic\",{\"1\":{\"175\":3}}],[\"trace\",{\"0\":{\"167\":1},\"1\":{\"445\":1}}],[\"training\",{\"1\":{\"106\":1,\"393\":2,\"422\":1}}],[\"trees\",{\"1\":{\"149\":1}}],[\"tree\",{\"1\":{\"105\":1,\"175\":6,\"176\":3}}],[\"true\",{\"1\":{\"75\":1,\"365\":13,\"372\":2,\"381\":1}}],[\"thputils\",{\"1\":{\"161\":1}}],[\"th\",{\"1\":{\"161\":2,\"162\":2}}],[\"thcpmodule\",{\"1\":{\"161\":1,\"162\":1,\"164\":9,\"165\":9}}],[\"thcd8\",{\"1\":{\"97\":2}}],[\"this\",{\"1\":{\"150\":2,\"205\":2}}],[\"these\",{\"1\":{\"212\":1}}],[\"they\",{\"1\":{\"205\":1}}],[\"the\",{\"1\":{\"98\":2,\"150\":2,\"156\":1,\"175\":2,\"205\":4,\"212\":6,\"382\":4}}],[\"tqtgh\",{\"1\":{\"97\":2}}],[\"tiny\",{\"1\":{\"224\":6}}],[\"timedelta\",{\"1\":{\"202\":1,\"204\":1}}],[\"time\",{\"1\":{\"149\":2,\"202\":1,\"211\":1}}],[\"timeout\",{\"1\":{\"75\":3,\"150\":1,\"202\":1,\"204\":1,\"366\":3,\"381\":1}}],[\"timings\",{\"1\":{\"149\":2}}],[\"title>\",{\"1\":{\"75\":1}}],[\"terapipe\",{\"1\":{\"451\":3}}],[\"tessel\",{\"1\":{\"441\":1,\"459\":1}}],[\"tesseract进一步结合了流水线并行和gpu\",{\"1\":{\"418\":1}}],[\"tesla\",{\"1\":{\"410\":2,\"454\":1}}],[\"test\",{\"0\":{\"146\":1},\"1\":{\"366\":3,\"381\":1}}],[\"tests\",{\"1\":{\"144\":1,\"147\":1,\"148\":1,\"149\":1}}],[\"tech\",{\"1\":{\"371\":1}}],[\"tensor>\",{\"1\":{\"161\":1}}],[\"tensor\",{\"1\":{\"156\":11,\"158\":4,\"160\":2,\"161\":3,\"162\":1,\"183\":5,\"433\":1,\"449\":1}}],[\"tensors\",{\"1\":{\"156\":2,\"161\":1,\"162\":1}}],[\"tensorflow\",{\"1\":{\"105\":1,\"454\":2}}],[\"tekton\",{\"1\":{\"106\":1}}],[\"text\",{\"1\":{\"75\":2,\"365\":5}}],[\"template\",{\"1\":{\"36\":1,\"43\":1,\"98\":1}}],[\"t8580\",{\"1\":{\"62\":1}}],[\"t4194304\",{\"1\":{\"62\":1}}],[\"tts1\",{\"1\":{\"365\":1}}],[\"tts\",{\"1\":{\"365\":1}}],[\"ttype\",{\"1\":{\"62\":1}}],[\"ttl\",{\"1\":{\"5\":1,\"305\":1}}],[\"table\",{\"1\":{\"433\":3}}],[\"tail\",{\"1\":{\"381\":1}}],[\"taints\",{\"1\":{\"36\":1}}],[\"taint\",{\"0\":{\"35\":1,\"36\":1},\"1\":{\"35\":2,\"36\":10}}],[\"tar\",{\"1\":{\"264\":2}}],[\"target\",{\"1\":{\"304\":2}}],[\"target=\",{\"1\":{\"75\":1}}],[\"targetport\",{\"1\":{\"40\":1,\"42\":1}}],[\"task\",{\"1\":{\"255\":1}}],[\"taskservice\",{\"1\":{\"108\":1,\"111\":1}}],[\"taking\",{\"1\":{\"156\":2}}],[\"tag\",{\"1\":{\"98\":1}}],[\"tcp将数据包分段并传递到网络层的ip协议\",{\"1\":{\"342\":1}}],[\"tcp\",{\"1\":{\"36\":1,\"143\":1,\"331\":2,\"337\":1,\"366\":1}}],[\"type=service这将显示服务的状态\",{\"1\":{\"263\":1}}],[\"typescript\",{\"1\":{\"130\":1}}],[\"types\",{\"1\":{\"75\":1}}],[\"type\",{\"1\":{\"25\":1,\"26\":1,\"36\":1,\"75\":2,\"149\":1,\"156\":1,\"282\":1,\"304\":2,\"372\":1}}],[\"toolchoice\",{\"1\":{\"365\":3}}],[\"tools\",{\"1\":{\"98\":3}}],[\"tokens\",{\"1\":{\"372\":1}}],[\"token=fastgpt\",{\"1\":{\"366\":1}}],[\"token=none\",{\"1\":{\"366\":1}}],[\"token\",{\"1\":{\"365\":4,\"366\":2}}],[\"top\",{\"1\":{\"365\":1}}],[\"top命令解释\",{\"1\":{\"255\":1}}],[\"topo\",{\"0\":{\"175\":1},\"1\":{\"149\":1,\"175\":7,\"176\":8}}],[\"topology\",{\"1\":{\"62\":2}}],[\"topologyspreadconstraints\",{\"1\":{\"57\":1,\"58\":2}}],[\"topologykey\",{\"1\":{\"54\":2,\"58\":1}}],[\"torchfx\",{\"1\":{\"445\":3}}],[\"torchrun\",{\"1\":{\"445\":1}}],[\"torch\",{\"0\":{\"156\":1,\"161\":1,\"164\":1,\"167\":1},\"1\":{\"150\":1,\"152\":1,\"154\":2,\"156\":8,\"157\":1,\"158\":5,\"159\":1,\"160\":2,\"161\":2,\"162\":1,\"183\":3,\"202\":2,\"204\":2,\"444\":2,\"445\":1}}],[\"total\",{\"1\":{\"149\":2}}],[\"toleration\",{\"1\":{\"36\":1}}],[\"tolerations\",{\"1\":{\"36\":2}}],[\"to\",{\"1\":{\"5\":1,\"62\":3,\"75\":1,\"143\":1,\"149\":2,\"150\":3,\"156\":1,\"175\":2,\"199\":1,\"205\":1,\"212\":3,\"366\":1,\"382\":3}}],[\"todo\",{\"1\":{\"5\":2}}],[\"tonistiigi\",{\"1\":{\"1\":1}}],[\"two\",{\"1\":{\"5\":1,\"156\":1,\"175\":2}}],[\"t\",{\"1\":{\"2\":1,\"62\":9,\"150\":2,\"175\":1,\"258\":1,\"263\":1}}],[\"s带宽的两倍多\",{\"1\":{\"417\":1}}],[\"s的双向数据传输带宽\",{\"1\":{\"402\":1}}],[\"sringboot\",{\"0\":{\"387\":1}}],[\"src=0\",{\"1\":{\"183\":1}}],[\"src\",{\"1\":{\"97\":1,\"145\":3}}],[\"s3\",{\"1\":{\"381\":6,\"382\":3,\"383\":9}}],[\"s390x\",{\"1\":{\"1\":1}}],[\"sql\",{\"1\":{\"366\":1}}],[\"sleep\",{\"1\":{\"366\":1}}],[\"slash\",{\"1\":{\"249\":2}}],[\"snapshot\",{\"1\":{\"366\":1}}],[\"small\",{\"1\":{\"365\":2}}],[\"smtp\",{\"1\":{\"340\":1}}],[\"svg\",{\"1\":{\"365\":5}}],[\"svc\",{\"1\":{\"43\":1}}],[\"sy\",{\"1\":{\"255\":3}}],[\"sysinfo\",{\"1\":{\"62\":1}}],[\"systemenv\",{\"1\":{\"365\":1}}],[\"systems\",{\"1\":{\"309\":1}}],[\"systemctl\",{\"1\":{\"263\":1}}],[\"systemd=true\",{\"1\":{\"263\":1}}],[\"systemd\",{\"1\":{\"62\":2,\"263\":2}}],[\"system\",{\"1\":{\"32\":1,\"34\":1,\"175\":1,\"176\":1,\"255\":2,\"263\":2,\"422\":1,\"442\":1}}],[\"skill\",{\"2\":{\"244\":1}}],[\"skipped\",{\"1\":{\"94\":1}}],[\"sb\",{\"1\":{\"240\":1}}],[\"swintransformer\",{\"0\":{\"455\":1},\"1\":{\"450\":1,\"452\":1,\"453\":1,\"454\":1,\"455\":2,\"457\":1,\"458\":1,\"459\":3}}],[\"swin\",{\"0\":{\"435\":1},\"1\":{\"435\":1}}],[\"switch\",{\"1\":{\"176\":1,\"335\":1}}],[\"swaps\",{\"1\":{\"62\":1}}],[\"swap\",{\"1\":{\"62\":3}}],[\"sure\",{\"1\":{\"382\":1}}],[\"sub\",{\"1\":{\"433\":3,\"435\":1}}],[\"subscribe\",{\"1\":{\"372\":1}}],[\"submodule\",{\"1\":{\"168\":1}}],[\"sudo\",{\"1\":{\"255\":1,\"257\":2,\"258\":1,\"259\":2,\"260\":1,\"261\":1,\"319\":3,\"325\":2,\"328\":2,\"331\":3}}],[\"suffix\",{\"1\":{\"164\":2,\"165\":3}}],[\"sum\",{\"1\":{\"149\":21,\"150\":1,\"156\":1,\"158\":1,\"162\":2}}],[\"super\",{\"1\":{\"149\":1}}],[\"supported\",{\"1\":{\"62\":1}}],[\"succeeded\",{\"1\":{\"94\":1}}],[\"sdk\",{\"0\":{\"81\":1},\"1\":{\"89\":1,\"122\":1}}],[\"sdb\",{\"1\":{\"62\":1}}],[\"saving\",{\"1\":{\"393\":2,\"422\":1}}],[\"sample\",{\"1\":{\"389\":1}}],[\"same\",{\"1\":{\"175\":1}}],[\"sameorigin\",{\"1\":{\"75\":1}}],[\"sandbox\",{\"1\":{\"366\":8}}],[\"sanjay\",{\"1\":{\"139\":1}}],[\"sans\",{\"1\":{\"75\":1}}],[\"sagemaker\",{\"1\":{\"105\":1}}],[\"shell\",{\"1\":{\"381\":1}}],[\"sh脚本执行的mongodb服务进程\",{\"1\":{\"366\":1}}],[\"sh\",{\"1\":{\"366\":1,\"381\":1}}],[\"show命令用于查看linux桥接设备的前向数据库\",{\"1\":{\"301\":1}}],[\"show命令用于显示linux桥接设备的前向数据库\",{\"1\":{\"296\":1}}],[\"show命令的示例输出可能如下所示\",{\"1\":{\"297\":1}}],[\"show\",{\"0\":{\"294\":1,\"296\":1},\"1\":{\"279\":2,\"281\":1,\"282\":1,\"283\":2,\"294\":2,\"295\":1,\"299\":3,\"300\":3,\"325\":1,\"328\":1}}],[\"should\",{\"1\":{\"205\":1}}],[\"shutdown\",{\"1\":{\"263\":1,\"264\":1}}],[\"sharing\",{\"1\":{\"96\":1}}],[\"sharedrunserver\",{\"1\":{\"108\":1,\"109\":1}}],[\"sharedjobserver\",{\"1\":{\"108\":1,\"109\":1}}],[\"sharedpipelineserver\",{\"1\":{\"108\":1,\"109\":1}}],[\"sharedexperimentserver\",{\"1\":{\"108\":1,\"109\":1}}],[\"shared\",{\"1\":{\"75\":1}}],[\"shimmer\",{\"1\":{\"365\":3}}],[\"shim\",{\"1\":{\"61\":6}}],[\"ssa\",{\"1\":{\"449\":2}}],[\"sso\",{\"1\":{\"381\":1}}],[\"sslmode=disable\",{\"1\":{\"381\":1}}],[\"ssl\",{\"1\":{\"75\":6,\"339\":1}}],[\"ssd存储空间\",{\"1\":{\"412\":1}}],[\"ssd\",{\"1\":{\"56\":1,\"410\":1}}],[\"si\",{\"1\":{\"255\":3}}],[\"simd\",{\"1\":{\"186\":3}}],[\"single\",{\"1\":{\"156\":3,\"184\":1,\"186\":1,\"189\":1,\"372\":2}}],[\"size\",{\"1\":{\"75\":2,\"149\":1,\"161\":2,\"162\":2,\"199\":3,\"202\":1,\"203\":2,\"204\":2}}],[\"signature\",{\"1\":{\"156\":1}}],[\"sigs\",{\"1\":{\"98\":1,\"99\":1}}],[\"sig\",{\"1\":{\"61\":1}}],[\"songquanpeng\",{\"1\":{\"366\":1}}],[\"some\",{\"1\":{\"205\":1}}],[\"so\",{\"1\":{\"145\":5,\"149\":5,\"156\":1,\"205\":1}}],[\"sock\",{\"1\":{\"62\":2}}],[\"socket\",{\"1\":{\"62\":2,\"143\":1,\"149\":2}}],[\"software\",{\"1\":{\"372\":1,\"373\":1}}],[\"softirq\",{\"1\":{\"255\":2}}],[\"soft\",{\"1\":{\"51\":3}}],[\"soft=imagefs\",{\"1\":{\"51\":1}}],[\"steal\",{\"1\":{\"255\":1}}],[\"stepfactor\",{\"1\":{\"150\":1}}],[\"stepbytes\",{\"1\":{\"150\":1}}],[\"step\",{\"1\":{\"95\":1,\"149\":1}}],[\"st\",{\"1\":{\"255\":2}}],[\"std\",{\"1\":{\"161\":2}}],[\"strace\",{\"1\":{\"252\":1,\"253\":4,\"254\":1,\"255\":3}}],[\"strace命令\",{\"1\":{\"252\":1}}],[\"strategy\",{\"1\":{\"105\":1}}],[\"str``\",{\"1\":{\"205\":1}}],[\"stringequals\",{\"1\":{\"383\":1}}],[\"string\",{\"1\":{\"205\":2}}],[\"strings\",{\"1\":{\"205\":2}}],[\"struct\",{\"1\":{\"175\":1,\"176\":1}}],[\"str\",{\"1\":{\"167\":2,\"168\":2,\"169\":1,\"202\":3,\"205\":2,\"206\":2,\"207\":2}}],[\"streamlit\",{\"1\":{\"223\":1}}],[\"streams=none\",{\"1\":{\"156\":1}}],[\"streams\",{\"1\":{\"156\":2,\"158\":1,\"161\":6,\"162\":6,\"408\":1}}],[\"stream\",{\"1\":{\"61\":1,\"75\":1,\"156\":1,\"158\":1,\"161\":1,\"204\":1}}],[\"streaming\",{\"1\":{\"61\":8}}],[\"stg\",{\"1\":{\"97\":1}}],[\"storage之类的工件存储中\",{\"1\":{\"86\":1}}],[\"store\",{\"1\":{\"62\":1,\"75\":1,\"202\":2,\"203\":1,\"204\":6,\"366\":1}}],[\"style=1\",{\"1\":{\"381\":1}}],[\"style=\",{\"1\":{\"75\":1}}],[\"style>\",{\"1\":{\"75\":1}}],[\"staged\",{\"1\":{\"452\":1}}],[\"stage\",{\"1\":{\"451\":1,\"455\":1,\"456\":2,\"457\":1}}],[\"stages\",{\"1\":{\"433\":1}}],[\"standalone\",{\"1\":{\"366\":1}}],[\"stale\",{\"1\":{\"294\":2}}],[\"stacklevel=2\",{\"1\":{\"156\":2}}],[\"start\",{\"1\":{\"149\":1,\"366\":2,\"371\":1}}],[\"startrpcserver\",{\"1\":{\"107\":1,\"111\":1}}],[\"started\",{\"1\":{\"78\":1,\"381\":3}}],[\"starting\",{\"1\":{\"62\":1}}],[\"statement\",{\"1\":{\"383\":1}}],[\"state\",{\"1\":{\"212\":1,\"282\":2,\"283\":4}}],[\"stateful\",{\"1\":{\"42\":2,\"43\":8}}],[\"statefulset\",{\"0\":{\"41\":1,\"43\":1},\"1\":{\"37\":1,\"38\":2,\"39\":2,\"41\":1,\"43\":3,\"44\":1}}],[\"static\",{\"0\":{\"31\":1,\"32\":1},\"1\":{\"30\":2,\"31\":4,\"32\":3,\"33\":3,\"34\":5,\"145\":1}}],[\"status=1\",{\"1\":{\"62\":1}}],[\"status\",{\"0\":{\"11\":1},\"1\":{\"1\":1,\"11\":1,\"75\":1,\"97\":1,\"199\":1,\"366\":1}}],[\"spine层\",{\"1\":{\"347\":1}}],[\"spine\",{\"1\":{\"344\":1,\"345\":1,\"347\":2,\"348\":2,\"349\":1}}],[\"spine交换机位于网络的核心层\",{\"1\":{\"349\":1}}],[\"spine交换机位于网络的骨干层\",{\"1\":{\"347\":1}}],[\"spine交换机的数量通常比leaf交换机少\",{\"1\":{\"345\":1}}],[\"spine交换机的主要功能是提供高带宽和低延迟的骨干互联\",{\"1\":{\"345\":1}}],[\"spine交换机之间一般不直接连接\",{\"1\":{\"345\":1}}],[\"spine交换机通常具有非常高的端口密度和带宽\",{\"1\":{\"345\":1}}],[\"spine交换机\",{\"0\":{\"344\":1},\"1\":{\"344\":1}}],[\"spoofing\",{\"1\":{\"306\":1}}],[\"speech\",{\"1\":{\"372\":1}}],[\"spend\",{\"1\":{\"211\":1}}],[\"special\",{\"1\":{\"382\":1}}],[\"specify\",{\"1\":{\"156\":2}}],[\"specified\",{\"1\":{\"62\":1,\"98\":1,\"156\":1}}],[\"spec\",{\"1\":{\"20\":1,\"25\":1,\"32\":1,\"36\":2,\"40\":1,\"42\":1,\"43\":2,\"54\":1,\"56\":1,\"58\":1,\"98\":2}}],[\"spmd\",{\"0\":{\"185\":1,\"186\":1,\"191\":1},\"1\":{\"184\":2,\"185\":3,\"186\":2,\"187\":4,\"188\":1,\"189\":2,\"190\":1,\"191\":1,\"425\":1,\"451\":1,\"452\":1}}],[\"split\",{\"1\":{\"175\":1,\"176\":1,\"444\":1}}],[\"springboot\",{\"0\":{\"388\":1,\"389\":1,\"390\":1,\"470\":1},\"1\":{\"386\":1}}],[\"spring\",{\"1\":{\"128\":1,\"387\":1,\"389\":2}}],[\"spread\",{\"0\":{\"57\":1},\"1\":{\"175\":2}}],[\"sparkdesk\",{\"1\":{\"365\":1}}],[\"spark\",{\"1\":{\"91\":2}}],[\"s\",{\"1\":{\"36\":1,\"68\":1,\"70\":1,\"73\":1,\"108\":8,\"109\":4,\"110\":1,\"149\":4,\"417\":1,\"422\":1,\"437\":2}}],[\"scope\",{\"1\":{\"283\":2}}],[\"scoped\",{\"1\":{\"161\":1,\"162\":2}}],[\"scopes\",{\"1\":{\"21\":1}}],[\"scale\",{\"1\":{\"393\":2,\"422\":1}}],[\"scale=1\",{\"1\":{\"75\":1}}],[\"scalable\",{\"1\":{\"176\":1}}],[\"scatter\",{\"1\":{\"143\":2,\"164\":2,\"165\":4,\"196\":1}}],[\"schedule\",{\"1\":{\"433\":1}}],[\"scheduledworkflow\",{\"1\":{\"97\":3}}],[\"scheduler\",{\"0\":{\"59\":1},\"1\":{\"30\":1,\"33\":1,\"36\":1,\"60\":2}}],[\"scheduling\",{\"1\":{\"36\":1}}],[\"s1\",{\"1\":{\"5\":6}}],[\"seccomp\",{\"1\":{\"366\":1,\"372\":1}}],[\"security\",{\"1\":{\"366\":1,\"372\":1}}],[\"secret=dbf205949d704de81b0b5b3603174e23fbecc354\",{\"1\":{\"382\":1}}],[\"secret=qctusye5hezg1igy1bmbw4sngf+ybkckha4ghuyi6wy=\",{\"1\":{\"381\":1}}],[\"secret=kix2wcuond4cx51e\",{\"1\":{\"381\":1}}],[\"secret=oneapikey\",{\"1\":{\"366\":1}}],[\"secret\",{\"1\":{\"366\":1,\"382\":2}}],[\"seconds\",{\"1\":{\"372\":1}}],[\"second\",{\"1\":{\"175\":3}}],[\"sent\",{\"1\":{\"199\":1}}],[\"sender\",{\"1\":{\"304\":2}}],[\"send\",{\"1\":{\"149\":1,\"196\":1,\"199\":1}}],[\"sendfile\",{\"1\":{\"75\":1}}],[\"self\",{\"1\":{\"161\":1,\"162\":2,\"169\":1,\"297\":2,\"298\":1}}],[\"selector\",{\"1\":{\"36\":1,\"40\":1,\"42\":1,\"43\":1,\"98\":1}}],[\"sequence\",{\"1\":{\"156\":6,\"158\":4,\"161\":2}}],[\"search\",{\"1\":{\"105\":3,\"175\":1}}],[\"serif\",{\"1\":{\"75\":1}}],[\"servlets\",{\"1\":{\"393\":1}}],[\"servers\",{\"1\":{\"393\":2,\"422\":1}}],[\"server\",{\"0\":{\"210\":1},\"1\":{\"30\":1,\"31\":2,\"33\":1,\"36\":1,\"61\":10,\"62\":3,\"75\":3,\"97\":1,\"108\":4,\"210\":1,\"366\":1,\"381\":2,\"387\":1}}],[\"serviceaccountname\",{\"1\":{\"98\":1}}],[\"servicename\",{\"1\":{\"43\":1}}],[\"services\",{\"0\":{\"37\":1},\"1\":{\"20\":1,\"68\":1,\"69\":1,\"70\":1,\"71\":1,\"72\":1,\"366\":1,\"372\":1,\"381\":1,\"387\":1}}],[\"service\",{\"0\":{\"38\":1,\"40\":1,\"41\":1,\"42\":1},\"1\":{\"20\":2,\"37\":3,\"38\":4,\"39\":3,\"40\":4,\"41\":1,\"42\":2,\"43\":4,\"44\":2,\"62\":2,\"68\":2,\"69\":1,\"70\":1,\"71\":2,\"72\":1,\"117\":1,\"149\":2,\"381\":13,\"387\":1}}],[\"setup\",{\"1\":{\"212\":1}}],[\"set\",{\"1\":{\"62\":1,\"75\":7,\"149\":1,\"325\":2}}],[\"settings\",{\"1\":{\"62\":1}}],[\"session\",{\"0\":{\"338\":1},\"1\":{\"5\":2,\"75\":2,\"366\":1}}],[\"sessions\",{\"1\":{\"5\":1}}],[\"separate\",{\"1\":{\"5\":1}}],[\"vtensor6\",{\"1\":{\"444\":1}}],[\"vtensor5\",{\"1\":{\"444\":1}}],[\"vtensor4\",{\"1\":{\"444\":1}}],[\"vtensor3\",{\"1\":{\"444\":1}}],[\"vtensor\",{\"0\":{\"443\":1},\"1\":{\"442\":1,\"443\":14,\"444\":5}}],[\"vtep作为vxlan架构中的关键组件\",{\"1\":{\"293\":1}}],[\"vtep将该帧封装到一个udp包中\",{\"1\":{\"292\":1}}],[\"vtep通过监听网络流量和arp\",{\"1\":{\"291\":1}}],[\"vtep负责将二层网络中的vlan\",{\"1\":{\"291\":1}}],[\"vtep是vxlan隧道的起点和终点\",{\"1\":{\"291\":1}}],[\"vtep是vxlan架构中的关键组件\",{\"1\":{\"291\":1}}],[\"vtep\",{\"0\":{\"291\":1,\"292\":1},\"1\":{\"287\":1}}],[\"vdnn和superneurons等系统在运行时根据内存使用情况\",{\"1\":{\"418\":1}}],[\"v4\",{\"1\":{\"366\":2}}],[\"volumes\",{\"1\":{\"366\":8,\"381\":4}}],[\"voices\",{\"1\":{\"365\":1}}],[\"void\",{\"1\":{\"170\":3,\"171\":2,\"173\":1}}],[\"vpn\",{\"1\":{\"307\":2}}],[\"vni映射\",{\"1\":{\"291\":1}}],[\"vnet\",{\"1\":{\"2\":1}}],[\"vxlan和vtep的结合\",{\"1\":{\"293\":1}}],[\"vxlan通过在现有的三层ip网络上创建虚拟二层网络\",{\"1\":{\"293\":1}}],[\"vxlan通过udp隧道封装将二层以太网帧封装在三层ip包中\",{\"1\":{\"290\":1}}],[\"vxlan通过udp隧道封装\",{\"1\":{\"286\":1}}],[\"vxlan包封装\",{\"1\":{\"292\":1}}],[\"vxlan可以在现有的ip网络上实现二层网络的扩展和弹性\",{\"1\":{\"290\":1}}],[\"vxlan可以在现有的ip网络基础上创建虚拟网络\",{\"1\":{\"286\":1}}],[\"vxlan允许在同一个物理网络基础设施上运行多个独立的虚拟网络\",{\"1\":{\"290\":1}}],[\"vxlan是一种用于扩展二层网络的技术\",{\"1\":{\"290\":1}}],[\"vxlan是一种用于在大规模数据中心和云环境中创建虚拟网络的技术\",{\"1\":{\"286\":1}}],[\"vxlan与vtep\",{\"0\":{\"289\":1}}],[\"vxlan适用于大规模的分布式数据中心环境\",{\"1\":{\"286\":1}}],[\"vxlan使用24位的vni\",{\"1\":{\"286\":1,\"290\":1}}],[\"vxlan\",{\"0\":{\"286\":1,\"290\":1,\"291\":1,\"292\":1},\"1\":{\"286\":1,\"287\":1,\"290\":1}}],[\"vlan适用于较小规模的网络分段和隔离\",{\"1\":{\"288\":1}}],[\"vlan的配置相对简单\",{\"1\":{\"285\":1}}],[\"vlan使用ieee\",{\"1\":{\"285\":1}}],[\"vlan是一种用于在同一物理网络上创建多个逻辑网络的技术\",{\"1\":{\"285\":1}}],[\"vlan\",{\"0\":{\"284\":1,\"285\":1},\"1\":{\"284\":1,\"285\":1,\"287\":1,\"297\":2,\"298\":2}}],[\"vldb23\",{\"1\":{\"139\":1}}],[\"vgextend\",{\"1\":{\"259\":1}}],[\"vue\",{\"1\":{\"130\":1}}],[\"vii\",{\"0\":{\"419\":1}}],[\"vi\",{\"0\":{\"418\":1}}],[\"via\",{\"1\":{\"328\":1,\"393\":2,\"422\":1}}],[\"virtual\",{\"0\":{\"285\":1,\"286\":1,\"290\":1},\"1\":{\"176\":1,\"284\":2}}],[\"vision\",{\"1\":{\"365\":2,\"381\":1}}],[\"visibility\",{\"1\":{\"170\":1,\"171\":1}}],[\"visualizations\",{\"1\":{\"212\":1}}],[\"visualizationserviceport\",{\"1\":{\"108\":1}}],[\"visualizationservicehost\",{\"1\":{\"108\":1}}],[\"visualizationservice\",{\"1\":{\"108\":1,\"111\":1}}],[\"visualizationserver\",{\"1\":{\"97\":3}}],[\"visualize\",{\"1\":{\"212\":1}}],[\"viewer\",{\"1\":{\"97\":3}}],[\"viewport\",{\"1\":{\"75\":1}}],[\"vectormodels\",{\"1\":{\"365\":1}}],[\"vectormaxprocess\",{\"1\":{\"365\":1}}],[\"vector<std\",{\"1\":{\"161\":1}}],[\"vector<at\",{\"1\":{\"161\":1}}],[\"ve\",{\"1\":{\"212\":1}}],[\"vertical\",{\"1\":{\"249\":2}}],[\"verbs\",{\"1\":{\"143\":2}}],[\"version\",{\"1\":{\"75\":1,\"149\":1,\"164\":4,\"165\":6,\"264\":1,\"366\":1,\"372\":1,\"382\":1,\"383\":1}}],[\"veth1\",{\"1\":{\"282\":3,\"283\":3}}],[\"veth0\",{\"1\":{\"281\":1,\"282\":3}}],[\"vethc5ec3b7<0>\",{\"1\":{\"149\":1}}],[\"vethc5ec3b7\",{\"1\":{\"149\":1}}],[\"vethd14a450<0>\",{\"1\":{\"149\":1}}],[\"vethd14a450\",{\"1\":{\"149\":1}}],[\"veth\",{\"1\":{\"47\":1,\"48\":2,\"50\":1,\"279\":1,\"280\":1,\"282\":2}}],[\"vaults\",{\"1\":{\"381\":1}}],[\"valid\",{\"1\":{\"205\":1,\"283\":2}}],[\"validation\",{\"1\":{\"149\":1}}],[\"valueerror\",{\"1\":{\"150\":3,\"154\":3,\"156\":1}}],[\"valuefrom\",{\"1\":{\"98\":1}}],[\"values\",{\"1\":{\"54\":1,\"56\":1,\"149\":1,\"205\":1}}],[\"value\",{\"1\":{\"36\":2,\"205\":1,\"365\":6}}],[\"variables\",{\"1\":{\"382\":3}}],[\"varargs\",{\"1\":{\"164\":6,\"165\":6}}],[\"var\",{\"1\":{\"62\":3,\"366\":2,\"381\":1}}],[\"v100\",{\"1\":{\"410\":1,\"454\":1}}],[\"v1beta1\",{\"0\":{\"108\":1},\"1\":{\"48\":1,\"111\":8}}],[\"v1\",{\"1\":{\"20\":1,\"25\":1,\"32\":1,\"36\":1,\"40\":1,\"42\":1,\"43\":1,\"54\":1,\"56\":1,\"58\":1,\"60\":1,\"98\":1,\"223\":1,\"366\":2,\"372\":2,\"373\":1,\"375\":1,\"382\":1,\"410\":1}}],[\"v\",{\"0\":{\"417\":1},\"1\":{\"17\":3,\"66\":2,\"331\":1,\"375\":2}}],[\"v6\",{\"1\":{\"1\":1}}],[\"v7\",{\"1\":{\"1\":1}}],[\"v3\",{\"1\":{\"1\":1,\"365\":1,\"366\":1}}],[\"v2ray\",{\"2\":{\"137\":1}}],[\"v2beta1\",{\"0\":{\"109\":1},\"1\":{\"111\":4}}],[\"v2\",{\"1\":{\"1\":1,\"366\":1,\"454\":1}}],[\"v0\",{\"1\":{\"1\":1,\"366\":2}}],[\"a2\",{\"1\":{\"444\":1}}],[\"a1\",{\"1\":{\"444\":1,\"452\":3}}],[\"a100\",{\"1\":{\"249\":1,\"410\":1,\"417\":1}}],[\"aq0uogrk8ujsazfy3e986c5993bb4af3a9c3eb20708144f4\",{\"1\":{\"366\":1}}],[\"audiospeechmodels\",{\"1\":{\"365\":1}}],[\"authorization\",{\"1\":{\"387\":1}}],[\"authz\",{\"1\":{\"387\":1}}],[\"auth\",{\"0\":{\"386\":1},\"1\":{\"381\":5,\"382\":2,\"386\":1},\"2\":{\"391\":1,\"392\":1}}],[\"authentication\",{\"1\":{\"366\":1}}],[\"authenticationdatabase\",{\"1\":{\"366\":2}}],[\"authsource=admin\",{\"1\":{\"366\":1}}],[\"authservice\",{\"1\":{\"108\":1,\"111\":1}}],[\"autograd\",{\"1\":{\"445\":1}}],[\"autonomous\",{\"1\":{\"309\":1}}],[\"autoscaler\",{\"1\":{\"212\":1}}],[\"auto\",{\"1\":{\"161\":2,\"366\":2}}],[\"automl\",{\"1\":{\"105\":3,\"106\":1}}],[\"aka\",{\"1\":{\"359\":2}}],[\"aws\",{\"1\":{\"383\":6,\"417\":1}}],[\"awselasticblockstore\",{\"1\":{\"10\":1}}],[\"awesome\",{\"1\":{\"217\":1}}],[\"assign\",{\"0\":{\"430\":1},\"1\":{\"424\":1,\"428\":1,\"430\":1,\"433\":4,\"439\":2,\"444\":1}}],[\"assign和op\",{\"1\":{\"423\":1}}],[\"assume\",{\"1\":{\"205\":1}}],[\"asn\",{\"1\":{\"310\":1}}],[\"as\",{\"1\":{\"183\":1,\"205\":2,\"212\":1,\"263\":1,\"309\":1,\"310\":1,\"382\":1}}],[\"asynchronous\",{\"1\":{\"139\":1}}],[\"attention\",{\"1\":{\"455\":1}}],[\"attn\",{\"1\":{\"435\":3}}],[\"attributes\",{\"1\":{\"205\":1}}],[\"attribute\",{\"1\":{\"170\":1,\"171\":1}}],[\"atc2024\",{\"1\":{\"139\":1}}],[\"able\",{\"1\":{\"212\":1}}],[\"abc\",{\"1\":{\"156\":1}}],[\"absolute\",{\"1\":{\"75\":1}}],[\"analysis\",{\"1\":{\"457\":1}}],[\"any\",{\"1\":{\"202\":1}}],[\"an\",{\"1\":{\"156\":2,\"205\":1}}],[\"and\",{\"1\":{\"156\":2,\"175\":1,\"176\":1,\"205\":2,\"433\":1}}],[\"anti\",{\"0\":{\"53\":1}}],[\"avatar\",{\"1\":{\"365\":5}}],[\"available=2m\",{\"1\":{\"51\":3}}],[\"available<30\",{\"1\":{\"51\":1}}],[\"available<5\",{\"1\":{\"51\":1}}],[\"available<500mi\",{\"1\":{\"51\":1}}],[\"available<15\",{\"1\":{\"51\":1}}],[\"available<10\",{\"1\":{\"51\":3}}],[\"available<100mi\",{\"1\":{\"51\":1}}],[\"available\",{\"1\":{\"12\":1,\"16\":2,\"17\":2,\"36\":2,\"51\":3,\"62\":1,\"205\":1}}],[\"average\",{\"1\":{\"150\":1,\"211\":1}}],[\"avg\",{\"1\":{\"149\":1,\"150\":1}}],[\"a\",{\"0\":{\"404\":1,\"410\":1},\"1\":{\"145\":1,\"150\":3,\"156\":4,\"283\":1,\"321\":1,\"322\":1,\"331\":1,\"332\":2,\"429\":2,\"433\":1,\"443\":2,\"444\":1}}],[\"admin\",{\"1\":{\"366\":2,\"387\":1}}],[\"administrator\",{\"1\":{\"242\":2}}],[\"advertise\",{\"1\":{\"366\":1}}],[\"ada\",{\"1\":{\"365\":1}}],[\"adaptation\",{\"1\":{\"105\":1}}],[\"add\",{\"1\":{\"75\":13,\"282\":1,\"328\":1,\"449\":1}}],[\"address=http\",{\"1\":{\"366\":1}}],[\"address\",{\"1\":{\"291\":1,\"302\":1,\"304\":6,\"366\":2,\"381\":2}}],[\"addr\",{\"1\":{\"75\":2}}],[\"amd\",{\"1\":{\"446\":1}}],[\"amd64\",{\"1\":{\"1\":3}}],[\"amazon\",{\"1\":{\"105\":1}}],[\"azure\",{\"1\":{\"105\":1}}],[\"azuredisk和cinder类型的pv支持delete策略\",{\"1\":{\"10\":1}}],[\"ai大模型部署\",{\"0\":{\"469\":1}}],[\"aigc\",{\"2\":{\"377\":1,\"384\":1}}],[\"ai助手百科全书\",{\"1\":{\"372\":1}}],[\"ai模型的api\",{\"1\":{\"366\":1}}],[\"ai模型的api地址哦\",{\"1\":{\"366\":1}}],[\"aifoundation\",{\"1\":{\"232\":1}}],[\"ai\",{\"1\":{\"105\":1,\"106\":1,\"232\":5,\"233\":2,\"364\":1,\"371\":1,\"372\":2,\"429\":1},\"2\":{\"213\":1}}],[\"aggregation\",{\"1\":{\"176\":1}}],[\"agg\",{\"1\":{\"149\":1,\"150\":1}}],[\"ago\",{\"1\":{\"97\":1}}],[\"agent\",{\"1\":{\"223\":1,\"224\":3}}],[\"age\",{\"1\":{\"36\":1,\"75\":1,\"97\":1}}],[\"a><\",{\"1\":{\"75\":1}}],[\"algos\",{\"1\":{\"429\":1}}],[\"algo\",{\"1\":{\"429\":2,\"433\":1}}],[\"algbw\",{\"1\":{\"149\":2}}],[\"alphafold2\",{\"0\":{\"437\":1,\"457\":1},\"1\":{\"426\":1,\"437\":1,\"450\":1,\"451\":1,\"453\":1,\"454\":1,\"457\":3,\"458\":2,\"459\":2}}],[\"alpa\",{\"1\":{\"425\":2,\"427\":1,\"450\":1,\"454\":2,\"455\":1,\"456\":2,\"458\":1}}],[\"alpine\",{\"1\":{\"381\":1}}],[\"aliyuncs\",{\"1\":{\"366\":4,\"372\":1,\"373\":1}}],[\"alive\",{\"1\":{\"269\":1}}],[\"align\",{\"1\":{\"75\":2}}],[\"also\",{\"1\":{\"205\":1}}],[\"always\",{\"1\":{\"75\":1,\"366\":5,\"381\":3}}],[\"alltoall\",{\"1\":{\"444\":2}}],[\"all>\",{\"1\":{\"150\":3}}],[\"alloy\",{\"1\":{\"365\":3}}],[\"alloc\",{\"1\":{\"149\":1}}],[\"allow\",{\"1\":{\"75\":4,\"381\":1,\"383\":3}}],[\"allgathers\",{\"1\":{\"149\":1}}],[\"allgather\",{\"1\":{\"143\":1,\"444\":1}}],[\"allreduce操作\",{\"1\":{\"181\":1}}],[\"allreduce\",{\"1\":{\"143\":2,\"150\":1,\"161\":1,\"444\":1,\"448\":1}}],[\"all\",{\"1\":{\"1\":1,\"143\":4,\"149\":2,\"164\":4,\"165\":6,\"175\":1,\"375\":1}}],[\"affinity\",{\"0\":{\"53\":1,\"55\":1},\"1\":{\"54\":1,\"55\":1,\"56\":1}}],[\"apt\",{\"1\":{\"239\":1}}],[\"application\",{\"0\":{\"340\":1},\"1\":{\"75\":1,\"98\":3,\"99\":1}}],[\"app=myapp\",{\"1\":{\"54\":1}}],[\"app\",{\"1\":{\"36\":2,\"40\":4,\"42\":2,\"43\":7,\"54\":1,\"58\":1,\"98\":1,\"366\":1,\"368\":1,\"381\":1}}],[\"apps\",{\"1\":{\"36\":1,\"43\":1,\"98\":1}}],[\"apikey\",{\"1\":{\"372\":1}}],[\"apiv2beta1\",{\"1\":{\"109\":4}}],[\"apiv1beta1\",{\"1\":{\"108\":8}}],[\"apiversion\",{\"1\":{\"20\":1,\"25\":1,\"32\":1,\"36\":1,\"40\":1,\"42\":1,\"43\":1,\"48\":1,\"54\":1,\"56\":1,\"58\":1,\"60\":1,\"98\":1}}],[\"api服务器以创建运行管道所需的必要kubernetes资源\",{\"1\":{\"84\":1}}],[\"apiserver\",{\"1\":{\"30\":1,\"33\":1,\"97\":1}}],[\"api\",{\"0\":{\"108\":1,\"109\":1},\"1\":{\"30\":1,\"31\":2,\"33\":1,\"61\":10,\"91\":1,\"95\":1,\"96\":1,\"97\":2,\"103\":2,\"116\":1,\"118\":1,\"122\":1,\"143\":3,\"150\":1,\"154\":1,\"156\":1,\"158\":1,\"159\":3,\"161\":1,\"162\":1,\"164\":1,\"172\":1,\"195\":1,\"223\":4,\"366\":4,\"372\":4,\"381\":3,\"382\":2}}],[\"action\",{\"1\":{\"383\":3}}],[\"ac\",{\"1\":{\"297\":2}}],[\"accept\",{\"1\":{\"331\":2}}],[\"accepts\",{\"1\":{\"205\":1}}],[\"accessed\",{\"1\":{\"205\":1}}],[\"access\",{\"0\":{\"9\":1},\"1\":{\"75\":7,\"350\":1,\"366\":1,\"382\":3}}],[\"acquired\",{\"1\":{\"5\":1}}],[\"acquire\",{\"1\":{\"5\":1}}],[\"arn\",{\"1\":{\"383\":3}}],[\"arp检测\",{\"1\":{\"307\":1}}],[\"arp欺骗的防御措施\",{\"0\":{\"307\":1}}],[\"arp的安全问题\",{\"0\":{\"306\":1}}],[\"arp缓存中的条目通常有一个生存时间\",{\"1\":{\"305\":1}}],[\"arp请求中该字段为空\",{\"1\":{\"304\":1}}],[\"arp请求和arp响应\",{\"1\":{\"304\":1}}],[\"arp报文包含两个主要部分\",{\"1\":{\"304\":1}}],[\"arp\",{\"0\":{\"303\":1,\"304\":1,\"305\":1},\"1\":{\"302\":1,\"303\":2,\"306\":1}}],[\"arp协议在ipv4网络中起到了关键的地址解析作用\",{\"1\":{\"308\":1}}],[\"arp协议本身没有安全机制\",{\"1\":{\"306\":1}}],[\"arp协议\",{\"0\":{\"302\":1}}],[\"argv\",{\"1\":{\"199\":2}}],[\"argc\",{\"1\":{\"199\":2}}],[\"argument\",{\"1\":{\"156\":1}}],[\"arguments\",{\"1\":{\"156\":2}}],[\"argo\",{\"0\":{\"96\":1},\"1\":{\"95\":3,\"97\":2,\"106\":1}}],[\"args\",{\"1\":{\"36\":1,\"150\":1,\"161\":3,\"162\":4}}],[\"artifact\",{\"1\":{\"95\":1}}],[\"artifacts\",{\"1\":{\"86\":1}}],[\"arial\",{\"1\":{\"75\":1}}],[\"area\",{\"0\":{\"285\":1},\"1\":{\"284\":1}}],[\"are\",{\"1\":{\"36\":2,\"205\":1,\"382\":1}}],[\"architecture\",{\"1\":{\"105\":2}}],[\"arch\",{\"1\":{\"2\":1}}],[\"arm\",{\"1\":{\"1\":2}}],[\"arm64\",{\"1\":{\"1\":1,\"2\":1}}],[\"lm和alpa\",{\"1\":{\"424\":1}}],[\"lm和alpa等解决方案相比\",{\"1\":{\"423\":1}}],[\"lm\",{\"1\":{\"398\":1,\"418\":1,\"425\":3,\"427\":1,\"450\":1,\"454\":4,\"455\":1,\"456\":1,\"458\":1}}],[\"lvextend\",{\"1\":{\"260\":1}}],[\"lvm\",{\"0\":{\"258\":1,\"259\":1},\"1\":{\"256\":1,\"258\":2,\"259\":2}}],[\"lladdr\",{\"1\":{\"294\":2}}],[\"llama3\",{\"1\":{\"224\":1}}],[\"llama\",{\"1\":{\"220\":1}}],[\"llms\",{\"1\":{\"426\":1}}],[\"llmmodels\",{\"1\":{\"365\":1}}],[\"llm\",{\"0\":{\"223\":1},\"1\":{\"220\":4,\"223\":9,\"224\":1,\"225\":1,\"226\":5,\"245\":1,\"248\":1,\"249\":2,\"381\":1,\"436\":1}}],[\"llm推理和部署理论与实践\",{\"1\":{\"219\":1}}],[\"lft\",{\"1\":{\"283\":4}}],[\"lf\",{\"1\":{\"145\":1}}],[\"l\",{\"1\":{\"62\":1,\"260\":1,\"331\":1}}],[\"large\",{\"1\":{\"365\":3}}],[\"laf环境\",{\"1\":{\"365\":1}}],[\"laf\",{\"1\":{\"365\":4}}],[\"lafenv\",{\"1\":{\"365\":1}}],[\"label\",{\"1\":{\"365\":6}}],[\"labelselector\",{\"1\":{\"54\":1,\"58\":1}}],[\"labels\",{\"1\":{\"36\":1,\"43\":1,\"98\":2}}],[\"labring\",{\"1\":{\"363\":1,\"366\":2}}],[\"lan\",{\"0\":{\"286\":1,\"290\":1},\"1\":{\"284\":1}}],[\"langchain\",{\"0\":{\"223\":1},\"1\":{\"220\":1,\"223\":2}}],[\"lang=\",{\"1\":{\"75\":1}}],[\"layer\",{\"0\":{\"334\":1,\"335\":1,\"336\":1,\"337\":1,\"338\":1,\"339\":1,\"340\":1},\"1\":{\"255\":1}}],[\"latest\",{\"1\":{\"32\":1,\"66\":1,\"366\":2}}],[\"leaf组网架构是一种扁平化\",{\"1\":{\"349\":1}}],[\"leaf和spine交换机之间形成多条等价路径\",{\"1\":{\"347\":1}}],[\"leaf层\",{\"1\":{\"347\":1}}],[\"leaf架构\",{\"1\":{\"348\":1}}],[\"leaf架构提供了高效的网络通信\",{\"1\":{\"348\":1}}],[\"leaf架构非常适合现代云计算和大数据中心\",{\"1\":{\"348\":1}}],[\"leaf架构可以在多个等价路径上分配流量\",{\"1\":{\"347\":1}}],[\"leaf架构采用了一种扁平化的双层网络拓扑\",{\"1\":{\"347\":1}}],[\"leaf架构中\",{\"1\":{\"345\":1,\"346\":1}}],[\"leaf交换机位于接入层\",{\"1\":{\"349\":1}}],[\"leaf交换机位于网络的接入层\",{\"1\":{\"347\":1}}],[\"leaf交换机数量通常较多\",{\"1\":{\"346\":1}}],[\"leaf交换机负责将服务器\",{\"1\":{\"346\":1}}],[\"leaf交换机主要用于南北向流量转发\",{\"1\":{\"346\":1}}],[\"leaf交换机\",{\"1\":{\"344\":1}}],[\"leaf\",{\"0\":{\"344\":1},\"1\":{\"344\":1,\"346\":1}}],[\"leaseid\",{\"1\":{\"5\":1}}],[\"lease\",{\"1\":{\"5\":2}}],[\"length\",{\"1\":{\"75\":2,\"304\":2}}],[\"level=warn\",{\"1\":{\"366\":1}}],[\"level=info\",{\"1\":{\"366\":1}}],[\"level=high\",{\"1\":{\"36\":2}}],[\"levelsio\",{\"1\":{\"359\":2}}],[\"level\",{\"1\":{\"36\":2}}],[\"live\",{\"1\":{\"366\":1}}],[\"like\",{\"1\":{\"205\":1}}],[\"listbucket\",{\"1\":{\"383\":1}}],[\"list=\",{\"1\":{\"382\":1}}],[\"list\",{\"1\":{\"156\":4,\"207\":1,\"263\":1,\"368\":1,\"372\":1}}],[\"listen\",{\"1\":{\"75\":1,\"366\":1}}],[\"lin\",{\"1\":{\"422\":1}}],[\"linkai\",{\"1\":{\"372\":2}}],[\"link=30\",{\"1\":{\"366\":1}}],[\"link\",{\"0\":{\"335\":1},\"1\":{\"176\":1,\"279\":2,\"281\":1,\"282\":2,\"283\":9,\"324\":1,\"325\":3,\"332\":2,\"371\":1}}],[\"lineage\",{\"1\":{\"95\":1}}],[\"linear\",{\"1\":{\"75\":1}}],[\"linux\",{\"1\":{\"1\":12,\"2\":1,\"220\":2,\"255\":5,\"258\":2,\"330\":1}}],[\"library\",{\"1\":{\"161\":1,\"164\":1,\"175\":1}}],[\"libibverbs\",{\"1\":{\"149\":1}}],[\"libnccl\",{\"1\":{\"145\":6,\"149\":4}}],[\"lib\",{\"1\":{\"62\":1,\"145\":1,\"366\":2,\"381\":1}}],[\"limitrange\",{\"1\":{\"25\":2}}],[\"limitranges\",{\"0\":{\"23\":1},\"1\":{\"17\":1,\"23\":2,\"24\":1,\"28\":1}}],[\"limits\",{\"1\":{\"20\":2,\"25\":2,\"36\":1,\"51\":1,\"98\":1}}],[\"longrope\",{\"1\":{\"446\":1}}],[\"lobehub\",{\"1\":{\"381\":1}}],[\"lobe\",{\"1\":{\"381\":17,\"382\":4,\"383\":4}}],[\"lobechat\",{\"0\":{\"379\":1},\"1\":{\"379\":1,\"380\":1,\"381\":1},\"2\":{\"385\":1}}],[\"loopback\",{\"1\":{\"283\":2}}],[\"lo\",{\"1\":{\"283\":2}}],[\"lower\",{\"1\":{\"282\":2,\"283\":2}}],[\"lowercase\",{\"1\":{\"205\":2}}],[\"lora\",{\"1\":{\"220\":1}}],[\"load\",{\"1\":{\"167\":2,\"168\":2,\"169\":1}}],[\"loading\",{\"1\":{\"62\":1}}],[\"location\",{\"1\":{\"75\":1}}],[\"localrank\",{\"1\":{\"149\":1}}],[\"localranks\",{\"1\":{\"149\":1}}],[\"localhost\",{\"1\":{\"68\":1,\"69\":1,\"70\":1,\"71\":1,\"72\":1,\"73\":1,\"74\":1,\"75\":1,\"366\":2,\"368\":1,\"369\":1,\"382\":2}}],[\"local\",{\"0\":{\"285\":1},\"1\":{\"43\":1,\"150\":1,\"284\":1,\"310\":1,\"381\":3,\"382\":1}}],[\"lock\",{\"1\":{\"5\":11}}],[\"logto\",{\"0\":{\"389\":1}}],[\"logo\",{\"1\":{\"365\":1}}],[\"logger\",{\"1\":{\"202\":2}}],[\"logs\",{\"0\":{\"61\":1},\"1\":{\"34\":1}}],[\"log\",{\"1\":{\"5\":4,\"75\":2,\"366\":2}}],[\"lsy\",{\"1\":{\"375\":1}}],[\"ls\",{\"1\":{\"1\":1}}],[\"0等软件\",{\"1\":{\"410\":1}}],[\"0a\",{\"1\":{\"294\":8}}],[\"0的张量值广播到所有进程\",{\"1\":{\"183\":1}}],[\"0>\",{\"1\":{\"150\":1}}],[\"0=无限循环\",{\"1\":{\"150\":1}}],[\"09\",{\"1\":{\"149\":3}}],[\"08\",{\"1\":{\"149\":1}}],[\"06\",{\"1\":{\"149\":3}}],[\"05\",{\"1\":{\"149\":2}}],[\"04\",{\"1\":{\"149\":3,\"264\":5,\"410\":1}}],[\"03d\",{\"1\":{\"242\":1}}],[\"03\",{\"1\":{\"149\":2,\"297\":1,\"366\":1}}],[\"02\",{\"1\":{\"149\":2,\"294\":6,\"297\":3}}],[\"01\",{\"1\":{\"149\":4,\"294\":2,\"297\":3,\"298\":1}}],[\"002\",{\"1\":{\"365\":1}}],[\"00\",{\"1\":{\"149\":53,\"283\":24,\"297\":8,\"298\":3}}],[\"000\",{\"1\":{\"445\":1}}],[\"000000\",{\"1\":{\"149\":2}}],[\"000096\",{\"1\":{\"149\":1}}],[\"000019\",{\"1\":{\"149\":1}}],[\"000105\",{\"1\":{\"149\":1}}],[\"000344\",{\"1\":{\"149\":1}}],[\"0x89b784d33d72ebbb\",{\"1\":{\"149\":2}}],[\"0x559205409610\",{\"1\":{\"149\":4}}],[\"0x01\",{\"1\":{\"149\":1}}],[\"07\",{\"1\":{\"62\":16,\"149\":2}}],[\"0\",{\"1\":{\"1\":1,\"5\":1,\"36\":2,\"43\":1,\"75\":4,\"97\":12,\"98\":3,\"149\":246,\"150\":6,\"156\":1,\"158\":1,\"160\":5,\"161\":2,\"183\":2,\"199\":7,\"204\":1,\"269\":1,\"283\":2,\"319\":1,\"328\":2,\"365\":7,\"366\":9,\"372\":1,\"398\":1,\"410\":2,\"411\":2,\"412\":2,\"414\":1,\"433\":2,\"454\":1}}],[\"7×\",{\"1\":{\"450\":1}}],[\"7的242gb模型数据应用gpu\",{\"1\":{\"416\":1}}],[\"70\",{\"1\":{\"412\":1}}],[\"700\",{\"1\":{\"365\":1}}],[\"7倍\",{\"1\":{\"411\":1}}],[\"7e\",{\"1\":{\"283\":2}}],[\"7890\",{\"1\":{\"382\":2}}],[\"7897\",{\"1\":{\"366\":2}}],[\"78\",{\"1\":{\"149\":1}}],[\"78d9bcc678\",{\"1\":{\"97\":2}}],[\"77gb\",{\"1\":{\"410\":1}}],[\"77\",{\"1\":{\"149\":1}}],[\"77d684cf4\",{\"1\":{\"97\":2}}],[\"71\",{\"1\":{\"149\":1}}],[\"72\",{\"1\":{\"149\":1}}],[\"725\",{\"1\":{\"62\":1}}],[\"799c5f4b48\",{\"1\":{\"97\":2}}],[\"798ad6b0ce9f\",{\"1\":{\"1\":1}}],[\"7cc7c5b47\",{\"1\":{\"97\":2}}],[\"7c6vk\",{\"1\":{\"97\":2}}],[\"7d7dffdb8f\",{\"1\":{\"97\":2}}],[\"74f5\",{\"1\":{\"149\":1}}],[\"74\",{\"1\":{\"62\":1}}],[\"7\",{\"0\":{\"72\":1,\"274\":1,\"340\":1,\"445\":1,\"446\":1,\"447\":1,\"448\":1,\"449\":1},\"1\":{\"1\":1,\"149\":1,\"366\":2,\"410\":1,\"416\":1,\"437\":2,\"452\":1,\"455\":2,\"458\":1,\"459\":3}}],[\"np\",{\"1\":{\"440\":1}}],[\"nnscaler能够在这些新的搜索空间中找到高效的并行化计划\",{\"1\":{\"424\":1}}],[\"nnscaler能够在新的搜索空间中找到并行化计划\",{\"1\":{\"423\":1}}],[\"nnscaler有效地避免了搜索空间爆炸的问题\",{\"1\":{\"424\":1}}],[\"nnscaler的核心思想是通过三个基本原语\",{\"1\":{\"424\":1}}],[\"nnscaler不仅可以重现现有的搜索空间\",{\"1\":{\"424\":1}}],[\"nnscaler不仅可以构建现有的搜索空间\",{\"1\":{\"423\":1}}],[\"nnscaler不依赖现有的搜索空间\",{\"1\":{\"423\":1}}],[\"nnscaler允许在构建空间时对这些原语应用约束\",{\"1\":{\"423\":1}}],[\"nnscaler\",{\"0\":{\"422\":1,\"447\":1},\"1\":{\"428\":1,\"429\":2,\"431\":2,\"432\":1,\"436\":1,\"438\":2,\"439\":1,\"441\":1,\"442\":4,\"443\":3,\"444\":4,\"445\":6,\"446\":3,\"447\":3,\"448\":1,\"449\":1,\"450\":3,\"451\":7,\"452\":1,\"454\":2,\"455\":3,\"456\":2,\"457\":3,\"458\":4,\"459\":1},\"2\":{\"460\":1,\"461\":1}}],[\"nnodes\",{\"1\":{\"149\":1}}],[\"nsf\",{\"1\":{\"393\":1}}],[\"ns1\",{\"1\":{\"283\":3}}],[\"n输入\",{\"1\":{\"372\":1}}],[\"n支持tool\",{\"1\":{\"372\":1}}],[\"n支持图片输出\",{\"1\":{\"372\":1}}],[\"n支持图片输入\",{\"1\":{\"372\":1}}],[\"n支持语音对话\",{\"1\":{\"372\":1}}],[\"n这里是chatgpt\",{\"1\":{\"372\":1}}],[\"n积分\",{\"1\":{\"365\":2}}],[\"nlp\",{\"1\":{\"218\":3}}],[\"nranks\",{\"1\":{\"149\":5}}],[\"ngpus\",{\"1\":{\"149\":1,\"150\":1}}],[\"nginx容器\",{\"1\":{\"75\":1}}],[\"nginx容器启动\",{\"0\":{\"66\":1}}],[\"nginx\",{\"1\":{\"32\":2,\"36\":4,\"66\":8,\"68\":1,\"75\":1},\"2\":{\"77\":1}}],[\"nthreads\",{\"1\":{\"150\":1}}],[\"nthread\",{\"1\":{\"149\":1}}],[\"ni\",{\"1\":{\"255\":1}}],[\"nice\",{\"1\":{\"255\":2}}],[\"nic流量分布在两个gpu之间\",{\"1\":{\"176\":2}}],[\"nic\",{\"1\":{\"175\":4,\"351\":1,\"353\":1}}],[\"nickel\",{\"1\":{\"143\":1}}],[\"nil\",{\"1\":{\"5\":5}}],[\"nvme0n1\",{\"1\":{\"257\":1,\"258\":1}}],[\"nvme0n1p1\",{\"1\":{\"256\":2,\"257\":4,\"258\":2,\"259\":2,\"262\":1}}],[\"nvmldev\",{\"1\":{\"149\":2}}],[\"nv\",{\"1\":{\"211\":4}}],[\"nvls+tree\",{\"1\":{\"175\":1}}],[\"nvls+sharp\",{\"1\":{\"175\":1}}],[\"nvls\",{\"1\":{\"149\":1,\"175\":1,\"176\":1}}],[\"nvlink\",{\"0\":{\"352\":1,\"353\":1},\"1\":{\"143\":2,\"350\":1,\"352\":3,\"353\":1,\"354\":4,\"355\":1,\"356\":3,\"417\":1,\"454\":1}}],[\"nvidia的grace\",{\"1\":{\"417\":1}}],[\"nvidia的p100\",{\"1\":{\"402\":1}}],[\"nvidia\",{\"1\":{\"143\":1,\"144\":1,\"147\":1,\"149\":1,\"161\":1,\"164\":1,\"175\":1,\"176\":1,\"204\":1,\"352\":2,\"446\":1,\"454\":1}}],[\"nvswitch\",{\"0\":{\"352\":1,\"353\":1},\"1\":{\"143\":1,\"350\":1,\"352\":2,\"353\":1,\"354\":4,\"355\":1,\"356\":3}}],[\"nv8km\",{\"1\":{\"97\":2}}],[\"nccl``\",{\"1\":{\"205\":1}}],[\"ncclcommsplit\",{\"1\":{\"204\":1}}],[\"ncclcomminitall\",{\"1\":{\"149\":3}}],[\"nccl提供了多种通信模式\",{\"1\":{\"176\":1}}],[\"nccltoposystem\",{\"1\":{\"175\":1,\"176\":1}}],[\"nccltoposearchinit\",{\"1\":{\"175\":1,\"176\":1}}],[\"nccltopocompute\",{\"1\":{\"175\":1,\"176\":1}}],[\"ncclresult\",{\"1\":{\"175\":1}}],[\"nccl是一款独立的库\",{\"1\":{\"143\":1}}],[\"nccl\",{\"0\":{\"142\":1,\"143\":1,\"146\":1,\"156\":1,\"161\":1,\"175\":1},\"1\":{\"142\":1,\"143\":22,\"144\":1,\"145\":3,\"147\":1,\"148\":1,\"149\":57,\"150\":3,\"156\":3,\"157\":1,\"159\":2,\"161\":6,\"162\":7,\"163\":3,\"164\":22,\"165\":35,\"166\":3,\"175\":8,\"176\":7,\"181\":1,\"204\":9,\"205\":1,\"206\":2,\"207\":3,\"410\":1,\"454\":1},\"2\":{\"178\":1,\"179\":1}}],[\"native\",{\"1\":{\"366\":1}}],[\"nacos\",{\"1\":{\"128\":1}}],[\"nas\",{\"1\":{\"105\":1}}],[\"name>\",{\"1\":{\"171\":1}}],[\"name=lobechat\",{\"1\":{\"382\":1}}],[\"name=hello\",{\"1\":{\"68\":1,\"71\":1}}],[\"name=\",{\"1\":{\"62\":1,\"75\":1}}],[\"namespace\",{\"1\":{\"18\":1,\"20\":2,\"25\":2,\"32\":1,\"40\":1,\"42\":1,\"43\":1,\"96\":1,\"98\":2}}],[\"name\",{\"1\":{\"1\":1,\"20\":1,\"25\":1,\"32\":2,\"36\":3,\"40\":2,\"42\":2,\"43\":2,\"54\":1,\"56\":1,\"58\":2,\"60\":1,\"66\":1,\"75\":1,\"97\":1,\"98\":3,\"167\":4,\"168\":7,\"169\":2,\"202\":1,\"204\":1,\"282\":1,\"365\":7,\"366\":8,\"372\":3,\"375\":1,\"381\":8}}],[\"nullptr\",{\"1\":{\"161\":6,\"162\":1,\"164\":9,\"165\":9}}],[\"null\",{\"1\":{\"75\":1,\"366\":1,\"381\":1}}],[\"necessary\",{\"1\":{\"382\":1}}],[\"needed\",{\"1\":{\"382\":1}}],[\"need\",{\"1\":{\"382\":2}}],[\"needs\",{\"1\":{\"175\":1}}],[\"next\",{\"1\":{\"381\":2}}],[\"neigh\",{\"0\":{\"294\":1},\"1\":{\"294\":2,\"295\":1}}],[\"neither\",{\"1\":{\"205\":1}}],[\"neural\",{\"1\":{\"105\":1}}],[\"netbios\",{\"1\":{\"338\":1}}],[\"netfilter\",{\"1\":{\"330\":1}}],[\"netmask\",{\"1\":{\"319\":1}}],[\"netnsid\",{\"1\":{\"283\":2}}],[\"netns\",{\"1\":{\"283\":3}}],[\"networks\",{\"1\":{\"366\":9,\"372\":2,\"381\":3}}],[\"network\",{\"0\":{\"285\":1,\"336\":1},\"1\":{\"149\":2,\"284\":1,\"286\":1,\"290\":1,\"381\":12}}],[\"network=kong\",{\"1\":{\"66\":1}}],[\"net\",{\"1\":{\"66\":2,\"145\":1,\"149\":4}}],[\"newauthserver\",{\"1\":{\"108\":1}}],[\"newvisualizationserver\",{\"1\":{\"108\":1}}],[\"newreportserver\",{\"1\":{\"108\":1}}],[\"newtaskserver\",{\"1\":{\"108\":1}}],[\"newmutex\",{\"1\":{\"5\":2}}],[\"newsession\",{\"1\":{\"5\":2}}],[\"new\",{\"1\":{\"5\":1,\"150\":1,\"152\":1,\"154\":2}}],[\"nova\",{\"1\":{\"365\":3}}],[\"noop\",{\"1\":{\"283\":2}}],[\"noqueue\",{\"1\":{\"282\":2,\"283\":2}}],[\"nor\",{\"1\":{\"205\":1}}],[\"noargs\",{\"1\":{\"164\":3,\"165\":4}}],[\"none\",{\"1\":{\"38\":1,\"40\":1,\"42\":1,\"47\":1,\"156\":7,\"161\":2,\"162\":3,\"202\":7}}],[\"notebook\",{\"1\":{\"228\":2}}],[\"note\",{\"1\":{\"205\":1}}],[\"not\",{\"1\":{\"36\":2,\"62\":3,\"149\":3,\"150\":4,\"154\":4,\"156\":4,\"211\":1,\"263\":1,\"382\":1,\"462\":1}}],[\"no\",{\"1\":{\"36\":2,\"75\":2,\"161\":1,\"162\":1,\"382\":2}}],[\"noexecute\",{\"1\":{\"36\":3}}],[\"noschedule\",{\"1\":{\"36\":5}}],[\"nodeaffinity\",{\"1\":{\"56\":1}}],[\"nodefs\",{\"1\":{\"51\":7}}],[\"nodeselectorterms\",{\"1\":{\"56\":1}}],[\"nodes\",{\"1\":{\"36\":2,\"62\":1,\"175\":1,\"176\":1}}],[\"node\",{\"0\":{\"55\":1},\"1\":{\"1\":1,\"36\":3,\"55\":1,\"61\":1}}],[\"n\",{\"1\":{\"34\":1,\"97\":1,\"150\":3,\"199\":2,\"258\":1,\"331\":1,\"425\":3,\"429\":2,\"433\":8}}],[\"~\",{\"1\":{\"1\":1,\"97\":1}}],[\"dj\",{\"1\":{\"433\":6}}],[\"dnn\",{\"1\":{\"394\":1,\"398\":1,\"404\":1,\"423\":1,\"424\":1,\"425\":1,\"429\":1,\"431\":3,\"446\":1}}],[\"dns\",{\"1\":{\"38\":4,\"43\":1,\"44\":1,\"340\":1}}],[\"dsn=root\",{\"1\":{\"366\":1}}],[\"dsl编译器将您的管道的python代码转换为静态配置\",{\"1\":{\"82\":1}}],[\"dsl\",{\"1\":{\"81\":1}}],[\"dgx\",{\"1\":{\"352\":1,\"410\":1,\"454\":1,\"458\":2}}],[\"dport\",{\"1\":{\"331\":2}}],[\"d2d交换节省了38gb的gpu内存\",{\"1\":{\"416\":1}}],[\"d2d交换节省了23\",{\"1\":{\"416\":1}}],[\"d2d交换提升了19\",{\"1\":{\"416\":1}}],[\"d2d交换和重计算的组合带来了最佳性能\",{\"1\":{\"416\":1}}],[\"d2d交换的内存节省量为3\",{\"1\":{\"416\":1}}],[\"d2d交换的快速速度对于避免重新计算和gpu\",{\"1\":{\"404\":1}}],[\"d2d交换\",{\"0\":{\"406\":1},\"1\":{\"410\":1,\"413\":1}}],[\"d2d交换技术\",{\"1\":{\"402\":1}}],[\"d2d\",{\"1\":{\"404\":1}}],[\"d2\",{\"1\":{\"283\":2}}],[\"df\",{\"1\":{\"262\":2}}],[\"duration\",{\"1\":{\"211\":4}}],[\"ddp\",{\"1\":{\"180\":1}}],[\"dynamo\",{\"0\":{\"167\":1}}],[\"dynamic\",{\"1\":{\"62\":1}}],[\"dcf9\",{\"1\":{\"149\":1}}],[\"dividing\",{\"1\":{\"433\":1}}],[\"di\",{\"1\":{\"433\":6,\"435\":1}}],[\"dir\",{\"1\":{\"366\":1,\"376\":1}}],[\"directly\",{\"1\":{\"205\":2}}],[\"direct\",{\"1\":{\"175\":2,\"176\":1,\"350\":1}}],[\"dimensions\",{\"1\":{\"365\":2}}],[\"dict\",{\"1\":{\"207\":1}}],[\"differentiable\",{\"1\":{\"105\":1}}],[\"discriminator\",{\"1\":{\"310\":1}}],[\"disk\",{\"1\":{\"255\":2}}],[\"disktype=ssd\",{\"1\":{\"56\":1}}],[\"disktype\",{\"1\":{\"56\":1}}],[\"dist\",{\"1\":{\"183\":4}}],[\"distributed\",{\"1\":{\"139\":1,\"150\":1,\"152\":1,\"154\":2,\"180\":1,\"183\":1,\"202\":2}}],[\"display\",{\"1\":{\"75\":1}}],[\"disable\",{\"1\":{\"62\":1}}],[\"dap+dp\",{\"1\":{\"457\":3}}],[\"dap\",{\"1\":{\"450\":1,\"451\":1,\"457\":2}}],[\"dapple进一步在流水线并行中添加了高效的调度和通信优化\",{\"1\":{\"418\":1}}],[\"dapple比pipedream晚了两年发布\",{\"1\":{\"412\":1}}],[\"dapple显著优于pipedream\",{\"1\":{\"412\":1}}],[\"dapple无法支持超过5\",{\"1\":{\"412\":1}}],[\"dapple+recomp\",{\"1\":{\"412\":1}}],[\"dapple能够训练最多具有53亿参数的gpt模型\",{\"1\":{\"400\":1}}],[\"dapple\",{\"1\":{\"398\":1}}],[\"dashboards\",{\"1\":{\"102\":1}}],[\"dashboard\",{\"1\":{\"100\":1,\"102\":1,\"212\":1}}],[\"date\",{\"1\":{\"98\":1}}],[\"datasourcename\",{\"1\":{\"381\":1}}],[\"datasetprocess\",{\"1\":{\"365\":2}}],[\"database\",{\"1\":{\"296\":1,\"366\":1,\"381\":3}}],[\"datawhalechina\",{\"1\":{\"217\":1,\"228\":1}}],[\"datatype\",{\"1\":{\"150\":1}}],[\"dataflow\",{\"1\":{\"139\":1}}],[\"dataproc\",{\"1\":{\"91\":1}}],[\"data\",{\"0\":{\"335\":1},\"1\":{\"66\":1,\"68\":2,\"71\":2,\"75\":1,\"180\":1,\"184\":1,\"186\":2,\"189\":2,\"195\":1,\"199\":8,\"366\":15,\"381\":9,\"433\":1}}],[\"d894ffcd8\",{\"1\":{\"97\":2}}],[\"dbname=casdoor\",{\"1\":{\"381\":1}}],[\"db=$\",{\"1\":{\"381\":1}}],[\"dbconfig\",{\"1\":{\"365\":1}}],[\"db\",{\"1\":{\"97\":3,\"366\":2,\"381\":2,\"382\":2}}],[\"draft\",{\"1\":{\"75\":1}}],[\"drivername\",{\"1\":{\"381\":1}}],[\"driver\",{\"1\":{\"1\":1,\"381\":3}}],[\"d\",{\"0\":{\"407\":1,\"413\":1},\"1\":{\"66\":2,\"149\":1,\"150\":1,\"199\":2,\"257\":1,\"264\":3,\"331\":1,\"430\":4,\"433\":3,\"436\":2,\"440\":1}}],[\"domain=http\",{\"1\":{\"381\":1}}],[\"do\",{\"1\":{\"366\":1}}],[\"down\",{\"1\":{\"283\":2,\"319\":1,\"325\":1}}],[\"downloads\",{\"1\":{\"242\":1}}],[\"done\",{\"1\":{\"175\":1,\"366\":1}}],[\"donotschedule\",{\"1\":{\"58\":1}}],[\"doc\",{\"1\":{\"364\":1}}],[\"doctype\",{\"1\":{\"75\":1}}],[\"docs\",{\"1\":{\"1\":1,\"78\":1,\"228\":1,\"364\":1,\"371\":1}}],[\"docker地址\",{\"1\":{\"373\":1}}],[\"dockerhub\",{\"1\":{\"366\":1}}],[\"docker0\",{\"1\":{\"297\":4}}],[\"dockerexecutor\",{\"1\":{\"96\":1,\"97\":2}}],[\"dockerd\",{\"1\":{\"62\":2}}],[\"dockershim\",{\"1\":{\"61\":1}}],[\"dockerfile\",{\"1\":{\"2\":1,\"97\":1}}],[\"docker\",{\"0\":{\"1\":1,\"366\":1,\"372\":1,\"381\":1},\"1\":{\"0\":1,\"1\":3,\"2\":1,\"61\":3,\"66\":3,\"89\":1,\"93\":1,\"96\":2,\"97\":3,\"366\":1,\"375\":1,\"380\":1,\"381\":3,\"382\":1,\"383\":1},\"2\":{\"3\":1}}],[\"docker知识点\",{\"0\":{\"0\":1}}],[\"deep\",{\"1\":{\"457\":1}}],[\"deepspeed\",{\"1\":{\"427\":1,\"450\":1,\"454\":3,\"455\":2,\"456\":2,\"457\":3,\"458\":3}}],[\"deepspeed和megatron\",{\"1\":{\"398\":1}}],[\"debug\",{\"1\":{\"366\":1}}],[\"debug=trace\",{\"1\":{\"149\":1}}],[\"democratizing\",{\"1\":{\"393\":2,\"422\":1}}],[\"demo\",{\"1\":{\"220\":1,\"223\":1,\"359\":2}}],[\"depends\",{\"1\":{\"366\":3,\"381\":2}}],[\"deprecated\",{\"1\":{\"156\":3}}],[\"deployments\",{\"1\":{\"101\":1}}],[\"deployment\",{\"1\":{\"31\":2,\"36\":1,\"97\":5,\"98\":1}}],[\"desc\",{\"1\":{\"372\":1}}],[\"destroy\",{\"1\":{\"149\":1}}],[\"desktop\",{\"1\":{\"1\":1,\"62\":9,\"149\":56}}],[\"del\",{\"1\":{\"328\":1}}],[\"delay\",{\"1\":{\"149\":1,\"294\":1}}],[\"deleteobject\",{\"1\":{\"383\":1}}],[\"delete\",{\"1\":{\"10\":1,\"70\":1,\"73\":1}}],[\"deletion\",{\"1\":{\"5\":1}}],[\"dean\",{\"1\":{\"139\":1}}],[\"declarative\",{\"1\":{\"122\":1}}],[\"devices\",{\"1\":{\"149\":1}}],[\"device\",{\"1\":{\"145\":2,\"149\":4,\"202\":2,\"204\":2,\"299\":1}}],[\"dev\",{\"1\":{\"62\":1,\"75\":1,\"256\":1,\"257\":2,\"258\":1,\"259\":2,\"260\":1,\"261\":1,\"262\":1,\"294\":4,\"295\":1,\"297\":4,\"298\":1,\"299\":2,\"300\":1,\"328\":1,\"365\":1,\"366\":1,\"381\":2}}],[\"define\",{\"1\":{\"175\":7}}],[\"definition\",{\"1\":{\"117\":1}}],[\"def\",{\"1\":{\"150\":1,\"156\":1,\"167\":1,\"168\":1,\"169\":1,\"202\":1}}],[\"defer\",{\"1\":{\"5\":2}}],[\"defaulttoken\",{\"1\":{\"365\":3}}],[\"defaultconfig\",{\"1\":{\"365\":4}}],[\"defaultsystemchatprompt\",{\"1\":{\"365\":2}}],[\"defaulting\",{\"1\":{\"62\":1}}],[\"defaultrequest\",{\"1\":{\"25\":1,\"26\":1}}],[\"default\",{\"1\":{\"1\":3,\"25\":1,\"26\":1,\"36\":1,\"40\":1,\"42\":1,\"43\":2,\"75\":1,\"150\":1,\"170\":1,\"171\":1,\"282\":4,\"283\":6,\"366\":2}}],[\"rdma的关键特性\",{\"1\":{\"351\":1}}],[\"rdma\",{\"0\":{\"350\":1,\"351\":1,\"353\":1},\"1\":{\"350\":1,\"351\":3,\"353\":1,\"354\":5,\"355\":1,\"356\":3}}],[\"rpc\",{\"1\":{\"338\":1}}],[\"rs\",{\"1\":{\"366\":2}}],[\"rs0\",{\"1\":{\"366\":2}}],[\"rsplit\",{\"1\":{\"167\":1,\"168\":2}}],[\"rsa+3des\",{\"1\":{\"75\":1}}],[\"rsa+aes256\",{\"1\":{\"75\":1}}],[\"rsa+aes128\",{\"1\":{\"75\":1}}],[\"rules\",{\"0\":{\"167\":1}}],[\"runmode\",{\"1\":{\"381\":1}}],[\"runtimeerror\",{\"1\":{\"150\":1}}],[\"runs创建过程是\",{\"1\":{\"113\":1}}],[\"runservice\",{\"1\":{\"108\":1,\"109\":1,\"111\":1}}],[\"running\",{\"1\":{\"1\":1,\"62\":1,\"94\":1,\"97\":13,\"381\":1}}],[\"run\",{\"1\":{\"1\":1,\"62\":4,\"66\":1,\"95\":2,\"150\":1,\"365\":1,\"366\":1,\"375\":1}}],[\"r\",{\"1\":{\"150\":2,\"242\":1}}],[\"rgmgf\",{\"1\":{\"97\":2}}],[\"rag\",{\"1\":{\"223\":1,\"224\":3,\"226\":1}}],[\"ratio\",{\"1\":{\"211\":2,\"212\":2}}],[\"rate\",{\"1\":{\"211\":4}}],[\"raise\",{\"1\":{\"150\":2,\"154\":2,\"156\":1}}],[\"raises\",{\"1\":{\"150\":1}}],[\"rand\",{\"1\":{\"366\":1}}],[\"random\",{\"1\":{\"105\":1}}],[\"ranks\",{\"1\":{\"150\":5,\"151\":6,\"154\":7}}],[\"rank``\",{\"1\":{\"150\":2}}],[\"rank\",{\"1\":{\"149\":6,\"150\":18,\"151\":9,\"152\":2,\"153\":2,\"154\":11,\"155\":2,\"164\":2,\"165\":3,\"183\":5,\"199\":5,\"202\":1,\"203\":2,\"204\":1}}],[\"range\",{\"1\":{\"75\":1,\"160\":1}}],[\"raft\",{\"1\":{\"5\":1}}],[\"ring\",{\"1\":{\"149\":1,\"175\":2,\"176\":1}}],[\"right\",{\"1\":{\"75\":1}}],[\"riscv64\",{\"1\":{\"1\":1}}],[\"rwx\",{\"1\":{\"9\":1}}],[\"rwo\",{\"1\":{\"9\":1}}],[\"roce\",{\"1\":{\"351\":1,\"354\":1}}],[\"router\",{\"1\":{\"336\":1}}],[\"routes\",{\"1\":{\"71\":1,\"72\":1,\"73\":1}}],[\"route\",{\"1\":{\"71\":2,\"72\":1,\"73\":1,\"327\":1,\"328\":3,\"332\":2}}],[\"rotation\",{\"1\":{\"62\":1}}],[\"rox\",{\"1\":{\"9\":1}}],[\"root的密钥\",{\"1\":{\"366\":1}}],[\"root=0\",{\"1\":{\"156\":1,\"160\":1}}],[\"root\",{\"1\":{\"1\":1,\"62\":1,\"75\":1,\"97\":1,\"149\":2,\"150\":3,\"156\":5,\"157\":1,\"158\":3,\"159\":1,\"160\":2,\"161\":4,\"162\":5,\"255\":1,\"256\":1,\"260\":2,\"261\":1,\"262\":1,\"366\":10,\"368\":1,\"369\":1,\"381\":5,\"382\":3,\"383\":1}}],[\"refer\",{\"1\":{\"382\":1}}],[\"reflection\",{\"1\":{\"110\":1}}],[\"reflectionservice\",{\"1\":{\"110\":1,\"111\":1}}],[\"rerankmodels\",{\"1\":{\"365\":1}}],[\"remote\",{\"1\":{\"350\":1}}],[\"related\",{\"1\":{\"382\":1}}],[\"relative\",{\"1\":{\"150\":2}}],[\"reload\",{\"1\":{\"372\":1}}],[\"release\",{\"1\":{\"5\":1,\"161\":1,\"162\":2,\"366\":1}}],[\"released\",{\"1\":{\"5\":1,\"16\":1,\"17\":1}}],[\"reduction\",{\"1\":{\"176\":1,\"196\":1}}],[\"reduce`\",{\"1\":{\"156\":1}}],[\"reducescatter\",{\"1\":{\"143\":1,\"150\":1}}],[\"reduce\",{\"1\":{\"143\":4,\"149\":2,\"150\":1,\"156\":6,\"157\":2,\"159\":1,\"160\":2,\"161\":6,\"162\":4,\"163\":1,\"164\":6,\"165\":13}}],[\"redop\",{\"1\":{\"149\":1}}],[\"redirect\",{\"1\":{\"61\":1,\"75\":1}}],[\"redis\",{\"1\":{\"5\":2,\"128\":1}}],[\"reply\",{\"1\":{\"372\":1}}],[\"replset\",{\"1\":{\"366\":1}}],[\"replicas\",{\"1\":{\"36\":1,\"43\":1}}],[\"replicaset\",{\"1\":{\"31\":2,\"97\":1}}],[\"report\",{\"1\":{\"150\":1}}],[\"reportservice\",{\"1\":{\"108\":1,\"111\":1}}],[\"registered\",{\"1\":{\"150\":1,\"154\":1,\"205\":1}}],[\"registerexperimentserviceserver\",{\"1\":{\"108\":1,\"109\":1}}],[\"register\",{\"1\":{\"110\":1,\"150\":1}}],[\"registerauthserviceserver\",{\"1\":{\"108\":1}}],[\"registervisualizationserviceserver\",{\"1\":{\"108\":1}}],[\"registerrecurringrunserviceserver\",{\"1\":{\"109\":1}}],[\"registerreportserviceserver\",{\"1\":{\"108\":1}}],[\"registerrunserviceserver\",{\"1\":{\"108\":1,\"109\":1}}],[\"registertaskserviceserver\",{\"1\":{\"108\":1}}],[\"registerjobserviceserver\",{\"1\":{\"108\":1}}],[\"registerpipelineserviceserver\",{\"1\":{\"108\":1,\"109\":1}}],[\"registry\",{\"1\":{\"36\":1,\"97\":1,\"366\":4,\"372\":1,\"373\":1}}],[\"retnet\",{\"1\":{\"446\":1}}],[\"retention=1000\",{\"1\":{\"366\":1}}],[\"retries\",{\"1\":{\"366\":3,\"381\":1}}],[\"returns\",{\"1\":{\"150\":2,\"205\":1}}],[\"return\",{\"1\":{\"75\":1,\"150\":2,\"154\":2,\"161\":2,\"162\":1,\"167\":1,\"168\":1,\"169\":1,\"170\":1,\"173\":1,\"199\":1,\"205\":1}}],[\"retain\",{\"1\":{\"10\":1}}],[\"resolution\",{\"1\":{\"291\":1,\"302\":1}}],[\"resource\",{\"1\":{\"117\":2,\"383\":3,\"387\":1}}],[\"resourcemanager\",{\"1\":{\"108\":4}}],[\"resources\",{\"1\":{\"36\":1,\"98\":1}}],[\"resourcequota\",{\"1\":{\"20\":2,\"21\":1}}],[\"resourcequotas\",{\"0\":{\"18\":1},\"1\":{\"17\":1,\"18\":1,\"19\":1,\"23\":1,\"28\":1}}],[\"rest\",{\"1\":{\"149\":1,\"387\":2}}],[\"restart\",{\"1\":{\"366\":5,\"381\":3}}],[\"restarts\",{\"1\":{\"97\":1}}],[\"restart=always\",{\"1\":{\"66\":1}}],[\"result\",{\"1\":{\"62\":1}}],[\"reset\",{\"1\":{\"62\":1}}],[\"requirements\",{\"1\":{\"382\":1}}],[\"requiredduringschedulingignoredduringexecution\",{\"1\":{\"54\":1,\"56\":1}}],[\"request\",{\"1\":{\"255\":1}}],[\"requests\",{\"1\":{\"20\":2,\"36\":1,\"98\":1,\"211\":1}}],[\"reachable\",{\"1\":{\"294\":1}}],[\"real\",{\"1\":{\"75\":1}}],[\"reasons\",{\"1\":{\"156\":1}}],[\"reason\",{\"1\":{\"36\":1}}],[\"read\",{\"1\":{\"75\":1,\"255\":3}}],[\"ready\",{\"1\":{\"36\":1,\"97\":1}}],[\"readwritemany\",{\"1\":{\"9\":1}}],[\"readwriteonce\",{\"1\":{\"9\":1}}],[\"readonlymany\",{\"1\":{\"9\":1}}],[\"recomputation\",{\"1\":{\"418\":1}}],[\"recognition\",{\"1\":{\"372\":1}}],[\"record\",{\"1\":{\"211\":2}}],[\"received\",{\"1\":{\"199\":1}}],[\"recv\",{\"1\":{\"149\":1,\"196\":1,\"199\":1}}],[\"recurringrunservice\",{\"1\":{\"109\":1,\"111\":1}}],[\"recurring\",{\"1\":{\"95\":1}}],[\"recycle\",{\"1\":{\"10\":1}}],[\"reclaim\",{\"0\":{\"10\":1}}],[\"revisions\",{\"1\":{\"5\":1}}],[\"revision\",{\"1\":{\"5\":3}}],[\"rm\",{\"1\":{\"1\":1}}],[\"phi\",{\"1\":{\"446\":1}}],[\"physical\",{\"0\":{\"334\":1}}],[\"ptensor\",{\"0\":{\"443\":1},\"1\":{\"442\":1,\"443\":8,\"444\":3}}],[\"ptuning\",{\"1\":{\"220\":1}}],[\"p3dn\",{\"1\":{\"400\":1,\"410\":1}}],[\"purl\",{\"1\":{\"393\":1}}],[\"public\",{\"1\":{\"381\":1}}],[\"putobject\",{\"1\":{\"383\":1}}],[\"put\",{\"1\":{\"75\":2}}],[\"psw=1234\",{\"1\":{\"366\":1}}],[\"pdf\",{\"1\":{\"226\":1,\"422\":1}}],[\"pdf下载地址\",{\"1\":{\"226\":1}}],[\"pg16\",{\"1\":{\"381\":1}}],[\"pgvector\",{\"1\":{\"381\":2}}],[\"pghnswefsearch\",{\"1\":{\"365\":1}}],[\"pg\",{\"1\":{\"150\":2,\"151\":2,\"154\":4,\"202\":1,\"204\":1,\"381\":1}}],[\"p2p\",{\"1\":{\"149\":3}}],[\"pinned\",{\"1\":{\"408\":1}}],[\"ping\",{\"0\":{\"239\":1},\"1\":{\"239\":1}}],[\"pipedream\",{\"1\":{\"418\":1,\"451\":1}}],[\"pipedream出现了gpu内存不足的错误\",{\"1\":{\"411\":1}}],[\"pipedream使用异步调度\",{\"1\":{\"400\":1}}],[\"pipedream可以支持2亿参数的bert模型\",{\"1\":{\"400\":1}}],[\"pipedream中使用的异步模式允许第二个微批次的前向传播与第一个微批次的反向传播并行进行\",{\"1\":{\"399\":1}}],[\"pipedream和dapple之间的模型规模和性能差距较大\",{\"1\":{\"412\":1}}],[\"pipedream和dapple之间的结果差异\",{\"1\":{\"412\":1}}],[\"pipedream和dapple之间可支持模型规模的差异在于\",{\"1\":{\"400\":1}}],[\"pipedream和dapple\",{\"1\":{\"396\":1}}],[\"pipeline创建流程\",{\"0\":{\"112\":1}}],[\"pipeline服务注册流程\",{\"0\":{\"107\":1}}],[\"pipelineservice\",{\"1\":{\"108\":1,\"109\":1,\"111\":1}}],[\"pipelines\",{\"1\":{\"89\":3,\"90\":1,\"92\":1,\"94\":2,\"95\":8,\"96\":2,\"97\":15,\"106\":1}}],[\"pipelines将工件存储在像minio服务器或cloud\",{\"1\":{\"86\":1}}],[\"pipelines将元数据存储在mysql数据库中\",{\"1\":{\"86\":1}}],[\"pipelines特定领域语言\",{\"1\":{\"81\":1}}],[\"pipeline\",{\"0\":{\"80\":1,\"89\":1},\"1\":{\"97\":24,\"98\":1,\"457\":1}}],[\"pictures\",{\"1\":{\"242\":1}}],[\"pid\",{\"1\":{\"149\":1,\"253\":1,\"263\":1}}],[\"pc\",{\"1\":{\"145\":1}}],[\"pcie\",{\"1\":{\"143\":2,\"352\":1}}],[\"pkgconfig\",{\"1\":{\"145\":1}}],[\"pki\",{\"1\":{\"62\":2}}],[\"pnsexecutor\",{\"1\":{\"96\":1,\"97\":2}}],[\"pymodinit\",{\"1\":{\"170\":1,\"171\":2,\"173\":1}}],[\"pyinit\",{\"1\":{\"170\":2,\"171\":4,\"173\":2,\"174\":1}}],[\"pybind11\",{\"1\":{\"161\":1,\"162\":2}}],[\"pyarg\",{\"1\":{\"161\":1,\"162\":2}}],[\"pyobject\",{\"1\":{\"161\":4,\"162\":4,\"170\":2,\"171\":3}}],[\"pytorchjob\",{\"1\":{\"106\":1}}],[\"pytorch\",{\"0\":{\"180\":1},\"1\":{\"105\":1,\"139\":1,\"152\":1,\"156\":1,\"161\":1,\"162\":1,\"164\":1,\"166\":3,\"180\":2,\"184\":1,\"410\":1,\"445\":7,\"454\":1},\"2\":{\"209\":1}}],[\"python调用c\",{\"1\":{\"170\":1}}],[\"python\",{\"0\":{\"81\":1,\"161\":1},\"1\":{\"36\":1,\"127\":1,\"161\":2,\"162\":12,\"163\":3,\"164\":2,\"166\":1,\"167\":1,\"170\":4,\"171\":5,\"172\":2,\"173\":3,\"174\":1,\"228\":1,\"431\":1,\"445\":2}}],[\"python3\",{\"1\":{\"36\":1,\"376\":1}}],[\"py\",{\"0\":{\"156\":1,\"167\":1},\"1\":{\"91\":1,\"145\":1,\"161\":1,\"162\":1,\"169\":3,\"202\":1,\"376\":1}}],[\"p>\",{\"1\":{\"75\":1}}],[\"p\",{\"1\":{\"66\":1,\"150\":1,\"252\":1,\"253\":2,\"331\":2,\"365\":1,\"366\":2,\"375\":1,\"437\":1}}],[\"pageable\",{\"1\":{\"408\":1}}],[\"password=your\",{\"1\":{\"382\":1}}],[\"password=uwnzugjbqixf8dxc\",{\"1\":{\"382\":1}}],[\"password=$\",{\"1\":{\"381\":3}}],[\"password=mypassword\",{\"1\":{\"366\":1}}],[\"password\",{\"1\":{\"366\":2,\"381\":4,\"382\":1}}],[\"passing\",{\"1\":{\"181\":1,\"190\":1,\"195\":1}}],[\"pattern\",{\"1\":{\"175\":6,\"176\":7}}],[\"path\",{\"1\":{\"347\":1,\"381\":1}}],[\"pathways\",{\"1\":{\"139\":2}}],[\"paths\",{\"1\":{\"71\":1}}],[\"package\",{\"1\":{\"169\":2}}],[\"par\",{\"1\":{\"393\":1}}],[\"parsed\",{\"1\":{\"205\":1}}],[\"parse\",{\"1\":{\"205\":1}}],[\"parsetuple\",{\"1\":{\"161\":1,\"162\":2}}],[\"parent\",{\"1\":{\"175\":2}}],[\"part\",{\"1\":{\"150\":2,\"154\":1}}],[\"partition\",{\"1\":{\"62\":1}}],[\"parallelisms\",{\"1\":{\"433\":1}}],[\"parallelism\",{\"1\":{\"393\":2,\"422\":1}}],[\"parallel\",{\"1\":{\"150\":1,\"180\":1}}],[\"parzen\",{\"1\":{\"105\":1}}],[\"pair\",{\"1\":{\"62\":1}}],[\"plugin=mysql\",{\"1\":{\"366\":1}}],[\"plugin\",{\"1\":{\"149\":5,\"372\":1}}],[\"place\",{\"1\":{\"149\":2}}],[\"plane\",{\"1\":{\"98\":3}}],[\"plain\",{\"1\":{\"75\":1}}],[\"platforms\",{\"1\":{\"1\":1}}],[\"platform\",{\"1\":{\"1\":1,\"2\":1}}],[\"please\",{\"1\":{\"62\":1,\"150\":1,\"154\":1,\"156\":2}}],[\"peer\",{\"1\":{\"149\":1,\"282\":1}}],[\"pem\",{\"1\":{\"62\":1}}],[\"permanent\",{\"1\":{\"297\":2,\"298\":1}}],[\"percentage\",{\"1\":{\"211\":1}}],[\"perf\",{\"1\":{\"149\":2}}],[\"persistenceagent\",{\"1\":{\"97\":3}}],[\"persistentvolumeclaim\",{\"1\":{\"11\":1}}],[\"persistentvolume\",{\"1\":{\"11\":1}}],[\"period\",{\"1\":{\"366\":1}}],[\"periodic\",{\"1\":{\"95\":1}}],[\"period=600\",{\"1\":{\"51\":1}}],[\"period=imagefs\",{\"1\":{\"51\":1}}],[\"per\",{\"1\":{\"62\":1,\"149\":1}}],[\"powershell\",{\"1\":{\"263\":1}}],[\"po\",{\"1\":{\"97\":1}}],[\"positional\",{\"1\":{\"156\":1}}],[\"position\",{\"1\":{\"75\":1}}],[\"postgres\",{\"1\":{\"381\":9,\"382\":2}}],[\"postgresql\",{\"1\":{\"381\":5}}],[\"post\",{\"1\":{\"68\":1,\"71\":1,\"75\":2}}],[\"policies\",{\"0\":{\"59\":1}}],[\"policy\",{\"0\":{\"10\":1},\"1\":{\"60\":4}}],[\"port=9000\",{\"1\":{\"382\":1}}],[\"port=8800\",{\"1\":{\"382\":1}}],[\"port=3210\",{\"1\":{\"382\":1}}],[\"port=5432\",{\"1\":{\"381\":1}}],[\"port\",{\"1\":{\"40\":1,\"42\":1,\"75\":2,\"376\":1,\"381\":9}}],[\"ports\",{\"1\":{\"32\":1,\"36\":1,\"40\":1,\"42\":1,\"43\":1,\"366\":5,\"381\":2}}],[\"pod存储两种类型的数据\",{\"1\":{\"86\":1}}],[\"pod中执行\",{\"1\":{\"85\":1}}],[\"podantiaffinity\",{\"1\":{\"54\":2}}],[\"pod设置toleration\",{\"1\":{\"36\":1}}],[\"pods\",{\"1\":{\"20\":1}}],[\"pod\",{\"0\":{\"31\":1,\"32\":1,\"52\":1,\"53\":2},\"1\":{\"20\":2,\"23\":2,\"24\":3,\"26\":1,\"28\":1,\"30\":3,\"31\":6,\"32\":6,\"33\":3,\"34\":9,\"35\":2,\"36\":8,\"37\":2,\"38\":6,\"39\":1,\"40\":2,\"43\":1,\"44\":2,\"45\":3,\"46\":5,\"47\":2,\"49\":4,\"50\":1,\"51\":5,\"52\":1,\"53\":3,\"54\":3,\"55\":1,\"56\":3,\"57\":1,\"58\":4,\"60\":1,\"89\":3,\"95\":1,\"97\":18,\"117\":1,\"212\":2}}],[\"pvcreate\",{\"1\":{\"259\":1}}],[\"pvc\",{\"1\":{\"11\":1,\"12\":5,\"13\":4,\"14\":4,\"16\":4,\"17\":2}}],[\"pv\",{\"0\":{\"11\":1},\"1\":{\"11\":4,\"12\":3,\"13\":2,\"14\":3,\"15\":3,\"16\":7}}],[\"pfx\",{\"1\":{\"5\":1}}],[\"pr\",{\"1\":{\"226\":2}}],[\"protected\",{\"1\":{\"387\":1}}],[\"proto\",{\"1\":{\"75\":1}}],[\"protocols\",{\"1\":{\"75\":1}}],[\"protocol\",{\"1\":{\"36\":1,\"176\":1,\"291\":1,\"302\":1,\"304\":4,\"309\":1,\"336\":1}}],[\"probe\",{\"1\":{\"294\":1}}],[\"providers=casdoor\",{\"1\":{\"381\":1}}],[\"provide\",{\"1\":{\"212\":1}}],[\"providing\",{\"1\":{\"62\":1}}],[\"program\",{\"1\":{\"184\":1,\"189\":2,\"195\":1}}],[\"progress\",{\"1\":{\"149\":1}}],[\"prod\",{\"1\":{\"150\":1,\"158\":1}}],[\"profiler\",{\"1\":{\"149\":2}}],[\"prompt\",{\"1\":{\"223\":1,\"226\":1}}],[\"prometheus\",{\"1\":{\"121\":3}}],[\"promiscuous\",{\"1\":{\"47\":1}}],[\"proxy=http\",{\"1\":{\"366\":2,\"382\":2}}],[\"proxy\",{\"1\":{\"75\":11,\"149\":3,\"372\":1,\"382\":2}}],[\"project\",{\"1\":{\"66\":2,\"75\":1}}],[\"processgroupnccl\",{\"1\":{\"204\":1}}],[\"processgroupoptions\",{\"1\":{\"204\":1}}],[\"processgroup\",{\"1\":{\"150\":3,\"152\":1}}],[\"processes\",{\"1\":{\"75\":1}}],[\"process\",{\"0\":{\"202\":1},\"1\":{\"62\":1,\"96\":1,\"150\":1,\"181\":1,\"183\":1,\"199\":4,\"202\":2}}],[\"proc\",{\"1\":{\"62\":1}}],[\"pretrained\",{\"1\":{\"374\":1,\"376\":1}}],[\"preset\",{\"1\":{\"382\":1}}],[\"presentation\",{\"0\":{\"339\":1}}],[\"present\",{\"1\":{\"205\":1}}],[\"pressure\",{\"1\":{\"51\":1}}],[\"preemption\",{\"1\":{\"36\":2}}],[\"preference\",{\"1\":{\"310\":1}}],[\"preferred\",{\"1\":{\"283\":2}}],[\"prefer\",{\"1\":{\"75\":1}}],[\"prefernoschedule\",{\"1\":{\"36\":1}}],[\"prefix\",{\"1\":{\"5\":4,\"372\":5,\"383\":1}}],[\"primitives\",{\"1\":{\"433\":3}}],[\"principal\",{\"1\":{\"383\":3}}],[\"printf\",{\"1\":{\"199\":2}}],[\"print\",{\"1\":{\"160\":1,\"169\":1,\"183\":1,\"366\":1}}],[\"println\",{\"1\":{\"5\":2}}],[\"priority\",{\"1\":{\"204\":1}}],[\"priorities\",{\"1\":{\"60\":1}}],[\"prior\",{\"1\":{\"5\":1}}],[\"privileged\",{\"1\":{\"1\":1,\"66\":1}}],[\"ppc64le\",{\"1\":{\"1\":1}}],[\"p54eaf3\",{\"1\":{\"1\":1,\"62\":9,\"149\":56}}],[\"m⋅kn​路数据并行来进一步提高训练性能\",{\"1\":{\"454\":1}}],[\"mfu\",{\"1\":{\"446\":1}}],[\"m+ofst+1\",{\"1\":{\"433\":1}}],[\"m+ofst\",{\"1\":{\"433\":1}}],[\"mbj\",{\"1\":{\"431\":1}}],[\"mbi\",{\"1\":{\"431\":2}}],[\"mb2\",{\"1\":{\"431\":1}}],[\"mb1\",{\"1\":{\"431\":1}}],[\"msg\",{\"1\":{\"372\":1}}],[\"mvp\",{\"1\":{\"359\":6}}],[\"mtu\",{\"1\":{\"282\":2,\"283\":4}}],[\"mp\",{\"1\":{\"422\":1}}],[\"mpress展示了在现有硬件约束下突破模型训练规模限制的潜力\",{\"1\":{\"419\":1}}],[\"mpress展示了此类架构的潜在优势及其在低硬件成本下解决内存墙问题的示例应用\",{\"1\":{\"417\":1}}],[\"mpress为未来高带宽异构计算环境中的大规模模型训练提供了设计思路\",{\"1\":{\"419\":1}}],[\"mpress为重新思考内存架构提供了帮助\",{\"1\":{\"417\":1}}],[\"mpress显著提高了训练吞吐量\",{\"1\":{\"419\":1}}],[\"mpress显著提升了多gpu服务器上十亿规模dnn模型的训练效率\",{\"1\":{\"397\":1}}],[\"mpress能够高效地减少gpu内存消耗\",{\"1\":{\"419\":1}}],[\"mpress能够在现有的gpu硬件上运行\",{\"1\":{\"418\":1}}],[\"mpress结合了三种内存优化技术\",{\"1\":{\"419\":1}}],[\"mpress结合了三种优化策略\",{\"1\":{\"411\":1}}],[\"mpress与上述工作不同\",{\"1\":{\"418\":1}}],[\"mpress与这些工作是互补的\",{\"1\":{\"418\":1}}],[\"mpress通过优先使用nvlink进行d2d交换\",{\"1\":{\"418\":1}}],[\"mpress通过d2d交换减少了gpu内存需求\",{\"1\":{\"418\":1}}],[\"mpress通过进一步利用空闲的gpu内存资源\",{\"1\":{\"412\":1}}],[\"mpress不局限于特定的调度策略\",{\"1\":{\"418\":1}}],[\"mpress可以部分弥补当前硬件的局限性\",{\"1\":{\"417\":1}}],[\"mpress可以解决这个问题\",{\"1\":{\"417\":1}}],[\"mpress中的d2d交换技术在这种情况下仍然有效\",{\"1\":{\"417\":1}}],[\"mpress选择对阶段0\",{\"1\":{\"416\":1}}],[\"mpress选择重计算\",{\"1\":{\"415\":1}}],[\"mpress没有使用gpu\",{\"1\":{\"416\":1}}],[\"mpress优先选择d2d交换\",{\"1\":{\"415\":1}}],[\"mpress会分配gpu\",{\"1\":{\"415\":1}}],[\"mpress会舍弃gpu\",{\"1\":{\"415\":1}}],[\"mpress会选择d2d交换\",{\"1\":{\"415\":1}}],[\"mpress会优先选择gpu\",{\"1\":{\"415\":1}}],[\"mpress也能在47秒内找到最优映射\",{\"1\":{\"414\":1}}],[\"mpress比zero\",{\"1\":{\"412\":1}}],[\"mpress支持的模型规模提高了2\",{\"1\":{\"411\":1}}],[\"mpress相比gpu\",{\"1\":{\"411\":1}}],[\"mpress在模型规模上始终能够保持稳定的训练性能\",{\"1\":{\"412\":1}}],[\"mpress在dapple上的性能\",{\"0\":{\"412\":1}}],[\"mpress在pipedream上的性能\",{\"0\":{\"411\":1}}],[\"mpress在相同内存优化下训练速度大幅提升\",{\"1\":{\"396\":1}}],[\"mpress变体采用我们之前算法生成的设备映射和内存节省计划\",{\"1\":{\"410\":1}}],[\"mpress是否能有效缓解gpu内存限制\",{\"1\":{\"409\":1}}],[\"mpress是通用的\",{\"1\":{\"408\":1}}],[\"mpress运行时部分与操作间并行训练框架的运行时部分共同工作\",{\"1\":{\"405\":1}}],[\"mpress静态部分是离线运行的\",{\"1\":{\"405\":1}}],[\"mpress的规划算法可以扩展\",{\"1\":{\"417\":1}}],[\"mpress的逻辑横跨静态和运行时部分\",{\"1\":{\"405\":1}}],[\"mpress的总体概述及工作流程\",{\"0\":{\"405\":1}}],[\"mpress还采用了重新计算和gpu\",{\"1\":{\"404\":1}}],[\"mpress采用了一种新的设备间\",{\"1\":{\"404\":1}}],[\"mpress被集成到现有的两种操作间并行训练系统中\",{\"1\":{\"396\":1}}],[\"mpress提出了一种新的单服务器多gpu系统\",{\"1\":{\"395\":1}}],[\"mpress\",{\"0\":{\"393\":1,\"403\":1},\"1\":{\"393\":3,\"422\":1},\"2\":{\"420\":1,\"421\":1}}],[\"mpeg\",{\"1\":{\"339\":1}}],[\"mp4\",{\"1\":{\"242\":1}}],[\"mpmd\",{\"0\":{\"190\":1,\"191\":1,\"194\":1},\"1\":{\"189\":3,\"190\":3,\"191\":3,\"192\":1,\"193\":1,\"194\":1,\"195\":2,\"451\":1}}],[\"mpich\",{\"1\":{\"197\":1}}],[\"mpi=1\",{\"1\":{\"150\":1}}],[\"mpi\",{\"0\":{\"196\":1,\"197\":1},\"1\":{\"143\":7,\"181\":1,\"190\":1,\"193\":1,\"194\":2,\"195\":4,\"196\":12,\"197\":4,\"198\":4,\"199\":15,\"200\":2,\"204\":1,\"205\":1,\"206\":1,\"207\":3}}],[\"mnnvl\",{\"1\":{\"149\":1}}],[\"mnt\",{\"1\":{\"66\":2,\"149\":1}}],[\"mxnet\",{\"1\":{\"105\":1}}],[\"mlp\",{\"1\":{\"455\":1}}],[\"mlaas\",{\"1\":{\"139\":1}}],[\"mlops\",{\"0\":{\"129\":1}}],[\"ml\",{\"1\":{\"78\":6,\"79\":2,\"89\":1,\"90\":1,\"95\":2,\"97\":24,\"98\":1,\"105\":2,\"106\":2,\"139\":1}}],[\"mi\",{\"1\":{\"435\":1}}],[\"milvusdb\",{\"1\":{\"366\":1}}],[\"milvusstandalone\",{\"1\":{\"366\":4}}],[\"milvusetcd\",{\"1\":{\"366\":4}}],[\"milvus\",{\"1\":{\"366\":8}}],[\"mimd\",{\"1\":{\"186\":3}}],[\"mime\",{\"1\":{\"75\":1}}],[\"microsoft\",{\"1\":{\"105\":1,\"246\":1,\"446\":1}}],[\"miit\",{\"1\":{\"75\":1}}],[\"minference\",{\"1\":{\"245\":1,\"246\":1,\"247\":1,\"248\":1,\"249\":5}}],[\"minimize\",{\"1\":{\"440\":1}}],[\"minioadmin\",{\"1\":{\"366\":2}}],[\"minio\",{\"0\":{\"383\":1},\"1\":{\"366\":14,\"381\":20,\"382\":8,\"383\":1}}],[\"mini\",{\"1\":{\"188\":1}}],[\"minikube\",{\"1\":{\"36\":2}}],[\"minbytes\",{\"1\":{\"149\":1,\"150\":1}}],[\"min\",{\"1\":{\"25\":1,\"26\":1,\"150\":1,\"158\":1,\"211\":2}}],[\"mips64\",{\"1\":{\"1\":1}}],[\"mips64le\",{\"1\":{\"1\":1}}],[\"making\",{\"1\":{\"382\":1}}],[\"make\",{\"1\":{\"145\":2,\"148\":1}}],[\"makefile\",{\"1\":{\"145\":1}}],[\"mac地址长度\",{\"1\":{\"304\":1}}],[\"mac地址\",{\"1\":{\"294\":1,\"298\":1}}],[\"mac地址学习\",{\"1\":{\"291\":1}}],[\"mapper\",{\"1\":{\"256\":1,\"260\":1,\"261\":1,\"262\":1}}],[\"markdown\",{\"1\":{\"228\":1}}],[\"margin\",{\"1\":{\"75\":2}}],[\"matmul\",{\"1\":{\"429\":2,\"448\":1}}],[\"matrix\",{\"1\":{\"105\":1}}],[\"matchexpressions\",{\"1\":{\"54\":1,\"56\":1}}],[\"matchlabels\",{\"1\":{\"36\":1,\"43\":1,\"58\":1,\"98\":1}}],[\"main\",{\"1\":{\"62\":1,\"199\":1}}],[\"manifests\",{\"1\":{\"31\":1,\"32\":3}}],[\"manager\",{\"0\":{\"98\":1},\"1\":{\"30\":1,\"33\":1,\"97\":6,\"98\":6}}],[\"maxtoken\",{\"1\":{\"365\":3}}],[\"maxtemperature\",{\"1\":{\"365\":2}}],[\"maxresponse\",{\"1\":{\"365\":2}}],[\"maxcontext\",{\"1\":{\"365\":2}}],[\"maxsplit=1\",{\"1\":{\"167\":1,\"168\":2}}],[\"maxskew\",{\"1\":{\"58\":2}}],[\"maxbytes\",{\"1\":{\"149\":1,\"150\":1}}],[\"max\",{\"1\":{\"25\":1,\"26\":1,\"51\":1,\"75\":1,\"150\":1,\"158\":1,\"162\":1,\"175\":1,\"176\":1,\"366\":1,\"372\":1,\"440\":1}}],[\"master\",{\"1\":{\"1\":1,\"98\":1,\"297\":2,\"298\":1}}],[\"megatron\",{\"1\":{\"418\":1,\"423\":1,\"424\":1,\"425\":3,\"427\":1,\"450\":1,\"454\":4,\"455\":1,\"456\":1,\"458\":1}}],[\"members\",{\"1\":{\"366\":1}}],[\"memory\",{\"1\":{\"20\":2,\"25\":4,\"36\":2,\"51\":4,\"98\":2,\"350\":1,\"366\":1,\"393\":2,\"408\":2,\"422\":1}}],[\"med\",{\"1\":{\"310\":1}}],[\"metric\",{\"1\":{\"212\":1}}],[\"meth\",{\"1\":{\"164\":9,\"165\":10}}],[\"method\",{\"1\":{\"75\":1,\"202\":1,\"203\":2,\"204\":3}}],[\"methods\",{\"1\":{\"75\":1}}],[\"metadata\",{\"1\":{\"20\":1,\"25\":1,\"32\":1,\"36\":2,\"40\":1,\"42\":1,\"43\":2,\"54\":1,\"56\":1,\"58\":1,\"86\":1,\"95\":3,\"97\":8,\"98\":3}}],[\"message\",{\"1\":{\"36\":1,\"190\":1,\"195\":1,\"336\":1}}],[\"m\",{\"1\":{\"5\":4,\"36\":1,\"66\":1,\"150\":1,\"425\":3,\"433\":8}}],[\"must\",{\"1\":{\"150\":1}}],[\"mutex\",{\"1\":{\"5\":3}}],[\"multicast\",{\"1\":{\"282\":2,\"283\":2}}],[\"multiple\",{\"1\":{\"184\":1,\"186\":3,\"189\":3,\"195\":2}}],[\"multi\",{\"1\":{\"1\":1,\"149\":1,\"310\":1,\"347\":1,\"393\":2,\"422\":1}}],[\"mypassword\",{\"1\":{\"366\":3}}],[\"myusername\",{\"1\":{\"366\":3}}],[\"myclass\",{\"1\":{\"169\":5}}],[\"mysql\",{\"1\":{\"121\":2,\"128\":1,\"366\":11}}],[\"mysql数据库和minio服务器都由kubernetes持久卷子系统支持\",{\"1\":{\"86\":1}}],[\"mytask\",{\"1\":{\"91\":3}}],[\"myapp\",{\"1\":{\"54\":1,\"58\":1}}],[\"myrev\",{\"1\":{\"5\":1}}],[\"mykey\",{\"1\":{\"5\":1}}],[\"my\",{\"1\":{\"5\":4,\"40\":2,\"42\":2,\"43\":10,\"58\":2,\"169\":5}}],[\"m1\",{\"1\":{\"5\":3}}],[\"mongodb\",{\"1\":{\"366\":7}}],[\"mongod\",{\"1\":{\"366\":1}}],[\"mongo\",{\"1\":{\"366\":12}}],[\"module\",{\"0\":{\"164\":1},\"1\":{\"167\":3,\"168\":6,\"169\":3}}],[\"mode=revision\",{\"1\":{\"366\":1}}],[\"mode=hairpin\",{\"1\":{\"48\":1}}],[\"models\",{\"1\":{\"374\":1,\"376\":1}}],[\"modelscope\",{\"1\":{\"374\":1}}],[\"model\",{\"1\":{\"365\":12,\"372\":1,\"375\":2,\"376\":2,\"382\":1,\"393\":2,\"422\":1,\"433\":1}}],[\"mode\",{\"0\":{\"46\":1},\"1\":{\"45\":3,\"47\":1,\"48\":1,\"50\":1,\"282\":2,\"283\":2,\"381\":3}}],[\"modes\",{\"0\":{\"9\":1}}],[\"more\",{\"1\":{\"2\":1}}],[\"moby\",{\"1\":{\"1\":1}}],[\"md5\",{\"1\":{\"75\":1}}],[\"md\",{\"1\":{\"1\":1}}],[\"b1\",{\"1\":{\"444\":1}}],[\"bk\",{\"1\":{\"429\":1}}],[\"billion\",{\"1\":{\"393\":2,\"422\":1}}],[\"bin\",{\"1\":{\"381\":1}}],[\"binfmt\",{\"1\":{\"1\":1}}],[\"bytes=4294967296\",{\"1\":{\"366\":1}}],[\"b6\",{\"1\":{\"283\":2}}],[\"bgn\",{\"1\":{\"433\":1}}],[\"bgm\",{\"1\":{\"433\":1}}],[\"bgi\",{\"1\":{\"433\":4}}],[\"bgp的配置和管理也相对复杂\",{\"1\":{\"315\":1}}],[\"bgp缺乏内置的安全机制\",{\"1\":{\"314\":1}}],[\"bgp在处理大型网络拓扑变化时的收敛时间较长\",{\"1\":{\"314\":1}}],[\"bgp配置和管理相对复杂\",{\"1\":{\"314\":1}}],[\"bgp设计用于在大型\",{\"1\":{\"313\":1}}],[\"bgp允许管理员根据特定需求配置路由策略\",{\"1\":{\"313\":1}}],[\"bgp允许网络管理员基于策略控制路由选择和路由传播\",{\"1\":{\"310\":1}}],[\"bgp能够处理大量的路由信息\",{\"1\":{\"313\":1}}],[\"bgp路由器会发送路由更新\",{\"1\":{\"311\":1}}],[\"bgp路由器根据接收到的路由信息更新其路由表\",{\"1\":{\"311\":1}}],[\"bgp对等体之间就开始交换完整的bgp路由表\",{\"1\":{\"311\":1}}],[\"bgp使用一套复杂的路由选择规则来确定最佳路径\",{\"1\":{\"310\":1}}],[\"bgp是互联网的关键路由协议\",{\"1\":{\"315\":1}}],[\"bgp是一种路径向量协议\",{\"1\":{\"310\":1}}],[\"bgp是唯一能够处理互联网中如此大规模路由的协议\",{\"1\":{\"309\":1}}],[\"bgp运行在tcp之上\",{\"1\":{\"310\":1}}],[\"bgp\",{\"0\":{\"310\":1,\"311\":1,\"312\":1},\"1\":{\"309\":1,\"310\":1}}],[\"bgp协议\",{\"0\":{\"309\":1}}],[\"bg\",{\"1\":{\"242\":1}}],[\"bgwtr\",{\"1\":{\"97\":2}}],[\"bc\",{\"1\":{\"156\":1}}],[\"b\",{\"0\":{\"405\":1,\"411\":1},\"1\":{\"149\":3,\"150\":2,\"429\":2,\"443\":2,\"444\":1}}],[\"br0\",{\"1\":{\"300\":2}}],[\"br0显示设备br0的fdb\",{\"1\":{\"299\":1}}],[\"brd\",{\"1\":{\"283\":4}}],[\"br\",{\"1\":{\"149\":1,\"299\":1,\"300\":1}}],[\"broadcast\",{\"1\":{\"143\":2,\"164\":2,\"165\":3,\"183\":1,\"196\":1}}],[\"branch\",{\"1\":{\"98\":1}}],[\"bridge\",{\"0\":{\"296\":1},\"1\":{\"47\":1,\"296\":1,\"299\":4,\"300\":3,\"301\":1,\"335\":1,\"381\":1}}],[\"block\",{\"1\":{\"255\":1}}],[\"blocking\",{\"1\":{\"150\":1,\"204\":1}}],[\"blog\",{\"1\":{\"224\":1}}],[\"blob\",{\"1\":{\"1\":1}}],[\"blank\",{\"1\":{\"75\":1}}],[\"bert模型的参数数量分别为1\",{\"1\":{\"410\":1}}],[\"bert\",{\"1\":{\"410\":3,\"416\":2}}],[\"behavior\",{\"1\":{\"212\":1}}],[\"been\",{\"1\":{\"212\":1,\"263\":1}}],[\"between\",{\"1\":{\"175\":2}}],[\"before\",{\"1\":{\"175\":1}}],[\"be\",{\"1\":{\"150\":1,\"156\":2,\"175\":1,\"205\":2,\"212\":1}}],[\"beian\",{\"1\":{\"75\":1}}],[\"besteffort\",{\"1\":{\"51\":1}}],[\"bash\",{\"1\":{\"366\":1}}],[\"base64=1\",{\"1\":{\"381\":1}}],[\"base64\",{\"1\":{\"366\":1}}],[\"base\",{\"1\":{\"1\":1,\"149\":1,\"366\":2,\"372\":1}}],[\"baye\",{\"1\":{\"359\":2}}],[\"bayesian\",{\"1\":{\"105\":1}}],[\"batch\",{\"1\":{\"188\":1,\"366\":2}}],[\"balanced\",{\"1\":{\"175\":1,\"176\":1}}],[\"bandwidth\",{\"1\":{\"149\":1}}],[\"backends\",{\"1\":{\"205\":3}}],[\"backend=\",{\"1\":{\"183\":1}}],[\"backend\",{\"0\":{\"205\":1,\"206\":1},\"1\":{\"97\":2,\"181\":1,\"202\":1,\"204\":2,\"205\":2,\"206\":5,\"207\":3,\"366\":1}}],[\"backendcode\",{\"1\":{\"75\":1}}],[\"backendip\",{\"1\":{\"75\":1}}],[\"background\",{\"1\":{\"62\":1,\"75\":1}}],[\"border\",{\"1\":{\"309\":1}}],[\"bot\",{\"1\":{\"372\":4}}],[\"both\",{\"1\":{\"156\":1}}],[\"bottom\",{\"1\":{\"75\":1}}],[\"booted\",{\"1\":{\"263\":1}}],[\"boot生态体系\",{\"1\":{\"128\":1}}],[\"boot\",{\"1\":{\"128\":1,\"263\":1,\"387\":1,\"389\":2}}],[\"boot框架开发企业级应用\",{\"1\":{\"127\":1}}],[\"bootstrap\",{\"1\":{\"62\":1,\"149\":3}}],[\"body>\",{\"1\":{\"75\":1}}],[\"body\",{\"1\":{\"75\":1}}],[\"bounds\",{\"1\":{\"149\":1}}],[\"bound\",{\"1\":{\"16\":1,\"17\":1}}],[\"bucket=lobe\",{\"1\":{\"382\":1}}],[\"bucket=$\",{\"1\":{\"381\":1}}],[\"bucket\",{\"0\":{\"383\":1},\"1\":{\"381\":1,\"382\":1,\"383\":1}}],[\"bufferid\",{\"1\":{\"365\":6}}],[\"bus\",{\"1\":{\"149\":1}}],[\"busbw\",{\"1\":{\"149\":2}}],[\"busid\",{\"1\":{\"149\":3}}],[\"built\",{\"1\":{\"98\":1}}],[\"build\",{\"1\":{\"2\":1,\"145\":1,\"149\":2}}],[\"buildkit\",{\"1\":{\"1\":2}}],[\"buildx\",{\"0\":{\"1\":1},\"1\":{\"1\":1,\"2\":1}}],[\"but\",{\"1\":{\"62\":1,\"205\":1}}],[\"bundle\",{\"1\":{\"62\":1}}],[\"burstable\",{\"1\":{\"51\":1}}]],\"serializationVersion\":2}}")).map(([e,t])=>[e,zt(t,{fields:["h","t","c"],storeFields:["h","t","c"]})]));self.onmessage=({data:{type:e="all",query:t,locale:s,options:n,id:o}})=>{const u=bt[s];e==="suggest"?self.postMessage([e,o,tt(t,u,n)]):e==="search"?self.postMessage([e,o,Z(t,u,n)]):self.postMessage({suggestions:[e,o,tt(t,u,n)],results:[e,o,Z(t,u,n)]})};
//# sourceMappingURL=index.js.map
