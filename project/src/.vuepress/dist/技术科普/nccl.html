<!doctype html>
<html lang="zh-CN" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.13" />
    <meta name="theme" content="VuePress Theme Hope 2.0.0-rc.48" />
    <style>
      html {
        background: var(--bg-color, #fff);
      }

      html[data-theme="dark"] {
        background: var(--bg-color, #1d1e1f);
      }

      body {
        background: var(--bg-color);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <meta property="og:url" content="https://mousesun846.github.io/KnowledgeBlog/KnowledgeBlog/%E6%8A%80%E6%9C%AF%E7%A7%91%E6%99%AE/nccl.html"><meta property="og:site_name" content="知识笔记"><meta property="og:title" content="nccl"><meta property="og:description" content="nccl nccl NCCL是一款独立的库，提供标准的 GPU 通信例程，支持全规约（all-reduce）、全收集（all-gather）、规约（reduce）、广播（broadcast）、规约并散播（reduce-scatter）以及任意基于发送/接收的通信模式。该库经过优化，能够在使用 PCIe、NVLink、NVSwitch 以及基于 Infi..."><meta property="og:type" content="article"><meta property="og:locale" content="zh-CN"><meta property="og:updated_time" content="2024-10-14T09:43:08.000Z"><meta property="article:author" content="MouseSun"><meta property="article:tag" content="nccl"><meta property="article:published_time" content="2024-10-08T00:00:00.000Z"><meta property="article:modified_time" content="2024-10-14T09:43:08.000Z"><script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"nccl","image":[""],"datePublished":"2024-10-08T00:00:00.000Z","dateModified":"2024-10-14T09:43:08.000Z","author":[{"@type":"Person","name":"MouseSun","url":"https://github.com/MouseSun846","email":""}]}</script><script type="text/javascript" src="https://fastly.jsdelivr.net/gh/stevenjoezhang/live2d-widget@latest/autoload.js"></script><title>nccl | 知识笔记</title><meta name="description" content="nccl nccl NCCL是一款独立的库，提供标准的 GPU 通信例程，支持全规约（all-reduce）、全收集（all-gather）、规约（reduce）、广播（broadcast）、规约并散播（reduce-scatter）以及任意基于发送/接收的通信模式。该库经过优化，能够在使用 PCIe、NVLink、NVSwitch 以及基于 Infi...">
    <link rel="preload" href="/KnowledgeBlog/assets/style-7-V567VJ.css" as="style"><link rel="stylesheet" href="/KnowledgeBlog/assets/style-7-V567VJ.css">
    <link rel="modulepreload" href="/KnowledgeBlog/assets/app-CqFSg5zC.js"><link rel="modulepreload" href="/KnowledgeBlog/assets/nccl.html-CX8__itw.js">
    <link rel="prefetch" href="/KnowledgeBlog/assets/index.html-yUv-lfIz.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/docker.html-BBVIHKMM.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/etcd.html-iWtwVqzZ.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/k8s.html-D7nlRjGA.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/kong.html-kRkcS0IX.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/kubeflow.html-BWVYYLBr.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/operator.html-6rSdUjYf.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/介绍.html-C5nqhdsB.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/Clash转V2ray.html-4jPbzCWh.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/异构计算.html-DTZD2oND.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/pytorch.html-BZ6EZYyJ.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/triton.html-BFunncuS.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/学习资料.html-TEt-erg2.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/工具.html-DGihUIve.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/开源技术.html-Cd3jKStn.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/操作系统.html-BBoHFd87.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/计算机网络.html-g7xsie4R.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/独立开发者.html-DfrMQ60Y.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/fastgpt.html-D3eer7L8.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/lobechat.html-BVwRx8w0.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/Auth.html-BPN-3HOE.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/MPress.html-CiRpr0GM.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/nnScaler.html-B-fIu5AY.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/index.html-DsCbqcfP.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/404.html-BOcbMeeE.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/index.html-B9ShzxOd.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/index.html-SC4GbKQV.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/index.html-Czb-4w3_.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/index.html-CF0uH9kY.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/index.html-JhMHPHPM.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/index.html-1Llo-_nT.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/index.html-CvExUgJX.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/index.html-DGuLUP_M.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/index.html-DslbogFv.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/index.html-BtCT8u58.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/index.html-DZQr7QbA.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/index.html-DlQAUgR4.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/index.html-C1x3K-hM.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/index.html-C0q6NHU2.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/index.html-BEsZZlmJ.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/index.html-B-p-oj59.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/index.html-hCaghuq4.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/index.html-E1dwkyUR.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/index.html-BcXhDeuO.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/index.html-Bk-lFBCl.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/index.html-D1Izhp_B.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/index.html-CnZMa8B4.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/index.html-STw2UEVL.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/index.html-CRhylAjV.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/index.html-D3ytL-8v.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/index.html-7pLuClGo.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/index.html-DUPHkgL5.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/index.html-CoJfLAIN.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/index.html-DTGTrJt7.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/index.html-D66Ew9FJ.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/index.html-C0exaOBh.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/index.html-Ce1ilKqV.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/index.html-5Tf6HbZI.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/index.html-CEHXPlBp.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/index.html-B7Qrux70.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/index.html-BZkpfWyU.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/index.html-BIs_jdcZ.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/index.html-BNeHhtQZ.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/index.html-ClOqi-4P.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/index.html--kfXXzQB.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/index.html-D-R6ZlgX.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/index.html-CFA3JS8q.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/index.html-zaCw_KoI.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/index.html-DfDILYir.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/index.html-DFMv1Zeu.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/index.html-umZUuSjm.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/index.html-fMs2uXdJ.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/index.html-Bc2BVEBu.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/index.html-D_Qq5v7-.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/index.html-B_pENLr9.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/index.html-zi2tSbKg.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/index.html-DbkuNsCy.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/index.html-uchHNmUb.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/index.html-eay8pIOn.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/index.html-B7r0Td2L.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/index.html-CfGPwIoM.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/index.html-DPc5WPaB.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/index.html-CU-xXH08.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/index.html-CJ6WMohK.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/index.html-BM-HjauT.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/index.html-D_brA29S.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/index.html-CIYypcJT.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/index-DwmbPLJg.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/index-DRWmbcXV.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/index-AxlX3bpC.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/photoswipe.esm-GXRgw7eJ.js" as="script"><link rel="prefetch" href="/KnowledgeBlog/assets/SearchResult-Dns_7_wt.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">跳至主要內容</a><!--]--><!--[--><div class="theme-container external-link-icon has-toc"><!--[--><header id="navbar" class="vp-navbar"><div class="vp-navbar-start"><button type="button" class="vp-toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!----><!--[--><a class="route-link vp-brand" href="/KnowledgeBlog/"><img class="vp-nav-logo" src="https://mousesun846.github.io/KnowledgeBlog/logo.png" alt><!----><span class="vp-site-name hide-in-pad">知识笔记</span></a><!--]--><!----></div><div class="vp-navbar-center"><!----><!--[--><nav class="vp-nav-links"><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/KnowledgeBlog/" aria-label="主页"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-home" style=""></span><!--]-->主页<!----></a></div><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/KnowledgeBlog/%E4%BB%8B%E7%BB%8D/" aria-label="介绍"><!---->介绍<!----></a></div><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/KnowledgeBlog/%E4%BA%91%E5%8E%9F%E7%94%9F/" aria-label="云原生"><!---->云原生<!----></a></div><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/KnowledgeBlog/%E6%9D%82%E8%B0%88/" aria-label="杂谈"><!---->杂谈<!----></a></div><div class="vp-nav-item hide-in-mobile"><a class="route-link route-link-active auto-link" href="/KnowledgeBlog/%E6%8A%80%E6%9C%AF%E7%A7%91%E6%99%AE/" aria-label="技术科普"><!---->技术科普<!----></a></div><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/KnowledgeBlog/%E5%B7%A5%E5%85%B7/" aria-label="工具"><!---->工具<!----></a></div><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/KnowledgeBlog/%E5%BC%82%E6%9E%84%E8%AE%A1%E7%AE%97/" aria-label="异构计算"><!---->异构计算<!----></a></div></nav><!--]--><!----></div><div class="vp-navbar-end"><!----><!--[--><!----><!----><div class="vp-nav-item hide-in-mobile"><button type="button" class="vp-outlook-button" tabindex="-1" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" class="icon outlook-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="outlook icon" name="outlook"><path d="M224 800c0 9.6 3.2 44.8 6.4 54.4 6.4 48-48 76.8-48 76.8s80 41.6 147.2 0 134.4-134.4 38.4-195.2c-22.4-12.8-41.6-19.2-57.6-19.2C259.2 716.8 227.2 761.6 224 800zM560 675.2l-32 51.2c-51.2 51.2-83.2 32-83.2 32 25.6 67.2 0 112-12.8 128 25.6 6.4 51.2 9.6 80 9.6 54.4 0 102.4-9.6 150.4-32l0 0c3.2 0 3.2-3.2 3.2-3.2 22.4-16 12.8-35.2 6.4-44.8-9.6-12.8-12.8-25.6-12.8-41.6 0-54.4 60.8-99.2 137.6-99.2 6.4 0 12.8 0 22.4 0 12.8 0 38.4 9.6 48-25.6 0-3.2 0-3.2 3.2-6.4 0-3.2 3.2-6.4 3.2-6.4 6.4-16 6.4-16 6.4-19.2 9.6-35.2 16-73.6 16-115.2 0-105.6-41.6-198.4-108.8-268.8C704 396.8 560 675.2 560 675.2zM224 419.2c0-28.8 22.4-51.2 51.2-51.2 28.8 0 51.2 22.4 51.2 51.2 0 28.8-22.4 51.2-51.2 51.2C246.4 470.4 224 448 224 419.2zM320 284.8c0-22.4 19.2-41.6 41.6-41.6 22.4 0 41.6 19.2 41.6 41.6 0 22.4-19.2 41.6-41.6 41.6C339.2 326.4 320 307.2 320 284.8zM457.6 208c0-12.8 12.8-25.6 25.6-25.6 12.8 0 25.6 12.8 25.6 25.6 0 12.8-12.8 25.6-25.6 25.6C470.4 233.6 457.6 220.8 457.6 208zM128 505.6C128 592 153.6 672 201.6 736c28.8-60.8 112-60.8 124.8-60.8-16-51.2 16-99.2 16-99.2l316.8-422.4c-48-19.2-99.2-32-150.4-32C297.6 118.4 128 291.2 128 505.6zM764.8 86.4c-22.4 19.2-390.4 518.4-390.4 518.4-22.4 28.8-12.8 76.8 22.4 99.2l9.6 6.4c35.2 22.4 80 12.8 99.2-25.6 0 0 6.4-12.8 9.6-19.2 54.4-105.6 275.2-524.8 288-553.6 6.4-19.2-3.2-32-19.2-32C777.6 76.8 771.2 80 764.8 86.4z"></path></svg><div class="vp-outlook-dropdown"><!----></div></button></div><!--[--><button type="button" class="search-pro-button" aria-label="搜索"><svg xmlns="http://www.w3.org/2000/svg" class="icon search-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="search icon" name="search"><path d="M192 480a256 256 0 1 1 512 0 256 256 0 0 1-512 0m631.776 362.496-143.2-143.168A318.464 318.464 0 0 0 768 480c0-176.736-143.264-320-320-320S128 303.264 128 480s143.264 320 320 320a318.016 318.016 0 0 0 184.16-58.592l146.336 146.368c12.512 12.48 32.768 12.48 45.28 0 12.48-12.512 12.48-32.768 0-45.28"></path></svg><div class="search-pro-placeholder">搜索</div><div class="search-pro-key-hints"><kbd class="search-pro-key">Ctrl</kbd><kbd class="search-pro-key">K</kbd></div></button><!--]--><!--]--><!----><button type="button" class="vp-toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span><span class="vp-top"></span><span class="vp-middle"></span><span class="vp-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><aside id="sidebar" class="vp-sidebar"><!----><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">论文解读</span><span class="vp-arrow end"></span></button><!----></section></li><li><a class="route-link auto-link vp-sidebar-link" href="/KnowledgeBlog/%E6%8A%80%E6%9C%AF%E7%A7%91%E6%99%AE/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.html" aria-label="操作系统"><!---->操作系统<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/KnowledgeBlog/%E6%8A%80%E6%9C%AF%E7%A7%91%E6%99%AE/%E5%B7%A5%E5%85%B7.html" aria-label="常用工具总结"><!---->常用工具总结<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/KnowledgeBlog/%E6%8A%80%E6%9C%AF%E7%A7%91%E6%99%AE/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C.html" aria-label="计算机网络"><!---->计算机网络<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/KnowledgeBlog/%E6%8A%80%E6%9C%AF%E7%A7%91%E6%99%AE/%E5%BC%80%E6%BA%90%E6%8A%80%E6%9C%AF.html" aria-label="开源技术"><!---->开源技术<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/KnowledgeBlog/%E6%8A%80%E6%9C%AF%E7%A7%91%E6%99%AE/%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%96%99.html" aria-label="学习资料"><!---->学习资料<!----></a></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">AI大模型部署</span><span class="vp-arrow end"></span></button><!----></section></li><li><a class="route-link route-link-active auto-link vp-sidebar-link active" href="/KnowledgeBlog/%E6%8A%80%E6%9C%AF%E7%A7%91%E6%99%AE/nccl.html" aria-label="nccl"><!---->nccl<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/KnowledgeBlog/%E6%8A%80%E6%9C%AF%E7%A7%91%E6%99%AE/pytorch.html" aria-label="PyTorch"><!---->PyTorch<!----></a></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Springboot</span><span class="vp-arrow end"></span></button><!----></section></li><li><a class="route-link auto-link vp-sidebar-link" href="/KnowledgeBlog/%E6%8A%80%E6%9C%AF%E7%A7%91%E6%99%AE/triton.html" aria-label="Triton Inference Server"><!---->Triton Inference Server<!----></a></li></ul><!----></aside><!--[--><main id="main-content" class="vp-page"><!--[--><!----><!----><nav class="vp-breadcrumb disable"></nav><div class="vp-page-title"><h1><!---->nccl</h1><div class="page-info"><span class="page-author-info" aria-label="作者🖊" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon author-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="author icon" name="author"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z"></path></svg><span><a class="page-author-item" href="https://github.com/MouseSun846" target="_blank" rel="noopener noreferrer">MouseSun</a></span><span property="author" content="MouseSun"></span></span><!----><span class="page-date-info" aria-label="写作日期📅" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon calendar-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="calendar icon" name="calendar"><path d="M716.4 110.137c0-18.753-14.72-33.473-33.472-33.473-18.753 0-33.473 14.72-33.473 33.473v33.473h66.993v-33.473zm-334.87 0c0-18.753-14.72-33.473-33.473-33.473s-33.52 14.72-33.52 33.473v33.473h66.993v-33.473zm468.81 33.52H716.4v100.465c0 18.753-14.72 33.473-33.472 33.473a33.145 33.145 0 01-33.473-33.473V143.657H381.53v100.465c0 18.753-14.72 33.473-33.473 33.473a33.145 33.145 0 01-33.473-33.473V143.657H180.6A134.314 134.314 0 0046.66 277.595v535.756A134.314 134.314 0 00180.6 947.289h669.74a134.36 134.36 0 00133.94-133.938V277.595a134.314 134.314 0 00-133.94-133.938zm33.473 267.877H147.126a33.145 33.145 0 01-33.473-33.473c0-18.752 14.72-33.473 33.473-33.473h736.687c18.752 0 33.472 14.72 33.472 33.473a33.145 33.145 0 01-33.472 33.473z"></path></svg><span><!----></span><meta property="datePublished" content="2024-10-08T00:00:00.000Z"></span><!----><span class="page-reading-time-info" aria-label="阅读时间⌛" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon" name="timer"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>大约 24 分钟</span><meta property="timeRequired" content="PT24M"></span><span class="page-category-info" aria-label="分类🌈" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon category-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="category icon" name="category"><path d="M148.41 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H148.41c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.311-40.31zM147.556 553.478H429.73c22.263 0 40.311 18.048 40.311 40.31v282.176c0 22.263-18.048 40.312-40.31 40.312H147.555c-22.263 0-40.311-18.049-40.311-40.312V593.79c0-22.263 18.048-40.311 40.31-40.311zM593.927 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H593.927c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.31-40.31zM730.22 920.502H623.926c-40.925 0-74.22-33.388-74.22-74.425V623.992c0-41.038 33.387-74.424 74.425-74.424h222.085c41.038 0 74.424 33.226 74.424 74.067v114.233c0 10.244-8.304 18.548-18.547 18.548s-18.548-8.304-18.548-18.548V623.635c0-20.388-16.746-36.974-37.33-36.974H624.13c-20.585 0-37.331 16.747-37.331 37.33v222.086c0 20.585 16.654 37.331 37.126 37.331H730.22c10.243 0 18.547 8.304 18.547 18.547 0 10.244-8.304 18.547-18.547 18.547z"></path></svg><!--[--><span class="page-category-item color4 clickable" role="navigation">nccl</span><!--]--><meta property="articleSection" content="nccl"></span><span class="page-tag-info" aria-label="标签🏷" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon tag-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="tag icon" name="tag"><path d="M939.902 458.563L910.17 144.567c-1.507-16.272-14.465-29.13-30.737-30.737L565.438 84.098h-.402c-3.215 0-5.726 1.005-7.634 2.913l-470.39 470.39a10.004 10.004 0 000 14.164l365.423 365.424c1.909 1.908 4.42 2.913 7.132 2.913s5.223-1.005 7.132-2.913l470.39-470.39c2.01-2.11 3.014-5.023 2.813-8.036zm-240.067-72.121c-35.458 0-64.286-28.828-64.286-64.286s28.828-64.285 64.286-64.285 64.286 28.828 64.286 64.285-28.829 64.286-64.286 64.286z"></path></svg><!--[--><span class="page-tag-item color4 clickable" role="navigation">nccl</span><!--]--><meta property="keywords" content="nccl"></span></div><hr></div><div class="vp-toc-placeholder"><aside id="toc"><!----><div class="vp-toc-header">此页内容<button type="button" class="print-button" title="打印"><svg xmlns="http://www.w3.org/2000/svg" class="icon print-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="print icon" name="print"><path d="M819.2 364.8h-44.8V128c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v236.8h-44.8C145.067 364.8 96 413.867 96 473.6v192c0 59.733 49.067 108.8 108.8 108.8h44.8V896c0 17.067 14.933 32 32 32h460.8c17.067 0 32-14.933 32-32V774.4h44.8c59.733 0 108.8-49.067 108.8-108.8v-192c0-59.733-49.067-108.8-108.8-108.8zM313.6 160h396.8v204.8H313.6V160zm396.8 704H313.6V620.8h396.8V864zM864 665.6c0 25.6-19.2 44.8-44.8 44.8h-44.8V588.8c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v121.6h-44.8c-25.6 0-44.8-19.2-44.8-44.8v-192c0-25.6 19.2-44.8 44.8-44.8h614.4c25.6 0 44.8 19.2 44.8 44.8v192z"></path></svg></button><div class="arrow end"></div></div><div class="vp-toc-wrapper"><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#nccl">nccl</a></li><li><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#下载源码">下载源码</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#构建编译">构建编译</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#nccl-test">nccl-test</a></li><li><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#下载">下载</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#编译">编译</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#运行">运行</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#参数">参数</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#具体工作原理">具体工作原理</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#参数说明">参数说明：</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#返回">返回：</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#代码解释">代码解释：</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#应用场景">应用场景</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#torch-cuda-nccl-py">torch/cuda/nccl.py</a></li><li><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#核心功能">核心功能</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#参数解析">参数解析</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#核心逻辑">核心逻辑</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#示例">示例</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#torch-csrc-cuda-python-nccl-cpp">torch/csrc/cuda/python_nccl.cpp</a></li><li><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#代码解析">代码解析</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#总结">总结</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#torch-csrc-cuda-module-cpp">torch/csrc/cuda/Module.cpp</a></li><li><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#代码结构和功能">代码结构和功能</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#总结-1">总结</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#torch-dynamo-trace-rules-py">torch_dynamo\trace_rules.py</a></li><li><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#代码解析-1">代码解析</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#示例用法">示例用法</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#总结-2">总结</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#代码解析-2">代码解析</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#典型应用">典型应用</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#总结-3">总结</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#nccl-topo">nccl topo</a></li><li><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#代码解析-3">代码解析：</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#拓扑结构的意义">拓扑结构的意义：</a></li><!----><!--]--></ul></li><!--]--></ul><div class="vp-toc-marker" style="top:-1.7rem;"></div></div><!----></aside></div><!----><div class="theme-hope-content"><div class="hint-container tip"><p class="hint-container-title">nccl</p></div><h2 id="nccl" tabindex="-1"><a class="header-anchor" href="#nccl"><span>nccl</span></a></h2><p>NCCL是一款独立的库，提供标准的 GPU 通信例程，支持全规约（all-reduce）、全收集（all-gather）、规约（reduce）、广播（broadcast）、规约并散播（reduce-scatter）以及任意基于发送/接收的通信模式。该库经过优化，能够在使用 PCIe、NVLink、NVSwitch 以及基于 InfiniBand Verbs 或 TCP/IP 套接字的网络平台上实现高带宽。NCCL 支持任意数量的 GPU，无论是安装在单节点还是跨多个节点的系统中，并且可以在单进程或多进程（如 MPI）应用程序中使用。</p><p>NCCL 概述<br> NVIDIA 集体通信库（NCCL，发音为“Nickel”）是一个库，提供拓扑感知的 GPU 间通信原语，能够方便地集成到应用程序中。</p><p>NCCL 实现了集体通信和点对点发送/接收原语。它不是一个完整的并行编程框架，而是一个专注于加速 GPU 间通信的库。</p><p>NCCL 提供以下集体通信原语：</p><ul><li>AllReduce（全规约）</li><li>Broadcast（广播）</li><li>Reduce（规约）</li><li>AllGather（全收集）</li><li>ReduceScatter（规约并散播）</li></ul><p>此外，它还支持点对点发送/接收通信，允许实现 scatter、gather 或 all-to-all 操作。</p><p>在集体通信中，通信处理器之间的紧密同步是关键。传统上，基于 CUDA 的集体操作通常通过 CUDA 内存拷贝操作和 CUDA 核函数结合本地规约来实现。而 NCCL 则将每个集体操作实现为一个处理通信和计算操作的单一核函数。这样可以实现快速同步，并最大限度地减少达到峰值带宽所需的资源。</p><p>NCCL 方便地免除了开发人员为特定机器优化应用程序的需求。NCCL 在多个 GPU 之间提供快速的集体通信，无论是在单个节点内还是跨节点。它支持多种互连技术，包括 PCIe、NVLINK、InfiniBand Verbs 和 IP 套接字。</p><p>除了性能，简便的编程体验也是 NCCL 设计的主要考虑因素之一。NCCL 使用简单的 C API，可以轻松通过多种编程语言访问。NCCL 紧密遵循 MPI（消息传递接口）定义的流行集体操作 API，因此熟悉 MPI 的用户会发现 NCCL 的 API 非常容易使用。与 MPI 略有不同的是，NCCL 的集体操作带有一个“流”参数，使其能够直接与 CUDA 编程模型集成。最后，NCCL 几乎兼容任何多 GPU 并行化模型，例如：</p><ul><li>单线程控制所有 GPU</li><li>多线程（例如，每个 GPU 一个线程）</li><li>多进程（例如，MPI）</li></ul><p>NCCL 在深度学习框架中有着广泛的应用，AllReduce 集体操作在神经网络训练中被广泛使用。通过 NCCL 提供的多 GPU 和多节点通信，可以实现神经网络训练的高效扩展。</p><p>NCCL 是一个通信库，提供用于高性能应用的 GPU 间优化通信。与 MPI 不同，NCCL 不提供并行环境，也不包含进程启动器和管理器。因此，NCCL 依赖于应用程序的进程管理系统和 CPU 端的通信系统来进行自启动。</p><p>与 MPI 和其他为性能优化的库类似，NCCL 不提供 GPU 之间的安全网络通信。因此，用户有责任确保 NCCL 在安全的网络上运行，无论是在自启动阶段（由 NCCL_SOCKET_IFNAME 控制）还是在高速通信过程中。</p><h3 id="下载源码" tabindex="-1"><a class="header-anchor" href="#下载源码"><span>下载源码</span></a></h3><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span>git clone https://github.com/NVIDIA/nccl-tests.git</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h3 id="构建编译" tabindex="-1"><a class="header-anchor" href="#构建编译"><span>构建编译</span></a></h3><ul><li><p>修改换行格式 LF</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span>src\device\generate.py</span></span>
<span class="line"><span></span></span>
<span class="line"><span>src\device\Makefile</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li><li><p>编译并安装</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span> make -j src.build</span></span>
<span class="line"><span> make install</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div></li><li><p>构建产物如下</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span>├── include</span></span>
<span class="line"><span>│   ├── nccl.h</span></span>
<span class="line"><span>│   └── nccl_net.h</span></span>
<span class="line"><span>├── lib</span></span>
<span class="line"><span>    ├── libnccl.so -&gt; libnccl.so.2</span></span>
<span class="line"><span>    ├── libnccl.so.2 -&gt; libnccl.so.2.23.4</span></span>
<span class="line"><span>    ├── libnccl.so.2.23.4</span></span>
<span class="line"><span>    ├── libnccl_static.a</span></span>
<span class="line"><span>    └── pkgconfig</span></span>
<span class="line"><span>        └── nccl.pc</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li></ul><h2 id="nccl-test" tabindex="-1"><a class="header-anchor" href="#nccl-test"><span>nccl-test</span></a></h2><h3 id="下载" tabindex="-1"><a class="header-anchor" href="#下载"><span>下载</span></a></h3><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span>git clone https://github.com/NVIDIA/nccl-tests.git</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h3 id="编译" tabindex="-1"><a class="header-anchor" href="#编译"><span>编译</span></a></h3><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span>cd nccl-tests </span></span>
<span class="line"><span>make</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="运行" tabindex="-1"><a class="header-anchor" href="#运行"><span>运行</span></a></h3><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span>export NCCL_DEBUG=TRACE</span></span>
<span class="line"><span>./build/all_reduce_perf -b 8 -e 8M -f 2 -g 1</span></span>
<span class="line"><span></span></span>
<span class="line"><span></span></span>
<span class="line"><span>(base) root@DESKTOP-P54EAF3:/mnt/d/Code/nccl-tests# ./build/all_reduce_perf -b 8 -e 8M -f 2 -g 1</span></span>
<span class="line"><span># nThread 1 nGpus 1 minBytes 8 maxBytes 8388608 step: 2(factor) warmup iters: 5 iters: 20 agg iters: 1 validation: 1 graph: 0</span></span>
<span class="line"><span>#</span></span>
<span class="line"><span># Using devices</span></span>
<span class="line"><span>#  Rank  0 Group  0 Pid  58239 on DESKTOP-P54EAF3 device  0 [0x01] NVIDIA GeForce GTX 1660 SUPER</span></span>
<span class="line"><span>DESKTOP-P54EAF3:58239:58239 [0] NCCL INFO Bootstrap : Using eth0:172.26.190.235&lt;0&gt;</span></span>
<span class="line"><span>DESKTOP-P54EAF3:58239:58239 [0] NCCL INFO cudaDriverVersion 12050</span></span>
<span class="line"><span>DESKTOP-P54EAF3:58239:58239 [0] NCCL INFO NCCL version 2.23.4+cuda12.1</span></span>
<span class="line"><span>DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal network plugin.</span></span>
<span class="line"><span>DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO Failed to open libibverbs.so[.1]</span></span>
<span class="line"><span>DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO NET/Socket : Using [0]eth0:172.26.190.235&lt;0&gt; [1]br-eaee979aadb0:172.19.0.1&lt;0&gt; [2]vethd14a450:fe80::c821:6bff:fea5:dcf9%vethd14a450&lt;0&gt; [3]vethc5ec3b7:fe80::74f5:23ff:fe0a:3d6d%vethc5ec3b7&lt;0&gt;</span></span>
<span class="line"><span>DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so.</span></span>
<span class="line"><span>DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO Using network Socket</span></span>
<span class="line"><span>DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO ncclCommInitAll comm 0x559205409610 rank 0 nranks 1 cudaDev 0 nvmlDev 0 busId 1000 commId 0x89b784d33d72ebbb - Init START</span></span>
<span class="line"><span>DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO Bootstrap timings total 0.000344 (create 0.000019, send 0.000105, recv 0.000096, ring 0.000000, delay 0.000000)</span></span>
<span class="line"><span>DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO comm 0x559205409610 rank 0 nRanks 1 nNodes 1 localRanks 1 localRank 0 MNNVL 0</span></span>
<span class="line"><span>DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO Channel 00/32 : 0</span></span>
<span class="line"><span>DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO Channel 01/32 : 0</span></span>
<span class="line"><span>DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO Channel 02/32 : 0</span></span>
<span class="line"><span>DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO Channel 03/32 : 0</span></span>
<span class="line"><span>DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO Channel 04/32 : 0</span></span>
<span class="line"><span>DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO Channel 05/32 : 0</span></span>
<span class="line"><span>DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO Channel 06/32 : 0</span></span>
<span class="line"><span>DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO Channel 07/32 : 0</span></span>
<span class="line"><span>DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO Channel 08/32 : 0</span></span>
<span class="line"><span>DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO Channel 09/32 : 0</span></span>
<span class="line"><span>DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO Channel 10/32 : 0</span></span>
<span class="line"><span>DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO Channel 11/32 : 0</span></span>
<span class="line"><span>DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO Channel 12/32 : 0</span></span>
<span class="line"><span>DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO Channel 13/32 : 0</span></span>
<span class="line"><span>DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO Channel 14/32 : 0</span></span>
<span class="line"><span>DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO Channel 15/32 : 0</span></span>
<span class="line"><span>DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO Channel 16/32 : 0</span></span>
<span class="line"><span>DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO Channel 17/32 : 0</span></span>
<span class="line"><span>DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO Channel 18/32 : 0</span></span>
<span class="line"><span>DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO Channel 19/32 : 0</span></span>
<span class="line"><span>DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO Channel 20/32 : 0</span></span>
<span class="line"><span>DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO Channel 21/32 : 0</span></span>
<span class="line"><span>DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO Channel 22/32 : 0</span></span>
<span class="line"><span>DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO Channel 23/32 : 0</span></span>
<span class="line"><span>DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO Channel 24/32 : 0</span></span>
<span class="line"><span>DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO Channel 25/32 : 0</span></span>
<span class="line"><span>DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO Channel 26/32 : 0</span></span>
<span class="line"><span>DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO Channel 27/32 : 0</span></span>
<span class="line"><span>DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO Channel 28/32 : 0</span></span>
<span class="line"><span>DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO Channel 29/32 : 0</span></span>
<span class="line"><span>DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO Channel 30/32 : 0</span></span>
<span class="line"><span>DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO Channel 31/32 : 0</span></span>
<span class="line"><span>DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO Trees [0] -1/-1/-1-&gt;0-&gt;-1 [1] -1/-1/-1-&gt;0-&gt;-1 [2] -1/-1/-1-&gt;0-&gt;-1 [3] -1/-1/-1-&gt;0-&gt;-1 [4] -1/-1/-1-&gt;0-&gt;-1 [5] -1/-1/-1-&gt;0-&gt;-1 [6] -1/-1/-1-&gt;0-&gt;-1 [7] -1/-1/-1-&gt;0-&gt;-1 [8] -1/-1/-1-&gt;0-&gt;-1 [9] -1/-1/-1-&gt;0-&gt;-1 [10] -1/-1/-1-&gt;0-&gt;-1 [11] -1/-1/-1-&gt;0-&gt;-1 [12] -1/-1/-1-&gt;0-&gt;-1 [13] -1/-1/-1-&gt;0-&gt;-1 [14] -1/-1/-1-&gt;0-&gt;-1 [15] -1/-1/-1-&gt;0-&gt;-1 [16] -1/-1/-1-&gt;0-&gt;-1 [17] -1/-1/-1-&gt;0-&gt;-1 [18] -1/-1/-1-&gt;0-&gt;-1 [19] -1/-1/-1-&gt;0-&gt;-1 [20] -1/-1/-1-&gt;0-&gt;-1 [21] -1/-1/-1-&gt;0-&gt;-1 [22] -1/-1/-1-&gt;0-&gt;-1 [23] -1/-1/-1-&gt;0-&gt;-1 [24] -1/-1/-1-&gt;0-&gt;-1 [25] -1/-1/-1-&gt;0-&gt;-1 [26] -1/-1/-1-&gt;0-&gt;-1 [27] -1/-1/-1-&gt;0-&gt;-1 [28] -1/-1/-1-&gt;0-&gt;-1 [29] -1/-1/-1-&gt;0-&gt;-1 [30] -1/-1/-1-&gt;0-&gt;-1 [31] -1/-1/-1-&gt;0-&gt;-1</span></span>
<span class="line"><span>DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO P2P Chunksize set to 131072</span></span>
<span class="line"><span>DESKTOP-P54EAF3:58239:58246 [0] NCCL INFO [Proxy Service] Device 0 CPU core 8</span></span>
<span class="line"><span>DESKTOP-P54EAF3:58239:58247 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 11</span></span>
<span class="line"><span>DESKTOP-P54EAF3:58239:58248 [0] NCCL INFO [Proxy Progress] Device 0 CPU core 14</span></span>
<span class="line"><span>DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO 32 coll channels, 32 collnet channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer</span></span>
<span class="line"><span>DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO CC Off, Multi-GPU CC Off, workFifoBytes 1048576</span></span>
<span class="line"><span>DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so libnccl-net.so. Using internal tuner plugin.</span></span>
<span class="line"><span>DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO ncclCommInitAll comm 0x559205409610 rank 0 nranks 1 cudaDev 0 nvmlDev 0 busId 1000 commId 0x89b784d33d72ebbb - Init COMPLETE</span></span>
<span class="line"><span>DESKTOP-P54EAF3:58239:58245 [0] NCCL INFO Init timings - ncclCommInitAll: rank 0 nranks 1 total 0.22 (kernels 0.15, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.00, graphs 0.00, connections 0.01, rest 0.00) </span></span>
<span class="line"><span>#</span></span>
<span class="line"><span>#                                                              out-of-place                       in-place</span></span>
<span class="line"><span>#       size         count      type   redop    root     time   algbw   busbw #wrong     time   algbw   busbw #wrong</span></span>
<span class="line"><span>#        (B)    (elements)                               (us)  (GB/s)  (GB/s)            (us)  (GB/s)  (GB/s)</span></span>
<span class="line"><span>           8             2     float     sum      -1     9.32    0.00    0.00      0     0.14    0.06    0.00      0</span></span>
<span class="line"><span>          16             4     float     sum      -1    14.29    0.00    0.00      0     0.15    0.11    0.00      0</span></span>
<span class="line"><span>          32             8     float     sum      -1    12.24    0.00    0.00      0     0.15    0.22    0.00      0</span></span>
<span class="line"><span>          64            16     float     sum      -1    14.00    0.00    0.00      0     0.15    0.44    0.00      0</span></span>
<span class="line"><span>         128            32     float     sum      -1    11.98    0.01    0.00      0     1.06    0.12    0.00      0</span></span>
<span class="line"><span>         256            64     float     sum      -1    11.72    0.02    0.00      0     0.15    1.71    0.00      0</span></span>
<span class="line"><span>         512           128     float     sum      -1    13.87    0.04    0.00      0     0.15    3.53    0.00      0</span></span>
<span class="line"><span>        1024           256     float     sum      -1    13.81    0.07    0.00      0     0.15    6.83    0.00      0</span></span>
<span class="line"><span>        2048           512     float     sum      -1    17.77    0.12    0.00      0     0.15   13.65    0.00      0</span></span>
<span class="line"><span>        4096          1024     float     sum      -1    14.04    0.29    0.00      0     0.15   28.25    0.00      0</span></span>
<span class="line"><span>        8192          2048     float     sum      -1    13.54    0.61    0.00      0     0.15   54.61    0.00      0</span></span>
<span class="line"><span>       16384          4096     float     sum      -1    11.61    1.41    0.00      0     0.15  109.23    0.00      0</span></span>
<span class="line"><span>       32768          8192     float     sum      -1    13.64    2.40    0.00      0     0.15  218.45    0.00      0</span></span>
<span class="line"><span>       65536         16384     float     sum      -1    15.48    4.23    0.00      0     0.13  504.12    0.00      0</span></span>
<span class="line"><span>      131072         32768     float     sum      -1    23.09    5.68    0.00      0     0.13  1008.25    0.00      0</span></span>
<span class="line"><span>      262144         65536     float     sum      -1    25.09   10.45    0.00      0     0.14  1872.46    0.00      0</span></span>
<span class="line"><span>      524288        131072     float     sum      -1    26.29   19.94    0.00      0     0.15  3615.78    0.00      0</span></span>
<span class="line"><span>     1048576        262144     float     sum      -1    20.98   49.98    0.00      0     0.16  6553.60    0.00      0</span></span>
<span class="line"><span>     2097152        524288     float     sum      -1    26.15   80.20    0.00      0     0.16  13530.01    0.00      0</span></span>
<span class="line"><span>     4194304       1048576     float     sum      -1    37.97  110.46    0.00      0     0.15  27962.03    0.00      0</span></span>
<span class="line"><span>     8388608       2097152     float     sum      -1    66.97  125.27    0.00      0     0.14  59918.63    0.00      0</span></span>
<span class="line"><span>DESKTOP-P54EAF3:58239:58239 [0] NCCL INFO comm 0x559205409610 rank 0 nranks 1 cudaDev 0 busId 1000 - Destroy COMPLETE</span></span>
<span class="line"><span># Out of bounds values : 0 OK</span></span>
<span class="line"><span># Avg bus bandwidth    : 0</span></span>
<span class="line"><span>#</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="参数" tabindex="-1"><a class="header-anchor" href="#参数"><span>参数</span></a></h3><p>所有测试支持相同的一组参数：</p><ul><li>GPU 数量 <ul><li><code>-t,--nthreads &lt;线程数&gt;</code> 每个进程的线程数。默认值：1。</li><li><code>-g,--ngpus &lt;每个线程的 GPU 数量&gt;</code> 每个线程使用的 GPU 数量。默认值：1。</li></ul></li><li>扫描的大小范围 <ul><li><code>-b,--minbytes &lt;最小字节数&gt;</code> 开始的最小大小。默认值：32M。</li><li><code>-e,--maxbytes &lt;最大字节数&gt;</code> 结束的最大大小。默认值：32M。</li><li>递增方式可以是固定递增或乘法因子。仅应使用其中一种方式： <ul><li><code>-i,--stepbytes &lt;递增字节数&gt;</code> 各大小之间的固定增量。默认值：1M。</li><li><code>-f,--stepfactor &lt;递增因子&gt;</code> 各大小之间的乘法因子。默认值：禁用。</li></ul></li></ul></li><li>NCCL 操作参数 <ul><li><code>-o,--op &lt;sum/prod/min/max/avg/all&gt;</code> 指定执行哪种规约操作。仅对 Allreduce、Reduce 或 ReduceScatter 等规约操作有效。默认值：Sum（求和）。</li><li><code>-d,--datatype &lt;nccltype/all&gt;</code> 指定使用哪种数据类型。默认值：Float（浮点数）。</li><li><code>-r,--root &lt;root/all&gt;</code> 指定使用哪个 root，仅对有 root 的操作（如广播或规约）有效。默认值：0。</li></ul></li><li>性能参数 <ul><li><code>-n,--iters &lt;迭代次数&gt;</code> 迭代次数。默认值：20。</li><li><code>-w,--warmup_iters &lt;预热迭代次数&gt;</code> 预热迭代次数（不计时）。默认值：5。</li><li><code>-m,--agg_iters &lt;聚合次数&gt;</code> 每次迭代中聚合在一起的操作次数。默认值：1。</li><li><code>-N,--run_cycles &lt;循环次数&gt;</code> 运行并打印每个循环。默认值：1；0=无限循环。</li><li><code>-a,--average &lt;0/1/2/3&gt;</code> 将性能报告为所有节点的平均值（仅适用于 MPI=1）。&lt;0=Rank0, 1=平均, 2=最小, 3=最大&gt;。默认值：1（平均）。</li></ul></li><li>测试操作 <ul><li><code>-p,--parallel_init &lt;0/1&gt;</code> 使用线程并行初始化 NCCL。默认值：0。</li><li><code>-c,--check &lt;检查迭代次数&gt;</code> 执行指定次数的迭代，每次迭代都检查结果的正确性。对于大量 GPU 来说，这可能非常慢。默认值：1。</li><li><code>-z,--blocking &lt;0/1&gt;</code> 使 NCCL 操作阻塞，即在每次操作后等待并同步 CPU。默认值：0。</li><li><code>-G,--cudagraph &lt;CUDA 图启动次数&gt;</code> 将迭代捕获为 CUDA 图，然后重复指定次数。默认值：0。</li><li><code>-C,--report_cputime &lt;0/1&gt;</code> 报告 CPU 时间而非延迟。默认值：0。</li><li><code>-R,--local_register &lt;1/0&gt;</code> 在发送/接收缓冲区上启用本地缓冲区注册。默认值：0。</li><li><code>-T,--timeout &lt;超时时间（秒）&gt;</code> 在指定秒数后对每个测试进行超时。默认值：禁用。</li></ul></li></ul><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span>def get_group_rank(group: ProcessGroup, global_rank: int) -&gt; int:</span></span>
<span class="line"><span>    &quot;&quot;&quot;</span></span>
<span class="line"><span>    Translate a global rank into a group rank.</span></span>
<span class="line"><span></span></span>
<span class="line"><span>    ``global_rank`` must be part of ``group`` otherwise this raises RuntimeError.</span></span>
<span class="line"><span></span></span>
<span class="line"><span>    Args:</span></span>
<span class="line"><span>        group (ProcessGroup): ProcessGroup to find the relative rank.</span></span>
<span class="line"><span>        global_rank (int): Global rank to query.</span></span>
<span class="line"><span></span></span>
<span class="line"><span>    Returns:</span></span>
<span class="line"><span>        Group rank of ``global_rank`` relative to ``group``</span></span>
<span class="line"><span></span></span>
<span class="line"><span>    N.B. calling this function on the default process group returns identity</span></span>
<span class="line"><span>    &quot;&quot;&quot;</span></span>
<span class="line"><span>    if group is GroupMember.WORLD:</span></span>
<span class="line"><span>        return global_rank</span></span>
<span class="line"><span>    if group not in _world.pg_group_ranks:</span></span>
<span class="line"><span>        raise ValueError(</span></span>
<span class="line"><span>            f&quot;Group {group} is not registered, please create group with torch.distributed.new_group API&quot;</span></span>
<span class="line"><span>        )</span></span>
<span class="line"><span>    group_ranks = _world.pg_group_ranks[group]</span></span>
<span class="line"><span>    if global_rank not in group_ranks:</span></span>
<span class="line"><span>        raise ValueError(f&quot;Global rank {global_rank} is not part of group {group}&quot;)</span></span>
<span class="line"><span></span></span>
<span class="line"><span>    return group_ranks[global_rank]</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>这段代码的主要功能是将一个全局的 rank 转换为在某个进程组中的 rank。它实现了在分布式训练中，通过全局 rank 查询某个特定进程组内的相对 rank。如果 <code>global_rank</code> 不在给定的进程组 <code>group</code> 中，该函数会抛出 <code>ValueError</code> 异常。</p><h3 id="具体工作原理" tabindex="-1"><a class="header-anchor" href="#具体工作原理"><span>具体工作原理</span></a></h3><ol><li><p><strong>判断是否为默认进程组</strong>：</p><ul><li>如果 <code>group</code> 是默认的进程组 <code>GroupMember.WORLD</code>，则直接返回 <code>global_rank</code>，因为默认进程组中的 rank 就是全局 rank，保持不变。</li></ul></li><li><p><strong>检查组是否注册</strong>：</p><ul><li>如果 <code>group</code> 没有在 <code>_world.pg_group_ranks</code> 中找到，则抛出异常。<code>_world.pg_group_ranks</code> 存储了所有创建的进程组及其对应的 ranks。</li></ul></li><li><p><strong>检查全局 rank 是否在该组中</strong>：</p><ul><li>如果 <code>global_rank</code> 不在 <code>group_ranks</code> 列表中，抛出异常。<code>group_ranks</code> 保存了 <code>group</code> 中的全局 rank 映射。</li></ul></li><li><p><strong>返回相对 rank</strong>：</p><ul><li>最终根据 <code>group_ranks</code> 返回 <code>global_rank</code> 在 <code>group</code> 中的相对 rank。</li></ul></li></ol><h3 id="参数说明" tabindex="-1"><a class="header-anchor" href="#参数说明"><span>参数说明：</span></a></h3><ul><li><code>group (ProcessGroup)</code>：PyTorch 分布式的进程组，通常由 <code>torch.distributed.new_group</code> 创建。</li><li><code>global_rank (int)</code>：全局 rank 值，通常是指分布式训练中全局进程的编号。</li></ul><h3 id="返回" tabindex="-1"><a class="header-anchor" href="#返回"><span>返回：</span></a></h3><ul><li>返回值是 <code>global_rank</code> 在指定 <code>group</code> 中的 rank。</li></ul><h3 id="代码解释" tabindex="-1"><a class="header-anchor" href="#代码解释"><span>代码解释：</span></a></h3><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#C678DD;">if</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> group </span><span style="--shiki-light:#D73A49;--shiki-dark:#C678DD;">is</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> GroupMember.</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">WORLD</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">:</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#C678DD;">    return</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> global_rank</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>这段代码检查传入的 <code>group</code> 是否是默认的全局进程组。如果是的话，<code>global_rank</code> 和相对 rank 是一致的，直接返回。</li></ul><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#C678DD;">if</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> group </span><span style="--shiki-light:#D73A49;--shiki-dark:#C678DD;">not</span><span style="--shiki-light:#D73A49;--shiki-dark:#C678DD;"> in</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> _world.pg_group_ranks:</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#C678DD;">    raise</span><span style="--shiki-light:#005CC5;--shiki-dark:#ABB2BF;"> ValueError</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">(</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#C678DD;">        f</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">&quot;Group </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">{</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">group</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">}</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> is not registered, please create group with torch.distributed.new_group API&quot;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">    )</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>这里检查是否传入的 <code>group</code> 已经被注册到 <code>_world.pg_group_ranks</code> 中。如果没有注册，则抛出 <code>ValueError</code>，并提示用户需要通过 <code>torch.distributed.new_group</code> 来创建该组。</li></ul><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">group_ranks </span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> _world.pg_group_ranks[group]</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#C678DD;">if</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> global_rank </span><span style="--shiki-light:#D73A49;--shiki-dark:#C678DD;">not</span><span style="--shiki-light:#D73A49;--shiki-dark:#C678DD;"> in</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> group_ranks:</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#C678DD;">    raise</span><span style="--shiki-light:#005CC5;--shiki-dark:#ABB2BF;"> ValueError</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#D73A49;--shiki-dark:#C678DD;">f</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">&quot;Global rank </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">{</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">global_rank</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">}</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> is not part of group </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">{</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">group</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">}</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>这段代码从 <code>_world.pg_group_ranks</code> 获取当前 <code>group</code> 的所有全局 rank。如果 <code>global_rank</code> 不在该组中，则抛出异常。</li></ul><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#C678DD;">return</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> group_ranks[global_rank]</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><ul><li>最终返回 <code>global_rank</code> 在 <code>group</code> 中的相对 rank。</li></ul><h3 id="应用场景" tabindex="-1"><a class="header-anchor" href="#应用场景"><span>应用场景</span></a></h3><p>此功能非常适用于在分布式训练中处理多个进程组的情况，用户可以轻松找到某个全局 rank 在特定组内的 rank，从而进行更细粒度的进程控制或通信。</p><h2 id="torch-cuda-nccl-py" tabindex="-1"><a class="header-anchor" href="#torch-cuda-nccl-py"><span>torch/cuda/nccl.py</span></a></h2><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span># `output` used to be `outputs`, taking in a list of tensors. So we have two</span></span>
<span class="line"><span># arguments for BC reasons.</span></span>
<span class="line"><span>def reduce(</span></span>
<span class="line"><span>    inputs: Sequence[torch.Tensor],</span></span>
<span class="line"><span>    output: Optional[Union[torch.Tensor, Sequence[torch.Tensor]]] = None,</span></span>
<span class="line"><span>    root: int = 0,</span></span>
<span class="line"><span>    op: int = SUM,</span></span>
<span class="line"><span>    streams: Optional[Sequence[torch.cuda.Stream]] = None,</span></span>
<span class="line"><span>    comms=None,</span></span>
<span class="line"><span>    *,</span></span>
<span class="line"><span>    outputs: Optional[Sequence[torch.Tensor]] = None,</span></span>
<span class="line"><span>) -&gt; None:</span></span>
<span class="line"><span>    _check_sequence_type(inputs)</span></span>
<span class="line"><span>    _output: torch.Tensor</span></span>
<span class="line"><span>    if outputs is not None:</span></span>
<span class="line"><span>        if output is not None:</span></span>
<span class="line"><span>            raise ValueError(</span></span>
<span class="line"><span>                &quot;&#39;output&#39; and &#39;outputs&#39; can not be both specified. &#39;outputs&#39; is deprecated in &quot;</span></span>
<span class="line"><span>                &quot;favor of &#39;output&#39;, taking in a single output tensor. The signature of reduce is: &quot;</span></span>
<span class="line"><span>                &quot;reduce(inputs, output=None, root=0, op=SUM, streams=None, comms=None).&quot;</span></span>
<span class="line"><span>            )</span></span>
<span class="line"><span>        else:</span></span>
<span class="line"><span>            warnings.warn(</span></span>
<span class="line"><span>                &quot;`nccl.reduce` with an output tensor list is deprecated. &quot;</span></span>
<span class="line"><span>                &quot;Please specify a single output tensor with argument &#39;output&#39; instead instead.&quot;,</span></span>
<span class="line"><span>                FutureWarning,</span></span>
<span class="line"><span>                stacklevel=2,</span></span>
<span class="line"><span>            )</span></span>
<span class="line"><span>            _output = outputs[root]</span></span>
<span class="line"><span>    elif not isinstance(output, torch.Tensor) and isinstance(</span></span>
<span class="line"><span>        output, collections.abc.Sequence</span></span>
<span class="line"><span>    ):</span></span>
<span class="line"><span>        # User called old API with positional arguments of list of output tensors.</span></span>
<span class="line"><span>        warnings.warn(</span></span>
<span class="line"><span>            &quot;nccl.reduce with an output tensor list is deprecated. &quot;</span></span>
<span class="line"><span>            &quot;Please specify a single output tensor.&quot;,</span></span>
<span class="line"><span>            FutureWarning,</span></span>
<span class="line"><span>            stacklevel=2,</span></span>
<span class="line"><span>        )</span></span>
<span class="line"><span>        _output = output[root]</span></span>
<span class="line"><span>    else:</span></span>
<span class="line"><span>        _output = inputs[root] if output is None else output</span></span>
<span class="line"><span>    torch._C._nccl_reduce(inputs, _output, root, op, streams, comms)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>这段代码实现了 <code>reduce</code> 函数的分布式操作，用于将多个 GPU 的张量根据某种操作（如求和）合并到一个目标张量中，特别是在使用 PyTorch 的 NCCL 后端时。这是常见的分布式通信操作，例如在多卡训练中汇总各个设备上的张量。</p><h3 id="核心功能" tabindex="-1"><a class="header-anchor" href="#核心功能"><span>核心功能</span></a></h3><p>该函数通过调用 <code>torch._C._nccl_reduce</code> 来实现具体的 <code>reduce</code> 操作，该函数执行 GPU 间张量的归约（如求和、乘积等操作），并将结果存储在某个 root 节点的目标张量中。</p><h3 id="参数解析" tabindex="-1"><a class="header-anchor" href="#参数解析"><span>参数解析</span></a></h3><ol><li><p><strong>inputs</strong>:</p><ul><li><code>Sequence[torch.Tensor]</code>，表示输入的张量序列，来自不同的 GPU。每个张量包含设备上局部计算的结果。</li></ul></li><li><p><strong>output</strong>:</p><ul><li><code>Optional[Union[torch.Tensor, Sequence[torch.Tensor]]]</code>，可选参数，用于存放归约操作的结果。如果没有提供，将使用 root 节点上的输入张量。</li></ul></li><li><p><strong>root</strong>:</p><ul><li><code>int</code>，表示哪个 GPU 作为 root，将接收所有 GPU 的归约结果。默认是 <code>0</code>。</li></ul></li><li><p><strong>op</strong>:</p><ul><li><code>int</code>，指定归约操作，默认为 <code>SUM</code>（加法）。其它可能的操作有 <code>PROD</code>（乘法）、<code>MIN</code>（最小值）、<code>MAX</code>（最大值）等。</li></ul></li><li><p><strong>streams</strong>:</p><ul><li><code>Optional[Sequence[torch.cuda.Stream]]</code>，可以为每个 GPU 提供 CUDA 流，方便在不同 CUDA 流上进行归约操作。默认为空，即使用默认流。</li></ul></li><li><p><strong>comms</strong>:</p><ul><li>可选的通信器对象，负责管理 GPU 间的通信。</li></ul></li><li><p><strong>outputs</strong>:</p><ul><li><code>Optional[Sequence[torch.Tensor]]</code>，这是一个过时参数，用于指定多个输出张量的列表。新的 API 只需要传入一个单一的 <code>output</code>，如果同时传入 <code>outputs</code> 和 <code>output</code>，则会报错。</li></ul></li></ol><h3 id="核心逻辑" tabindex="-1"><a class="header-anchor" href="#核心逻辑"><span>核心逻辑</span></a></h3><ol><li><p><strong>处理参数的兼容性</strong>:</p><ul><li>首先检查 <code>inputs</code> 的类型是否正确。接着处理参数 <code>outputs</code> 和 <code>output</code> 的兼容性，确保两者不会同时传入。如果用户使用了旧版 API (<code>outputs</code>)，会抛出警告，提醒用户该功能将被弃用。</li></ul></li><li><p><strong>处理旧 API</strong>:</p><ul><li>如果 <code>output</code> 是一个张量序列而不是单个张量，函数会继续支持这种旧的用法，但是同样会抛出警告，提示用户迁移到新的 API。</li></ul></li><li><p><strong>调用底层 NCCL 函数</strong>:</p><ul><li>最后，函数调用 <code>torch._C._nccl_reduce</code> 执行真正的张量归约操作，使用给定的 <code>inputs</code>、<code>_output</code>、<code>root</code>、<code>op</code> 和其他可选参数。</li></ul></li></ol><h3 id="示例" tabindex="-1"><a class="header-anchor" href="#示例"><span>示例</span></a></h3><p>假设我们在分布式训练中使用 4 个 GPU，执行 <code>reduce</code> 操作：</p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">inputs </span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> [torch.</span><span style="--shiki-light:#24292E;--shiki-dark:#61AFEF;">tensor</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">([</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">1.0</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">]).</span><span style="--shiki-light:#24292E;--shiki-dark:#61AFEF;">cuda</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">(i) </span><span style="--shiki-light:#D73A49;--shiki-dark:#C678DD;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> i </span><span style="--shiki-light:#D73A49;--shiki-dark:#C678DD;">in</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> range</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">4</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">)]  </span><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># 各个 GPU 上的张量</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">output </span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> torch.</span><span style="--shiki-light:#24292E;--shiki-dark:#61AFEF;">tensor</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">([</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">0.0</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">]).</span><span style="--shiki-light:#24292E;--shiki-dark:#61AFEF;">cuda</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">)  </span><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># root GPU 上的输出张量</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#E06C75;">reduce</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">(inputs, </span><span style="--shiki-light:#E36209;--shiki-dark:#E06C75;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">output</span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">output, </span><span style="--shiki-light:#E36209;--shiki-dark:#E06C75;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">root</span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">(output)  </span><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># 输出归约后的结果</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>这段代码将各个 GPU 上的张量相加，并将结果存储在 root GPU（GPU 0）的 <code>output</code> 张量中。</p><h2 id="torch-csrc-cuda-python-nccl-cpp" tabindex="-1"><a class="header-anchor" href="#torch-csrc-cuda-python-nccl-cpp"><span>torch/csrc/cuda/python_nccl.cpp</span></a></h2><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span>PyObject* THCPModule_nccl_reduce(PyObject* self, PyObject* args) {</span></span>
<span class="line"><span>  HANDLE_TH_ERRORS</span></span>
<span class="line"><span>  PyObject *_inputs = nullptr, *_output = nullptr, *_streams = nullptr,</span></span>
<span class="line"><span>           *_comms = nullptr;</span></span>
<span class="line"><span>  int root = 0, op = 0;</span></span>
<span class="line"><span></span></span>
<span class="line"><span>  if (!PyArg_ParseTuple(</span></span>
<span class="line"><span>          args, &quot;OOiiOO&quot;, &amp;_inputs, &amp;_output, &amp;root, &amp;op, &amp;_streams, &amp;_comms)) {</span></span>
<span class="line"><span>    THPUtils_invalidArguments(</span></span>
<span class="line"><span>        args,</span></span>
<span class="line"><span>        nullptr,</span></span>
<span class="line"><span>        &quot;nccl_reduce&quot;,</span></span>
<span class="line"><span>        1,</span></span>
<span class="line"><span>        &quot;(sequence[Tensor] inputs, Tensor output, int root,&quot;</span></span>
<span class="line"><span>        &quot; int op, sequence[torch.cuda.Stream or None]&quot;);</span></span>
<span class="line"><span>    return nullptr;</span></span>
<span class="line"><span>  }</span></span>
<span class="line"><span></span></span>
<span class="line"><span>  std::vector&lt;at::Tensor&gt; inputs = extract_tensors(_inputs);</span></span>
<span class="line"><span>  auto output = extract_tensor(_output);</span></span>
<span class="line"><span>  std::vector&lt;std::optional&lt;at::cuda::CUDAStream&gt;&gt; streams =</span></span>
<span class="line"><span>      unpack_streams(_streams, inputs.size());</span></span>
<span class="line"><span>  auto user_comms = unpack_comms(_comms, inputs.size());</span></span>
<span class="line"><span></span></span>
<span class="line"><span>  {</span></span>
<span class="line"><span>    pybind11::gil_scoped_release no_gil;</span></span>
<span class="line"><span>    torch::cuda::nccl::reduce(inputs, output, root, op, streams, user_comms);</span></span>
<span class="line"><span>  }</span></span>
<span class="line"><span></span></span>
<span class="line"><span>  Py_RETURN_NONE;</span></span>
<span class="line"><span>  END_HANDLE_TH_ERRORS</span></span>
<span class="line"><span>}</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>上述代码是 PyTorch 中一个 C++ 函数，它通过 Python 的 C API 实现了 NCCL <code>reduce</code> 操作的接口。这个函数可以在 Python 中调用，从而完成 NCCL 的 <code>reduce</code> 操作。NCCL（NVIDIA Collective Communications Library）是一种用于多 GPU 间高效通信的库，特别适用于深度学习框架中的集体通信操作，如 <code>reduce</code>、<code>allreduce</code> 等。</p><h3 id="代码解析" tabindex="-1"><a class="header-anchor" href="#代码解析"><span>代码解析</span></a></h3><ol><li><p><strong>函数定义</strong>:</p><div class="language-cpp line-numbers-mode" data-highlighter="shiki" data-ext="cpp" data-title="cpp" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#E5C07B;">PyObject</span><span style="--shiki-light:#D73A49;--shiki-dark:#C678DD;">*</span><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;"> THCPModule_nccl_reduce</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#6F42C1;--shiki-dark:#E5C07B;">PyObject</span><span style="--shiki-light:#D73A49;--shiki-dark:#C678DD;">*</span><span style="--shiki-light:#E36209;--shiki-dark:#E06C75;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#6F42C1;--shiki-dark:#E5C07B;">PyObject</span><span style="--shiki-light:#D73A49;--shiki-dark:#C678DD;">*</span><span style="--shiki-light:#E36209;--shiki-dark:#E06C75;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"> args</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>这是一个 Python C API 的函数，<code>PyObject*</code> 是 Python 对象的通用类型，<code>self</code> 通常指模块对象，而 <code>args</code> 是从 Python 传递给这个函数的参数。</p></li><li><p><strong>参数解析</strong>:</p><div class="language-cpp line-numbers-mode" data-highlighter="shiki" data-ext="cpp" data-title="cpp" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#C678DD;">if</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> (</span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">!</span><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">PyArg_ParseTuple</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">(</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">        args, </span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">&quot;OOiiOO&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">&amp;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">_inputs, </span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">&amp;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">_output, </span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">&amp;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">root, </span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">&amp;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">op, </span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">&amp;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">_streams, </span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">&amp;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">_comms))</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><p><code>PyArg_ParseTuple</code> 用于从 Python 参数 <code>args</code> 中解析出输入的值。格式化字符串 <code>&quot;OOiiOO&quot;</code> 表示该函数期望接收的参数类型依次是：</p><ul><li><code>O</code>: Python 对象（<code>_inputs</code>）</li><li><code>O</code>: Python 对象（<code>_output</code>）</li><li><code>i</code>: 整数（<code>root</code>，指定哪个 GPU 是 root 节点）</li><li><code>i</code>: 整数（<code>op</code>，指定 NCCL 操作类型，如 <code>SUM</code> 或 <code>MAX</code> 等）</li><li><code>O</code>: Python 对象（<code>_streams</code>）</li><li><code>O</code>: Python 对象（<code>_comms</code>，通信对象）</li></ul><p>如果参数无法解析，将返回 <code>nullptr</code>，并抛出错误。</p></li><li><p><strong>参数转换</strong>:</p><ul><li><code>extract_tensors(_inputs)</code> 和 <code>extract_tensor(_output)</code> 是从 Python 对象中提取张量的自定义函数。</li><li><code>unpack_streams(_streams, inputs.size())</code> 是将 <code>streams</code> 从 Python 对象中解包成 <code>CUDAStream</code> 对象。</li><li><code>unpack_comms(_comms, inputs.size())</code> 同样用于将通信器对象解包。</li></ul></li><li><p><strong>释放 GIL 锁</strong>:</p><div class="language-cpp line-numbers-mode" data-highlighter="shiki" data-ext="cpp" data-title="cpp" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#ABB2BF;">pybind11</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">::gil_scoped_release no_gil;</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p><code>pybind11::gil_scoped_release</code> 用于释放 Python 的全局解释器锁（GIL），允许并行执行。因为 NCCL 操作是 GPU 通信操作，可能耗时较长，所以在执行这些操作前释放 GIL 是必要的。</p></li><li><p><strong>调用 NCCL <code>reduce</code></strong>:</p><div class="language-cpp line-numbers-mode" data-highlighter="shiki" data-ext="cpp" data-title="cpp" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#E5C07B;">torch</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">::</span><span style="--shiki-light:#6F42C1;--shiki-dark:#E5C07B;">cuda</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">::</span><span style="--shiki-light:#6F42C1;--shiki-dark:#E5C07B;">nccl</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">::</span><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">reduce</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">(inputs, output, root, op, streams, user_comms);</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>调用了 PyTorch CUDA 模块中的 NCCL <code>reduce</code> 函数，将输入张量 <code>inputs</code> 通过 NCCL 通信操作聚合成 <code>output</code> 张量，<code>root</code> 指定了哪块 GPU 是主节点（负责聚合结果），<code>op</code> 指定了操作类型，如 <code>SUM</code>。</p></li><li><p><strong>返回 <code>None</code></strong>:</p><div class="language-cpp line-numbers-mode" data-highlighter="shiki" data-ext="cpp" data-title="cpp" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">Py_RETURN_NONE;</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>函数完成后，返回 <code>None</code>，表示没有返回值。</p></li><li><p><strong>错误处理</strong>:</p><ul><li><code>HANDLE_TH_ERRORS</code> 和 <code>END_HANDLE_TH_ERRORS</code> 是用于捕获和处理 C++ 异常的宏。如果在函数执行过程中发生异常，它们将自动捕捉并将错误报告给 Python 层。</li></ul></li></ol><h3 id="总结" tabindex="-1"><a class="header-anchor" href="#总结"><span>总结</span></a></h3><p>此函数的作用是在 Python 层提供了 NCCL <code>reduce</code> 操作的接口，允许用户在 Python 中调用 NCCL 底层的 C++ 实现，以高效地在多 GPU 间进行通信和数据聚合。整个过程中，C++ 代码负责参数解析、执行 NCCL 操作并返回结果，而 Python 代码则以封装的方式调用这些底层实现。这种模式在深度学习框架中非常常见，尤其是在需要加速的分布式训练场景下。</p><h2 id="torch-csrc-cuda-module-cpp" tabindex="-1"><a class="header-anchor" href="#torch-csrc-cuda-module-cpp"><span>torch/csrc/cuda/Module.cpp</span></a></h2><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span>#ifdef USE_NCCL</span></span>
<span class="line"><span>    {&quot;_nccl_version&quot;, THCPModule_nccl_version, METH_NOARGS, nullptr},</span></span>
<span class="line"><span>    {&quot;_nccl_version_suffix&quot;,</span></span>
<span class="line"><span>     THCPModule_nccl_version_suffix,</span></span>
<span class="line"><span>     METH_NOARGS,</span></span>
<span class="line"><span>     nullptr},</span></span>
<span class="line"><span>    {&quot;_nccl_unique_id&quot;, THCPModule_nccl_unique_id, METH_NOARGS, nullptr},</span></span>
<span class="line"><span>    {&quot;_nccl_init_rank&quot;, THCPModule_nccl_init_rank, METH_VARARGS, nullptr},</span></span>
<span class="line"><span>    {&quot;_nccl_reduce&quot;, THCPModule_nccl_reduce, METH_VARARGS, nullptr},</span></span>
<span class="line"><span>    {&quot;_nccl_all_reduce&quot;, THCPModule_nccl_all_reduce, METH_VARARGS, nullptr},</span></span>
<span class="line"><span>    {&quot;_nccl_broadcast&quot;, THCPModule_nccl_broadcast, METH_VARARGS, nullptr},</span></span>
<span class="line"><span>    {&quot;_nccl_all_gather&quot;, THCPModule_nccl_all_gather, METH_VARARGS, nullptr},</span></span>
<span class="line"><span>    {&quot;_nccl_reduce_scatter&quot;,</span></span>
<span class="line"><span>     THCPModule_nccl_reduce_scatter,</span></span>
<span class="line"><span>     METH_VARARGS,</span></span>
<span class="line"><span>     nullptr},</span></span>
<span class="line"><span>#endif</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>这段代码是 PyTorch 的 C++ 代码片段，主要用于注册与 NCCL（NVIDIA Collective Communications Library）相关的 Python API 函数。通过这些函数，用户可以在 Python 中调用 NCCL 的功能，如初始化 NCCL、执行集合操作等。下面是对代码的逐行分析：</p><h3 id="代码结构和功能" tabindex="-1"><a class="header-anchor" href="#代码结构和功能"><span>代码结构和功能</span></a></h3><div class="language-cpp line-numbers-mode" data-highlighter="shiki" data-ext="cpp" data-title="cpp" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#C678DD;">#ifdef</span><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;"> USE_NCCL</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><ul><li>这一行使用条件编译指令来检查是否启用了 NCCL 支持。如果编译时定义了 <code>USE_NCCL</code>，则编译器会包含以下代码块。</li></ul><div class="language-cpp line-numbers-mode" data-highlighter="shiki" data-ext="cpp" data-title="cpp" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">    {</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">&quot;_nccl_version&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">, THCPModule_nccl_version, METH_NOARGS, </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">nullptr</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">},</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><ul><li>这一行注册了 <code>_nccl_version</code> 函数，该函数将返回 NCCL 的版本信息。<code>METH_NOARGS</code> 表示该函数不接受任何参数。</li></ul><div class="language-cpp line-numbers-mode" data-highlighter="shiki" data-ext="cpp" data-title="cpp" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">    {</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">&quot;_nccl_version_suffix&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">, THCPModule_nccl_version_suffix, METH_NOARGS, </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">nullptr</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">},</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><ul><li>注册了 <code>_nccl_version_suffix</code> 函数，返回 NCCL 版本的后缀。</li></ul><div class="language-cpp line-numbers-mode" data-highlighter="shiki" data-ext="cpp" data-title="cpp" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">    {</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">&quot;_nccl_unique_id&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">, THCPModule_nccl_unique_id, METH_NOARGS, </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">nullptr</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">},</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><ul><li>注册了 <code>_nccl_unique_id</code> 函数，用于生成 NCCL 的唯一标识符（Unique ID）。</li></ul><div class="language-cpp line-numbers-mode" data-highlighter="shiki" data-ext="cpp" data-title="cpp" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">    {</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">&quot;_nccl_init_rank&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">, THCPModule_nccl_init_rank, METH_VARARGS, </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">nullptr</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">},</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><ul><li>注册了 <code>_nccl_init_rank</code> 函数，接受参数并用于初始化 NCCL 通信。</li></ul><div class="language-cpp line-numbers-mode" data-highlighter="shiki" data-ext="cpp" data-title="cpp" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">    {</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">&quot;_nccl_reduce&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">, THCPModule_nccl_reduce, METH_VARARGS, </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">nullptr</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">},</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><ul><li>注册了 <code>_nccl_reduce</code> 函数，用于执行 NCCL 的 reduce 操作，接受一组输入张量和输出张量。</li></ul><div class="language-cpp line-numbers-mode" data-highlighter="shiki" data-ext="cpp" data-title="cpp" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">    {</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">&quot;_nccl_all_reduce&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">, THCPModule_nccl_all_reduce, METH_VARARGS, </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">nullptr</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">},</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><ul><li>注册了 <code>_nccl_all_reduce</code> 函数，用于执行所有进程的 reduce 操作。</li></ul><div class="language-cpp line-numbers-mode" data-highlighter="shiki" data-ext="cpp" data-title="cpp" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">    {</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">&quot;_nccl_broadcast&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">, THCPModule_nccl_broadcast, METH_VARARGS, </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">nullptr</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">},</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><ul><li>注册了 <code>_nccl_broadcast</code> 函数，用于执行广播操作，将数据从一个进程传递到所有其他进程。</li></ul><div class="language-cpp line-numbers-mode" data-highlighter="shiki" data-ext="cpp" data-title="cpp" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">    {</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">&quot;_nccl_all_gather&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">, THCPModule_nccl_all_gather, METH_VARARGS, </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">nullptr</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">},</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><ul><li>注册了 <code>_nccl_all_gather</code> 函数，用于收集所有进程的数据到每个进程中。</li></ul><div class="language-cpp line-numbers-mode" data-highlighter="shiki" data-ext="cpp" data-title="cpp" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">    {</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">&quot;_nccl_reduce_scatter&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">, THCPModule_nccl_reduce_scatter, METH_VARARGS, </span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">nullptr</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">},</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><ul><li>注册了 <code>_nccl_reduce_scatter</code> 函数，用于执行 reduce scatter 操作，将数据先进行 reduce，然后再分散到所有进程。</li></ul><h3 id="总结-1" tabindex="-1"><a class="header-anchor" href="#总结-1"><span>总结</span></a></h3><p>这段代码负责将 NCCL 的相关操作函数注册到 PyTorch 的 Python 接口中。这样用户在使用 PyTorch 时，可以方便地调用这些 NCCL 的操作来进行高效的多GPU并行计算。这种设计使得 PyTorch 的 CUDA 加速功能与 NCCL 库的集体通信能力紧密集成。</p><h2 id="torch-dynamo-trace-rules-py" tabindex="-1"><a class="header-anchor" href="#torch-dynamo-trace-rules-py"><span>torch_dynamo\trace_rules.py</span></a></h2><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span>def _load_obj_from_str(fully_qualified_name):</span></span>
<span class="line"><span>    module, obj_name = fully_qualified_name.rsplit(&quot;.&quot;, maxsplit=1)</span></span>
<span class="line"><span>    return getattr(importlib.import_module(module), obj_name)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>这个 Python 函数 <code>_load_obj_from_str</code> 用于根据一个完全限定的对象名称（通常是模块路径和对象名称的组合）动态地加载模块中的对象。下面是对该函数的逐行分析：</p><h3 id="代码解析-1" tabindex="-1"><a class="header-anchor" href="#代码解析-1"><span>代码解析</span></a></h3><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#C678DD;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;"> _load_obj_from_str</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#24292E;--shiki-dark:#D19A66;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">fully_qualified_name</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">):</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><ul><li>定义了一个名为 <code>_load_obj_from_str</code> 的函数，接受一个参数 <code>fully_qualified_name</code>，这是一个字符串，包含模块路径和对象名称，例如 <code>module.submodule.ClassName</code>。</li></ul><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">    module, obj_name </span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> fully_qualified_name.</span><span style="--shiki-light:#24292E;--shiki-dark:#61AFEF;">rsplit</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;">&quot;.&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#E06C75;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">maxsplit</span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><ul><li>使用 <code>rsplit</code> 方法将 <code>fully_qualified_name</code> 从右侧分割成模块名和对象名。<code>maxsplit=1</code> 参数确保只分割一次，这样得到的 <code>module</code> 是模块路径，而 <code>obj_name</code> 是模块中的对象名称。</li></ul><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#C678DD;">    return</span><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;"> getattr</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">(importlib.</span><span style="--shiki-light:#24292E;--shiki-dark:#61AFEF;">import_module</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">(module), obj_name)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><ul><li>使用 <code>importlib.import_module</code> 动态导入指定的模块。</li><li>使用 <code>getattr</code> 从导入的模块中获取指定的对象，返回这个对象。</li></ul><h3 id="示例用法" tabindex="-1"><a class="header-anchor" href="#示例用法"><span>示例用法</span></a></h3><p>假设你有一个模块结构如下：</p><div class="language-plaintext line-numbers-mode" data-highlighter="shiki" data-ext="plaintext" data-title="plaintext" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span>my_package/</span></span>
<span class="line"><span>    __init__.py</span></span>
<span class="line"><span>    my_module.py</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><code>my_module.py</code> 内容如下：</p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#C678DD;">class</span><span style="--shiki-light:#6F42C1;--shiki-dark:#E5C07B;"> MyClass</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">:</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#C678DD;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;"> greet</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#24292E;--shiki-dark:#E5C07B;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">self</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#C678DD;">        return</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> &quot;Hello, world!&quot;</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>你可以通过以下方式加载 <code>MyClass</code>：</p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">fully_qualified_name </span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#98C379;"> &quot;my_package.my_module.MyClass&quot;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">MyClass </span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#61AFEF;"> _load_obj_from_str</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">(fully_qualified_name)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">instance </span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#61AFEF;"> MyClass</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#56B6C2;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">(instance.</span><span style="--shiki-light:#24292E;--shiki-dark:#61AFEF;">greet</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">())  </span><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># 输出: Hello, world!</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="总结-2" tabindex="-1"><a class="header-anchor" href="#总结-2"><span>总结</span></a></h3><p>这个函数的主要作用是实现动态加载模块中的对象，允许你在运行时根据字符串路径获取对象。这种方法在需要根据配置文件或用户输入来加载类或函数时非常有用。</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span>#include &lt;Python.h&gt;</span></span>
<span class="line"><span></span></span>
<span class="line"><span>extern PyObject* initModule(void);</span></span>
<span class="line"><span></span></span>
<span class="line"><span>#ifndef _WIN32</span></span>
<span class="line"><span>#ifdef __cplusplus</span></span>
<span class="line"><span>extern &quot;C&quot;</span></span>
<span class="line"><span>#endif</span></span>
<span class="line"><span>__attribute__((visibility(&quot;default&quot;))) PyObject* PyInit__C(void);</span></span>
<span class="line"><span>#endif</span></span>
<span class="line"><span></span></span>
<span class="line"><span>PyMODINIT_FUNC PyInit__C(void)</span></span>
<span class="line"><span>{</span></span>
<span class="line"><span>  return initModule();</span></span>
<span class="line"><span>}</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><a href="https://zhuanlan.zhihu.com/p/647999983" target="_blank" rel="noopener noreferrer">python调用C/C++参考示例</a></p><p>这段 C/C++ 代码片段展示了一个用于初始化 Python 扩展模块的函数实现。在 Python 中，C 扩展模块需要实现一个模块初始化函数，它会在 Python 加载模块时被调用。这段代码的主要目的是将 <code>initModule</code> 函数作为 Python 模块的初始化函数，并通过兼容不同平台的方式导出。</p><h3 id="代码解析-2" tabindex="-1"><a class="header-anchor" href="#代码解析-2"><span>代码解析</span></a></h3><ol><li><p><strong><code>extern PyObject* initModule(void);</code></strong>:</p><ul><li>声明了一个外部的 C 函数 <code>initModule</code>，它返回一个 <code>PyObject*</code>，用于初始化模块。这个函数可能在别的地方定义，并负责创建和初始化模块对象。</li></ul></li><li><p><strong>平台相关宏控制</strong>:</p><ul><li><code>#ifndef _WIN32</code>：如果不是 Windows 平台，则会编译接下来的代码，这表明这个部分主要是为非 Windows 平台准备的。</li><li><code>#ifdef __cplusplus</code> 和 <code>extern &quot;C&quot;</code>：如果是在 C++ 中编译，这一部分会通过 <code>extern &quot;C&quot;</code> 指定 C 语言链接方式，确保 Python 模块能够以 C 语言的符号表被正确识别。</li><li><code>__attribute__((visibility(&quot;default&quot;)))</code>：用于控制符号的可见性。它保证了 <code>PyInit__C</code> 函数在共享库中对外可见（动态链接时需要）。</li></ul></li><li><p><strong><code>PyMODINIT_FUNC PyInit__C(void)</code></strong>:</p><ul><li><code>PyMODINIT_FUNC</code> 是一个宏，通常定义为 <code>extern &quot;C&quot;</code>，它用于标识 Python 扩展模块的初始化函数。</li><li>Python 期望扩展模块的初始化函数遵循特定的命名规范。在 Python 3 中，初始化函数的名称应为 <code>PyInit_&lt;module_name&gt;</code>，这里是 <code>PyInit__C</code>，意味着 Python 加载的模块名称为 <code>_C</code>。</li><li>这个函数返回一个 <code>PyObject*</code>，即模块对象，这个对象是通过调用 <code>initModule()</code> 获得的。</li></ul></li></ol><h3 id="典型应用" tabindex="-1"><a class="header-anchor" href="#典型应用"><span>典型应用</span></a></h3><p>这种模块初始化机制在 C 扩展模块中很常见，特别是在涉及到 Python 与 C/C++ 互操作时。<code>initModule()</code> 通常会调用一系列的 C API 函数来创建 Python 对象，并将它们绑定到模块的命名空间中。</p><h4 id="示例解释" tabindex="-1"><a class="header-anchor" href="#示例解释"><span>示例解释</span></a></h4><div class="language-c line-numbers-mode" data-highlighter="shiki" data-ext="c" data-title="c" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">PyMODINIT_FUNC </span><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;">PyInit__C</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#D73A49;--shiki-dark:#C678DD;">void</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">{</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#C678DD;">  return</span><span style="--shiki-light:#6F42C1;--shiki-dark:#61AFEF;"> initModule</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">();</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">}</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>当 Python 导入 <code>_C</code> 模块时，Python 解释器会调用 <code>PyInit__C()</code> 函数。这个函数又调用了 <code>initModule()</code>，返回初始化后的模块对象。</li><li>这个模块对象包含了所有需要导出的 C 函数和对象，使得这些函数能够被 Python 调用。</li></ul><h3 id="总结-3" tabindex="-1"><a class="header-anchor" href="#总结-3"><span>总结</span></a></h3><p>这段代码展示了如何在非 Windows 环境下创建一个 C 扩展模块的初始化函数。它将 <code>initModule</code> 作为模块的实际初始化逻辑，用于设置模块的内容，并通过 <code>PyInit__C</code> 函数将其导出给 Python 使用。</p><h2 id="nccl-topo" tabindex="-1"><a class="header-anchor" href="#nccl-topo"><span>nccl topo</span></a></h2><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span>#define NCCL_TOPO_MAX_NODES 256</span></span>
<span class="line"><span></span></span>
<span class="line"><span>// Init search. Needs to be done before calling ncclTopoCompute</span></span>
<span class="line"><span>ncclResult_t ncclTopoSearchInit(struct ncclTopoSystem* system);</span></span>
<span class="line"><span></span></span>
<span class="line"><span>#define NCCL_TOPO_PATTERN_BALANCED_TREE 1   // Spread NIC traffic between two GPUs (Tree parent + one child on first GPU, second child on second GPU)</span></span>
<span class="line"><span>#define NCCL_TOPO_PATTERN_SPLIT_TREE 2      // Spread NIC traffic between two GPUs (Tree parent on first GPU, tree children on the second GPU)</span></span>
<span class="line"><span>#define NCCL_TOPO_PATTERN_TREE 3            // All NIC traffic going to/from the same GPU</span></span>
<span class="line"><span>#define NCCL_TOPO_PATTERN_RING 4            // Ring</span></span>
<span class="line"><span>#define NCCL_TOPO_PATTERN_NVLS 5            // NVLS+SHARP and NVLS+Tree</span></span>
<span class="line"><span>#define NCCL_TOPO_PATTERN_COLLNET_DIRECT 6  // Collnet Direct</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>NCCL（NVIDIA Collective Communications Library）拓扑结构的定义和初始化。这些定义用于描述不同的通信模式以及节点间的互联方式，尤其是如何在GPU之间分配网络接口卡（NIC）流量的策略。</p><h3 id="代码解析-3" tabindex="-1"><a class="header-anchor" href="#代码解析-3"><span>代码解析：</span></a></h3><ol><li><p><strong><code>NCCL_TOPO_MAX_NODES 256</code></strong>： 这个宏定义了NCCL拓扑结构支持的<strong>最大节点数为256</strong>。这里的节点可以是GPU或网络设备（如NIC），意味着NCCL拓扑在设计上最多支持256个节点的互联。这与前面提到的NCCL理论上支持256卡互联是一致的。</p></li><li><p><strong><code>ncclTopoSearchInit(struct ncclTopoSystem* system)</code></strong>： 这个函数用于初始化NCCL拓扑搜索过程，准备计算通信拓扑。在调用 <code>ncclTopoCompute</code> 之前，必须先调用这个函数以初始化系统结构。</p></li><li><p><strong>拓扑通信模式定义</strong>： NCCL提供了多种通信模式（<code>TOPO_PATTERN</code>），这些模式定义了不同情况下网络流量如何在GPU之间分布：</p><ul><li><strong><code>NCCL_TOPO_PATTERN_BALANCED_TREE</code></strong> (1): 平衡树形结构，NIC流量分布在两个GPU之间。树的父节点和一个子节点在第一个GPU上，第二个子节点在第二个GPU上。</li><li><strong><code>NCCL_TOPO_PATTERN_SPLIT_TREE</code></strong> (2): 拆分树形结构，NIC流量分布在两个GPU之间。树的父节点在第一个GPU上，子节点都在第二个GPU上。</li><li><strong><code>NCCL_TOPO_PATTERN_TREE</code></strong> (3): 所有的NIC流量都集中在同一个GPU上。</li><li><strong><code>NCCL_TOPO_PATTERN_RING</code></strong> (4): 环形结构，流量在GPU之间按顺序传递。</li><li><strong><code>NCCL_TOPO_PATTERN_NVLS</code></strong> (5): 结合NVLS（NVIDIA Virtual Link Switch）和SHARP（Scalable Hierarchical Aggregation and Reduction Protocol）技术，进行通信优化。</li><li><strong><code>NCCL_TOPO_PATTERN_COLLNET_DIRECT</code></strong> (6): CollNet直接通信模式，通常用于优化大规模集群中的点对点通信。</li></ul></li></ol><h3 id="拓扑结构的意义" tabindex="-1"><a class="header-anchor" href="#拓扑结构的意义"><span>拓扑结构的意义：</span></a></h3><p>这些不同的拓扑模式允许NCCL根据具体的硬件拓扑和通信需求，选择最优的通信模式，以最大化带宽利用率、减少延迟，并优化多GPU、多节点的分布式训练任务。尤其在超大规模GPU集群中（例如256个GPU互联的场景），选择合适的拓扑模式对性能有显著影响。</p><p>因此，在实际使用中，理解这些拓扑模式的定义，并结合硬件架构和通信需求，能够有效提升NCCL的通信性能。</p></div><!----><footer class="vp-page-meta"><!----><div class="vp-meta-item git-info"><div class="update-time"><span class="vp-meta-label">上次编辑于: </span><!----></div><!----></div></footer><nav class="vp-page-nav"><a class="route-link auto-link prev" href="/KnowledgeBlog/%E6%8A%80%E6%9C%AF%E7%A7%91%E6%99%AE/AI%E5%A4%A7%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/" aria-label="AI大模型部署"><div class="hint"><span class="arrow start"></span>上一页</div><div class="link"><!---->AI大模型部署</div></a><a class="route-link auto-link next" href="/KnowledgeBlog/%E6%8A%80%E6%9C%AF%E7%A7%91%E6%99%AE/pytorch.html" aria-label="PyTorch"><div class="hint">下一页<span class="arrow end"></span></div><div class="link">PyTorch<!----></div></a></nav><!----><!----><!--]--></main><!--]--><footer class="vp-footer-wrapper"><!----><div class="vp-copyright">Copyright © 2024 MouseSun </div></footer></div><!--]--><!--]--><!--[--><!----><!----><!--]--><!--]--></div>
    <script type="module" src="/KnowledgeBlog/assets/app-CqFSg5zC.js" defer></script>
  </body>
</html>
